#!/usr/bin/env python3
# -*- coding: utf-8 -*-
r"""
æ™ºèƒ½é—¨åº—ç»è¥çœ‹æ¿ - å¯è§†åŒ–ç•Œé¢
é›†æˆStreamlitæ„å»ºäº¤äº’å¼çœ‹æ¿ï¼Œå±•ç¤ºäº”å¤§AIæ¨¡å‹çš„åˆ†æç»“æœ

ğŸš€ å¿«é€Ÿå¯åŠ¨ï¼š
=============
å¯åŠ¨å‘½ä»¤ï¼š
  cd "d:\Python1\O2O_Analysis\O2Oæ•°æ®åˆ†æ\æµ‹ç®—æ¨¡å‹"
  & "d:\Python1\O2O_Analysis\O2Oæ•°æ®åˆ†æ\.venv\Scripts\streamlit.exe" run æ™ºèƒ½é—¨åº—ç»è¥çœ‹æ¿_å¯è§†åŒ–.py --server.port 8502

ç®€åŒ–å‘½ä»¤ï¼š
  cd "d:\Python1\O2O_Analysis\O2Oæ•°æ®åˆ†æ\æµ‹ç®—æ¨¡å‹"
  ..\\.venv\\Scripts\\streamlit run æ™ºèƒ½é—¨åº—ç»è¥çœ‹æ¿_å¯è§†åŒ–.py --server.port 8502

è®¿é—®åœ°å€ï¼š
  æœ¬åœ°åœ°å€: http://localhost:8502
  ç½‘ç»œåœ°å€: http://26.26.26.1:8502

ğŸ“‹ åŠŸèƒ½æ¨¡å—ï¼š
=============
- ğŸ’¹ æ¯”ä»·åˆ†æï¼šæ”¯æŒä¸Šä¼ æ¯”ä»·ç»“æœExcelæ–‡ä»¶è¿›è¡Œå¯è§†åŒ–åˆ†æ
- ğŸ“Š è®¢å•åˆ†æï¼šé—¨åº—è®¢å•æ•°æ®çš„æ·±åº¦åˆ†æå’Œè¶‹åŠ¿é¢„æµ‹
- ğŸ¯ æ™ºèƒ½å†³ç­–ï¼šåŸºäºAIæ¨¡å‹çš„ç»è¥å»ºè®®å’Œä¼˜åŒ–æ–¹æ¡ˆ
- ğŸ“ˆ å®æ—¶ç›‘æ§ï¼šå…³é”®ç»è¥æŒ‡æ ‡çš„å®æ—¶ç›‘æ§å’Œé¢„è­¦
- ğŸ” ç«å¯¹åˆ†æï¼šç«äº‰å¯¹æ‰‹åˆ†æå’Œå¸‚åœºå®šä½å»ºè®®

ğŸ’¡ ä½¿ç”¨æç¤ºï¼š
=============
- ç¡®ä¿è™šæ‹Ÿç¯å¢ƒå·²æ¿€æ´»
- é¦–æ¬¡è¿è¡Œå¯èƒ½éœ€è¦ä¸‹è½½AIæ¨¡å‹ï¼Œè¯·è€å¿ƒç­‰å¾…
- æ”¯æŒçš„æ–‡ä»¶æ ¼å¼ï¼šExcel (.xlsx, .xls), JSON
- å»ºè®®ä½¿ç”¨Chromeæˆ–Edgeæµè§ˆå™¨ä»¥è·å¾—æœ€ä½³ä½“éªŒ
"""

import sys
import os
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple

# ğŸ”§ Windows ç¯å¢ƒå˜é‡è®¾ç½®ï¼šç¡®ä¿ UTF-8 è¾“å‡º
if sys.platform == 'win32':
    # è®¾ç½®ç¯å¢ƒå˜é‡ï¼Œè®© Python ä½¿ç”¨ UTF-8 ç¼–ç 
    os.environ['PYTHONIOENCODING'] = 'utf-8'

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from datetime import datetime
import json

APP_DIR = Path(__file__).resolve().parent
if str(APP_DIR) not in sys.path:
    sys.path.insert(0, str(APP_DIR))

# å¯¼å…¥å•†å“åˆ†ç±»ç»“æ„åˆ†ææ¨¡å—
try:
    from å•†å“åˆ†ç±»ç»“æ„åˆ†æ import render_category_analysis
    CATEGORY_ANALYSIS_AVAILABLE = True
    print("[OK] å•†å“åˆ†ç±»ç»“æ„åˆ†ææ¨¡å—å·²åŠ è½½")
except ImportError as e:
    CATEGORY_ANALYSIS_AVAILABLE = False
    print(f"[WARN] å•†å“åˆ†ç±»ç»“æ„åˆ†ææ¨¡å—åŠ è½½å¤±è´¥: {e}")

# å¯¼å…¥ç»Ÿä¸€ä¸šåŠ¡é€»è¾‘é…ç½®
try:
    sys.path.append(str(APP_DIR.parent))
    from standard_business_config import StandardBusinessConfig, StandardBusinessLogic, create_order_level_summary, apply_standard_business_logic
    STANDARD_CONFIG_AVAILABLE = True
    print("[OK] å·²åŠ è½½ç»Ÿä¸€ä¸šåŠ¡é€»è¾‘é…ç½®")
except ImportError as e:
    print(f"[WARN] æœªæ‰¾åˆ°standard_business_configæ¨¡å—: {e}")
    print("å°†ä½¿ç”¨é»˜è®¤é…ç½®")
    STANDARD_CONFIG_AVAILABLE = False

# å¯¼å…¥çœ‹æ¿ç³»ç»Ÿæ¨¡å—ï¼ˆæœ¬åœ°æ¨¡å—ï¼‰
try:
    from æ™ºèƒ½é—¨åº—ç»è¥çœ‹æ¿ç³»ç»Ÿ import SmartStoreDashboard
    from çœŸå®æ•°æ®å¤„ç†å™¨ import RealDataProcessor
    from price_comparison_dashboard import create_price_comparison_dashboard
    DASHBOARD_MODULES_AVAILABLE = True
    print("[OK] æ ¸å¿ƒä¸šåŠ¡é€»è¾‘æ¨¡å—å·²åŠ è½½")
except ImportError as e:
    print(f"[WARN] çœ‹æ¿ç³»ç»Ÿæ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
    print("éƒ¨åˆ†åŠŸèƒ½å¯èƒ½ä¸å¯ç”¨")
    DASHBOARD_MODULES_AVAILABLE = False
    # åˆ›å»ºå ä½ç±»é¿å…é”™è¯¯
    class SmartStoreDashboard:
        def __init__(self, *args, **kwargs):
            pass
        def get_learning_status(self):
            return {"status": "unavailable", "message": "çœ‹æ¿ç³»ç»Ÿæ¨¡å—æœªåŠ è½½"}
    class RealDataProcessor:
        def __init__(self, *args, **kwargs):
            self.data_dir = args[0] if args else "å®é™…æ•°æ®"
    def create_price_comparison_dashboard():
        st.warning("æ¯”ä»·åˆ†ææ¨¡å—æš‚ä¸å¯ç”¨")

# å¯¼å…¥æ ¸å¿ƒä¸šåŠ¡é€»è¾‘ï¼ˆä¸Šçº§ç›®å½•ï¼‰
try:
    sys.path.append(str(APP_DIR.parent))
    from æ ¸å¿ƒä¸šåŠ¡é€»è¾‘ import CoreBusinessLogic
    print("[OK] æ ¸å¿ƒä¸šåŠ¡é€»è¾‘æ¨¡å—å·²åŠ è½½")
except ImportError as e:
    print(f"[WARN] æ ¸å¿ƒä¸šåŠ¡é€»è¾‘æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
    class CoreBusinessLogic:
        pass

# å¯¼å…¥è®¢å•åˆ†æå¢å¼ºæ¨¡å—
try:
    from è®¢å•åˆ†æå¢å¼ºæ¨¡å— import (
        render_enhanced_order_overview,
        render_enhanced_profit_analysis
    )
    ORDER_ENHANCEMENT_AVAILABLE = True
    print("[OK] è®¢å•åˆ†æå¢å¼ºæ¨¡å—å·²åŠ è½½")
except ImportError as e:
    print(f"[WARN] è®¢å•åˆ†æå¢å¼ºæ¨¡å—æœªåŠ è½½: {e}")
    ORDER_ENHANCEMENT_AVAILABLE = False

# å¯¼å…¥åœºæ™¯è¥é”€æ™ºèƒ½å†³ç­–å¼•æ“
try:
    from åœºæ™¯è¥é”€æ™ºèƒ½å†³ç­–å¼•æ“ import (
        SceneMarketingIntelligence,
        ProductCombinationMiner,
        SceneRecognitionModel,
        RFMCustomerSegmentation,
        SceneDecisionTreeRules
    )
    SCENE_INTELLIGENCE_AVAILABLE = True
    print("[OK] åœºæ™¯è¥é”€æ™ºèƒ½å†³ç­–å¼•æ“å·²åŠ è½½")
except ImportError as e:
    print(f"[WARN] åœºæ™¯è¥é”€æ™ºèƒ½å†³ç­–å¼•æ“æœªåŠ è½½: {e}")
    SCENE_INTELLIGENCE_AVAILABLE = False

# å¯¼å…¥é—®é¢˜è¯Šæ–­å¼•æ“
try:
    from é—®é¢˜è¯Šæ–­å¼•æ“ import ProblemDiagnosticEngine
    PROBLEM_DIAGNOSTIC_AVAILABLE = True
    print("[OK] é—®é¢˜è¯Šæ–­å¼•æ“å·²åŠ è½½")
except ImportError as e:
    print(f"[WARN] é—®é¢˜è¯Šæ–­å¼•æ“æœªåŠ è½½: {e}")
    PROBLEM_DIAGNOSTIC_AVAILABLE = False

PRICE_PANEL_INTERMEDIATE_DIR = APP_DIR.parent / "æ¯”ä»·æ•°æ®" / "intermediate"

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="æ™ºèƒ½é—¨åº—ç»è¥çœ‹æ¿",
    page_icon="ğŸª",
    layout="wide",
    initial_sidebar_state="expanded"
)

# è‡ªå®šä¹‰CSSæ ·å¼
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
        font-weight: bold;
    }
    .metric-card {
        background-color: #f8f9fa;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 4px solid #1f77b4;
        margin: 1rem 0;
    }
    .recommendation-box {
        background-color: #e8f5e8;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 4px solid #28a745;
        margin: 0.5rem 0;
    }
    .risk-warning {
        background-color: #fff3cd;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 4px solid #ffc107;
        margin: 0.5rem 0;
    }
    .high-risk {
        background-color: #f8d7da;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 4px solid #dc3545;
        margin: 0.5rem 0;
    }
</style>
""", unsafe_allow_html=True)

@st.cache_resource(hash_funcs={type: lambda _: None})
def load_dashboard_system() -> SmartStoreDashboard:
    """åŠ è½½æ™ºèƒ½é—¨åº—ç»è¥çœ‹æ¿ç³»ç»Ÿå®ä¾‹"""
    return SmartStoreDashboard()

@st.cache_resource(hash_funcs={type: lambda _: None})
def load_data_processor() -> RealDataProcessor:
    """åŠ è½½çœŸå®æ•°æ®å¤„ç†å™¨å®ä¾‹"""
    return RealDataProcessor("å®é™…æ•°æ®")

COLUMN_NAME_FIXES: Dict[str, str] = {
    # æ­£å¸¸åˆ—åé€ä¼ 
    "å•†å“åç§°": "å•†å“åç§°",
    "å•†å“å®å”®ä»·": "å•†å“å®å”®ä»·",
    "å•†å“åŸä»·": "å•†å“åŸä»·",
    "é—¨åº—åç§°": "é—¨åº—åç§°",
    "é—¨åº—ç¼–ç ": "é—¨åº—ç¼–ç ",
    "è®¢å•ID": "è®¢å•ID",
    "ä¸‹å•æ—¶é—´": "ä¸‹å•æ—¶é—´",
    "æ”¶è´§åœ°å€": "æ”¶è´§åœ°å€",
    "ç”¨æˆ·ID": "ç”¨æˆ·ID",
    "ç”¨æˆ·åç§°": "ç”¨æˆ·åç§°",
    "æ•°é‡": "æ•°é‡",
    "å‰©ä½™åº“å­˜": "å‰©ä½™åº“å­˜",
    "ç¾å›¢ä¸€çº§åˆ†ç±»": "ç¾å›¢ä¸€çº§åˆ†ç±»",
    "ç¾å›¢ä¸‰çº§åˆ†ç±»": "ç¾å›¢ä¸‰çº§åˆ†ç±»",
    "é…é€æ–¹å¼": "é…é€æ–¹å¼",
    "æ¸ é“": "æ¸ é“",
    "åŸå¸‚åç§°": "åŸå¸‚åç§°",
    "ç‰©æµé…é€è´¹": "ç‰©æµé…é€è´¹",
    "å¹³å°ä½£é‡‘": "å¹³å°ä½£é‡‘",
    "å®æ”¶ä»·æ ¼": "å®æ”¶ä»·æ ¼",
    "é¢„ä¼°è®¢å•æ”¶å…¥": "é¢„ä¼°è®¢å•æ”¶å…¥",
    "ç”¨æˆ·æ”¯ä»˜é…é€è´¹": "ç”¨æˆ·æ”¯ä»˜é…é€è´¹",
    "é…é€è´¹å‡å…é‡‘é¢": "é…é€è´¹å‡å…é‡‘é¢",
    "å•†å“ä¼˜æƒ é‡‘é¢": "å•†å“ä¼˜æƒ é‡‘é¢",
    "å•†å“å‡å…é‡‘é¢": "å•†å“å‡å…é‡‘é¢",
    # å¸¸è§ä¹±ç æ˜ å°„
    "Ò»": "ä¸€çº§åˆ†ç±»",
    "": "åŸå¸‚åç§°",
    "": "ä¸‰çº§åˆ†ç±»",
    "Æ·": "å•†å“åç§°",
    "Æ·": "å•†å“ç¼–ç ",
    "Æ·ÊµÛ¼": "å•†å“å®å”®ä»·",
    "Æ·Ô­": "å•†å“åŸä»·",
    "": "æ•°é‡",
    "Ê£": "å‰©ä½™åº“å­˜",
    "Æ·": "å•†å“ä¼˜æƒ é‡‘é¢",
    "": "é…é€æ–¹å¼",
    "ID": "è®¢å•ID",
    "Ã»ID": "ç”¨æˆ·ID",
    "Ã»": "ç”¨æˆ·åç§°",
    "Ì»": "é—¨åº—åç§°",
    "Åµ": "é—¨åº—åç§°",
    "ÂµÊ±": "ä¸‹å•æ—¶é—´",
    "Õ»Ö·": "æ”¶è´§åœ°å€",
    "Æ½Ì¨Ó¶": "å¹³å°ä½£é‡‘",
    "ÊµÕ¼Û¸": "å®æ”¶ä»·æ ¼",
    "Ô¤Æ¶": "é¢„ä¼°è®¢å•æ”¶å…¥",
    "Ã»Ö§": "ç”¨æˆ·æ”¯ä»˜é…é€è´¹",
    "Ã»Ö§Í·": "é…é€è´¹å‡å…é‡‘é¢",
    "Í·Ñ¼": "ç‰©æµé…é€è´¹",
    "Æ·": "å•†å“åç§°",
    "Ì¼Ò³ĞµÈ¯": "å•†å®¶ä¼˜æƒ åˆ¸",
    "Ì¼Ò´È¯": "å•†å®¶ä¼˜æƒ åˆ¸",
    "": "å•†å“å‡å…é‡‘é¢",
    "": "æ¸ é“",
}

SHEET_KEYWORDS: Dict[str, List[str]] = {
    "order": ["é—¨åº—è®¢å•", "è®¢å•", "order"],
    "competitor": ["ç«å¯¹", "ç«å“", "å¯¹æ‰‹"],
    "cost": ["æˆæœ¬", "è´¹ç”¨", "cost"],
    "traffic": ["æµé‡", "äº¤é€š", "å®¢æµ", "traffic"],
}

NUMERIC_COLUMNS = [
    "å•†å“å®å”®ä»·",
    "å•†å“åŸä»·",
    "æ•°é‡",
    "å‰©ä½™åº“å­˜",
    "å¹³å°ä½£é‡‘",
    "ç‰©æµé…é€è´¹",
    "ç”¨æˆ·æ”¯ä»˜é…é€è´¹",
    "é…é€è´¹å‡å…é‡‘é¢",
    "é¢„ä¼°è®¢å•æ”¶å…¥",
    "å®æ”¶ä»·æ ¼",
    "å•†å“ä¼˜æƒ é‡‘é¢",
    "å•†å“å‡å…é‡‘é¢",
]

CHANNELS_TO_REMOVE = CoreBusinessLogic.CHANNELS_TO_REMOVE

# ==================== ğŸ“Š æ•°æ®è´¨é‡æ£€æŸ¥ä¸ç¼“å­˜ç®¡ç† ====================

def perform_data_quality_check(df: pd.DataFrame) -> Dict[str, Any]:
    """
    æ‰§è¡Œå…¨é¢çš„æ•°æ®è´¨é‡æ£€æŸ¥
    
    Returns:
        åŒ…å«è´¨é‡æ£€æŸ¥ç»“æœçš„å­—å…¸
    """
    quality_report = {
        'total_rows': len(df),
        'total_columns': len(df.columns),
        'issues': [],
        'warnings': [],
        'summary': {},
        'score': 100  # åˆå§‹åˆ†æ•°100åˆ†
    }
    
    # 1. æ£€æŸ¥ç¼ºå¤±å€¼
    missing_data = df.isnull().sum()
    if missing_data.sum() > 0:
        missing_cols = missing_data[missing_data > 0]
        quality_report['summary']['missing_values'] = missing_cols.to_dict()
        
        for col, count in missing_cols.items():
            percentage = (count / len(df)) * 100
            if percentage > 50:
                quality_report['issues'].append({
                    'type': 'ä¸¥é‡',
                    'column': col,
                    'description': f'ç¼ºå¤±å€¼è¿‡å¤šï¼š{count}è¡Œ ({percentage:.1f}%)'
                })
                quality_report['score'] -= 10
            elif percentage > 10:
                quality_report['warnings'].append({
                    'type': 'è­¦å‘Š',
                    'column': col,
                    'description': f'å­˜åœ¨ç¼ºå¤±å€¼ï¼š{count}è¡Œ ({percentage:.1f}%)'
                })
                quality_report['score'] -= 3
    
    # 2. æ£€æŸ¥å®Œå…¨é‡å¤çš„æ•°æ®è¡Œ
    duplicate_rows = df.duplicated().sum()
    if duplicate_rows > 0:
        quality_report['issues'].append({
            'type': 'è­¦å‘Š',
            'column': 'æ•°æ®è¡Œ',
            'description': f'å‘ç°å®Œå…¨é‡å¤çš„æ•°æ®è¡Œï¼š{duplicate_rows}æ¡ï¼ˆæ‰€æœ‰å­—æ®µå®Œå…¨ç›¸åŒï¼‰'
        })
        quality_report['score'] -= 5
    
    # 2.1 æ£€æŸ¥è®¢å•-å•†å“æ˜ç»†ç»“æ„ï¼ˆä¿¡æ¯æ€§æ£€æŸ¥ï¼Œä¸æ‰£åˆ†ï¼‰
    if 'è®¢å•ID' in df.columns:
        unique_orders = df['è®¢å•ID'].nunique()
        total_rows = len(df)
        items_per_order = total_rows / unique_orders if unique_orders > 0 else 0
        
        quality_report['issues'].append({
            'type': 'ä¿¡æ¯',
            'column': 'è®¢å•ç»“æ„',
            'description': f'è®¢å•-å•†å“æ˜ç»†çº§æ•°æ®ï¼š{unique_orders}ä¸ªè®¢å•ï¼Œ{total_rows}æ¡æ˜ç»†ï¼ˆå¹³å‡æ¯å•{items_per_order:.1f}ä¸ªå•†å“ï¼‰'
        })
    
    # 3. æ£€æŸ¥æ—¥æœŸæ ¼å¼
    if 'ä¸‹å•æ—¶é—´' in df.columns:
        try:
            date_series = pd.to_datetime(df['ä¸‹å•æ—¶é—´'], errors='coerce')
            invalid_dates = date_series.isnull().sum()
            if invalid_dates > 0:
                quality_report['warnings'].append({
                    'type': 'è­¦å‘Š',
                    'column': 'ä¸‹å•æ—¶é—´',
                    'description': f'æ— æ•ˆæ—¥æœŸæ ¼å¼ï¼š{invalid_dates}è¡Œ'
                })
                quality_report['score'] -= 3
        except Exception as e:
            quality_report['issues'].append({
                'type': 'ä¸¥é‡',
                'column': 'ä¸‹å•æ—¶é—´',
                'description': f'æ—¥æœŸè§£æå¤±è´¥ï¼š{str(e)}'
            })
            quality_report['score'] -= 10
    
    # 4. æ£€æŸ¥æ•°å€¼å¼‚å¸¸
    numeric_cols = ['å•†å“å®å”®ä»·', 'å•†å“åŸä»·', 'é”€é‡', 'åˆ©æ¶¦é¢', 'è®¢å•é›¶å”®é¢']
    for col in numeric_cols:
        if col in df.columns:
            try:
                numeric_series = pd.to_numeric(df[col], errors='coerce')
                
                # æ£€æŸ¥è´Ÿæ•°ï¼ˆæŸäº›å­—æ®µä¸åº”ä¸ºè´Ÿï¼‰
                if col in ['å•†å“å®å”®ä»·', 'å•†å“åŸä»·', 'é”€é‡']:
                    negative_count = (numeric_series < 0).sum()
                    if negative_count > 0:
                        quality_report['warnings'].append({
                            'type': 'è­¦å‘Š',
                            'column': col,
                            'description': f'å­˜åœ¨è´Ÿæ•°ï¼š{negative_count}è¡Œ'
                        })
                        quality_report['score'] -= 2
                
                # æ£€æŸ¥å¼‚å¸¸å€¼ï¼ˆè¶…å‡ºåˆç†èŒƒå›´ï¼‰
                if col == 'å•†å“å®å”®ä»·':
                    outliers = ((numeric_series > 10000) | (numeric_series < 0.1)).sum()
                    if outliers > 0:
                        quality_report['warnings'].append({
                            'type': 'æç¤º',
                            'column': col,
                            'description': f'å¯èƒ½å­˜åœ¨å¼‚å¸¸ä»·æ ¼ï¼š{outliers}è¡Œï¼ˆ<0.1æˆ–>10000ï¼‰'
                        })
                        
            except Exception:
                pass
    
    # 5. æ£€æŸ¥å¿…éœ€å­—æ®µ
    required_fields = ['è®¢å•ID', 'å•†å“åç§°', 'å•†å“å®å”®ä»·', 'é”€é‡', 'ä¸‹å•æ—¶é—´']
    missing_required = [field for field in required_fields if field not in df.columns]
    if missing_required:
        quality_report['issues'].append({
            'type': 'ä¸¥é‡',
            'column': ','.join(missing_required),
            'description': f'ç¼ºå°‘å¿…éœ€å­—æ®µï¼š{missing_required}'
        })
        quality_report['score'] -= 15
    
    # ç¡®ä¿åˆ†æ•°ä¸ä½äº0
    quality_report['score'] = max(0, quality_report['score'])
    
    # ç”Ÿæˆç­‰çº§
    if quality_report['score'] >= 90:
        quality_report['grade'] = 'ä¼˜ç§€'
        quality_report['grade_color'] = 'green'
    elif quality_report['score'] >= 70:
        quality_report['grade'] = 'è‰¯å¥½'
        quality_report['grade_color'] = 'blue'
    elif quality_report['score'] >= 50:
        quality_report['grade'] = 'ä¸€èˆ¬'
        quality_report['grade_color'] = 'orange'
    else:
        quality_report['grade'] = 'è¾ƒå·®'
        quality_report['grade_color'] = 'red'
    
    return quality_report


def save_data_to_cache(df: pd.DataFrame, file_name: str) -> str:
    """
    ä¿å­˜æ•°æ®åˆ°æœ¬åœ°ç¼“å­˜
    
    Args:
        df: è¦ä¿å­˜çš„DataFrame
        file_name: åŸå§‹æ–‡ä»¶å
        
    Returns:
        ä¿å­˜çš„æ–‡ä»¶è·¯å¾„
    """
    import hashlib
    from datetime import datetime
    import pickle
    import gzip
    
    # åˆ›å»ºç¼“å­˜ç›®å½•
    cache_dir = APP_DIR / "å­¦ä¹ æ•°æ®ä»“åº“" / "uploaded_data"
    cache_dir.mkdir(parents=True, exist_ok=True)
    
    # ç”Ÿæˆæ–‡ä»¶åï¼ˆåŸºäºå†…å®¹hashå’Œæ—¶é—´æˆ³ï¼‰
    content_hash = hashlib.md5(df.to_json().encode()).hexdigest()[:8]
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    safe_name = file_name.replace('.xlsx', '').replace('.xls', '')
    
    cache_file = cache_dir / f"{safe_name}_{content_hash}_{timestamp}.pkl.gz"
    
    # ä¿å­˜å…ƒæ•°æ®
    metadata = {
        'original_file': file_name,
        'upload_time': datetime.now().isoformat(),
        'rows': len(df),
        'columns': list(df.columns),
        'data_hash': content_hash
    }
    
    # ä½¿ç”¨gzipå‹ç¼©ä¿å­˜
    with gzip.open(cache_file, 'wb') as f:
        pickle.dump({'data': df, 'metadata': metadata}, f)
    
    return str(cache_file)


def load_cached_data_list() -> List[Dict[str, Any]]:
    """
    è·å–æ‰€æœ‰ç¼“å­˜æ•°æ®çš„åˆ—è¡¨
    
    Returns:
        ç¼“å­˜æ•°æ®ä¿¡æ¯åˆ—è¡¨
    """
    import pickle
    import gzip
    
    cache_dir = APP_DIR / "å­¦ä¹ æ•°æ®ä»“åº“" / "uploaded_data"
    if not cache_dir.exists():
        return []
    
    cached_files = []
    for file in sorted(cache_dir.glob("*.pkl.gz"), reverse=True):
        try:
            with gzip.open(file, 'rb') as f:
                cached = pickle.load(f)
                metadata = cached.get('metadata', {})
                cached_files.append({
                    'file_path': str(file),
                    'file_name': file.name,
                    'original_file': metadata.get('original_file', 'Unknown'),
                    'upload_time': metadata.get('upload_time', 'Unknown'),
                    'rows': metadata.get('rows', 0),
                    'size_mb': file.stat().st_size / (1024 * 1024)
                })
        except Exception:
            continue
    
    return cached_files


def load_data_from_cache(file_path: str) -> Optional[pd.DataFrame]:
    """
    ä»ç¼“å­˜åŠ è½½æ•°æ®
    
    Args:
        file_path: ç¼“å­˜æ–‡ä»¶è·¯å¾„
        
    Returns:
        DataFrameæˆ–None
    """
    import pickle
    import gzip
    
    try:
        with gzip.open(file_path, 'rb') as f:
            cached = pickle.load(f)
            return cached.get('data')
    except Exception as e:
        st.error(f"âŒ åŠ è½½ç¼“å­˜å¤±è´¥: {str(e)}")
        return None



def normalize_label(label: Any) -> Any:
    """å°è¯•è§„æ•´åˆ—å/è¡¨åï¼Œå…¼å®¹ä¹±ç """
    if not isinstance(label, str):
        return label
    trimmed = label.strip()
    if trimmed in COLUMN_NAME_FIXES:
        return COLUMN_NAME_FIXES[trimmed]
    # å¤šç§ç¼–ç å›é€€
    for source in ("latin1", "cp1252"):
        for target in ("gbk", "gb2312"):
            try:
                decoded = trimmed.encode(source, errors="ignore").decode(target, errors="ignore").strip()
                if decoded:
                    return COLUMN_NAME_FIXES.get(decoded, decoded)
            except Exception:
                continue
    return COLUMN_NAME_FIXES.get(trimmed, trimmed)

def rename_columns(df: pd.DataFrame, extra_map: Optional[Dict[str, str]] = None) -> pd.DataFrame:
    """ç»Ÿä¸€DataFrameåˆ—å"""
    extra_map = extra_map or {}
    rename_map: Dict[str, str] = {}
    for col in df.columns:
        normalized = normalize_label(col)
        normalized = extra_map.get(normalized, normalized)
        rename_map[col] = normalized
    return df.rename(columns=rename_map)

def convert_numeric(df: pd.DataFrame, columns: List[str]) -> pd.DataFrame:
    for col in columns:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors="coerce")
    return df

def aggregate_product_data(order_df: pd.DataFrame) -> pd.DataFrame:
    if "å•†å“åç§°" not in order_df.columns:
        return pd.DataFrame()
    agg_map: Dict[str, str] = {}
    if "å•†å“å®å”®ä»·" in order_df.columns:
        agg_map["å•†å“å®å”®ä»·"] = "mean"
    if "å•†å“åŸä»·" in order_df.columns:
        agg_map["å•†å“åŸä»·"] = "mean"
    if "æ•°é‡" in order_df.columns:
        agg_map["æ•°é‡"] = "sum"
    if "å‰©ä½™åº“å­˜" in order_df.columns:
        agg_map["å‰©ä½™åº“å­˜"] = "max"
    if "ä¸€çº§åˆ†ç±»" in order_df.columns:
        agg_map["ä¸€çº§åˆ†ç±»"] = "first"
    if "ä¸‰çº§åˆ†ç±»" in order_df.columns:
        agg_map["ä¸‰çº§åˆ†ç±»"] = "first"
    if not agg_map:
        return pd.DataFrame()
    product_df = order_df.groupby("å•†å“åç§°", as_index=False).agg(agg_map)
    rename_map = {
        "å•†å“å®å”®ä»·": "å”®ä»·",
        "å•†å“åŸä»·": "åŸä»·",
        "æ•°é‡": "æœˆå”®",
        "å‰©ä½™åº“å­˜": "åº“å­˜",
        "ä¸€çº§åˆ†ç±»": "ç¾å›¢ä¸€çº§åˆ†ç±»",
        "ä¸‰çº§åˆ†ç±»": "ç¾å›¢ä¸‰çº§åˆ†ç±»",
    }
    return product_df.rename(columns={k: v for k, v in rename_map.items() if k in product_df.columns})

def build_sales_summary(order_df: pd.DataFrame) -> pd.DataFrame:
    """æ„å»ºé”€å”®æ±‡æ€»æ•°æ® - ç®€åŒ–ç‰ˆï¼Œé¿å…å¤æ‚èšåˆé—®é¢˜"""
    if "ä¸‹å•æ—¶é—´" in order_df.columns:
        order_df = order_df.copy()
        order_df["ä¸‹å•æ—¶é—´"] = pd.to_datetime(order_df["ä¸‹å•æ—¶é—´"], errors="coerce")
        order_df["ä¸‹å•æ—¥æœŸ"] = order_df["ä¸‹å•æ—¶é—´"].dt.date
    if "ä¸‹å•æ—¥æœŸ" not in order_df.columns:
        return pd.DataFrame()
    
    # ç®€åŒ–èšåˆé€»è¾‘ï¼Œåªèšåˆæ•°å€¼åˆ—
    agg_dict: Dict[str, Any] = {"ä¸‹å•æ—¥æœŸ": "first"}
    if "é¢„ä¼°è®¢å•æ”¶å…¥" in order_df.columns:
        agg_dict["é¢„ä¼°è®¢å•æ”¶å…¥"] = "sum"
    if "å®æ”¶ä»·æ ¼" in order_df.columns:
        agg_dict["å®æ”¶ä»·æ ¼"] = "sum"
    if "æ•°é‡" in order_df.columns:
        agg_dict["æ•°é‡"] = "sum"
    
    # ä¸åœ¨è¿™é‡Œèšåˆè®¢å•IDï¼Œé¿å…ç»´åº¦é—®é¢˜
    # ç›´æ¥æŒ‰æ—¥æœŸåˆ†ç»„èšåˆæ•°å€¼
    try:
        summary = order_df.groupby("ä¸‹å•æ—¥æœŸ").agg(agg_dict).reset_index(drop=True)
    except Exception as e:
        # å¦‚æœèšåˆå¤±è´¥ï¼Œè¿”å›ç©ºDataFrame
        return pd.DataFrame()
    
    rename_map = {
        "ä¸‹å•æ—¥æœŸ": "date",
        "é¢„ä¼°è®¢å•æ”¶å…¥": "estimated_revenue",
        "å®æ”¶ä»·æ ¼": "net_revenue",
        "æ•°é‡": "items_sold",
    }
    return summary.rename(columns={k: v for k, v in rename_map.items() if k in summary.columns})

def build_customer_profile(order_df: pd.DataFrame) -> pd.DataFrame:
    candidate_cols = [
        "è®¢å•ID",
        "ç”¨æˆ·ID",
        "ç”¨æˆ·åç§°",
        "ä¸‹å•æ—¶é—´",
        "æ”¶è´§åœ°å€",
        "åŸå¸‚åç§°",
        "æ¸ é“",
        "é…é€æ–¹å¼",
        "é—¨åº—åç§°",
    ]
    available = [col for col in candidate_cols if col in order_df.columns]
    if not available:
        return pd.DataFrame()
    profile = order_df[available].copy()
    if "ä¸‹å•æ—¶é—´" in profile.columns:
        profile["ä¸‹å•æ—¶é—´"] = pd.to_datetime(profile["ä¸‹å•æ—¶é—´"], errors="coerce")
    if "è®¢å•ID" in profile.columns:
        profile = profile.drop_duplicates(subset=["è®¢å•ID"], keep="last")
    return profile

def filter_channels(order_df: pd.DataFrame) -> pd.DataFrame:
    if "æ¸ é“" not in order_df.columns:
        return order_df
    filtered = order_df[~order_df["æ¸ é“"].isin(CHANNELS_TO_REMOVE)].copy()
    return filtered

def detect_data_period(order_df: pd.DataFrame) -> Optional[str]:
    date_series = None
    if "ä¸‹å•æ—¶é—´" in order_df.columns:
        date_series = pd.to_datetime(order_df["ä¸‹å•æ—¶é—´"], errors="coerce")
    elif "ä¸‹å•æ—¥æœŸ" in order_df.columns:
        date_series = pd.to_datetime(order_df["ä¸‹å•æ—¥æœŸ"], errors="coerce")
    if date_series is None or date_series.dropna().empty:
        return None
    date_series = date_series.dropna()
    start, end = date_series.min(), date_series.max()
    try:
        return f"{start:%Y-%m-%d} ~ {end:%Y-%m-%d}"
    except Exception:
        return None

@st.cache_data(ttl=60)  # 1åˆ†é’Ÿç¼“å­˜ï¼Œé…é€æˆæœ¬å‡€æˆæœ¬æ¨¡å¼æœ€ç»ˆä¿®æ­£ 2025-10-13
def load_real_business_data(_cache_version: str = "v11_NEW_DATA_2025_10_15") -> Tuple[Optional[Dict[str, Any]], List[str]]:
    """æ‰«æå¹¶åŠ è½½çœŸå®ä¸šåŠ¡æ•°æ®ï¼Œè¿”å›(æ•°æ®, æç¤ºä¿¡æ¯)
    
    é‡è¦æ›´æ–° 2025-10-13: é…é€æˆæœ¬å‡€æˆæœ¬æ¨¡å¼æœ€ç»ˆä¿®æ­£
    - é…é€æˆæœ¬å…¬å¼: (é…é€è´¹å‡å… + ç‰©æµé…é€è´¹) - ç”¨æˆ·æ”¯ä»˜é…é€è´¹ = å‡€æˆæœ¬
    - è®¢å•æ€»æ”¶å…¥: å•†å“å®å”®ä»· + æ‰“åŒ…è´¹ + ç”¨æˆ·æ”¯ä»˜é…é€è´¹ï¼ˆå®Œæ•´æ”¶å…¥ï¼‰
    - åˆ©æ¶¦å…¬å¼: æ€»æ”¶å…¥ - å•†å“æˆæœ¬ - é…é€å‡€æˆæœ¬ - å…¶ä»–æˆæœ¬
    
    Args:
        _cache_version: ç¼“å­˜ç‰ˆæœ¬å·ï¼Œä¿®æ”¹æ­¤å‚æ•°å¯å¼ºåˆ¶åˆ·æ–°ç¼“å­˜
    """
    messages: List[str] = []
    candidate_dirs = [
        APP_DIR / "å®é™…æ•°æ®",
        APP_DIR.parent / "å®é™…æ•°æ®",
        APP_DIR / "é—¨åº—æ•°æ®",
        APP_DIR.parent / "æµ‹ç®—æ¨¡å‹" / "é—¨åº—æ•°æ®",
        APP_DIR.parent / "æµ‹ç®—æ¨¡å‹" / "é—¨åº—æ•°æ®" / "æ¯”ä»·çœ‹æ¿æ¨¡å—",
    ]

    data_dir: Optional[Path] = None
    candidates: List[Path] = []
    for path in candidate_dirs:
        if not path.exists():
            continue
        current_candidates = sorted(
            f for f in path.glob("*.xlsx")
            if not f.name.startswith("~$")
        )
        if current_candidates:
            data_dir = path
            candidates = current_candidates
            break
    if data_dir is None:
        tried = "ï¼›".join(str(path) for path in candidate_dirs)
        messages.append(f"æœªæ‰¾åˆ°æ•°æ®ç›®å½•ï¼Œå¯åœ¨ä»¥ä¸‹ä½ç½®ä¹‹ä¸€åˆ›å»º: {tried}")
        return None, messages
    if not candidates:
        messages.append("æ•°æ®ç›®å½•ä¸‹æœªæ‰¾åˆ°Excelæ–‡ä»¶")
        return None, messages

    target_file = next((f for f in candidates if "æµ‹è¯•æ•°æ®" in f.name), candidates[0])
    try:
        xls = pd.ExcelFile(target_file)
    except Exception as exc:
        messages.append(f"è¯»å– {target_file.name} å¤±è´¥: {exc}")
        return None, messages

    def pick_sheet(kind: str) -> Optional[str]:
        keywords = SHEET_KEYWORDS.get(kind, [])
        for sheet in xls.sheet_names:
            normalized = str(normalize_label(sheet)).replace(" ", "")
            for kw in keywords:
                if kw in normalized:
                    return sheet
        return None

    sheet_map = {
        "order": pick_sheet("order") or (xls.sheet_names[0] if xls.sheet_names else None),
        "competitor": pick_sheet("competitor"),
        "cost": pick_sheet("cost"),
        "traffic": pick_sheet("traffic"),
    }

    if sheet_map["competitor"] is None:
        for sheet in xls.sheet_names:
            normalized = str(normalize_label(sheet)).replace(" ", "")
            if "ç«å¯¹" in normalized or "ç«å“" in normalized:
                sheet_map["competitor"] = sheet
                break

    if sheet_map["cost"] is None:
        for sheet in xls.sheet_names:
            normalized = str(normalize_label(sheet)).replace(" ", "")
            if "æˆæœ¬" in normalized or "è´¹ç”¨" in normalized:
                sheet_map["cost"] = sheet
                break

    if sheet_map["traffic"] is None:
        for sheet in xls.sheet_names:
            normalized = str(normalize_label(sheet)).replace(" ", "")
            if "æµé‡" in normalized or "å®¢æµ" in normalized:
                sheet_map["traffic"] = sheet
                break

    data_frames: Dict[str, pd.DataFrame] = {}
    for key, sheet_name in sheet_map.items():
        if sheet_name is None:
            messages.append(f"æœªæ‰¾åˆ°{key}ç›¸å…³çš„å·¥ä½œè¡¨")
            continue
        try:
            df = pd.read_excel(xls, sheet_name=sheet_name)
            data_frames[key] = rename_columns(df)
        except Exception as exc:
            messages.append(f"è¯»å–å·¥ä½œè¡¨ {sheet_name} å¤±è´¥: {exc}")

    order_df = data_frames.get("order", pd.DataFrame())
    if order_df.empty:
        messages.append("æœªè·å–åˆ°é—¨åº—è®¢å•æ•°æ®")
        return None, messages

    order_df = convert_numeric(order_df, NUMERIC_COLUMNS)
    filtered_order_df = filter_channels(order_df)
    removed_rows = len(order_df) - len(filtered_order_df)
    if removed_rows > 0:
        messages.append(f"å·²å‰”é™¤æŒ‡å®šæ¸ é“è®¢å• {removed_rows:,} æ¡")
    order_df = filtered_order_df

    product_df = aggregate_product_data(order_df)
    sales_summary = build_sales_summary(order_df)
    customer_df = build_customer_profile(order_df)

    competitor_df = data_frames.get("competitor", pd.DataFrame())
    if not competitor_df.empty:
        competitor_df = convert_numeric(competitor_df, ["å”®ä»·", "åŸä»·", "æœˆå”®"])

    cost_df = data_frames.get("cost", pd.DataFrame())
    traffic_df = data_frames.get("traffic", pd.DataFrame())

    store_identifier = order_df.get("é—¨åº—åç§°")
    store_id = "REAL_STORE_DATA"
    if store_identifier is not None and not store_identifier.dropna().empty:
        store_id = str(store_identifier.mode().iat[0])

    data_period = detect_data_period(order_df) or "è¿‘30å¤©"
    
    # å®‰å…¨è®¡ç®—è®¢å•æ•°å’Œå•†å“æ•°
    try:
        if "è®¢å•ID" in order_df.columns:
            total_orders = int(order_df["è®¢å•ID"].nunique())
        else:
            total_orders = len(order_df)
    except Exception:
        total_orders = len(order_df)
    
    try:
        if not product_df.empty and "å•†å“åç§°" in product_df.columns:
            total_products = int(product_df["å•†å“åç§°"].nunique())
        elif "å•†å“åç§°" in order_df.columns:
            total_products = int(order_df["å•†å“åç§°"].nunique())
        else:
            total_products = 0
    except Exception:
        total_products = 0

    result: Dict[str, Any] = {
        "store_id": store_id,
        "order_data": order_df,
        "raw_data": order_df,  # æ·»åŠ  raw_data é”®ç”¨äºåœºæ™¯è¥é”€åˆ†æ
        "product_data": product_df,
        "sales_data": sales_summary,
        "customer_data": customer_df,
        "competitor_data": competitor_df,
        "cost_data": cost_df,
        "traffic_data": traffic_df,
        "data_source": f"æ–‡ä»¶: {target_file.name}",
        "data_period": data_period,
        "total_orders": total_orders,
        "total_products": total_products,
    }

    return result, messages

def process_uploaded_comparison_file(comparison_file) -> Optional[Dict[str, Any]]:
    """å¤„ç†ä¸Šä¼ çš„å·²æ¯”å¯¹å¥½çš„Excelæ–‡ä»¶"""
    if not comparison_file:
        return None
        
    try:
        # è¯»å–Excelæ–‡ä»¶çš„æ‰€æœ‰Sheet
        st.info("ğŸ“Š æ­£åœ¨è¯»å–æ¯”ä»·ç»“æœæ–‡ä»¶...")
        
        excel_file = pd.ExcelFile(comparison_file)
        sheet_names = excel_file.sheet_names
        
        st.success(f"âœ… æ£€æµ‹åˆ° {len(sheet_names)} ä¸ªSheet: {sheet_names}")
        
        # è¯»å–å„ä¸ªSheetçš„æ•°æ®
        sheets_data = {}
        for sheet_name in sheet_names:
            try:
                df = pd.read_excel(comparison_file, sheet_name=sheet_name)
                if len(df) > 0:
                    sheets_data[sheet_name] = df
                    st.info(f"âœ… {sheet_name}: {len(df)} æ¡è®°å½•")
                else:
                    st.info(f"âš ï¸ {sheet_name}: ç©ºè¡¨")
            except Exception as e:
                st.warning(f"âŒ è¯»å– {sheet_name} å¤±è´¥: {e}")
                continue
        
        if not sheets_data:
            st.error("Excelæ–‡ä»¶ä¸­æ²¡æœ‰æœ‰æ•ˆæ•°æ®ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼")
            return None
        
        # è§£ææ¯”ä»·æ•°æ®å¹¶ç”Ÿæˆç»Ÿè®¡æŒ‡æ ‡
        st.info("ğŸ”„ æ­£åœ¨è§£ææ¯”ä»·ç»“æœ...")
        
        # ç»Ÿè®¡åŒ¹é…æƒ…å†µ
        barcode_matches = sheets_data.get('1-æ¡ç ç²¾ç¡®åŒ¹é…', pd.DataFrame())
        name_matches = sheets_data.get('2-åç§°æ¨¡ç³ŠåŒ¹é…(æ— æ¡ç )', pd.DataFrame())
        
        barcode_match_count = len(barcode_matches)
        name_match_count = len(name_matches)
        total_matches = barcode_match_count + name_match_count
        
        # ç»Ÿè®¡ç‹¬æœ‰å•†å“
        store_a_unique_key = None
        store_b_unique_key = None
        store_names = []
        
        for sheet_name in sheet_names:
            if 'ç‹¬æœ‰å•†å“' in sheet_name:
                if sheet_name.startswith('3-'):
                    store_a_unique_key = sheet_name
                    # æå–åº—é“ºåç§°
                    parts = sheet_name.split('-')
                    if len(parts) >= 2:
                        store_name = parts[1]
                        store_names.append(store_name)
                elif sheet_name.startswith('4-'):
                    store_b_unique_key = sheet_name
                    # æå–åº—é“ºåç§°
                    parts = sheet_name.split('-')
                    if len(parts) >= 2:
                        store_name = parts[1]
                        store_names.append(store_name)
        
        store_a_unique = sheets_data.get(store_a_unique_key, pd.DataFrame())
        store_b_unique = sheets_data.get(store_b_unique_key, pd.DataFrame())
        
        store_a_unique_count = len(store_a_unique)
        store_b_unique_count = len(store_b_unique)
        
        # ä»·æ ¼ä¼˜åŠ¿åˆ†æ
        price_advantage = sheets_data.get('5-åº“å­˜>0&AæŠ˜æ‰£â‰¥BæŠ˜æ‰£', pd.DataFrame())
        price_advantage_count = len(price_advantage)
        
        # è®¡ç®—ä»·æ ¼å·®å¼‚ç»Ÿè®¡ï¼ˆä»åŒ¹é…çš„å•†å“ä¸­ï¼‰
        avg_price_diff = 0
        max_price_diff = 0
        
        # å°è¯•ä»åŒ¹é…æ•°æ®ä¸­è®¡ç®—ä»·æ ¼å·®å¼‚
        if len(barcode_matches) > 0:
            price_cols = [col for col in barcode_matches.columns if 'å”®ä»·' in col or 'ä»·æ ¼' in col]
            if len(price_cols) >= 2:
                try:
                    price_diffs = barcode_matches[price_cols[0]] - barcode_matches[price_cols[1]]
                    avg_price_diff = price_diffs.mean()
                    max_price_diff = price_diffs.abs().max()
                except Exception:
                    pass
        
        # æ„é€ åˆ†æç»“æœ
        store_display_names = store_names if len(store_names) >= 2 else ['é—¨åº—A', 'é—¨åº—B']
        
        analysis_result = {
            "generated_at": pd.Timestamp.now().isoformat(),
            "comparison_type": "multi_store_comparison",
            "sheets_data": sheets_data,
            "sheet_names": sheet_names,
            "stores": [
                {"display_name": store_display_names[0], "unique_products": store_a_unique_count},
                {"display_name": store_display_names[1], "unique_products": store_b_unique_count}
            ],
            "metrics": [
                {
                    "id": "barcode_matches",
                    "label": "æ¡ç ç²¾ç¡®åŒ¹é…",
                    "value": barcode_match_count,
                    "unit": "ä¸ª",
                    "context": {"type": "exact_match"}
                },
                {
                    "id": "name_matches",
                    "label": "åç§°æ¨¡ç³ŠåŒ¹é…",
                    "value": name_match_count,
                    "unit": "ä¸ª", 
                    "context": {"type": "fuzzy_match"}
                },
                {
                    "id": "total_matches",
                    "label": "æ€»åŒ¹é…å•†å“æ•°",
                    "value": total_matches,
                    "unit": "ä¸ª",
                    "context": {"barcode": barcode_match_count, "name": name_match_count}
                },
                {
                    "id": "unique_store_a",
                    "label": f"{store_display_names[0]} ç‹¬æœ‰å•†å“",
                    "value": store_a_unique_count,
                    "unit": "ä¸ª",
                    "context": {"store": store_display_names[0]}
                },
                {
                    "id": "unique_store_b",
                    "label": f"{store_display_names[1]} ç‹¬æœ‰å•†å“",
                    "value": store_b_unique_count,
                    "unit": "ä¸ª",
                    "context": {"store": store_display_names[1]}
                },
                {
                    "id": "price_advantage",
                    "label": "ä»·æ ¼ä¼˜åŠ¿å•†å“æ•°",
                    "value": price_advantage_count,
                    "unit": "ä¸ª",
                    "context": {"criteria": "åº“å­˜>0&AæŠ˜æ‰£â‰¥BæŠ˜æ‰£"}
                }
            ],
            "summary": {
                "avg_price_diff": avg_price_diff,
                "max_price_diff": max_price_diff,
                "comparison_coverage": total_matches / (total_matches + store_a_unique_count + store_b_unique_count) if (total_matches + store_a_unique_count + store_b_unique_count) > 0 else 0
            },
            "warnings": []
        }
        
        # æ·»åŠ è­¦å‘Š
        if total_matches < 10:
            analysis_result["warnings"].append("åŒ¹é…å•†å“æ•°é‡è¾ƒå°‘ï¼Œå¯èƒ½å½±å“åˆ†æå‡†ç¡®æ€§")
        
        if store_a_unique_count + store_b_unique_count > total_matches:
            analysis_result["warnings"].append("ç‹¬æœ‰å•†å“æ•°é‡è¾ƒå¤šï¼Œå»ºè®®æ£€æŸ¥å•†å“åˆ†ç±»å’Œå‘½åè§„èŒƒ")
        
        st.success(f"ğŸ‰ æ¯”ä»·ç»“æœè§£æå®Œæˆï¼åŒ¹é… {total_matches} ä¸ªå•†å“ (æ¡ç :{barcode_match_count}, åç§°:{name_match_count})")
        return analysis_result
        
    except Exception as e:
        st.error(f"âŒ å¤„ç†æ¯”ä»·ç»“æœæ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
        import traceback
        st.error(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
        return None



def render_comparison_file_analysis(price_panel_payload: Dict[str, Any]) -> None:
    """æ¸²æŸ“æ¯”ä»·ç»“æœæ–‡ä»¶åˆ†æ"""
    try:
        # æ˜¾ç¤ºåŸºç¡€ç»Ÿè®¡
        st.subheader("ğŸ“Š æ¯”ä»·ç»“æœæ¦‚è§ˆ")
        
        # åŸºç¡€æŒ‡æ ‡å¡ç‰‡
        col1, col2, col3, col4 = st.columns(4)
        
        metrics = price_panel_payload.get("metrics", [])
        stores = price_panel_payload.get("stores", [])
        summary = price_panel_payload.get("summary", {})
        
        # æ‰¾åˆ°ç›¸å…³æŒ‡æ ‡
        total_matches = 0
        barcode_matches = 0
        name_matches = 0
        store_a_unique = 0
        store_b_unique = 0
        
        for metric in metrics:
            metric_id = metric.get("id", "")
            value = metric.get("value", 0)
            
            if metric_id == "total_matches":
                total_matches = value
            elif metric_id == "barcode_matches":
                barcode_matches = value
            elif metric_id == "name_matches":
                name_matches = value
            elif metric_id == "unique_store_a":
                store_a_unique = value
            elif metric_id == "unique_store_b":
                store_b_unique = value
        
        with col1:
            st.metric(
                "æ€»åŒ¹é…å•†å“",
                f"{total_matches:,}",
                help="æ¡ç åŒ¹é… + åç§°åŒ¹é…çš„æ€»å•†å“æ•°é‡"
            )
        
        with col2:
            st.metric(
                "æ¡ç ç²¾ç¡®åŒ¹é…",
                f"{barcode_matches:,}",
                help="é€šè¿‡æ¡ç ç²¾ç¡®åŒ¹é…çš„å•†å“æ•°é‡"
            )
        
        with col3:
            st.metric(
                "åç§°æ¨¡ç³ŠåŒ¹é…",
                f"{name_matches:,}",
                help="é€šè¿‡å•†å“åç§°æ¨¡ç³ŠåŒ¹é…çš„å•†å“æ•°é‡"
            )
        
        with col4:
            coverage = summary.get("comparison_coverage", 0)
            st.metric(
                "åŒ¹é…è¦†ç›–ç‡",
                f"{coverage:.1%}",
                help="åŒ¹é…å•†å“æ•°å æ€»å•†å“æ•°çš„æ¯”ä¾‹"
            )
        
        # åº—é“ºå¯¹æ¯”
        st.subheader("ğŸª åº—é“ºå•†å“å¯¹æ¯”")
        
        col1, col2 = st.columns(2)
        
        with col1:
            if len(stores) > 0:
                store_name_a = stores[0].get("display_name", "åº—é“ºA")
                st.metric(
                    f"{store_name_a} ç‹¬æœ‰å•†å“",
                    f"{store_a_unique:,}",
                    help=f"{store_name_a}ç‰¹æœ‰çš„å•†å“æ•°é‡"
                )
        
        with col2:
            if len(stores) > 1:
                store_name_b = stores[1].get("display_name", "åº—é“ºB")
                st.metric(
                    f"{store_name_b} ç‹¬æœ‰å•†å“",
                    f"{store_b_unique:,}",
                    help=f"{store_name_b}ç‰¹æœ‰çš„å•†å“æ•°é‡"
                )
        
        # åŒ¹é…ç»“æœå¯è§†åŒ–
        st.subheader("ğŸ“ˆ åŒ¹é…ç»“æœåˆ†æ")
        
        # åŒ¹é…ç±»å‹åˆ†å¸ƒé¥¼å›¾
        if total_matches > 0:
            col1, col2 = st.columns(2)
            
            with col1:
                # åŒ¹é…ç±»å‹åˆ†å¸ƒ
                match_data = {
                    "åŒ¹é…ç±»å‹": ["æ¡ç ç²¾ç¡®åŒ¹é…", "åç§°æ¨¡ç³ŠåŒ¹é…"],
                    "æ•°é‡": [barcode_matches, name_matches]
                }
                
                fig_match = px.pie(
                    values=match_data["æ•°é‡"],
                    names=match_data["åŒ¹é…ç±»å‹"],
                    title="åŒ¹é…ç±»å‹åˆ†å¸ƒ",
                    color_discrete_sequence=px.colors.qualitative.Set3
                )
                st.plotly_chart(fig_match, use_container_width=True)
            
            with col2:
                # å•†å“åˆ†å¸ƒå¯¹æ¯”
                all_data = {
                    "ç±»åˆ«": ["åŒ¹é…å•†å“", f"{store_name_a}ç‹¬æœ‰", f"{store_name_b}ç‹¬æœ‰"],
                    "æ•°é‡": [total_matches, store_a_unique, store_b_unique]
                }
                
                fig_distribution = px.bar(
                    x=all_data["ç±»åˆ«"],
                    y=all_data["æ•°é‡"],
                    title="å•†å“åˆ†å¸ƒå¯¹æ¯”",
                    color=all_data["ç±»åˆ«"],
                    color_discrete_sequence=px.colors.qualitative.Pastel
                )
                fig_distribution.update_layout(showlegend=False)
                st.plotly_chart(fig_distribution, use_container_width=True)
        
        # è¯¦ç»†Sheetæ•°æ®å±•ç¤º
        st.subheader("ğŸ“‹ è¯¦ç»†æ•°æ®æŸ¥çœ‹")
        
        sheets_data = price_panel_payload.get("sheets_data", {})
        sheet_names = price_panel_payload.get("sheet_names", [])
        
        if sheets_data:
            # åˆ›å»ºSheeté€‰æ‹©å™¨
            selected_sheet = st.selectbox(
                "é€‰æ‹©è¦æŸ¥çœ‹çš„æ•°æ®Sheet:",
                options=sheet_names,
                                 help="é€‰æ‹©ä¸åŒçš„SheetæŸ¥çœ‹è¯¦ç»†æ•°æ®å†…å®¹"
            )
            
            if selected_sheet and selected_sheet in sheets_data:
                df = sheets_data[selected_sheet]
                
                st.write(f"**{selected_sheet}** - å…± {len(df)} æ¡è®°å½•")
                
                if len(df) > 0:
                    # æ˜¾ç¤ºå‰å‡ è¡Œæ•°æ®
                    st.dataframe(df.head(20), use_container_width=True)
                    
                    # æä¾›ä¸‹è½½é€‰é¡¹
                    csv_data = df.to_csv(index=False, encoding='utf-8-sig')
                    st.download_button(
                        label=f"ä¸‹è½½ {selected_sheet} æ•°æ® (CSV)",
                        data=csv_data,
                        file_name=f"{selected_sheet}_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.csv",
                        mime="text/csv",
                        key=f"download_{selected_sheet}"
                    )
                else:
                    st.info("æ­¤Sheetæš‚æ— æ•°æ®")
        
        # æ·»åŠ æ™ºèƒ½æ´å¯ŸæŠ¥å‘Šç”ŸæˆæŒ‰é’®
        st.markdown("---")
        if st.button("ğŸ¯ ç”Ÿæˆæ™ºèƒ½æ´å¯ŸæŠ¥å‘Š", help="åŸºäºå½“å‰æ•°æ®ç”Ÿæˆè¯¦ç»†çš„æ¯”ä»·åˆ†ææŠ¥å‘Š"):
            generate_insight_report(price_panel_payload)        # æ–°å¢é«˜çº§åˆ†ææ¨¡å—
        st.markdown("---")
        render_advanced_price_analysis(price_panel_payload)
        
        # è­¦å‘Šä¿¡æ¯
        warnings = price_panel_payload.get("warnings", [])
        if warnings:
            st.subheader("âš ï¸ æ³¨æ„äº‹é¡¹")
            for warning in warnings:
                st.warning(warning)
                
    except Exception as e:
        st.error(f"æ¸²æŸ“æ¯”ä»·åˆ†ææ—¶å‡ºé”™: {str(e)}")
        import traceback
        st.error(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")


def render_advanced_price_analysis(price_panel_payload: Dict[str, Any]) -> None:
    """æ¸²æŸ“é«˜çº§æ¯”ä»·åˆ†ææ¨¡å—"""
    st.subheader("ğŸ¯ é«˜çº§ä»·æ ¼åˆ†æ")
    
    sheets_data = price_panel_payload.get("sheets_data", {})
    stores = price_panel_payload.get("stores", [])
    
    if not sheets_data:
        st.info("æš‚æ— è¯¦ç»†æ•°æ®ï¼Œæ— æ³•è¿›è¡Œé«˜çº§åˆ†æ")
        return
    
    # è·å–åŒ¹é…æ•°æ®
    barcode_matches = sheets_data.get('1-æ¡ç ç²¾ç¡®åŒ¹é…', pd.DataFrame())
    name_matches = sheets_data.get('2-åç§°æ¨¡ç³ŠåŒ¹é…(æ— æ¡ç )', pd.DataFrame())
    
    # åˆå¹¶åŒ¹é…æ•°æ®
    all_matches = pd.DataFrame()
    if not barcode_matches.empty:
        barcode_matches['åŒ¹é…ç±»å‹'] = 'æ¡ç ç²¾ç¡®åŒ¹é…'
        all_matches = pd.concat([all_matches, barcode_matches], ignore_index=True)
    if not name_matches.empty:
        name_matches['åŒ¹é…ç±»å‹'] = 'åç§°æ¨¡ç³ŠåŒ¹é…'
        all_matches = pd.concat([all_matches, name_matches], ignore_index=True)
    
    if all_matches.empty:
        st.info("æš‚æ— åŒ¹é…æ•°æ®ï¼Œæ— æ³•è¿›è¡Œä»·æ ¼åˆ†æ")
        return
    
    # åˆ›å»ºåˆ†æé€‰é¡¹å¡
    analysis_tabs = st.tabs([
        "ğŸ’° ä»·æ ¼ç«äº‰åŠ›çƒ­åŠ›å›¾", 
        "ğŸ“Š ä»·æ ¼åˆ†å±‚åˆ†æ", 
        "ğŸ¯ åŒ¹é…è´¨é‡åˆ†æ",
        "ğŸ“ˆ åº“å­˜-ä»·æ ¼å…³ç³»",
        "ğŸ† ç«äº‰ä¼˜åŠ¿åˆ†æ"
    ])
    
    with analysis_tabs[0]:
        render_price_competitiveness_heatmap(all_matches, stores)
    
    with analysis_tabs[1]:
        render_price_tier_analysis(all_matches, stores)
    
    with analysis_tabs[2]:
        render_match_quality_analysis(all_matches, price_panel_payload)
    
    with analysis_tabs[3]:
        render_inventory_price_analysis(all_matches, stores)
    
    with analysis_tabs[4]:
        render_competitive_advantage_analysis(all_matches, sheets_data, stores)


def render_price_competitiveness_heatmap(all_matches: pd.DataFrame, stores: List[Dict]) -> None:
    """æ¸²æŸ“ä»·æ ¼ç«äº‰åŠ›çƒ­åŠ›å›¾"""
    st.write("**ğŸ’° æŒ‰å•†å“åˆ†ç±»çš„ä»·æ ¼ç«äº‰åŠ›çƒ­åŠ›å›¾**")
    
    try:
        # å¯»æ‰¾ä»·æ ¼åˆ—
        price_cols = [col for col in all_matches.columns if 'å”®ä»·' in col or 'ä»·æ ¼' in col]
        category_cols = [col for col in all_matches.columns if 'åˆ†ç±»' in col]
        
        if len(price_cols) < 2 or not category_cols:
            st.info("æ•°æ®ä¸­ç¼ºå°‘ä»·æ ¼æˆ–åˆ†ç±»ä¿¡æ¯ï¼Œæ— æ³•ç”Ÿæˆçƒ­åŠ›å›¾")
            return
        
        price_col_a = price_cols[0]
        price_col_b = price_cols[1] if len(price_cols) > 1 else price_cols[0]
        category_col = category_cols[0]
        
        # è®¡ç®—ä»·æ ¼ä¼˜åŠ¿
        all_matches = all_matches.copy()
        all_matches['ä»·æ ¼å·®å¼‚'] = pd.to_numeric(all_matches[price_col_a], errors='coerce') - pd.to_numeric(all_matches[price_col_b], errors='coerce')
        all_matches['ä»·æ ¼ä¼˜åŠ¿ç‡'] = (all_matches['ä»·æ ¼å·®å¼‚'] / pd.to_numeric(all_matches[price_col_b], errors='coerce')) * 100
        
        # å®šä¹‰ä»·æ ¼åŒºé—´
        all_matches['ä»·æ ¼åŒºé—´'] = pd.cut(
            pd.to_numeric(all_matches[price_col_a], errors='coerce'), 
            bins=[0, 10, 30, 50, 100, float('inf')], 
            labels=['ä½ä»·(<10å…ƒ)', 'ä¸­ä½ä»·(10-30å…ƒ)', 'ä¸­ä»·(30-50å…ƒ)', 'ä¸­é«˜ä»·(50-100å…ƒ)', 'é«˜ä»·(>100å…ƒ)']
        )
        
        # æŒ‰åˆ†ç±»å’Œä»·æ ¼åŒºé—´èšåˆ
        heatmap_data = all_matches.groupby([category_col, 'ä»·æ ¼åŒºé—´']).agg({
            'ä»·æ ¼ä¼˜åŠ¿ç‡': 'mean',
            price_col_a: 'count'
        }).reset_index()
        
        # åˆ›å»ºé€è§†è¡¨ç”¨äºçƒ­åŠ›å›¾
        pivot_data = heatmap_data.pivot(index=category_col, columns='ä»·æ ¼åŒºé—´', values='ä»·æ ¼ä¼˜åŠ¿ç‡')
        
        if not pivot_data.empty:
            fig = px.imshow(
                pivot_data.values,
                x=pivot_data.columns,
                y=pivot_data.index,
                color_continuous_scale='RdYlGn',
                title="ä»·æ ¼ç«äº‰åŠ›çƒ­åŠ›å›¾ (ç»¿è‰²=æœ‰ä¼˜åŠ¿ï¼Œçº¢è‰²=å¤„åŠ£åŠ¿)",
                labels={'color': 'ä»·æ ¼ä¼˜åŠ¿ç‡(%)'}
            )
            
            fig.update_layout(
                height=max(400, len(pivot_data.index) * 30),
                xaxis_title="ä»·æ ¼åŒºé—´",
                yaxis_title="å•†å“åˆ†ç±»"
            )
            
            st.plotly_chart(fig, use_container_width=True)
            
            # æ˜¾ç¤ºæ•°æ®è¡¨
            with st.expander("ğŸ“Š è¯¦ç»†æ•°æ®"):
                display_data = heatmap_data.copy()
                display_data['ä»·æ ¼ä¼˜åŠ¿ç‡'] = display_data['ä»·æ ¼ä¼˜åŠ¿ç‡'].round(2)
                display_data = display_data.rename(columns={price_col_a: 'å•†å“æ•°é‡'})
                st.dataframe(display_data, use_container_width=True)
        else:
            st.info("æ•°æ®ä¸è¶³ä»¥ç”Ÿæˆçƒ­åŠ›å›¾")
            
    except Exception as e:
        st.error(f"ç”Ÿæˆä»·æ ¼ç«äº‰åŠ›çƒ­åŠ›å›¾æ—¶å‡ºé”™: {str(e)}")


def render_price_tier_analysis(all_matches: pd.DataFrame, stores: List[Dict]) -> None:
    """æ¸²æŸ“ä»·æ ¼åˆ†å±‚åˆ†æ"""
    st.write("**ğŸ“Š ä»·æ ¼åˆ†å±‚ç«äº‰åˆ†æ**")
    
    try:
        price_cols = [col for col in all_matches.columns if 'å”®ä»·' in col or 'ä»·æ ¼' in col]
        
        if len(price_cols) < 2:
            st.info("æ•°æ®ä¸­ç¼ºå°‘è¶³å¤Ÿçš„ä»·æ ¼ä¿¡æ¯")
            return
        
        price_col_a = price_cols[0]
        price_col_b = price_cols[1]
        
        # æ•°æ®å¤„ç†
        df = all_matches.copy()
        df[price_col_a] = pd.to_numeric(df[price_col_a], errors='coerce')
        df[price_col_b] = pd.to_numeric(df[price_col_b], errors='coerce')
        df = df.dropna(subset=[price_col_a, price_col_b])
        
        # å®šä¹‰ä»·æ ¼åˆ†å±‚
        df['ä»·æ ¼åˆ†å±‚_A'] = pd.cut(df[price_col_a], bins=[0, 10, 30, 50, 100, float('inf')], 
                              labels=['ä½ä»·', 'ä¸­ä½ä»·', 'ä¸­ä»·', 'ä¸­é«˜ä»·', 'é«˜ä»·'])
        df['ä»·æ ¼åˆ†å±‚_B'] = pd.cut(df[price_col_b], bins=[0, 10, 30, 50, 100, float('inf')], 
                              labels=['ä½ä»·', 'ä¸­ä½ä»·', 'ä¸­ä»·', 'ä¸­é«˜ä»·', 'é«˜ä»·'])
        
        col1, col2 = st.columns(2)
        
        with col1:
            # ä»·æ ¼åˆ†å±‚åˆ†å¸ƒå¯¹æ¯”
            tier_counts_a = df['ä»·æ ¼åˆ†å±‚_A'].value_counts()
            tier_counts_b = df['ä»·æ ¼åˆ†å±‚_B'].value_counts()
            
            fig = go.Figure()
            
            store_name_a = stores[0].get('display_name', 'åº—é“ºA') if stores else 'åº—é“ºA'
            store_name_b = stores[1].get('display_name', 'åº—é“ºB') if len(stores) > 1 else 'åº—é“ºB'
            
            fig.add_trace(go.Bar(
                name=store_name_a,
                x=tier_counts_a.index,
                y=tier_counts_a.values,
                marker_color='lightblue'
            ))
            
            fig.add_trace(go.Bar(
                name=store_name_b,
                x=tier_counts_b.index,
                y=tier_counts_b.values,
                marker_color='lightcoral'
            ))
            
            fig.update_layout(
                title='ä»·æ ¼åˆ†å±‚åˆ†å¸ƒå¯¹æ¯”',
                xaxis_title='ä»·æ ¼åˆ†å±‚',
                yaxis_title='å•†å“æ•°é‡',
                barmode='group'
            )
            
            st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            # ä»·æ ¼å·®å¼‚ç®±çº¿å›¾
            df['ä»·æ ¼å·®å¼‚'] = df[price_col_a] - df[price_col_b]
            
            fig = px.box(
                df, 
                x='ä»·æ ¼åˆ†å±‚_A', 
                y='ä»·æ ¼å·®å¼‚',
                title='å„ä»·æ ¼åˆ†å±‚çš„ä»·æ ¼å·®å¼‚åˆ†å¸ƒ',
                labels={'ä»·æ ¼åˆ†å±‚_A': 'ä»·æ ¼åˆ†å±‚', 'ä»·æ ¼å·®å¼‚': 'ä»·æ ¼å·®å¼‚(å…ƒ)'}
            )
            
            fig.add_hline(y=0, line_dash="dash", line_color="red", 
                         annotation_text="ä»·æ ¼æŒå¹³çº¿")
            
            st.plotly_chart(fig, use_container_width=True)
        
        # ä»·æ ¼ä¼˜åŠ¿ç»Ÿè®¡
        st.write("**ğŸ“ˆ ä»·æ ¼ä¼˜åŠ¿ç»Ÿè®¡**")
        
        df['ä»·æ ¼ä¼˜åŠ¿'] = df['ä»·æ ¼å·®å¼‚'].apply(lambda x: 'æˆ‘æ–¹ä¼˜åŠ¿' if x < 0 else 'å¯¹æ‰‹ä¼˜åŠ¿' if x > 0 else 'ä»·æ ¼ç›¸ç­‰')
        
        advantage_stats = df.groupby(['ä»·æ ¼åˆ†å±‚_A', 'ä»·æ ¼ä¼˜åŠ¿']).size().unstack(fill_value=0)
        
        if not advantage_stats.empty:
            # è®¡ç®—ä¼˜åŠ¿æ¯”ä¾‹
            advantage_pct = advantage_stats.div(advantage_stats.sum(axis=1), axis=0) * 100
            
            fig = px.bar(
                advantage_pct.reset_index(),
                x='ä»·æ ¼åˆ†å±‚_A',
                y=['æˆ‘æ–¹ä¼˜åŠ¿', 'å¯¹æ‰‹ä¼˜åŠ¿', 'ä»·æ ¼ç›¸ç­‰'] if all(col in advantage_pct.columns for col in ['æˆ‘æ–¹ä¼˜åŠ¿', 'å¯¹æ‰‹ä¼˜åŠ¿', 'ä»·æ ¼ç›¸ç­‰']) else advantage_pct.columns,
                title='å„ä»·æ ¼åˆ†å±‚çš„ç«äº‰ä¼˜åŠ¿å æ¯”',
                labels={'value': 'å æ¯”(%)', 'ä»·æ ¼åˆ†å±‚_A': 'ä»·æ ¼åˆ†å±‚'}
            )
            
            st.plotly_chart(fig, use_container_width=True)
        
    except Exception as e:
        st.error(f"ç”Ÿæˆä»·æ ¼åˆ†å±‚åˆ†ææ—¶å‡ºé”™: {str(e)}")


def render_match_quality_analysis(all_matches: pd.DataFrame, price_panel_payload: Dict[str, Any]) -> None:
    """æ¸²æŸ“åŒ¹é…è´¨é‡åˆ†æ"""
    st.write("**ğŸ¯ å•†å“åŒ¹é…è´¨é‡åˆ†æ**")
    
    try:
        col1, col2 = st.columns(2)
        
        with col1:
            # åŒ¹é…ç±»å‹è´¨é‡åˆ†å¸ƒ
            if 'åŒ¹é…ç±»å‹' in all_matches.columns:
                match_type_counts = all_matches['åŒ¹é…ç±»å‹'].value_counts()
                
                fig = px.pie(
                    values=match_type_counts.values,
                    names=match_type_counts.index,
                    title="åŒ¹é…æ–¹å¼åˆ†å¸ƒ",
                    color_discrete_sequence=['#2E8B57', '#4682B4', '#DC143C']
                )
                
                st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            # åŒ¹é…ç½®ä¿¡åº¦åˆ†æï¼ˆå¦‚æœæœ‰ç›¸ä¼¼åº¦æ•°æ®ï¼‰
            similarity_cols = [col for col in all_matches.columns if 'ç›¸ä¼¼åº¦' in col or 'ç½®ä¿¡åº¦' in col or 'similarity' in col.lower()]
            
            if similarity_cols:
                similarity_col = similarity_cols[0]
                similarity_data = pd.to_numeric(all_matches[similarity_col], errors='coerce').dropna()
                
                if not similarity_data.empty:
                    fig = px.histogram(
                        x=similarity_data,
                        title="åŒ¹é…ç½®ä¿¡åº¦åˆ†å¸ƒ",
                        labels={'x': 'ç½®ä¿¡åº¦', 'y': 'å•†å“æ•°é‡'},
                        nbins=20
                    )
                    
                    fig.add_vline(x=0.8, line_dash="dash", line_color="green", 
                                 annotation_text="é«˜è´¨é‡åŒ¹é…çº¿(0.8)")
                    fig.add_vline(x=0.6, line_dash="dash", line_color="orange", 
                                 annotation_text="ä¸­ç­‰è´¨é‡åŒ¹é…çº¿(0.6)")
                    
                    st.plotly_chart(fig, use_container_width=True)
                else:
                    st.info("æš‚æ— æœ‰æ•ˆçš„ç½®ä¿¡åº¦æ•°æ®")
            else:
                # åŸºäºåŒ¹é…ç±»å‹çš„è´¨é‡è¯„ä¼°
                quality_map = {'æ¡ç ç²¾ç¡®åŒ¹é…': 'é«˜è´¨é‡', 'åç§°æ¨¡ç³ŠåŒ¹é…': 'ä¸­ç­‰è´¨é‡'}
                all_matches['åŒ¹é…è´¨é‡'] = all_matches['åŒ¹é…ç±»å‹'].map(quality_map)
                
                quality_counts = all_matches['åŒ¹é…è´¨é‡'].value_counts()
                
                fig = px.bar(
                    x=quality_counts.index,
                    y=quality_counts.values,
                    title="åŒ¹é…è´¨é‡åˆ†å¸ƒ",
                    color=quality_counts.values,
                    color_continuous_scale='Viridis'
                )
                
                st.plotly_chart(fig, use_container_width=True)
        
        # æœªåŒ¹é…åŸå› åˆ†æ
        st.write("**ğŸ“‹ æœªåŒ¹é…å•†å“åˆ†æ**")
        
        sheets_data = price_panel_payload.get("sheets_data", {})
        
        # è·å–ç‹¬æœ‰å•†å“æ•°æ®
        unique_products = []
        for sheet_name, df in sheets_data.items():
            if 'ç‹¬æœ‰å•†å“' in sheet_name and not df.empty:
                unique_products.append({
                    'sheet': sheet_name,
                    'count': len(df),
                    'store': sheet_name.split('-')[1] if '-' in sheet_name else sheet_name
                })
        
        if unique_products:
            unique_df = pd.DataFrame(unique_products)
            
            fig = px.bar(
                unique_df,
                x='store',
                y='count',
                title='å„åº—é“ºç‹¬æœ‰å•†å“æ•°é‡',
                color='count',
                color_continuous_scale='Reds'
            )
            
            st.plotly_chart(fig, use_container_width=True)
            
            # æ˜¾ç¤ºæœªåŒ¹é…åŸå› åˆ†æ
            with st.expander("ğŸ” å¯èƒ½çš„æœªåŒ¹é…åŸå› "):
                st.markdown("""
                **å¸¸è§æœªåŒ¹é…åŸå› ï¼š**
                - ğŸ·ï¸ **å•†å“åç§°å·®å¼‚**ï¼šåŒä¸€å•†å“åœ¨ä¸åŒå¹³å°ä½¿ç”¨ä¸åŒåç§°
                - ğŸ“¦ **è§„æ ¼æè¿°ä¸ä¸€è‡´**ï¼šåŒ…è£…è§„æ ¼ã€å®¹é‡æè¿°æ–¹å¼ä¸åŒ
                - ğŸª **ç‹¬å®¶å•†å“**ï¼šæŸåº—é“ºç‹¬æœ‰çš„å•†å“æˆ–å“ç‰Œ
                - ğŸ“Š **åˆ†ç±»ä½“ç³»å·®å¼‚**ï¼šä¸åŒå¹³å°çš„å•†å“åˆ†ç±»æ ‡å‡†ä¸åŒ
                - ğŸ”¢ **æ¡ç ç¼ºå¤±**ï¼šéƒ¨åˆ†å•†å“ç¼ºå°‘æ ‡å‡†æ¡ç ä¿¡æ¯
                
                **å»ºè®®æ”¹è¿›æªæ–½ï¼š**
                - å®Œå–„å•†å“ä¸»æ•°æ®ç®¡ç†
                - ç»Ÿä¸€å•†å“å‘½åè§„èŒƒ
                - è¡¥å……ç¼ºå¤±çš„æ¡ç ä¿¡æ¯
                - å»ºç«‹åˆ†ç±»æ˜ å°„å…³ç³»
                """)
        
    except Exception as e:
        st.error(f"ç”ŸæˆåŒ¹é…è´¨é‡åˆ†ææ—¶å‡ºé”™: {str(e)}")


def render_inventory_price_analysis(all_matches: pd.DataFrame, stores: List[Dict]) -> None:
    """æ¸²æŸ“åº“å­˜-ä»·æ ¼å…³ç³»åˆ†æ"""
    st.write("**ğŸ“ˆ åº“å­˜ä¸ä»·æ ¼ç­–ç•¥åˆ†æ**")
    
    try:
        # å¯»æ‰¾åº“å­˜å’Œä»·æ ¼ç›¸å…³åˆ—
        inventory_cols = [col for col in all_matches.columns if 'åº“å­˜' in col or 'åº“å­˜é‡' in col or 'stock' in col.lower()]
        price_cols = [col for col in all_matches.columns if 'å”®ä»·' in col or 'ä»·æ ¼' in col]
        sales_cols = [col for col in all_matches.columns if 'é”€é‡' in col or 'æœˆå”®' in col or 'sales' in col.lower()]
        
        if not inventory_cols or len(price_cols) < 2:
            st.info("æ•°æ®ä¸­ç¼ºå°‘åº“å­˜æˆ–ä»·æ ¼ä¿¡æ¯ï¼Œæ— æ³•è¿›è¡Œåº“å­˜-ä»·æ ¼åˆ†æ")
            return
        
        inventory_col = inventory_cols[0]
        price_col_a = price_cols[0]
        price_col_b = price_cols[1] if len(price_cols) > 1 else price_cols[0]
        
        # æ•°æ®å¤„ç†
        df = all_matches.copy()
        df[inventory_col] = pd.to_numeric(df[inventory_col], errors='coerce')
        df[price_col_a] = pd.to_numeric(df[price_col_a], errors='coerce')
        df[price_col_b] = pd.to_numeric(df[price_col_b], errors='coerce')
        df = df.dropna(subset=[inventory_col, price_col_a, price_col_b])
        
        if df.empty:
            st.info("å¤„ç†åæ— æœ‰æ•ˆæ•°æ®")
            return
        
        df['ä»·æ ¼å·®å¼‚'] = df[price_col_a] - df[price_col_b]
        
        col1, col2 = st.columns(2)
        
        with col1:
            # åº“å­˜-ä»·æ ¼æ•£ç‚¹å›¾
            fig = px.scatter(
                df,
                x=inventory_col,
                y=price_col_a,
                size='ä»·æ ¼å·®å¼‚' if 'ä»·æ ¼å·®å¼‚' in df.columns else None,
                color='ä»·æ ¼å·®å¼‚',
                title='åº“å­˜é‡ä¸ä»·æ ¼å…³ç³»',
                labels={inventory_col: 'åº“å­˜é‡', price_col_a: 'æˆ‘æ–¹ä»·æ ¼(å…ƒ)'},
                color_continuous_scale='RdYlGn_r'
            )
            
            st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            # åº“å­˜é¢„è­¦åˆ†æ
            if sales_cols:
                sales_col = sales_cols[0]
                df[sales_col] = pd.to_numeric(df[sales_col], errors='coerce')
                df = df.dropna(subset=[sales_col])
                
                # è®¡ç®—åº“é”€æ¯”
                df['åº“é”€æ¯”'] = df[inventory_col] / (df[sales_col] + 1)  # +1é¿å…é™¤é›¶
                
                # å®šä¹‰é¢„è­¦ç­‰çº§
                def get_warning_level(row):
                    if row['åº“é”€æ¯”'] < 0.5:
                        return 'é«˜é£é™©'
                    elif row['åº“é”€æ¯”'] < 1.0:
                        return 'ä¸­é£é™©'
                    elif row['åº“é”€æ¯”'] < 2.0:
                        return 'ä½é£é™©'
                    else:
                        return 'å®‰å…¨'
                
                df['é¢„è­¦ç­‰çº§'] = df.apply(get_warning_level, axis=1)
                
                warning_counts = df['é¢„è­¦ç­‰çº§'].value_counts()
                
                fig = px.pie(
                    values=warning_counts.values,
                    names=warning_counts.index,
                    title="åº“å­˜é¢„è­¦ç­‰çº§åˆ†å¸ƒ",
                    color_discrete_map={
                        'é«˜é£é™©': '#DC143C',
                        'ä¸­é£é™©': '#FF8C00',
                        'ä½é£é™©': '#32CD32',
                        'å®‰å…¨': '#228B22'
                    }
                )
                
                st.plotly_chart(fig, use_container_width=True)
            else:
                # åº“å­˜æ°´å¹³åˆ†å¸ƒ
                df['åº“å­˜æ°´å¹³'] = pd.cut(df[inventory_col], 
                                    bins=[0, 10, 50, 100, 500, float('inf')],
                                    labels=['æä½åº“å­˜', 'ä½åº“å­˜', 'ä¸­ç­‰åº“å­˜', 'é«˜åº“å­˜', 'è¿‡é‡åº“å­˜'])
                
                inventory_dist = df['åº“å­˜æ°´å¹³'].value_counts()
                
                fig = px.bar(
                    x=inventory_dist.index,
                    y=inventory_dist.values,
                    title='åº“å­˜æ°´å¹³åˆ†å¸ƒ',
                    color=inventory_dist.values,
                    color_continuous_scale='Blues'
                )
                
                st.plotly_chart(fig, use_container_width=True)
        
        # é«˜é£é™©å•†å“æé†’
        if sales_cols and 'é¢„è­¦ç­‰çº§' in df.columns:
            high_risk_products = df[df['é¢„è­¦ç­‰çº§'] == 'é«˜é£é™©']
            
            if not high_risk_products.empty:
                st.warning(f"âš ï¸ å‘ç° {len(high_risk_products)} ä¸ªé«˜é£é™©å•†å“ï¼ˆåº“å­˜ä¸è¶³ï¼‰")
                
                with st.expander("æŸ¥çœ‹é«˜é£é™©å•†å“è¯¦æƒ…"):
                    risk_display = high_risk_products[['å•†å“åç§°', inventory_col, sales_col, 'åº“é”€æ¯”', 'ä»·æ ¼å·®å¼‚']].copy() if 'å•†å“åç§°' in high_risk_products.columns else high_risk_products[[inventory_col, sales_col, 'åº“é”€æ¯”', 'ä»·æ ¼å·®å¼‚']].copy()
                    risk_display = risk_display.round(2)
                    st.dataframe(risk_display, use_container_width=True)
        
    except Exception as e:
        st.error(f"ç”Ÿæˆåº“å­˜-ä»·æ ¼åˆ†ææ—¶å‡ºé”™: {str(e)}")


def render_competitive_advantage_analysis(all_matches: pd.DataFrame, sheets_data: Dict, stores: List[Dict]) -> None:
    """æ¸²æŸ“ç«äº‰ä¼˜åŠ¿åˆ†æ"""
    st.write("**ğŸ† ç»¼åˆç«äº‰ä¼˜åŠ¿åˆ†æ**")
    
    try:
        price_cols = [col for col in all_matches.columns if 'å”®ä»·' in col or 'ä»·æ ¼' in col]
        
        if len(price_cols) < 2:
            st.info("æ•°æ®ä¸­ç¼ºå°‘è¶³å¤Ÿçš„ä»·æ ¼ä¿¡æ¯")
            return
        
        price_col_a = price_cols[0]
        price_col_b = price_cols[1]
        
        # æ•°æ®å¤„ç†
        df = all_matches.copy()
        df[price_col_a] = pd.to_numeric(df[price_col_a], errors='coerce')
        df[price_col_b] = pd.to_numeric(df[price_col_b], errors='coerce')
        df = df.dropna(subset=[price_col_a, price_col_b])
        
        # è®¡ç®—ç«äº‰æŒ‡æ ‡
        df['ä»·æ ¼å·®å¼‚'] = df[price_col_a] - df[price_col_b]
        df['ä»·æ ¼ä¼˜åŠ¿ç‡'] = (df['ä»·æ ¼å·®å¼‚'] / df[price_col_b]) * 100
        
        store_name_a = stores[0].get('display_name', 'åº—é“ºA') if stores else 'åº—é“ºA'
        store_name_b = stores[1].get('display_name', 'åº—é“ºB') if len(stores) > 1 else 'åº—é“ºB'
        
        col1, col2 = st.columns(2)
        
        with col1:
            # ä»·æ ¼ä¼˜åŠ¿åˆ†å¸ƒ
            df['ç«äº‰çŠ¶æ€'] = df['ä»·æ ¼ä¼˜åŠ¿ç‡'].apply(
                lambda x: f'{store_name_a}æ˜¾è‘—ä¼˜åŠ¿' if x < -10 
                else f'{store_name_a}è½»å¾®ä¼˜åŠ¿' if x < 0 
                else 'ä»·æ ¼ç›¸å½“' if abs(x) < 5 
                else f'{store_name_b}è½»å¾®ä¼˜åŠ¿' if x < 10 
                else f'{store_name_b}æ˜¾è‘—ä¼˜åŠ¿'
            )
            
            competitive_dist = df['ç«äº‰çŠ¶æ€'].value_counts()
            
            colors = {
                f'{store_name_a}æ˜¾è‘—ä¼˜åŠ¿': '#228B22',
                f'{store_name_a}è½»å¾®ä¼˜åŠ¿': '#90EE90',
                'ä»·æ ¼ç›¸å½“': '#FFD700',
                f'{store_name_b}è½»å¾®ä¼˜åŠ¿': '#FFA07A',
                f'{store_name_b}æ˜¾è‘—ä¼˜åŠ¿': '#DC143C'
            }
            
            fig = px.pie(
                values=competitive_dist.values,
                names=competitive_dist.index,
                title='ç«äº‰ä¼˜åŠ¿åˆ†å¸ƒ',
                color=competitive_dist.index,
                color_discrete_map=colors
            )
            
            st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            # åˆ†ç±»åˆ«ç«äº‰ä¼˜åŠ¿
            category_cols = [col for col in df.columns if 'åˆ†ç±»' in col]
            
            if category_cols:
                category_col = category_cols[0]
                
                category_advantage = df.groupby(category_col).agg({
                    'ä»·æ ¼ä¼˜åŠ¿ç‡': 'mean',
                    price_col_a: 'count'
                }).reset_index()
                
                category_advantage = category_advantage.rename(columns={price_col_a: 'å•†å“æ•°é‡'})
                category_advantage['ä¼˜åŠ¿æ–¹'] = category_advantage['ä»·æ ¼ä¼˜åŠ¿ç‡'].apply(
                    lambda x: store_name_a if x < 0 else store_name_b
                )
                
                fig = px.bar(
                    category_advantage,
                    x=category_col,
                    y='ä»·æ ¼ä¼˜åŠ¿ç‡',
                    color='ä¼˜åŠ¿æ–¹',
                    title='å„åˆ†ç±»ä»·æ ¼ä¼˜åŠ¿å¯¹æ¯”',
                    color_discrete_map={
                        store_name_a: '#1f77b4',
                        store_name_b: '#ff7f0e'
                    }
                )
                
                fig.add_hline(y=0, line_dash="dash", line_color="black", annotation_text="å¹³è¡¡çº¿")
                
                st.plotly_chart(fig, use_container_width=True)
            else:
                # ä»·æ ¼ä¼˜åŠ¿ç‡åˆ†å¸ƒç›´æ–¹å›¾
                fig = px.histogram(
                    df,
                    x='ä»·æ ¼ä¼˜åŠ¿ç‡',
                    title='ä»·æ ¼ä¼˜åŠ¿ç‡åˆ†å¸ƒ',
                    labels={'ä»·æ ¼ä¼˜åŠ¿ç‡': 'ä»·æ ¼ä¼˜åŠ¿ç‡(%)', 'count': 'å•†å“æ•°é‡'},
                    nbins=30
                )
                
                fig.add_vline(x=0, line_dash="dash", line_color="black", annotation_text="å¹³è¡¡çº¿")
                fig.add_vline(x=-10, line_dash="dash", line_color="green", annotation_text="æ˜¾è‘—ä¼˜åŠ¿çº¿")
                fig.add_vline(x=10, line_dash="dash", line_color="red", annotation_text="æ˜¾è‘—åŠ£åŠ¿çº¿")
                
                st.plotly_chart(fig, use_container_width=True)
        
        # ç«äº‰ç­–ç•¥å»ºè®®
        st.subheader("ğŸ’¡ ç«äº‰ç­–ç•¥å»ºè®®")
        
        # è®¡ç®—å…³é”®æŒ‡æ ‡
        total_products = len(df)
        our_advantage = len(df[df['ä»·æ ¼ä¼˜åŠ¿ç‡'] < -5])
        competitor_advantage = len(df[df['ä»·æ ¼ä¼˜åŠ¿ç‡'] > 5])
        similar_price = total_products - our_advantage - competitor_advantage
        
        our_advantage_rate = our_advantage / total_products * 100
        competitor_advantage_rate = competitor_advantage / total_products * 100
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric(
                f"{store_name_a}ä¼˜åŠ¿å•†å“",
                f"{our_advantage} ä¸ª",
                delta=f"{our_advantage_rate:.1f}%",
                delta_color="normal"
            )
        
        with col2:
            st.metric(
                "ä»·æ ¼ç›¸å½“å•†å“",
                f"{similar_price} ä¸ª",
                delta=f"{similar_price/total_products*100:.1f}%",
                delta_color="off"
            )
        
        with col3:
            st.metric(
                f"{store_name_b}ä¼˜åŠ¿å•†å“",
                f"{competitor_advantage} ä¸ª",
                delta=f"{competitor_advantage_rate:.1f}%",
                delta_color="inverse"
            )
        
        # ç­–ç•¥å»ºè®®
        if our_advantage_rate > 50:
            st.success(f"ğŸ‰ æ•´ä½“ä»·æ ¼ç«äº‰åŠ›è¾ƒå¼ºï¼åœ¨ {our_advantage_rate:.1f}% çš„å•†å“ä¸Šå…·æœ‰ä»·æ ¼ä¼˜åŠ¿")
        elif our_advantage_rate > 30:
            st.info(f"ğŸ’ª ä»·æ ¼ç«äº‰åŠ›ä¸­ç­‰ï¼Œå»ºè®®é‡ç‚¹å…³æ³¨ {store_name_b} ä¼˜åŠ¿å•†å“çš„å®šä»·ç­–ç•¥")
        else:
            st.warning(f"âš ï¸ ä»·æ ¼ç«äº‰åŠ›è¾ƒå¼±ï¼Œå»ºè®®å…¨é¢å®¡è§†å®šä»·ç­–ç•¥ï¼Œç‰¹åˆ«æ˜¯ {competitor_advantage} ä¸ªåŠ£åŠ¿å•†å“")
        
        # å…·ä½“å»ºè®®
        with st.expander("ğŸ“‹ è¯¦ç»†ç­–ç•¥å»ºè®®"):
            if our_advantage_rate > 40:
                st.markdown(f"""
                **ğŸ¯ ç»´æŒä¼˜åŠ¿ç­–ç•¥ï¼š**
                - ä¿æŒç°æœ‰ {our_advantage} ä¸ªä¼˜åŠ¿å•†å“çš„ä»·æ ¼ç«äº‰åŠ›
                - é€‚å½“æå‡ä¼˜åŠ¿å•†å“çš„æ¯›åˆ©ç‡
                - é‡ç‚¹æ¨å¹¿ä»·æ ¼ä¼˜åŠ¿å•†å“ï¼Œæå‡é”€é‡
                """)
            
            if competitor_advantage > 0:
                st.markdown(f"""
                **âš¡ åŠ£åŠ¿æ”¹è¿›ç­–ç•¥ï¼š**
                - ç´§æ€¥è°ƒæ•´ {competitor_advantage} ä¸ªåŠ£åŠ¿å•†å“å®šä»·
                - åˆ†ææˆæœ¬ç»“æ„ï¼Œå¯»æ‰¾é™ä»·ç©ºé—´
                - è€ƒè™‘æ†ç»‘é”€å”®æˆ–ä¿ƒé”€æ´»åŠ¨
                """)
            
            if similar_price > 0:
                st.markdown(f"""
                **ğŸ”„ å‡åŠ¿å•†å“ç­–ç•¥ï¼š**
                - é€šè¿‡æœåŠ¡å·®å¼‚åŒ–è·å¾—ç«äº‰ä¼˜åŠ¿
                - è€ƒè™‘å°å¹…è°ƒä»·æµ‹è¯•å¸‚åœºååº”
                - å…³æ³¨åº“å­˜å’Œé”€é‡æƒ…å†µï¼Œä¼˜åŒ–å•†å“ç»„åˆ
                """)
        
    except Exception as e:
        st.error(f"ç”Ÿæˆç«äº‰ä¼˜åŠ¿åˆ†ææ—¶å‡ºé”™: {str(e)}")


def generate_insight_report(price_panel_payload: Dict[str, Any]) -> None:
    """ç”Ÿæˆæ™ºèƒ½æ´å¯ŸæŠ¥å‘Š"""
    try:
        st.subheader("ğŸ¯ æ™ºèƒ½æ´å¯ŸæŠ¥å‘Š")
        
        sheets_data = price_panel_payload.get("sheets_data", {})
        stores = price_panel_payload.get("stores", [])
        metrics = price_panel_payload.get("metrics", [])
        summary = price_panel_payload.get("summary", {})
        
        # è·å–åŸºç¡€æ•°æ®
        barcode_matches = sheets_data.get('1-æ¡ç ç²¾ç¡®åŒ¹é…', pd.DataFrame())
        name_matches = sheets_data.get('2-åç§°æ¨¡ç³ŠåŒ¹é…(æ— æ¡ç )', pd.DataFrame())
        
        store_name_a = stores[0].get('display_name', 'åº—é“ºA') if stores else 'åº—é“ºA'
        store_name_b = stores[1].get('display_name', 'åº—é“ºB') if len(stores) > 1 else 'åº—é“ºB'
        
        # åˆå¹¶åŒ¹é…æ•°æ®è¿›è¡Œåˆ†æ
        all_matches = pd.DataFrame()
        if not barcode_matches.empty:
            all_matches = pd.concat([all_matches, barcode_matches], ignore_index=True)
        if not name_matches.empty:
            all_matches = pd.concat([all_matches, name_matches], ignore_index=True)
        
        report_content = []
        
        # 1. æ‰§è¡Œæ‘˜è¦
        report_content.append("## ğŸ“‹ æ‰§è¡Œæ‘˜è¦")
        
        total_matches = len(all_matches)
        barcode_match_count = len(barcode_matches)
        name_match_count = len(name_matches)
        coverage = summary.get("comparison_coverage", 0)
        
        report_content.append(f"""
**æ¯”ä»·æ¦‚å†µï¼š**
- æˆåŠŸåŒ¹é…å•†å“ **{total_matches:,}** ä¸ªï¼Œè¦†ç›–ç‡ **{coverage:.1%}**
- æ¡ç ç²¾ç¡®åŒ¹é… **{barcode_match_count:,}** ä¸ªï¼Œåç§°æ¨¡ç³ŠåŒ¹é… **{name_match_count:,}** ä¸ª
- æ•°æ®è´¨é‡è¯„ä¼°ï¼š{'ä¼˜ç§€' if coverage > 0.8 else 'è‰¯å¥½' if coverage > 0.6 else 'å¾…æ”¹å–„'}
        """)
        
        # 2. ä»·æ ¼ç«äº‰åŠ›åˆ†æ
        if not all_matches.empty:
            price_cols = [col for col in all_matches.columns if 'å”®ä»·' in col or 'ä»·æ ¼' in col]
            
            if len(price_cols) >= 2:
                price_col_a = price_cols[0]
                price_col_b = price_cols[1]
                
                # ä»·æ ¼åˆ†æ
                df = all_matches.copy()
                df[price_col_a] = pd.to_numeric(df[price_col_a], errors='coerce')
                df[price_col_b] = pd.to_numeric(df[price_col_b], errors='coerce')
                df = df.dropna(subset=[price_col_a, price_col_b])
                
                if not df.empty:
                    df['ä»·æ ¼å·®å¼‚'] = df[price_col_a] - df[price_col_b]
                    df['ä»·æ ¼ä¼˜åŠ¿ç‡'] = (df['ä»·æ ¼å·®å¼‚'] / df[price_col_b]) * 100
                    
                    our_advantage_count = len(df[df['ä»·æ ¼ä¼˜åŠ¿ç‡'] < -5])
                    competitor_advantage_count = len(df[df['ä»·æ ¼ä¼˜åŠ¿ç‡'] > 5])
                    similar_price_count = len(df) - our_advantage_count - competitor_advantage_count
                    
                    our_advantage_rate = our_advantage_count / len(df) * 100
                    avg_price_advantage = df['ä»·æ ¼ä¼˜åŠ¿ç‡'].mean()
                    
                    report_content.append("## ğŸ’° ä»·æ ¼ç«äº‰åŠ›åˆ†æ")
                    
                    competitive_status = ""
                    if our_advantage_rate > 50:
                        competitive_status = "ğŸŸ¢ **ä»·æ ¼ç«äº‰åŠ›å¼º**"
                    elif our_advantage_rate > 30:
                        competitive_status = "ğŸŸ¡ **ä»·æ ¼ç«äº‰åŠ›ä¸­ç­‰**"
                    else:
                        competitive_status = "ğŸ”´ **ä»·æ ¼ç«äº‰åŠ›è¾ƒå¼±**"
                    
                    report_content.append(f"""
**ç«äº‰åŠ›è¯„ä¼°ï¼š** {competitive_status}

**è¯¦ç»†æŒ‡æ ‡ï¼š**
- {store_name_a}ä¼˜åŠ¿å•†å“ï¼š**{our_advantage_count:,}** ä¸ª ({our_advantage_rate:.1f}%)
- {store_name_b}ä¼˜åŠ¿å•†å“ï¼š**{competitor_advantage_count:,}** ä¸ª ({competitor_advantage_count/len(df)*100:.1f}%)
- ä»·æ ¼ç›¸å½“å•†å“ï¼š**{similar_price_count:,}** ä¸ª ({similar_price_count/len(df)*100:.1f}%)
- å¹³å‡ä»·æ ¼ä¼˜åŠ¿ç‡ï¼š**{avg_price_advantage:.1f}%** {'(æˆ‘æ–¹å ä¼˜)' if avg_price_advantage < 0 else '(å¯¹æ‰‹å ä¼˜)' if avg_price_advantage > 0 else '(åŠ¿å‡åŠ›æ•Œ)'}
                    """)
        
        # 3. åˆ†ç±»ç«äº‰åˆ†æ
        if not all_matches.empty:
            category_cols = [col for col in all_matches.columns if 'åˆ†ç±»' in col]
            
            if category_cols and len(price_cols) >= 2:
                category_col = category_cols[0]
                
                category_analysis = df.groupby(category_col).agg({
                    'ä»·æ ¼ä¼˜åŠ¿ç‡': ['mean', 'count'],
                    price_col_a: 'mean'
                }).round(2)
                
                category_analysis.columns = ['å¹³å‡ä¼˜åŠ¿ç‡', 'å•†å“æ•°é‡', 'å¹³å‡ä»·æ ¼']
                category_analysis = category_analysis.reset_index()
                category_analysis['ç«äº‰çŠ¶æ€'] = category_analysis['å¹³å‡ä¼˜åŠ¿ç‡'].apply(
                    lambda x: f'{store_name_a}ä¼˜åŠ¿' if x < -5 else f'{store_name_b}ä¼˜åŠ¿' if x > 5 else 'åŠ¿å‡åŠ›æ•Œ'
                )
                
                report_content.append("## ğŸ“Š åˆ†ç±»ç«äº‰åˆ†æ")
                
                # æ‰¾å‡ºä¼˜åŠ¿å’ŒåŠ£åŠ¿åˆ†ç±»
                our_advantage_categories = category_analysis[category_analysis['å¹³å‡ä¼˜åŠ¿ç‡'] < -5]
                competitor_advantage_categories = category_analysis[category_analysis['å¹³å‡ä¼˜åŠ¿ç‡'] > 5]
                
                if not our_advantage_categories.empty:
                    report_content.append(f"""
**ğŸŸ¢ {store_name_a}ä¼˜åŠ¿åˆ†ç±»ï¼š**
                    """)
                    for _, row in our_advantage_categories.iterrows():
                        report_content.append(f"- **{row[category_col]}**ï¼šä¼˜åŠ¿ç‡ {row['å¹³å‡ä¼˜åŠ¿ç‡']:.1f}%ï¼Œ{row['å•†å“æ•°é‡']} ä¸ªå•†å“")
                
                if not competitor_advantage_categories.empty:
                    report_content.append(f"""
**ğŸ”´ {store_name_b}ä¼˜åŠ¿åˆ†ç±»ï¼š**
                    """)
                    for _, row in competitor_advantage_categories.iterrows():
                        report_content.append(f"- **{row[category_col]}**ï¼šåŠ£åŠ¿ {row['å¹³å‡ä¼˜åŠ¿ç‡']:.1f}%ï¼Œ{row['å•†å“æ•°é‡']} ä¸ªå•†å“")
        
        # 4. åº“å­˜é£é™©é¢„è­¦
        inventory_cols = [col for col in all_matches.columns if 'åº“å­˜' in col]
        sales_cols = [col for col in all_matches.columns if 'é”€é‡' in col or 'æœˆå”®' in col]
        
        if inventory_cols and sales_cols:
            inventory_col = inventory_cols[0]
            sales_col = sales_cols[0]
            
            df[inventory_col] = pd.to_numeric(df[inventory_col], errors='coerce')
            df[sales_col] = pd.to_numeric(df[sales_col], errors='coerce')
            
            inventory_df = df.dropna(subset=[inventory_col, sales_col])
            
            if not inventory_df.empty:
                inventory_df['åº“é”€æ¯”'] = inventory_df[inventory_col] / (inventory_df[sales_col] + 1)
                high_risk_products = inventory_df[inventory_df['åº“é”€æ¯”'] < 0.5]
                low_inventory_products = inventory_df[inventory_df[inventory_col] < 10]
                
                if not high_risk_products.empty or not low_inventory_products.empty:
                    report_content.append("## âš ï¸ åº“å­˜é£é™©é¢„è­¦")
                    
                    if not high_risk_products.empty:
                        report_content.append(f"""
**ğŸ”´ é«˜é£é™©å•†å“ï¼ˆåº“é”€æ¯”<0.5ï¼‰ï¼š** {len(high_risk_products)} ä¸ª
- å»ºè®®ç«‹å³è¡¥è´§æˆ–è°ƒæ•´é”€å”®ç­–ç•¥
                        """)
                    
                    if not low_inventory_products.empty:
                        report_content.append(f"""
**ğŸŸ¡ ä½åº“å­˜å•†å“ï¼ˆåº“å­˜<10ï¼‰ï¼š** {len(low_inventory_products)} ä¸ª
- å»ºè®®å…³æ³¨é”€å”®æƒ…å†µï¼ŒåŠæ—¶è¡¥è´§
                        """)
        
        # 5. ç­–ç•¥å»ºè®®
        report_content.append("## ğŸ’¡ ç­–ç•¥å»ºè®®")
        
        suggestions = []
        
        if not all_matches.empty and len(price_cols) >= 2:
            if our_advantage_rate > 50:
                suggestions.append("ğŸ¯ **ç»´æŒä¼˜åŠ¿ç­–ç•¥**ï¼šä¿æŒç°æœ‰ä»·æ ¼ä¼˜åŠ¿ï¼Œé‡ç‚¹æ¨å¹¿ä¼˜åŠ¿å•†å“")
                suggestions.append("ğŸ“ˆ **æå‡ç›ˆåˆ©**ï¼šé€‚å½“æå‡ä¼˜åŠ¿å•†å“æ¯›åˆ©ç‡ï¼Œå¢åŠ æ•´ä½“æ”¶ç›Š")
            elif our_advantage_rate > 30:
                suggestions.append("âš¡ **é‡ç‚¹æ”¹è¿›**ï¼šå…³æ³¨å¯¹æ‰‹ä¼˜åŠ¿å•†å“ï¼Œåˆ†ææˆæœ¬ç»“æ„å¯»æ‰¾é™ä»·ç©ºé—´")
                suggestions.append("ğŸ”„ **å·®å¼‚åŒ–ç­–ç•¥**ï¼šé€šè¿‡æœåŠ¡ã€å“è´¨ç­‰éä»·æ ¼å› ç´ è·å¾—ç«äº‰ä¼˜åŠ¿")
            else:
                suggestions.append("ğŸš¨ **ç´§æ€¥è°ƒæ•´**ï¼šå…¨é¢å®¡è§†å®šä»·ç­–ç•¥ï¼Œé‡ç‚¹è°ƒæ•´åŠ£åŠ¿å•†å“ä»·æ ¼")
                suggestions.append("ğŸ **ä¿ƒé”€æ´»åŠ¨**ï¼šè€ƒè™‘æ†ç»‘é”€å”®ã€é™æ—¶æŠ˜æ‰£ç­‰ä¿ƒé”€æ‰‹æ®µ")
        
        # åŒ¹é…è´¨é‡å»ºè®®
        if barcode_match_count < total_matches * 0.6:
            suggestions.append("ğŸ“Š **æ•°æ®ä¼˜åŒ–**ï¼šå®Œå–„å•†å“æ¡ç ä¿¡æ¯ï¼Œæå‡åŒ¹é…å‡†ç¡®åº¦")
        
        if coverage < 0.7:
            suggestions.append("ğŸ” **æ‰©å¤§è¦†ç›–**ï¼šå¢åŠ å•†å“å“ç±»ï¼Œå®Œå–„å•†å“ä¸»æ•°æ®ç®¡ç†")
        
        for i, suggestion in enumerate(suggestions, 1):
            report_content.append(f"{i}. {suggestion}")
        
        # 6. æ•°æ®è´¨é‡è¯„ä¼°
        report_content.append("## ğŸ“ˆ æ•°æ®è´¨é‡è¯„ä¼°")
        
        quality_score = 0
        quality_factors = []
        
        # åŒ¹é…ç‡è¯„åˆ†
        if coverage > 0.8:
            quality_score += 25
            quality_factors.append("âœ… åŒ¹é…è¦†ç›–ç‡ä¼˜ç§€")
        elif coverage > 0.6:
            quality_score += 15
            quality_factors.append("ğŸŸ¡ åŒ¹é…è¦†ç›–ç‡è‰¯å¥½")
        else:
            quality_score += 5
            quality_factors.append("âŒ åŒ¹é…è¦†ç›–ç‡å¾…æ”¹å–„")
        
        # ç²¾ç¡®åŒ¹é…ç‡è¯„åˆ†
        if total_matches > 0:
            exact_match_rate = barcode_match_count / total_matches
            if exact_match_rate > 0.7:
                quality_score += 25
                quality_factors.append("âœ… ç²¾ç¡®åŒ¹é…ç‡é«˜")
            elif exact_match_rate > 0.4:
                quality_score += 15
                quality_factors.append("ğŸŸ¡ ç²¾ç¡®åŒ¹é…ç‡ä¸­ç­‰")
            else:
                quality_score += 5
                quality_factors.append("âŒ ç²¾ç¡®åŒ¹é…ç‡ä½")
        
        # æ•°æ®å®Œæ•´æ€§è¯„åˆ†
        if not all_matches.empty:
            completeness = 1 - (all_matches.isnull().sum().sum() / (len(all_matches) * len(all_matches.columns)))
            if completeness > 0.9:
                quality_score += 25
                quality_factors.append("âœ… æ•°æ®å®Œæ•´æ€§ä¼˜ç§€")
            elif completeness > 0.7:
                quality_score += 15
                quality_factors.append("ğŸŸ¡ æ•°æ®å®Œæ•´æ€§è‰¯å¥½")
            else:
                quality_score += 5
                quality_factors.append("âŒ æ•°æ®å­˜åœ¨ç¼ºå¤±")
        
        # æ•°æ®ä¸€è‡´æ€§è¯„åˆ†
        if len(sheets_data) >= 5:
            quality_score += 25
            quality_factors.append("âœ… æ•°æ®ç»“æ„å®Œæ•´")
        elif len(sheets_data) >= 3:
            quality_score += 15
            quality_factors.append("ğŸŸ¡ æ•°æ®ç»“æ„åŸºæœ¬å®Œæ•´")
        else:
            quality_score += 5
            quality_factors.append("âŒ æ•°æ®ç»“æ„ä¸å®Œæ•´")
        
        quality_level = "ä¼˜ç§€" if quality_score > 80 else "è‰¯å¥½" if quality_score > 60 else "å¾…æ”¹å–„"
        
        report_content.append(f"""
**æ€»ä½“è¯„åˆ†ï¼š** {quality_score}/100 ({quality_level})

**è¯„ä¼°æ˜ç»†ï¼š**
        """)
        
        for factor in quality_factors:
            report_content.append(f"- {factor}")
        
        # æ˜¾ç¤ºå®Œæ•´æŠ¥å‘Š
        report_text = "\n".join(report_content)
        st.markdown(report_text)
        
        # æä¾›ä¸‹è½½é€‰é¡¹
        st.download_button(
            label="ğŸ“¥ ä¸‹è½½å®Œæ•´æŠ¥å‘Š (Markdown)",
            data=report_text,
            file_name=f"æ¯”ä»·åˆ†ææŠ¥å‘Š_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.md",
            mime="text/markdown",
            key="download_insight_report"
        )
        
    except Exception as e:
        st.error(f"ç”Ÿæˆæ´å¯ŸæŠ¥å‘Šæ—¶å‡ºé”™: {str(e)}")


@st.cache_data(ttl=300)  # 5åˆ†é’Ÿç¼“å­˜
def load_price_panel_metrics(uploaded_file=None) -> Optional[Dict[str, Any]]:
    """è¯»å–æ¯”ä»·é¢æ¿æŒ‡æ ‡ï¼Œæ”¯æŒä¸Šä¼ æ–‡ä»¶æˆ–æœ¬åœ°è·¯å¾„"""
    
    # ä¼˜å…ˆä½¿ç”¨ä¸Šä¼ çš„æ–‡ä»¶
    if uploaded_file is not None:
        try:
            # è¯»å–ä¸Šä¼ çš„JSONæ–‡ä»¶
            content = uploaded_file.read()
            if isinstance(content, bytes):
                content = content.decode('utf-8')
            payload = json.loads(content)
            
            # éªŒè¯æ•°æ®ç»“æ„
            if not isinstance(payload, dict):
                st.error("âš ï¸ ä¸Šä¼ çš„æ–‡ä»¶æ ¼å¼é”™è¯¯ï¼Œè¯·ä¸Šä¼ æœ‰æ•ˆçš„JSONæ–‡ä»¶")
                return None
                
            # æ£€æŸ¥å¿…è¦å­—æ®µ
            if "metrics" not in payload:
                st.warning("âš ï¸ ä¸Šä¼ çš„æ–‡ä»¶ä¸­ç¼ºå°‘ 'metrics' å­—æ®µ")
                
            st.success(f"âœ… æˆåŠŸåŠ è½½ä¸Šä¼ çš„æ¯”ä»·æ•°æ®ï¼š{uploaded_file.name}")
            return payload
            
        except json.JSONDecodeError as e:
            st.error(f"âŒ JSONè§£æé”™è¯¯: {str(e)}")
            return None
        except Exception as e:
            st.error(f"âŒ åŠ è½½ä¸Šä¼ æ–‡ä»¶å¤±è´¥: {str(e)}")
            return None
    
    # å¦‚æœæ²¡æœ‰ä¸Šä¼ æ–‡ä»¶ï¼Œå°è¯•è¯»å–æœ¬åœ°æ–‡ä»¶ï¼ˆä½œä¸ºå¤‡ç”¨ï¼‰
    metrics_path = PRICE_PANEL_INTERMEDIATE_DIR / "price_panel_metrics.json"
    
    if not PRICE_PANEL_INTERMEDIATE_DIR.exists():
        return None
        
    if not metrics_path.exists():
        return None
        
    try:
        with open(metrics_path, "r", encoding="utf-8") as fp:
            payload = json.load(fp)
        
        # éªŒè¯æ•°æ®ç»“æ„
        if not isinstance(payload, dict):
            return None
            
        # æ·»åŠ æ•°æ®æ–°é²œåº¦æ£€æŸ¥
        timestamp = payload.get("generated_at")
        if timestamp:
            try:
                from datetime import datetime
                gen_time = datetime.fromisoformat(timestamp.replace('Z', '+00:00'))
                age_minutes = (datetime.now() - gen_time.replace(tzinfo=None)).total_seconds() / 60
                if age_minutes > 60:  # æ•°æ®è¶…è¿‡1å°æ—¶
                    st.info(f"ğŸ—ºï¸ æ£€æµ‹åˆ°æœ¬åœ°æ•°æ® ({age_minutes:.0f}åˆ†é’Ÿå‰)ï¼Œå»ºè®®ä¸Šä¼ æœ€æ–°æ•°æ®")
            except Exception:
                pass
                
        return payload
        
    except json.JSONDecodeError:
        return None
    except Exception:
        return None


def preview_uploaded_data(payload: Dict[str, Any]) -> None:
    """é¢„è§ˆä¸Šä¼ çš„æ¯”ä»·æ•°æ®"""
    if not payload:
        return
        
    with st.expander("ğŸ” æ•°æ®é¢„è§ˆä¸éªŒè¯", expanded=False):
        col1, col2 = st.columns(2)
        
        with col1:
            st.write("**ğŸ“ˆ æ•°æ®æ¦‚è§ˆ**")
            
            # åŸºæœ¬ä¿¡æ¯
            timestamp = payload.get("generated_at", "N/A")
            if timestamp != "N/A":
                timestamp = timestamp.replace('T', ' ')[:19]
            st.metric("ç”Ÿæˆæ—¶é—´", timestamp)
            
            metrics_count = len(payload.get("metrics", []))
            st.metric("æŒ‡æ ‡æ•°é‡", metrics_count)
            
            warnings_count = len(payload.get("warnings", []))
            st.metric("è­¦å‘Šæ•°é‡", warnings_count)
            
        with col2:
            st.write("**ğŸ¢ é—¨åº—ä¿¡æ¯**")
            stores = payload.get("stores", [])
            if stores:
                for i, store in enumerate(stores[:2], 1):
                    store_name = store.get("display_name", f"é—¨åº—{i}")
                    st.write(f"â€¢ {store_name}")
            else:
                st.write("âš ï¸ æœªæ£€æµ‹åˆ°é—¨åº—ä¿¡æ¯")
        
        # è­¦å‘Šä¿¡æ¯
        warnings = payload.get("warnings", [])
        if warnings:
            st.write("**âš ï¸ è­¦å‘Šä¿¡æ¯**")
            for warning in warnings:
                st.warning(warning)
        
        # JSONç»“æ„é¢„è§ˆ
        st.write("**ğŸ“œ JSONç»“æ„é¢„è§ˆ**")
        structure = {key: type(value).__name__ for key, value in payload.items()}
        st.json(structure)


def _format_metric_value(metric: Dict[str, Any]) -> str:
    value = metric.get("value")
    unit = metric.get("unit")
    if value is None:
        return "â€”"
    if unit == "%":
        return f"{float(value):.1f}%"
    if unit == "ä¸ª":
        try:
            return f"{int(value):,}"
        except Exception:
            return str(value)
    if isinstance(value, float):
        return f"{value:,.2f}"
    if isinstance(value, int):
        return f"{value:,}"
    return str(value)


def _build_metric_context_lines(metric: Dict[str, Any], payload: Dict[str, Any]) -> List[str]:
    context = metric.get("context") or {}
    metric_id = metric.get("id")
    lines: List[str] = []

    if metric_id == "matched_pairs":
        stores = context.get("stores") or [store.get("display_name", "") for store in payload.get("stores", [])[:2]]
        stores = [s for s in stores if s]
        if stores:
            lines.append(" vs ".join(stores))
    elif metric_id in {"match_rate_store_a", "match_rate_store_b"}:
        matched = context.get("matched")
        total = context.get("total")
        if matched is not None and total:
            lines.append(f"åŒ¹é… {int(matched):,} / æ€» {int(total):,}")
    elif metric_id in {"unique_store_a", "unique_store_b"}:
        total = context.get("total")
        value = metric.get("value")
        if value is not None and total:
            lines.append(f"ç‹¬æœ‰ {int(value):,} / æ€» {int(total):,}")
    elif metric_id == "stockout_alert":
        stores = payload.get("stores", [])[:2]
        for store in stores:
            name = store.get("display_name")
            details = context.get(name, {}) if name else {}
            zero = details.get("zero")
            with_sales = details.get("with_sales")
            if zero is None:
                continue
            line = f"{name}: {int(zero):,} ä¸ª"
            if with_sales:
                line += f"ï¼ˆå«é”€é‡ {int(with_sales):,}ï¼‰"
            lines.append(line)
        diff = context.get("difference")
        if isinstance(diff, (int, float)) and diff != 0:
            symbol = "+" if diff > 0 else ""
            lines.append(f"å·®å€¼ {symbol}{int(diff):,}")

    return lines


def render_price_panel_overview(payload: Dict[str, Any]) -> None:
    """æ¸²æŸ“æ¯”ä»·åŸºç¡€çœ‹æ¿æŒ‡æ ‡ï¼ˆä¼˜åŒ–ç‰ˆï¼‰"""
    st.subheader("ğŸ’¹ æ¯”ä»·åŸºç¡€çœ‹æ¿")
    
    # æ˜¾ç¤ºæ•°æ®æ›´æ–°æ—¶é—´
    timestamp = payload.get("generated_at")
    if timestamp:
        formatted_time = timestamp.replace('T', ' ')[:19]
        st.caption(f"ğŸ”„ æ•°æ®æ›´æ–°: {formatted_time}")
    
    # æ˜¾ç¤ºè­¦å‘Šä¿¡æ¯
    warnings = payload.get("warnings", []) or []
    if warnings:
        for warn in warnings:
            st.warning(f"âš ï¸ {warn}")
    
    # è·å–æŒ‡æ ‡æ•°æ®
    metrics = payload.get("metrics") or []
    if not metrics:
        st.info("ğŸ“ˆ æš‚æ— æ¯”ä»·æŒ‡æ ‡ï¼Œè¯·å…ˆè¿è¡Œæ¯”ä»·ETLã€‚")
        
        # æä¾›å¸®åŠ©ä¿¡æ¯
        with st.expander("ğŸ”§ å¦‚ä½•ç”Ÿæˆæ¯”ä»·æ•°æ®ï¼Ÿ"):
            st.markdown("""
            **æ­¥éª¤è¯´æ˜:**
            1. ç¡®ä¿æ¯”ä»·æ•°æ®æ–‡ä»¶å­˜åœ¨äº: `æ¯”ä»·æ•°æ®/` ç›®å½•
            2. è¿è¡Œæ¯”ä»·ETLå¤„ç†è„šæœ¬
            3. ç­‰å¾…ç”Ÿæˆ `price_panel_metrics.json` æ–‡ä»¶
            4. åˆ·æ–°æœ¬é¡µé¢æŸ¥çœ‹æ•°æ®
            """)
        return
    
    # æ˜¾ç¤ºæŒ‡æ ‡ç»Ÿè®¡
    st.caption(f"ğŸ“Š å…± {len(metrics)} ä¸ªæ¯”ä»·æŒ‡æ ‡")
    
    # æŒ‰è¡Œæ˜¾ç¤ºæŒ‡æ ‡ï¼ˆæ¯è¡Œ3ä¸ªï¼‰
    for start in range(0, len(metrics), 3):
        row_metrics = metrics[start:start + 3]
        columns = st.columns(len(row_metrics))
        
        for col, metric in zip(columns, row_metrics):
            with col:
                metric_label = metric.get("label", "æœªçŸ¥æŒ‡æ ‡")
                metric_value = _format_metric_value(metric)
                
                # æ˜¾ç¤ºæŒ‡æ ‡
                st.metric(metric_label, metric_value)
                
                # æ˜¾ç¤ºä¸Šä¸‹æ–‡ä¿¡æ¯
                context_lines = _build_metric_context_lines(metric, payload)
                if context_lines:
                    context_text = " | ".join(context_lines)
                    st.caption(f"ğŸ“ {context_text}")
    
    # æ·»åŠ åˆ·æ–°æŒ‰é’®
    col1, col2, col3 = st.columns([1, 1, 2])
    with col1:
        if st.button("ğŸ”„ åˆ·æ–°æ¯”ä»·æ•°æ®"):
            st.cache_data.clear()
            st.rerun()
    
    with col2:
        if st.button("ğŸ“ˆ è¯¦ç»†åˆ†æ"):
            # è·³è½¬åˆ°æ¯”ä»·çœ‹æ¿é€‰é¡¹å¡
            st.info("ğŸ‘† è¯·ç‚¹å‡»ä¸Šæ–¹ 'æ¯”ä»·çœ‹æ¿' é€‰é¡¹å¡æŸ¥çœ‹è¯¦ç»†åˆ†æ")


def render_unified_price_comparison_module() -> None:
    """ç»Ÿä¸€çš„æ¯”ä»·æ¨¡å—æ¸²æŸ“å‡½æ•°ï¼ˆæ”¯æŒæ–‡ä»¶ä¸Šä¼ ï¼‰"""
    st.subheader("ğŸ’¹ æ¯”ä»·åˆ†ææ¨¡å—")
    
    # é€‰æ‹©æ•°æ®è¾“å…¥æ–¹å¼
    input_method = st.radio(
        "ğŸ“ é€‰æ‹©æ•°æ®è¾“å…¥æ–¹å¼",
        ["ä¸Šä¼ æ¯”ä»·ç»“æœæ–‡ä»¶", "ä¸Šä¼ JSONæ–‡ä»¶", "ä½¿ç”¨æœ¬åœ°æ•°æ®"],
        horizontal=True,
        key="price_comparison_input_method_radio"
    )
    
    price_panel_payload = None
    
    if input_method == "ä¸Šä¼ æ¯”ä»·ç»“æœæ–‡ä»¶":
        st.write("**ğŸ“Š æ¯”ä»·ç»“æœæ–‡ä»¶åˆ†æ**")
        st.info("ğŸ¯ ä¸Šä¼ é€šè¿‡æ¯”ä»·è„šæœ¬ç”Ÿæˆçš„å®Œæ•´æ¯”ä»·ç»“æœExcelæ–‡ä»¶")
        
        comparison_file = st.file_uploader(
            "ğŸ“¤ é€‰æ‹©æ¯”ä»·ç»“æœExcelæ–‡ä»¶",
            type=['xlsx', 'xls'],
            help="ä¸Šä¼ é€šè¿‡ product_comparison_tool_local.py ç”Ÿæˆçš„æ¯”ä»·ç»“æœæ–‡ä»¶",
            key="comparison_file_uploader"
        )
        
        # æ˜¾ç¤ºæ–‡ä»¶è¦æ±‚
        with st.expander("ğŸ“‹ æ¯”ä»·ç»“æœæ–‡ä»¶è¯´æ˜"):
            st.markdown("""
            **æ”¯æŒçš„æ–‡ä»¶ç±»å‹:**
            - âœ… é€šè¿‡ `product_comparison_tool_local.py` ç”Ÿæˆçš„æ¯”ä»·ç»“æœæ–‡ä»¶
            - âœ… æ–‡ä»¶åæ ¼å¼: `matched_products_comparison_final_YYYYMMDD_HHMMSS.xlsx`
            
            **æ–‡ä»¶åº”åŒ…å«çš„Sheet:**
            - **1-æ¡ç ç²¾ç¡®åŒ¹é…**: æ¡ç ç›¸åŒçš„å•†å“åŒ¹é…ç»“æœ
            - **2-åç§°æ¨¡ç³ŠåŒ¹é…(æ— æ¡ç )**: åŸºäºå•†å“åç§°çš„åŒ¹é…ç»“æœ  
            - **3-{åº—é“ºA}-ç‹¬æœ‰å•†å“**: åº—é“ºAç‹¬æœ‰çš„å•†å“
            - **4-{åº—é“ºB}-ç‹¬æœ‰å•†å“**: åº—é“ºBç‹¬æœ‰çš„å•†å“
            - **5-åº“å­˜>0&AæŠ˜æ‰£â‰¥BæŠ˜æ‰£**: ä»·æ ¼ä¼˜åŠ¿å•†å“
            - **6-8**: æ¸…æ´—æ•°æ®å¯¹æ¯”Sheet(å¯é€‰)
            
            **ä½¿ç”¨æµç¨‹:**
            1. ğŸ”§ å…ˆç”¨æ¯”ä»·è„šæœ¬å¤„ç†ä¸¤ä¸ªåº—é“ºçš„åŸå§‹æ•°æ®
            2. ğŸ“¤ ä¸Šä¼ ç”Ÿæˆçš„æ¯”ä»·ç»“æœExcelæ–‡ä»¶
            3. ğŸ“Š ç³»ç»Ÿè‡ªåŠ¨è§£æå¹¶å±•ç¤ºå¯è§†åŒ–åˆ†æç»“æœ
            
            **æ³¨æ„äº‹é¡¹:**
            - ç¡®ä¿æ–‡ä»¶æ˜¯æœ€æ–°çš„æ¯”ä»·ç»“æœ
            - æ£€æŸ¥å„ä¸ªSheetæ˜¯å¦åŒ…å«æœ‰æ•ˆæ•°æ®
            - æ”¯æŒä¸­æ–‡å•†å“åç§°å’Œåº—é“ºåç§°
            """)

        # å½“æ–‡ä»¶ä¸Šä¼ åï¼Œæ‰§è¡Œåˆ†æ
        if comparison_file:
            price_panel_payload = process_uploaded_comparison_file(comparison_file)
            
    elif input_method == "ä¸Šä¼ JSONæ–‡ä»¶":
        st.write("**ï¿½ JSONæ–‡ä»¶ä¸Šä¼ **")
        uploaded_file = st.file_uploader(
            "ğŸ“¤ é€‰æ‹©æ¯”ä»·æ•°æ®æ–‡ä»¶ (JSON)",
            type=['json'],
            help="è¯·ä¸Šä¼ ç”±æ¯”ä»·ETLç”Ÿæˆçš„ price_panel_metrics.json æ–‡ä»¶",
            key="json_uploader"
        )
        
        if uploaded_file:
            price_panel_payload = load_price_panel_metrics(uploaded_file)
            
    else:  # ä½¿ç”¨æœ¬åœ°æ•°æ®
        st.write("**ğŸ’¾ æœ¬åœ°æ•°æ®è¯»å–**")
        price_panel_payload = load_price_panel_metrics()
        
        if price_panel_payload:
            st.info("ğŸ—‚ï¸ å·²åŠ è½½æœ¬åœ°æ¯”ä»·æ•°æ®")
        else:
            st.warning("âš ï¸ æœªæ‰¾åˆ°æœ¬åœ°æ¯”ä»·æ•°æ®æ–‡ä»¶")
    
    # æ•°æ®æœ‰æ•ˆæ—¶æ˜¾ç¤ºåˆ†æç»“æœ
    if price_panel_payload:
        st.markdown("---")
        
        # æ ¹æ®æ•°æ®ç±»å‹é€‰æ‹©ä¸åŒçš„å±•ç¤ºæ–¹å¼
        if price_panel_payload.get("comparison_type") == "multi_store_comparison":
            # æ–°çš„æ¯”ä»·ç»“æœæ–‡ä»¶å±•ç¤º
            render_comparison_file_analysis(price_panel_payload)
        else:
            # ä¼ ç»Ÿçš„JSONæ–‡ä»¶å±•ç¤º
            tab1, tab2 = st.tabs(["ğŸ“ˆ åŸºç¡€æŒ‡æ ‡", "ğŸ—ºï¸ è¯¦ç»†åˆ†æ"])
            
            with tab1:
                if price_panel_payload.get("metrics"):
                    render_price_panel_overview(price_panel_payload)
                else:
                    st.warning("ğŸš« æ•°æ®ä¸­æœªåŒ…å«æœ‰æ•ˆæŒ‡æ ‡")
        
            with tab2:
                st.caption("ğŸ” è¯¦ç»†æ¯”ä»·åˆ†æçœ‹æ¿")
                # åªæœ‰åœ¨ä½¿ç”¨æœ¬åœ°æ•°æ®æ—¶æ‰è°ƒç”¨è€çš„dashboard
                if input_method == "ä½¿ç”¨æœ¬åœ°æ•°æ®":
                    try:
                        create_price_comparison_dashboard()
                    except Exception as e:
                        st.error(f"âŒ åŠ è½½è¯¦ç»†åˆ†æå¤±è´¥: {str(e)}")
                        st.info("ğŸ“ å»ºè®®æ£€æŸ¥ä¸Šä¼ çš„æ•°æ®æ–‡ä»¶æ ¼å¼")
                else:
                    st.info("ğŸ“Š è¯·ä¸Šä¼ æ¯”ä»·ç»“æœæ–‡ä»¶æˆ–JSONæ–‡ä»¶ä»¥æŸ¥çœ‹è¯¦ç»†åˆ†æ")
    else:
        # æ ¹æ®é€‰æ‹©çš„è¾“å…¥æ–¹å¼æ˜¾ç¤ºä¸åŒçš„æç¤º
        if input_method == "ä¸Šä¼ æ¯”ä»·ç»“æœæ–‡ä»¶":
            st.info("ğŸ‘† è¯·ä¸Šä¼ æ¯”ä»·ç»“æœExcelæ–‡ä»¶å¼€å§‹åˆ†æ")
        elif input_method == "ä¸Šä¼ JSONæ–‡ä»¶":
            st.info("ğŸ‘† è¯·ä¸Šä¼ JSONæ–‡ä»¶å¼€å§‹åˆ†æ")  
        else:  # ä½¿ç”¨æœ¬åœ°æ•°æ®
            st.info("ğŸ” æ­£åœ¨å°è¯•åŠ è½½æœ¬åœ°æ¯”ä»·æ•°æ®...")
            # åªæœ‰é€‰æ‹©æœ¬åœ°æ•°æ®æ—¶æ‰æ˜¾ç¤ºè€çš„dashboard
            try:
                create_price_comparison_dashboard()
            except Exception as e:
                st.warning("âš ï¸ æœªæ‰¾åˆ°æœ¬åœ°æ¯”ä»·æ•°æ®æ–‡ä»¶")
                st.info("ğŸ’¡ å»ºè®®ä¸Šä¼ æ¯”ä»·ç»“æœæ–‡ä»¶æˆ–JSONæ–‡ä»¶è¿›è¡Œåˆ†æ")


def render_order_data_uploader():
    """æ¸²æŸ“è®¢å•æ•°æ®ä¸Šä¼ å’Œåˆ†ææ¨¡å— - æ”¯æŒæ‰¹é‡ä¸Šä¼ """
    st.info("ğŸ“¤ ä¸Šä¼ è®¢å•æ•°æ®Excelæ–‡ä»¶è¿›è¡Œæ·±åº¦åˆ†æï¼ˆæ”¯æŒæ‰¹é‡ä¸Šä¼ å¤šä¸ªæ–‡ä»¶ï¼‰")
    
    # æ·»åŠ æ•°æ®æ¥æºé€‰æ‹©
    data_source_tab1, data_source_tab2 = st.tabs(["ğŸ“¤ ä¸Šä¼ æ–°æ•°æ®", "ğŸ“‚ åŠ è½½å†å²æ•°æ®"])
    
    order_data_to_analyze = None
    data_source_label = ""
    
    with data_source_tab1:
        # æ–‡ä»¶ä¸Šä¼  - æ”¯æŒå¤šæ–‡ä»¶
        order_files = st.file_uploader(
            "é€‰æ‹©è®¢å•æ•°æ®æ–‡ä»¶ï¼ˆå¯é€‰æ‹©å¤šä¸ªæ–‡ä»¶ï¼‰",
            type=['xlsx', 'xls'],
            help="ä¸Šä¼ åŒ…å«è®¢å•ä¿¡æ¯çš„Excelæ–‡ä»¶ï¼Œæ”¯æŒåŒæ—¶ä¸Šä¼ å¤šä¸ªæ–‡ä»¶è¿›è¡Œåˆå¹¶åˆ†æ",
            key="order_data_uploader",
            accept_multiple_files=True  # å¯ç”¨å¤šæ–‡ä»¶ä¸Šä¼ 
        )
        
        if order_files:
            data_source_label = "æ–°ä¸Šä¼ æ•°æ®"
            # åç»­å¤„ç†é€»è¾‘...
            
    with data_source_tab2:
        st.write("**ğŸ“¦ å†å²ç¼“å­˜æ•°æ®**")
        
        # è·å–å†å²ç¼“å­˜åˆ—è¡¨
        cached_list = load_cached_data_list()
        
        if not cached_list:
            st.info("ğŸ“­ æš‚æ— å†å²ç¼“å­˜æ•°æ®ï¼Œè¯·å…ˆä¸Šä¼ æ–°æ•°æ®")
        else:
            st.success(f"âœ… æ‰¾åˆ° {len(cached_list)} ä¸ªå†å²æ•°æ®ç‰ˆæœ¬")
            
            # åˆ›å»ºé€‰æ‹©åˆ—è¡¨
            cache_options = []
            for idx, cache_info in enumerate(cached_list):
                upload_time = cache_info['upload_time']
                if upload_time != 'Unknown':
                    try:
                        from datetime import datetime
                        dt = datetime.fromisoformat(upload_time)
                        time_str = dt.strftime('%Y-%m-%d %H:%M')
                    except:
                        time_str = upload_time
                else:
                    time_str = "æœªçŸ¥æ—¶é—´"
                
                label = f"{cache_info['original_file']} | {time_str} | {cache_info['rows']:,}è¡Œ | {cache_info['size_mb']:.1f}MB"
                cache_options.append((label, cache_info['file_path']))
            
            # é€‰æ‹©è¦åŠ è½½çš„ç¼“å­˜
            selected_cache_label = st.selectbox(
                "é€‰æ‹©è¦åŠ è½½çš„å†å²æ•°æ®",
                options=[opt[0] for opt in cache_options],
                key="cached_data_selector"
            )
            
            if st.button("ğŸ”„ åŠ è½½é€‰ä¸­çš„å†å²æ•°æ®", key="load_cached_btn"):
                # æ‰¾åˆ°å¯¹åº”çš„æ–‡ä»¶è·¯å¾„
                selected_path = next(opt[1] for opt in cache_options if opt[0] == selected_cache_label)
                
                with st.spinner("ğŸ“– æ­£åœ¨åŠ è½½å†å²æ•°æ®..."):
                    order_data_to_analyze = load_data_from_cache(selected_path)
                    if order_data_to_analyze is not None:
                        st.success(f"âœ… æˆåŠŸåŠ è½½å†å²æ•°æ®ï¼š{len(order_data_to_analyze):,}è¡Œ")
                        data_source_label = f"å†å²æ•°æ®: {selected_cache_label}"
                        
                        # è®¾ç½®åˆ°session_stateä¾›å…¶ä»–æ ‡ç­¾é¡µä½¿ç”¨
                        if 'current_data' not in st.session_state:
                            st.session_state['current_data'] = {}
                        st.session_state['current_data']['raw_data'] = order_data_to_analyze
                        st.session_state['uploaded_order_data'] = st.session_state['current_data']
                        st.info("ğŸ’¡ æ•°æ®å·²åŠ è½½ï¼Œå¯å‰å¾€å…¶ä»–æ ‡ç­¾é¡µï¼ˆå¦‚AIåœºæ™¯è¥é”€ï¼‰æŸ¥çœ‹åˆ†æ")
    
    # åªæœ‰å½“æœ‰æ•°æ®éœ€è¦åˆ†ææ—¶æ‰ç»§ç»­
    if order_files:
        # åŸæœ‰çš„ä¸Šä¼ å¤„ç†é€»è¾‘
        pass  # å°†åœ¨ä¸‹é¢æ›¿æ¢
    
    # æ˜¾ç¤ºæ–‡ä»¶æ ¼å¼è¦æ±‚
    with st.expander("ğŸ“‹ è®¢å•æ•°æ®æ ¼å¼è¦æ±‚"):
        st.markdown("""
        **å¿…éœ€å­—æ®µï¼š**
        - `è®¢å•ID`: è®¢å•å”¯ä¸€æ ‡è¯†
        - `å•†å“åç§°`: å•†å“åç§°
        - `å•†å“å®å”®ä»·`: å•†å“å”®ä»·
        - `é”€é‡`: å•†å“æ•°é‡
        - `ä¸‹å•æ—¶é—´`: è®¢å•æ—¶é—´ï¼ˆæ ¼å¼ï¼šYYYY-MM-DD HH:MM:SSï¼‰
        - `é—¨åº—åç§°`: é—¨åº—æ ‡è¯†
        - `æ¸ é“`: é”€å”®æ¸ é“ï¼ˆå¦‚ï¼šç¾å›¢ã€é¥¿äº†ä¹ˆç­‰ï¼‰
        
        **æ¨èå­—æ®µï¼ˆç”¨äºå®Œæ•´åˆ†æï¼‰ï¼š**
        - `ç‰©æµé…é€è´¹`: é…é€è´¹ç”¨
        - `å¹³å°ä½£é‡‘`: å¹³å°æŠ½æˆ
        - `é…é€è·ç¦»`: é…é€è·ç¦»ï¼ˆç±³æˆ–å…¬é‡Œï¼‰
        - `ç¾å›¢ä¸€çº§åˆ†ç±»`: å•†å“ä¸€çº§åˆ†ç±»
        - `ç¾å›¢ä¸‰çº§åˆ†ç±»`: å•†å“ä¸‰çº§åˆ†ç±»
        - `æ”¶è´§åœ°å€`: é…é€åœ°å€
        - `é…é€è´¹å‡å…`ã€`æ»¡å‡`ã€`å•†å“å‡å…`ã€`ä»£é‡‘åˆ¸`: å„ç±»ä¼˜æƒ é‡‘é¢
        - `ç”¨æˆ·æ”¯ä»˜é…é€è´¹`ã€`è®¢å•é›¶å”®é¢`ã€`æ‰“åŒ…è´¹`: è®¢å•é‡‘é¢æ˜ç»†
        
        **åˆ†æåŠŸèƒ½ï¼š**
        - âœ… 13ä¸ªæ ¸å¿ƒæŒ‡æ ‡å¡ç‰‡ï¼ˆè®¢å•æ•°ã€æ”¶å…¥ã€åˆ©æ¶¦ã€å®¢å•ä»·ç­‰ï¼‰
        - âœ… è´Ÿæ¯›åˆ©å•†å“è¯†åˆ«Top 50
        - âœ… æˆæœ¬ç»“æ„åˆ†æï¼ˆå•†å®¶æ´»åŠ¨ã€å¹³å°ä½£é‡‘ã€é…é€æˆæœ¬ï¼‰
        - âœ… ä¸»å•å“vså‡‘å•å“å¯¹æ¯”
        - âœ… æ¯æ—¥åˆ©æ¶¦è¶‹åŠ¿å›¾ï¼ˆåˆ©æ¶¦é¢+åˆ©æ¶¦ç‡ï¼‰
        - âœ… æ•°æ®è´¨é‡æ£€æŸ¥æŠ¥å‘Š
        """)
    
    # å¤„ç†ä¸Šä¼ çš„æ–‡ä»¶ï¼ˆæ”¯æŒå¤šæ–‡ä»¶åˆå¹¶ï¼‰æˆ–åŠ è½½å†å²æ•°æ®
    if order_files or order_data_to_analyze is not None:
        st.markdown("""
        **å¿…éœ€å­—æ®µï¼š**
        - `è®¢å•ID`: è®¢å•å”¯ä¸€æ ‡è¯†
        - `å•†å“åç§°`: å•†å“åç§°
        - `å•†å“å®å”®ä»·`: å•†å“å”®ä»·
        - `é”€é‡`: å•†å“æ•°é‡
        - `ä¸‹å•æ—¶é—´`: è®¢å•æ—¶é—´ï¼ˆæ ¼å¼ï¼šYYYY-MM-DD HH:MM:SSï¼‰
        - `é—¨åº—åç§°`: é—¨åº—æ ‡è¯†
        - `æ¸ é“`: é”€å”®æ¸ é“ï¼ˆå¦‚ï¼šç¾å›¢ã€é¥¿äº†ä¹ˆç­‰ï¼‰
        
        **æ¨èå­—æ®µï¼ˆç”¨äºå®Œæ•´åˆ†æï¼‰ï¼š**
        - `ç‰©æµé…é€è´¹`: é…é€è´¹ç”¨
        - `å¹³å°ä½£é‡‘`: å¹³å°æŠ½æˆ
        - `é…é€è·ç¦»`: é…é€è·ç¦»ï¼ˆç±³æˆ–å…¬é‡Œï¼‰
        - `ç¾å›¢ä¸€çº§åˆ†ç±»`: å•†å“ä¸€çº§åˆ†ç±»
        - `ç¾å›¢ä¸‰çº§åˆ†ç±»`: å•†å“ä¸‰çº§åˆ†ç±»
        - `æ”¶è´§åœ°å€`: é…é€åœ°å€
        - `é…é€è´¹å‡å…`ã€`æ»¡å‡`ã€`å•†å“å‡å…`ã€`ä»£é‡‘åˆ¸`: å„ç±»ä¼˜æƒ é‡‘é¢
        - `ç”¨æˆ·æ”¯ä»˜é…é€è´¹`ã€`è®¢å•é›¶å”®é¢`ã€`æ‰“åŒ…è´¹`: è®¢å•é‡‘é¢æ˜ç»†
        
        **åˆ†æåŠŸèƒ½ï¼š**
        - âœ… 13ä¸ªæ ¸å¿ƒæŒ‡æ ‡å¡ç‰‡ï¼ˆè®¢å•æ•°ã€æ”¶å…¥ã€åˆ©æ¶¦ã€å®¢å•ä»·ç­‰ï¼‰
        - âœ… è´Ÿæ¯›åˆ©å•†å“è¯†åˆ«Top 50
        - âœ… æˆæœ¬ç»“æ„åˆ†æï¼ˆå•†å®¶æ´»åŠ¨ã€å¹³å°ä½£é‡‘ã€é…é€æˆæœ¬ï¼‰
        - âœ… ä¸»å•å“vså‡‘å•å“å¯¹æ¯”
        - âœ… æ¯æ—¥åˆ©æ¶¦è¶‹åŠ¿å›¾ï¼ˆåˆ©æ¶¦é¢+åˆ©æ¶¦ç‡ï¼‰
        - âœ… æ•°æ®è´¨é‡æ£€æŸ¥æŠ¥å‘Š
        """)
    
    
    # å¤„ç†ä¸Šä¼ çš„æ–‡ä»¶ï¼ˆæ”¯æŒå¤šæ–‡ä»¶åˆå¹¶ï¼‰æˆ–åŠ è½½å†å²æ•°æ®
    if order_files or order_data_to_analyze is not None:
        try:
            # åŒºåˆ†ä¸¤ç§æ•°æ®æ¥æº
            if order_data_to_analyze is not None:
                # ä½¿ç”¨å†å²ç¼“å­˜æ•°æ®
                order_data = order_data_to_analyze
                original_count = len(order_data)
                st.success(f"âœ… å·²åŠ è½½å†å²æ•°æ®ï¼š{original_count:,}æ¡è®¢å•")
                
            else:
                # å¤„ç†æ–°ä¸Šä¼ çš„æ–‡ä»¶
                # å¦‚æœä¸Šä¼ äº†å¤šä¸ªæ–‡ä»¶ï¼Œå…ˆæ˜¾ç¤ºæ–‡ä»¶åˆ—è¡¨
                if len(order_files) > 1:
                    st.success(f"âœ… æ£€æµ‹åˆ° {len(order_files)} ä¸ªæ–‡ä»¶ï¼Œå°†è‡ªåŠ¨åˆå¹¶åˆ†æ")
                    with st.expander("ğŸ“‚ æ–‡ä»¶åˆ—è¡¨"):
                        for idx, file in enumerate(order_files, 1):
                            st.write(f"{idx}. {file.name}")
                
                with st.spinner("ğŸ“– æ­£åœ¨è¯»å–è®¢å•æ•°æ®..."):
                    # è¯»å–æ‰€æœ‰Excelæ–‡ä»¶å¹¶åˆå¹¶
                    all_order_data = []
                    file_stats = []
                    
                    for file in order_files:
                        try:
                            df = pd.read_excel(file)
                            all_order_data.append(df)
                            file_stats.append({
                                'æ–‡ä»¶å': file.name,
                                'è®¢å•è¡Œæ•°': len(df),
                                'çŠ¶æ€': 'âœ… æˆåŠŸ'
                            })
                        except Exception as e:
                            file_stats.append({
                                'æ–‡ä»¶å': file.name,
                                'è®¢å•è¡Œæ•°': 0,
                                'çŠ¶æ€': f'âŒ å¤±è´¥: {str(e)}'
                            })
                            st.error(f"âŒ è¯»å–æ–‡ä»¶ {file.name} å¤±è´¥: {str(e)}")
                    
                    # æ˜¾ç¤ºæ–‡ä»¶è¯»å–ç»Ÿè®¡
                    if len(order_files) > 1:
                        st.dataframe(
                            pd.DataFrame(file_stats),
                            use_container_width=True,
                            hide_index=True
                        )
                    
                    # åˆå¹¶æ‰€æœ‰æ•°æ®
                    if not all_order_data:
                        st.error("âŒ æ²¡æœ‰æˆåŠŸè¯»å–ä»»ä½•æ–‡ä»¶")
                        return
                    
                    order_data = pd.concat(all_order_data, ignore_index=True)
                    
                    original_count = len(order_data)
                    
                    # æ™ºèƒ½å»é‡ï¼šåªåˆ é™¤å®Œå…¨ç›¸åŒçš„è¡Œï¼ˆæ‰€æœ‰å­—æ®µéƒ½ç›¸åŒï¼‰
                    before_dedup = len(order_data)
                    order_data = order_data.drop_duplicates(keep='first')
                    after_dedup = len(order_data)
                    
                    if before_dedup > after_dedup:
                        st.info(f"ğŸ”„ å·²å»é™¤å®Œå…¨é‡å¤çš„æ•°æ®è¡Œï¼š{before_dedup:,} â†’ {after_dedup:,} è¡Œï¼ˆå»é™¤ {before_dedup - after_dedup:,} è¡Œï¼‰")
                        st.caption("ğŸ’¡ è¯´æ˜ï¼šåªåˆ é™¤æ‰€æœ‰å­—æ®µå®Œå…¨ç›¸åŒçš„è¡Œï¼Œä¿ç•™è®¢å•-å•†å“æ˜ç»†çº§æ•°æ®")
                    
                    # æ£€æŸ¥è®¢å•-å•†å“æ˜ç»†ç»“æ„
                    if 'è®¢å•ID' in order_data.columns:
                        unique_orders = order_data['è®¢å•ID'].nunique()
                        total_items = len(order_data)
                        avg_items = total_items / unique_orders if unique_orders > 0 else 0
                        
                        st.success(f"âœ… æˆåŠŸåŠ è½½æ•°æ®ï¼š{unique_orders:,} ä¸ªè®¢å•ï¼Œ{total_items:,} ä¸ªå•†å“æ˜ç»†ï¼ˆå¹³å‡æ¯å• {avg_items:.1f} ä¸ªå•†å“ï¼‰")
                    else:
                        st.success(f"âœ… æˆåŠŸåŠ è½½ {after_dedup:,} æ¡æ•°æ®")
                    
                    # ğŸ” æ•°æ®è´¨é‡æ£€æŸ¥ï¼ˆä»…å¯¹æ–°ä¸Šä¼ æ•°æ®ï¼‰
                    with st.spinner("ğŸ” æ­£åœ¨è¿›è¡Œæ•°æ®è´¨é‡æ£€æŸ¥..."):
                        quality_report = perform_data_quality_check(order_data)
                        
                        # æ˜¾ç¤ºè´¨é‡æ£€æŸ¥ç»“æœ
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            st.metric("æ•°æ®è´¨é‡è¯„åˆ†", f"{quality_report['score']}åˆ†")
                        with col2:
                            st.metric("è´¨é‡ç­‰çº§", quality_report['grade'])
                        with col3:
                            st.metric("é—®é¢˜æ•°é‡", f"{len(quality_report['issues'])}ä¸ª")
                        
                        # è¯¦ç»†è´¨é‡æŠ¥å‘Š
                        if quality_report['issues'] or quality_report['warnings']:
                            with st.expander("ğŸ“‹ æ•°æ®è´¨é‡è¯¦ç»†æŠ¥å‘Š"):
                                if quality_report['issues']:
                                    st.write("**ğŸ”´ ä¸¥é‡é—®é¢˜ï¼š**")
                                    for issue in quality_report['issues']:
                                        st.error(f"â€¢ {issue['column']}: {issue['description']}")
                                
                                if quality_report['warnings']:
                                    st.write("**âš ï¸ è­¦å‘Šæç¤ºï¼š**")
                                    for warning in quality_report['warnings']:
                                        st.warning(f"â€¢ {warning['column']}: {warning['description']}")
                        else:
                            st.success("âœ… æ•°æ®è´¨é‡ä¼˜ç§€ï¼Œæœªå‘ç°é—®é¢˜")
                    
                    # ğŸ’¾ è‡ªåŠ¨ä¿å­˜åˆ°ç¼“å­˜
                    with st.spinner("ğŸ’¾ æ­£åœ¨ä¿å­˜æ•°æ®åˆ°æœ¬åœ°ç¼“å­˜..."):
                        try:
                            # ä¿å­˜åŸå§‹åˆå¹¶æ•°æ®
                            file_name = order_files[0].name if len(order_files) == 1 else f"åˆå¹¶æ•°æ®_{len(order_files)}ä¸ªæ–‡ä»¶"
                            cache_path = save_data_to_cache(order_data, file_name)
                            st.success(f"ğŸ’¾ æ•°æ®å·²ä¿å­˜åˆ°ç¼“å­˜ï¼Œä¸‹æ¬¡å¯å¿«é€ŸåŠ è½½")
                        except Exception as e:
                            st.warning(f"âš ï¸ ç¼“å­˜ä¿å­˜å¤±è´¥ï¼ˆä¸å½±å“åˆ†æï¼‰: {str(e)}")
            
            # æ˜¾ç¤ºæ•°æ®é¢„è§ˆï¼ˆä¸¤ç§æ¥æºé€šç”¨ï¼‰
            with st.expander("ğŸ‘€ æ•°æ®é¢„è§ˆï¼ˆå‰10è¡Œï¼‰"):
                st.dataframe(order_data.head(10))
                
                # æ•°æ®å¤„ç†å’Œåˆ†æ
                with st.spinner("ğŸ”„ æ­£åœ¨å¤„ç†å’Œåˆ†ææ•°æ®..."):
                    try:
                        # è°ƒç”¨æ ‡å‡†ä¸šåŠ¡é€»è¾‘å¤„ç†ï¼ˆä¼šè‡ªåŠ¨å‰”é™¤è€—ææ•°æ®ï¼‰
                        processed_order_data = preprocess_order_data(order_data)
                        
                        # æ˜¾ç¤ºè€—æå‰”é™¤ä¿¡æ¯
                        processed_count = len(processed_order_data)
                        if processed_count < original_count:
                            removed_count = original_count - processed_count
                            st.warning(f"ğŸ”´ å·²è‡ªåŠ¨å‰”é™¤ {removed_count} è¡Œè€—ææ•°æ®ï¼ˆå¦‚è´­ç‰©è¢‹ï¼‰ï¼Œå®é™…åˆ†æ {processed_count:,} è¡Œæ•°æ®")
                        
                        order_summary = calculate_order_metrics(processed_order_data)
                        
                        # ä¿å­˜æ•°æ®åˆ°session_stateä¾›å…¶ä»–æ ‡ç­¾é¡µä½¿ç”¨
                        if 'current_data' not in st.session_state:
                            st.session_state['current_data'] = {}
                        st.session_state['current_data']['raw_data'] = processed_order_data
                        st.session_state['current_data']['order_summary'] = order_summary
                        
                        # åŒæ—¶è®¾ç½®uploaded_order_dataæ ‡å¿—
                        st.session_state['uploaded_order_data'] = st.session_state['current_data']
                        
                        st.success("âœ… æ•°æ®å¤„ç†å®Œæˆï¼å¯ä»¥å‰å¾€å…¶ä»–æ ‡ç­¾é¡µï¼ˆå¦‚AIåœºæ™¯è¥é”€ï¼‰æŸ¥çœ‹æ›´å¤šåˆ†æ")
                        
                        # åˆ›å»ºåˆ†æé€‰é¡¹å¡
                        st.markdown("---")
                        analysis_tabs = st.tabs([
                            "ğŸ“Š è®¢å•æ¦‚è§ˆ", 
                            "ğŸ’° åˆ©æ¶¦åˆ†æ", 
                            "â° æ—¶é—´åˆ†æ",
                            "ğŸª é—¨åº—åˆ†æ",
                            "ğŸ“¦ å•†å“åˆ†æ"
                        ])
                        
                        with analysis_tabs[0]:
                            if ORDER_ENHANCEMENT_AVAILABLE:
                                render_enhanced_order_overview(processed_order_data, order_summary)
                            else:
                                render_order_overview(processed_order_data, order_summary)
                        
                        with analysis_tabs[1]:
                            if ORDER_ENHANCEMENT_AVAILABLE:
                                render_enhanced_profit_analysis(processed_order_data, order_summary)
                            else:
                                render_profit_analysis(processed_order_data, order_summary)
                        
                        with analysis_tabs[2]:
                            render_time_analysis(processed_order_data)
                        
                        with analysis_tabs[3]:
                            render_store_analysis(processed_order_data)
                        
                        with analysis_tabs[4]:
                            render_product_analysis(processed_order_data)
                            
                    except Exception as e:
                        st.error(f"âŒ æ•°æ®å¤„ç†å¤±è´¥: {str(e)}")
                        st.info("ğŸ’¡ è¯·æ£€æŸ¥ä¸Šä¼ çš„æ–‡ä»¶æ˜¯å¦åŒ…å«å¿…éœ€å­—æ®µ")
                        
                        # æ˜¾ç¤ºè¯¦ç»†é”™è¯¯ä¿¡æ¯
                        with st.expander("ğŸ” é”™è¯¯è¯¦æƒ…"):
                            st.code(str(e))
                            import traceback
                            st.code(traceback.format_exc())
                        
        except Exception as e:
            st.error(f"âŒ æ–‡ä»¶è¯»å–å¤±è´¥: {str(e)}")
            st.info("ğŸ’¡ è¯·ç¡®ä¿ä¸Šä¼ çš„æ˜¯æœ‰æ•ˆçš„Excelæ–‡ä»¶ï¼ˆ.xlsx æˆ– .xlsï¼‰")


@st.cache_data
def load_sample_data():
    """åŠ è½½ç¤ºä¾‹æ•°æ®"""
    return {
        'store_id': 'DEMO_STORE_001',
        'product_data': pd.DataFrame({
            'å•†å“åç§°': ['å¯å£å¯ä¹330ml', 'å†œå¤«å±±æ³‰550ml', 'åº·å¸ˆå‚…çº¢çƒ§ç‰›è‚‰é¢', 'äº”ç²®æ¶²52åº¦500ml', 'é£å¤©èŒ…å°53åº¦500ml', 
                      'åŒæ±‡ç«è…¿è‚ ', 'ç»Ÿä¸€ç»¿èŒ¶', 'å¥¥åˆ©å¥¥é¥¼å¹²', 'å¾·èŠ™å·§å…‹åŠ›', 'æ—ºæ—ºä»™è´'],
            'å”®ä»·': [3.5, 2.0, 4.5, 168.0, 2680.0, 6.8, 3.2, 12.5, 28.0, 8.9],
            'åŸä»·': [4.0, 2.5, 5.0, 188.0, 2980.0, 8.0, 4.0, 15.0, 32.0, 10.0],
            'æœˆå”®': [1500, 2800, 800, 50, 5, 1200, 900, 600, 300, 450],
            'åº“å­˜': [200, 300, 150, 20, 3, 180, 120, 80, 50, 75],
            'ç¾å›¢ä¸€çº§åˆ†ç±»': ['é¥®å“', 'é¥®å“', 'é£Ÿå“', 'é…’ç±»', 'é…’ç±»', 'é£Ÿå“', 'é¥®å“', 'é£Ÿå“', 'é£Ÿå“', 'é£Ÿå“'],
            'ç¾å›¢ä¸‰çº§åˆ†ç±»': ['ç¢³é…¸é¥®æ–™', 'æ°´', 'æ–¹ä¾¿é¢', 'ç™½é…’', 'ç™½é…’', 'è‚‰åˆ¶å“', 'èŒ¶é¥®æ–™', 'é¥¼å¹²', 'å·§å…‹åŠ›', 'è†¨åŒ–é£Ÿå“']
        }),
        'competitor_data': pd.DataFrame({
            'å•†å“åç§°': ['å¯å£å¯ä¹330ml', 'å†œå¤«å±±æ³‰550ml', 'åº·å¸ˆå‚…çº¢çƒ§ç‰›è‚‰é¢', 'é›ªç¢§æŸ æª¬å‘³', 'ç™¾äº‹å¯ä¹'],
            'å”®ä»·': [3.2, 1.8, 4.2, 3.0, 3.3],
            'åŸä»·': [3.8, 2.2, 4.8, 3.5, 3.8],
            'æœˆå”®': [1800, 3200, 900, 1400, 1100],
            'é—¨åº—åç§°': ['ç«å¯¹A', 'ç«å¯¹A', 'ç«å¯¹A', 'ç«å¯¹A', 'ç«å¯¹A'],
            'ç¾å›¢ä¸€çº§åˆ†ç±»': ['é¥®å“', 'é¥®å“', 'é£Ÿå“', 'é¥®å“', 'é¥®å“']
        })
    }

def main():
    """ä¸»å‡½æ•° - ç®€åŒ–çš„æ ‡ç­¾é¡µç•Œé¢"""
    
    # é¡µé¢æ ‡é¢˜
    st.markdown('<h1 class="main-header">ğŸª æ™ºèƒ½é—¨åº—ç»è¥çœ‹æ¿</h1>', unsafe_allow_html=True)
    st.markdown("---")
    
    # åˆå§‹åŒ–ç³»ç»Ÿç»„ä»¶
    dashboard = load_dashboard_system()
    data_processor = load_data_processor()
    
    # åˆ›å»º7ä¸ªåŠŸèƒ½æ ‡ç­¾é¡µ
    tab1, tab2, tab3, tab4, tab5, tab6, tab7 = st.tabs([
        "ğŸ“Š è®¢å•æ•°æ®åˆ†æ",
        "ğŸ’° æ¯”ä»·åˆ†æ", 
        "ğŸ¯ AIåœºæ™¯è¥é”€",
        "ğŸ“‹ é—®é¢˜è¯Šæ–­",
        "ğŸ›’ å¤šå•†å“è®¢å•å¼•å¯¼",
        "ğŸª å•†å“åˆ†ç±»ç»“æ„ç«äº‰åŠ›",
        "âš™ï¸ é«˜çº§åŠŸèƒ½"
    ])
    
    # === Tab 1: è®¢å•æ•°æ®åˆ†æ ===
    with tab1:
        st.header("ğŸ“Š è®¢å•æ•°æ®åˆ†æ")
        
        # ç›´æ¥æ˜¾ç¤ºä¸Šä¼ ç•Œé¢
        render_order_data_uploader()
        
        # å¦‚æœå·²æœ‰åˆ†æç»“æœï¼Œæ˜¾ç¤º
        if "analysis_result" in st.session_state and "è®¢å•åˆ†æ" in st.session_state.get("analysis_result", {}):
            st.markdown("---")
            st.subheader("ğŸ“ˆ åˆ†æç»“æœ")
            
            # æ˜¾ç¤ºè®¢å•åˆ†æéƒ¨åˆ†ç»“æœ
            analysis_result = st.session_state["analysis_result"]
            
            # åŸºç¡€æŒ‡æ ‡
            if "åŸºç¡€æŒ‡æ ‡" in analysis_result:
                metrics = analysis_result["åŸºç¡€æŒ‡æ ‡"]
                col1, col2, col3, col4 = st.columns(4)
                col1.metric("è®¢å•æ€»æ•°", f"{metrics.get('è®¢å•æ€»æ•°', 0):,}")
                col2.metric("æ€»é”€å”®é¢", f"Â¥{metrics.get('æ€»é”€å”®é¢', 0):,.2f}")
                col3.metric("æ€»åˆ©æ¶¦", f"Â¥{metrics.get('æ€»åˆ©æ¶¦', 0):,.2f}")
                col4.metric("åˆ©æ¶¦ç‡", f"{metrics.get('åˆ©æ¶¦ç‡', 0):.1f}%")
    
    # === Tab 2: æ¯”ä»·åˆ†æ ===
    with tab2:
        st.header("ğŸ’° æ¯”ä»·åˆ†æ")
        render_unified_price_comparison_module()
    
    # === Tab 3: AIåœºæ™¯è¥é”€ ===
    with tab3:
        st.header("ğŸ¯ AIåœºæ™¯è¥é”€")
        
        # æ£€æŸ¥æ˜¯å¦å·²ä¸Šä¼ å¹¶å¤„ç†æ•°æ®
        has_data = False
        current_data = {}
        
        # ä¼˜å…ˆæ£€æŸ¥å·²å¤„ç†çš„æ•°æ®
        if "current_data" in st.session_state and "raw_data" in st.session_state["current_data"]:
            current_data = st.session_state["current_data"]
            has_data = True
        # å…¶æ¬¡æ£€æŸ¥ä¸Šä¼ çš„æ•°æ®
        elif "uploaded_order_data" in st.session_state:
            current_data = st.session_state["uploaded_order_data"]
            has_data = True
        
        if not has_data:
            st.warning("âš ï¸ è¯·å…ˆåœ¨ã€è®¢å•æ•°æ®åˆ†æã€æ ‡ç­¾é¡µä¸Šä¼ æ•°æ®")
            st.info("ğŸ’¡ åœºæ™¯è¥é”€åˆ†æéœ€è¦åŸºäºè®¢å•æ•°æ®ï¼Œè¯·å…ˆä¸Šä¼ Excelæ–‡ä»¶")
            
            # æä¾›å¿«é€Ÿæ¼”ç¤ºå…¥å£
            if st.button("ğŸª ä½¿ç”¨ç¤ºä¾‹æ•°æ®æ¼”ç¤ºåœºæ™¯è¥é”€", type="secondary"):
                sample_data = load_sample_data()
                st.session_state["uploaded_order_data"] = sample_data
                st.session_state["current_data"] = sample_data
                st.success("âœ… å·²åŠ è½½ç¤ºä¾‹æ•°æ®")
                st.rerun()
        else:
            # ç›´æ¥æ˜¾ç¤ºåœºæ™¯è¥é”€çœ‹æ¿
            display_scenario_marketing_dashboard(current_data)
    
    # === Tab 4: é—®é¢˜è¯Šæ–­ ===
    with tab4:
        st.header("ğŸ“‹ æ™ºèƒ½é—®é¢˜è¯Šæ–­")
        
        st.info("""
        **ğŸ¯ åŠŸèƒ½è¯´æ˜**ï¼šåŸºäºè®¢å•æ•°æ®ï¼Œæ™ºèƒ½è¯†åˆ«ç»è¥ä¸­çš„æ½œåœ¨é—®é¢˜ï¼Œå¹¶æä¾›é’ˆå¯¹æ€§çš„è§£å†³æ–¹æ¡ˆ
        
        **ğŸ’¡ è¯Šæ–­ç»´åº¦**ï¼š
        - ğŸ“‰ é”€å”®ä¸‹æ»‘åˆ†æ
        - ğŸ’° åˆ©æ¶¦å¼‚å¸¸è¯Šæ–­
        - ğŸ“¦ åº“å­˜é—®é¢˜è¯†åˆ«
        - ğŸ¯ å•†å“ç»“æ„ä¼˜åŒ–
        - ğŸ‘¥ å®¢æˆ·æµå¤±é¢„è­¦
        - âš ï¸ è¿è¥é£é™©æç¤º
        """)
        
        # æ£€æŸ¥æ˜¯å¦å·²ä¸Šä¼ å¹¶å¤„ç†æ•°æ®
        has_data = False
        current_data = {}
        
        # ä¼˜å…ˆæ£€æŸ¥å·²å¤„ç†çš„æ•°æ®
        if "current_data" in st.session_state and "raw_data" in st.session_state["current_data"]:
            current_data = st.session_state["current_data"]
            has_data = True
        # å…¶æ¬¡æ£€æŸ¥ä¸Šä¼ çš„æ•°æ®
        elif "uploaded_order_data" in st.session_state:
            current_data = st.session_state["uploaded_order_data"]
            has_data = True
        
        if not has_data:
            st.warning("âš ï¸ è¯·å…ˆåœ¨ã€è®¢å•æ•°æ®åˆ†æã€æ ‡ç­¾é¡µä¸Šä¼ æ•°æ®")
            st.info("ğŸ’¡ é—®é¢˜è¯Šæ–­éœ€è¦åŸºäºè®¢å•æ•°æ®ï¼Œè¯·å…ˆä¸Šä¼ Excelæ–‡ä»¶")
            
            # æ˜¾ç¤ºåŠŸèƒ½ä»‹ç»
            with st.expander("ğŸ“‹ æŸ¥çœ‹è¯Šæ–­åŠŸèƒ½è¯¦æƒ…"):
                st.markdown("""
                **é—®é¢˜è¯Šæ–­ä¸­å¿ƒæä¾›ä»¥ä¸‹åŠŸèƒ½**ï¼š
                
                1. **è‡ªåŠ¨é—®é¢˜è¯†åˆ«**
                   - æ™ºèƒ½æ‰«ææ•°æ®ï¼Œè¯†åˆ«æ½œåœ¨é—®é¢˜
                   - é—®é¢˜ä¸¥é‡ç¨‹åº¦åˆ†çº§ï¼ˆä¸¥é‡ã€è­¦å‘Šã€å»ºè®®ï¼‰
                   - æä¾›é—®é¢˜å½±å“èŒƒå›´å’Œé‡‘é¢ä¼°ç®—
                
                2. **æ ¹å› åˆ†æ**
                   - æ·±åº¦æŒ–æ˜é—®é¢˜äº§ç”Ÿçš„æ ¹æœ¬åŸå› 
                   - å¤šç»´åº¦äº¤å‰åˆ†æ
                   - æ•°æ®å¯è§†åŒ–å‘ˆç°
                
                3. **è§£å†³æ–¹æ¡ˆæ¨è**
                   - åŸºäºè¡Œä¸šæœ€ä½³å®è·µçš„å»ºè®®
                   - å¯é‡åŒ–çš„æ”¹è¿›ç›®æ ‡
                   - åˆ†æ­¥éª¤å®æ–½è®¡åˆ’
                
                4. **è¯Šæ–­æŠ¥å‘Šå¯¼å‡º**
                   - ç”Ÿæˆå®Œæ•´çš„è¯Šæ–­æŠ¥å‘Š
                   - æ”¯æŒExcelæ ¼å¼ä¸‹è½½
                   - åŒ…å«é—®é¢˜æ¸…å•å’Œè§£å†³æ–¹æ¡ˆ
                """)
        else:
            # è°ƒç”¨é—®é¢˜è¯Šæ–­æ¨¡å—
            try:
                # é¢„å¤„ç†æ•°æ®ï¼šç¡®ä¿æœ‰æ—¥æœŸåˆ—
                # é‡è¦ï¼šä½¿ç”¨æ·±æ‹·è´é¿å…ä¿®æ”¹åŸå§‹æ•°æ®
                processed_data = {
                    'raw_data': current_data.get('raw_data', pd.DataFrame()).copy()
                }
                raw_df = processed_data['raw_data']
                
                # ğŸ” DEBUG: æ£€æŸ¥æ•°æ®é‡
                print(f"[DEBUG] Tab4 - è·å–åˆ°çš„åŸå§‹æ•°æ®é‡: {len(raw_df)}è¡Œ")
                
                if not raw_df.empty:
                    # ç¡®ä¿æœ‰æ—¥æœŸåˆ—ï¼ˆé—®é¢˜è¯Šæ–­å¼•æ“éœ€è¦ï¼‰
                    if 'ä¸‹å•æ—¶é—´' in raw_df.columns:
                        if 'æ—¥æœŸ' not in raw_df.columns:
                            raw_df['æ—¥æœŸ'] = pd.to_datetime(raw_df['ä¸‹å•æ—¶é—´'], errors='coerce')
                        else:
                            # å¦‚æœå·²æœ‰æ—¥æœŸåˆ—,ç¡®ä¿æ ¼å¼æ­£ç¡®
                            raw_df['æ—¥æœŸ'] = pd.to_datetime(raw_df['æ—¥æœŸ'], errors='coerce')
                        
                        # ğŸ” DEBUG: æ£€æŸ¥æ—¥æœŸèŒƒå›´
                        if 'æ—¥æœŸ' in raw_df.columns:
                            valid_dates = raw_df['æ—¥æœŸ'].dropna()
                            if len(valid_dates) > 0:
                                print(f"[DEBUG] Tab4 - æ—¥æœŸèŒƒå›´: {valid_dates.min()} è‡³ {valid_dates.max()}")
                                print(f"[DEBUG] Tab4 - å”¯ä¸€æ—¥æœŸæ•°: {valid_dates.dt.date.nunique()}")
                    
                    # æ£€æŸ¥æ•°æ®æ—¶é—´èŒƒå›´
                    if 'æ—¥æœŸ' in raw_df.columns:
                        valid_dates = raw_df['æ—¥æœŸ'].dropna()
                        if len(valid_dates) > 0:
                            date_range = (valid_dates.max() - valid_dates.min()).days
                            
                            if date_range < 7:
                                st.warning(f"""
                                âš ï¸ æ•°æ®æ—¶é—´èŒƒå›´è¾ƒçŸ­ï¼ˆä»…{date_range}å¤©ï¼‰ï¼Œéƒ¨åˆ†å‘¨æœŸå¯¹æ¯”åˆ†æåŠŸèƒ½å¯èƒ½å—é™
                                
                                **ğŸ’¡ å»ºè®®**ï¼š
                                - ä¸Šä¼ è‡³å°‘7å¤©ä»¥ä¸Šçš„æ•°æ®ä»¥è¿›è¡Œå‘¨å¯¹å‘¨åˆ†æ
                                - ä¸Šä¼ è‡³å°‘30å¤©ä»¥ä¸Šçš„æ•°æ®ä»¥è¿›è¡Œæœˆå¯¹æœˆåˆ†æ
                                - å½“å‰æ•°æ®èŒƒå›´ï¼š{valid_dates.min().strftime('%Y-%m-%d')} ~ {valid_dates.max().strftime('%Y-%m-%d')}
                                """)
                                st.info("ğŸ“Š ä»å¯ä½¿ç”¨åŸºç¡€è¯Šæ–­åŠŸèƒ½ï¼ˆè´Ÿæ¯›åˆ©é¢„è­¦ã€è§’è‰²å¤±è¡¡ç­‰ï¼‰")
                    
                    # æ›´æ–°processed_data
                    processed_data['raw_data'] = raw_df
                
                display_problem_diagnostic_center(processed_data)
            except Exception as e:
                st.error(f"âŒ é—®é¢˜è¯Šæ–­åŠ è½½å¤±è´¥: {str(e)}")
                with st.expander("ğŸ” æŸ¥çœ‹è¯¦ç»†é”™è¯¯ä¿¡æ¯"):
                    import traceback
                    st.code(traceback.format_exc())
    
    # === Tab 5: å¤šå•†å“è®¢å•å¼•å¯¼ ===
    with tab5:
        st.header("ğŸ›’ å¤šå•†å“è®¢å•å¼•å¯¼åˆ†æ")
        
        st.info("""
        **ğŸ“Š ç»Ÿè®¡å‘ç°**ï¼šå•†å“æ•°é‡æ¯å¢åŠ 1ä¸ªï¼Œå®¢å•ä»·å¹³å‡å¢åŠ  **Â¥3.16**ï¼ˆåŸºäº6297ä¸ªè®¢å•çš„å›å½’åˆ†æï¼‰
        
        **ğŸ¯ åˆ†æç›®æ ‡**ï¼šé€šè¿‡æ•°æ®åˆ†æï¼Œæ‰¾åˆ°æå‡å¤šå•†å“è®¢å•ç‡çš„æœ‰æ•ˆç­–ç•¥ï¼Œä»è€Œæå‡æ•´ä½“å®¢å•ä»·
        """)
        
        # æ£€æŸ¥æ˜¯å¦å·²ä¸Šä¼ æ•°æ®
        has_data = False
        current_df = None
        
        if "uploaded_order_data" in st.session_state:
            current_data = st.session_state["uploaded_order_data"]
            if "raw_data" in current_data:
                current_df = current_data["raw_data"]
                has_data = True
        
        if not has_data:
            st.warning("âš ï¸ è¯·å…ˆåœ¨ã€è®¢å•æ•°æ®åˆ†æã€æ ‡ç­¾é¡µä¸Šä¼ æ•°æ®")
            
            with st.expander("ğŸ“‹ æŸ¥çœ‹æ‰€éœ€æ•°æ®æ ¼å¼"):
                st.markdown("""
                **å¿…éœ€å­—æ®µ**ï¼š
                - `è®¢å•ID`: è®¢å•å”¯ä¸€æ ‡è¯†
                - `å•†å“åç§°`: å•†å“åç§°
                - `å•†å“å®å”®ä»·`: å•†å“å®é™…å”®ä»·
                
                **å¯é€‰å­—æ®µ**ï¼ˆå¢å¼ºåˆ†æï¼‰ï¼š
                - `ä¸‹å•æ—¶é—´`: è®¢å•æ—¶é—´
                - `ä¸€çº§åˆ†ç±»å`: å•†å“åˆ†ç±»
                - `åˆ©æ¶¦é¢`: å•†å“åˆ©æ¶¦
                
                **ç¤ºä¾‹æ•°æ®**ï¼š
                ```
                è®¢å•ID    | å•†å“åç§°      | å•†å“å®å”®ä»·
                ORD001   | å¯å£å¯ä¹      | 3.5
                ORD001   | è–¯ç‰‡         | 5.8
                ORD002   | ç‰›å¥¶         | 12.0
                ```
                """)
        else:
            # å¯¼å…¥å¤šå•†å“è®¢å•åˆ†ææ¨¡å—
            try:
                from å¤šå•†å“è®¢å•å¼•å¯¼åˆ†æçœ‹æ¿ import (
                    filter_retail_data,
                    calculate_order_item_stats,
                    render_order_quantity_distribution,
                    render_item_quantity_analysis,
                    render_frequent_combos,
                    render_single_order_diagnosis,
                    render_promotion_suggestions
                )
                
                # è¿‡æ»¤O2Oé›¶å”®æ•°æ®ï¼ˆå‰”é™¤å’–å•¡ç­‰å…¶ä»–ä¸šåŠ¡æ¸ é“ï¼‰
                current_df_filtered = filter_retail_data(current_df)
                
                # æ˜¾ç¤ºè¿‡æ»¤ä¿¡æ¯
                if len(current_df_filtered) < len(current_df):
                    excluded_count = len(current_df) - len(current_df_filtered)
                    st.info(f"â„¹ï¸ å·²è‡ªåŠ¨å‰”é™¤å’–å•¡æ¸ é“æ•°æ® {excluded_count} è¡Œï¼Œä¿ç•™O2Oé›¶å”®æ•°æ® {len(current_df_filtered)} è¡Œ")
                
                # è®¡ç®—è®¢å•ç»Ÿè®¡
                order_stats = calculate_order_item_stats(current_df_filtered)
                
                # æ˜¾ç¤ºå„ä¸ªåˆ†ææ¨¡å—
                st.markdown("---")
                render_order_quantity_distribution(order_stats)
                
                st.markdown("---")
                render_item_quantity_analysis(order_stats)
                
                st.markdown("---")
                render_frequent_combos(current_df_filtered)
                
                st.markdown("---")
                render_single_order_diagnosis(current_df_filtered, order_stats)
                
                st.markdown("---")
                render_promotion_suggestions(order_stats)
                
            except Exception as e:
                st.error(f"åˆ†æè¿‡ç¨‹å‡ºé”™: {str(e)}")
                with st.expander("æŸ¥çœ‹è¯¦ç»†é”™è¯¯"):
                    import traceback
                    st.code(traceback.format_exc())
    
    # === Tab 6: å•†å“åˆ†ç±»ç»“æ„ç«äº‰åŠ› ===
    with tab6:
        # æ£€æŸ¥æ˜¯å¦å·²ä¸Šä¼ å¹¶å¤„ç†æ•°æ®
        has_data = False
        current_df = None
        
        # ä¼˜å…ˆæ£€æŸ¥å·²å¤„ç†çš„æ•°æ®
        if "current_data" in st.session_state and "raw_data" in st.session_state["current_data"]:
            current_df = st.session_state["current_data"]["raw_data"]
            has_data = True
        # å…¶æ¬¡æ£€æŸ¥ä¸Šä¼ çš„æ•°æ®
        elif "uploaded_order_data" in st.session_state and "raw_data" in st.session_state["uploaded_order_data"]:
            current_df = st.session_state["uploaded_order_data"]["raw_data"]
            has_data = True
        
        if not has_data:
            st.warning("âš ï¸ è¯·å…ˆåœ¨ã€è®¢å•æ•°æ®åˆ†æã€æ ‡ç­¾é¡µä¸Šä¼ æ•°æ®")
            st.info("ğŸ’¡ å•†å“åˆ†ç±»åˆ†æéœ€è¦åŸºäºè®¢å•æ•°æ®ï¼Œå¹¶ä¸”æ•°æ®ä¸­éœ€è¦åŒ…å«ã€ä¸€çº§åˆ†ç±»åã€å­—æ®µ")
            
            # æ˜¾ç¤ºæ•°æ®è¦æ±‚
            with st.expander("ğŸ“‹ æŸ¥çœ‹æ•°æ®è¦æ±‚"):
                st.markdown("""
                **å¿…éœ€å­—æ®µ**ï¼š
                - `è®¢å•ID`: è®¢å•å”¯ä¸€æ ‡è¯†
                - `å•†å“åç§°`: å•†å“åç§°
                - `å•†å“å®å”®ä»·`: å•†å“å®é™…å”®ä»·
                - `ä¸€çº§åˆ†ç±»å`: å•†å“ä¸€çº§åˆ†ç±»ï¼ˆ**æ ¸å¿ƒå­—æ®µ**ï¼‰
                
                **å¯é€‰å­—æ®µ**ï¼ˆå¢å¼ºåˆ†æï¼‰ï¼š
                - `ä¸‰çº§åˆ†ç±»å`: å•†å“ä¸‰çº§åˆ†ç±»
                - `æˆæœ¬`: å•†å“æˆæœ¬ï¼ˆç”¨äºè®¡ç®—æ¯›åˆ©ç‡ï¼‰
                - `æ¸ é“`: è®¢å•æ¥æºæ¸ é“
                """)
        else:
            # æ£€æŸ¥å¿…éœ€å­—æ®µ
            required_fields = ['è®¢å•ID', 'å•†å“åç§°', 'å•†å“å®å”®ä»·']
            category_field = 'ä¸€çº§åˆ†ç±»å' if 'ä¸€çº§åˆ†ç±»å' in current_df.columns else 'ä¸€çº§åˆ†ç±»'
            
            missing_fields = [f for f in required_fields if f not in current_df.columns]
            if missing_fields:
                st.error(f"âŒ æ•°æ®ç¼ºå°‘å¿…éœ€å­—æ®µ: {', '.join(missing_fields)}")
                return
            
            if category_field not in current_df.columns:
                st.error("âŒ æ•°æ®ä¸­ç¼ºå°‘åˆ†ç±»å­—æ®µï¼ˆä¸€çº§åˆ†ç±»å æˆ– ä¸€çº§åˆ†ç±»ï¼‰")
                st.info("ğŸ’¡ å•†å“åˆ†ç±»åˆ†æéœ€è¦å•†å“åˆ†ç±»ä¿¡æ¯ï¼Œè¯·ç¡®ä¿æ•°æ®ä¸­åŒ…å«ã€ä¸€çº§åˆ†ç±»åã€æˆ–ã€ä¸€çº§åˆ†ç±»ã€å­—æ®µ")
                return
            
            # æ˜¾ç¤ºæ•°æ®æ¦‚è§ˆ
            st.success(f"âœ… æ•°æ®å·²åŠ è½½ï¼š{len(current_df)} è¡Œè®¢å•æ•°æ®")
            
            # è°ƒç”¨å•†å“åˆ†ç±»åˆ†ææ¨¡å—
            if CATEGORY_ANALYSIS_AVAILABLE:
                try:
                    render_category_analysis(current_df)
                except Exception as e:
                    st.error(f"âŒ åˆ†æè¿‡ç¨‹å‡ºé”™: {str(e)}")
                    with st.expander("ğŸ” æŸ¥çœ‹è¯¦ç»†é”™è¯¯ä¿¡æ¯"):
                        import traceback
                        st.code(traceback.format_exc())
                    
                    # æä¾›å¯èƒ½çš„è§£å†³æ–¹æ¡ˆ
                    st.info("""
                    **ğŸ’¡ å¸¸è§é—®é¢˜æ’æŸ¥**ï¼š
                    1. æ£€æŸ¥æ•°æ®ä¸­æ˜¯å¦åŒ…å«ã€ä¸€çº§åˆ†ç±»åã€æˆ–ã€ä¸‰çº§åˆ†ç±»åã€å­—æ®µ
                    2. ç¡®ä¿åˆ†ç±»å­—æ®µä¸ä¸ºç©º
                    3. å¦‚æœæœ‰ç‰¹æ®Šå­—ç¬¦æˆ–ç¼–ç é—®é¢˜ï¼Œè¯·å°è¯•é‡æ–°å¯¼å‡ºæ•°æ®
                    """)
            else:
                st.error("âŒ å•†å“åˆ†ç±»ç»“æ„åˆ†ææ¨¡å—æœªåŠ è½½")
                st.info("è¯·æ£€æŸ¥ `å•†å“åˆ†ç±»ç»“æ„åˆ†æ.py` æ–‡ä»¶æ˜¯å¦å­˜åœ¨")
    
    # === Tab 7: é«˜çº§åŠŸèƒ½ ===
    with tab7:
        st.header("âš™ï¸ é«˜çº§åŠŸèƒ½")
        
        # ============ å­æ ‡ç­¾é¡µ ============
        adv_tab1, adv_tab2, adv_tab3, adv_tab4 = st.tabs([
            "ğŸ”¬ AIç»¼åˆåˆ†æ",
            "ğŸ§  AIå­¦ä¹ ç³»ç»Ÿ", 
            "â„¹ï¸ ç³»ç»Ÿä¿¡æ¯",
            "ğŸ® æ¼”ç¤ºæ¨¡å¼"
        ])
        
        # === é«˜çº§Tab 1: AIç»¼åˆåˆ†æ ===
        with adv_tab1:
            st.subheader("ğŸ”¬ AIç»¼åˆåˆ†æ")
            st.info("æ­¤åŠŸèƒ½åŒ…å«ï¼šé”€å”®åˆ†æã€ç«å¯¹åˆ†æã€é£é™©è¯„ä¼°ã€ç­–ç•¥å»ºè®®ã€é¢„æµ‹åˆ†æç­‰å…¨é¢åˆ†æ")
            
            # æ£€æŸ¥æ˜¯å¦å·²ä¸Šä¼ æ•°æ®
            if "uploaded_order_data" not in st.session_state:
                st.warning("âš ï¸ è¯·å…ˆåœ¨ã€è®¢å•æ•°æ®åˆ†æã€æ ‡ç­¾é¡µä¸Šä¼ æ•°æ®")
            else:
                # åˆ†æå‚æ•°è®¾ç½®
                col1, col2 = st.columns([3, 1])
                with col1:
                    analysis_scope = st.multiselect(
                        "é€‰æ‹©åˆ†æç»´åº¦",
                        ["é”€å”®åˆ†æ", "ç«å¯¹åˆ†æ", "é£é™©è¯„ä¼°", "ç­–ç•¥å»ºè®®", "é¢„æµ‹åˆ†æ"],
                        default=["é”€å”®åˆ†æ", "ç­–ç•¥å»ºè®®"],
                    )
                with col2:
                    forecast_days = st.number_input("é¢„æµ‹å¤©æ•°", 7, 90, 30)
                
                # å¼€å§‹åˆ†ææŒ‰é’®
                if st.button("ğŸš€ å¼€å§‹AIç»¼åˆåˆ†æ", type="primary", use_container_width=True):
                    current_data = st.session_state["uploaded_order_data"]
                    
                    with st.spinner("æ­£åœ¨è¿›è¡ŒAIç»¼åˆåˆ†æ..."):
                        analysis_result = dashboard.comprehensive_analysis(
                            current_data,
                            current_data.get("competitor_data"),
                        )
                        st.session_state["analysis_result"] = analysis_result
                        st.session_state["current_data"] = current_data
                        st.session_state["forecast_days"] = forecast_days
                        
                        # ä¿å­˜åˆ°æ•°æ®å¤„ç†å™¨
                        data_processor.processed_data = {
                            "sales_data": current_data.get("product_data", pd.DataFrame()),
                            "order_data": current_data.get("order_data", pd.DataFrame()),
                        }
                        st.success("âœ… åˆ†æå®Œæˆï¼")
                        st.rerun()
                
                # æ˜¾ç¤ºåˆ†æç»“æœ
                if "analysis_result" in st.session_state:
                    st.markdown("---")
                    display_analysis_results(
                        st.session_state["analysis_result"], 
                        analysis_scope, 
                        dashboard
                    )
        
        # === é«˜çº§Tab 2: AIå­¦ä¹ ç³»ç»Ÿ ===
        with adv_tab2:
            st.subheader("ğŸ§  AIå­¦ä¹ ç³»ç»Ÿ")
            learning_status = dashboard.get_learning_status()
            
            if learning_status.get("enabled"):
                st.success("âœ… AIå­¦ä¹ ç³»ç»Ÿå·²å¯ç”¨")
                
                # å­¦ä¹ ç»Ÿè®¡
                learning_stats = learning_status.get("learning_statistics", {})
                if learning_stats:
                    col1, col2, col3 = st.columns(3)
                    col1.metric("æ€»å­¦ä¹ æ¬¡æ•°", learning_stats.get('total_learning_sessions', 0))
                    col2.metric("åœ¨çº¿æ›´æ–°", learning_stats.get('online_updates', 0))
                    col3.metric("æ‰¹é‡æ›´æ–°", learning_stats.get('batch_updates', 0))
                
                # å­¦ä¹ æ“ä½œ
                col1, col2 = st.columns(2)
                with col1:
                    if st.button("ğŸ”„ æ‰‹åŠ¨æ¨¡å‹è®­ç»ƒ", help="ä½¿ç”¨å†å²æ•°æ®æ‰‹åŠ¨è®­ç»ƒæ¨¡å‹"):
                        sample_data = load_sample_data()
                        with st.spinner("æ­£åœ¨è®­ç»ƒæ¨¡å‹..."):
                            training_result = dashboard.manual_model_training([sample_data])
                            if training_result.get("success"):
                                st.success("ğŸ‰ æ¨¡å‹è®­ç»ƒå®Œæˆ")
                            else:
                                st.error(f"âŒ è®­ç»ƒå¤±è´¥: {training_result.get('error', 'æœªçŸ¥é”™è¯¯')}")
                
                with col2:
                    if st.button("ğŸ“„ å¯¼å‡ºå­¦ä¹ æŠ¥å‘Š"):
                        report_path = dashboard.export_learning_insights()
                        if report_path:
                            st.success(f"âœ… æŠ¥å‘Šå·²å¯¼å‡º: {report_path}")
                        else:
                            st.error("âŒ å¯¼å‡ºå¤±è´¥")
            else:
                st.info("AIå­¦ä¹ ç³»ç»Ÿæš‚æœªå¯ç”¨")
        
        # === é«˜çº§Tab 3: ç³»ç»Ÿä¿¡æ¯ ===
        with adv_tab3:
            st.subheader("â„¹ï¸ ç³»ç»Ÿä¿¡æ¯")
            real_data, load_messages = load_real_business_data()
            
            if load_messages:
                st.warning("âš ï¸ æ•°æ®åŠ è½½æ¶ˆæ¯:")
                for msg in load_messages:
                    st.write(f"â€¢ {msg}")
            
            if real_data is not None:
                st.success("âœ… ç³»ç»Ÿå·²æ£€æµ‹åˆ°çœŸå®æ•°æ®æ–‡ä»¶")
                col1, col2 = st.columns(2)
                col1.metric("æ•°æ®æº", real_data['data_source'])
                col2.metric("æ•°æ®æœŸé—´", real_data['data_period'])
                col1.metric("è®¢å•æ•°", f"{real_data['total_orders']:,}")
                col2.metric("å•†å“ç§ç±»", f"{real_data['total_products']:,}")
            else:
                st.info("æœªæ£€æµ‹åˆ°çœŸå®æ•°æ®æ–‡ä»¶")
        
        # === é«˜çº§Tab 4: æ¼”ç¤ºæ¨¡å¼ ===
        with adv_tab4:
            st.subheader("ğŸ® æ¼”ç¤ºæ¨¡å¼")
            st.info("æ¼”ç¤ºæ¨¡å¼ä½¿ç”¨å†…ç½®ç¤ºä¾‹æ•°æ®ï¼Œå¯ç”¨äºç•Œé¢æ¼”ç¤ºå’ŒåŠŸèƒ½æµ‹è¯•")
            
            if st.button("ğŸª å¯åŠ¨ç¤ºä¾‹æ•°æ®æ¼”ç¤º", type="secondary"):
                sample_data = load_sample_data()
                st.session_state["uploaded_order_data"] = sample_data
                st.session_state["current_data"] = sample_data
                st.success("âœ… å·²åŠ è½½ç¤ºä¾‹æ•°æ®ï¼Œè¯·å‰å¾€å…¶ä»–æ ‡ç­¾é¡µä½“éªŒåŠŸèƒ½")
                st.rerun()

def display_analysis_results(analysis_result, analysis_scope, dashboard_instance):
    """æ˜¾ç¤ºåˆ†æç»“æœ"""
    
    # 1. æ€»ä½“æ¦‚è§ˆ
    st.subheader("ğŸ“Š åˆ†ææ¦‚è§ˆ")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric(
            "æ•°æ®è´¨é‡è¯„åˆ†",
            f"{analysis_result['store_overview']['data_quality_score']:.2f}",
            delta="è‰¯å¥½" if analysis_result['store_overview']['data_quality_score'] > 0.7 else "éœ€æ”¹å–„"
        )
    
    with col2:
        st.metric(
            "ç”Ÿæˆå‡è®¾æ•°é‡",
            len(analysis_result['hypothesis_analysis']),
            delta="å·²éªŒè¯"
        )
    
    with col3:
        total_decisions = sum(len(options) for options in analysis_result['strategic_decisions'].values())
        st.metric(
            "ç­–ç•¥å»ºè®®æ•°",
            total_decisions,
            delta="å¯æ‰§è¡Œ"
        )
    
    with col4:
        st.metric(
            "ç»¼åˆå»ºè®®æ•°",
            len(analysis_result['comprehensive_recommendations']),
            delta="ä¼˜å…ˆçº§æ’åº"
        )
    
    # 2. æ ¸å¿ƒå»ºè®®å±•ç¤º
    st.subheader("ğŸ¯ æ ¸å¿ƒå»ºè®®")
    
    for i, recommendation in enumerate(analysis_result['comprehensive_recommendations'][:5], 1):
        st.markdown(f"""
        <div class="recommendation-box">
            <strong>å»ºè®® {i}:</strong> {recommendation}
        </div>
        """, unsafe_allow_html=True)
    
    # 3. é€‰é¡¹å¡å¼è¯¦ç»†åˆ†æ
    tabs_to_create = ["ğŸ›ï¸ å•†å“ç­–ç•¥", "ğŸ“ˆ è¶‹åŠ¿é¢„æµ‹", "âš ï¸ é£é™©è¯„ä¼°", "ğŸ¢ ç«å¯¹åˆ†æ", "ğŸ”¬ å‡è®¾éªŒè¯", "ğŸ§  å­¦ä¹ æ•ˆæœ", "ğŸ’¹ æ¯”ä»·çœ‹æ¿", "ğŸ¯ åœºæ™¯è¥é”€", "ğŸ“‹ é—®é¢˜è¯Šæ–­"]
    tab_objects = st.tabs(tabs_to_create)
    
    tab_map = {name: obj for name, obj in zip(tabs_to_create, tab_objects)}

    with tab_map["ğŸ›ï¸ å•†å“ç­–ç•¥"]:
        display_product_strategy(analysis_result)
    
    with tab_map["ğŸ“ˆ è¶‹åŠ¿é¢„æµ‹"]:
        display_trend_analysis(analysis_result)
    
    with tab_map["âš ï¸ é£é™©è¯„ä¼°"]:
        display_risk_assessment(analysis_result)
    
    with tab_map["ğŸ¢ ç«å¯¹åˆ†æ"]:
        display_competitor_analysis(analysis_result)
    
    with tab_map["ğŸ”¬ å‡è®¾éªŒè¯"]:
        display_hypothesis_validation(analysis_result)
    
    with tab_map["ğŸ§  å­¦ä¹ æ•ˆæœ"]:
        display_learning_effects(analysis_result, dashboard_instance)

    with tab_map["ğŸ’¹ æ¯”ä»·çœ‹æ¿"]:
        st.caption("ğŸ” åˆ†æç»“æœä¸­çš„æ¯”ä»·çœ‹æ¿")
        render_unified_price_comparison_module()
        
        # æ·»åŠ è®¢å•æ•°æ®ä¸Šä¼ åŠŸèƒ½
        st.markdown("---")
        st.subheader("ğŸ“Š è®¢å•æ•°æ®åˆ†æ")
        render_order_data_uploader()
    
    with tab_map["ğŸ¯ åœºæ™¯è¥é”€"]:
        display_scenario_marketing_dashboard(st.session_state.get("current_data", {}))
    
    with tab_map["ğŸ“‹ é—®é¢˜è¯Šæ–­"]:
        display_problem_diagnostic_center(st.session_state.get("current_data", {}))

def display_product_strategy(analysis_result):
    """æ˜¾ç¤ºå•†å“ç­–ç•¥åˆ†æ"""
    st.subheader("ğŸ›ï¸ å•†å“ç­–ç•¥åˆ†æ")
    
    if 'strategic_decisions' in analysis_result:
        decisions = analysis_result['strategic_decisions']
        
        # æµé‡å“ç­–ç•¥
        if 'æµé‡å“é€‰æ‹©' in decisions:
            st.write("**ğŸ¯ æµé‡å“å»ºè®®**")
            
            traffic_options = decisions['æµé‡å“é€‰æ‹©']
            if traffic_options:
                for option in traffic_options:
                    col1, col2 = st.columns([3, 1])
                    
                    with col1:
                        st.write(f"**{option.description}**")
                        st.write(f"é¢„æœŸå®¢æµå¢é•¿: +{option.expected_outcome.get('å®¢æµé‡å¢é•¿', 0)*100:.1f}%")
                        st.write(f"å…³è”é”€å”®æå‡: +{option.expected_outcome.get('å…³è”é”€å”®æå‡', 0)*100:.1f}%")
                    
                    with col2:
                        confidence_color = "green" if option.confidence_score > 0.7 else "orange"
                        st.markdown(f"<div style='text-align: center; color: {confidence_color}; font-size: 1.2em; font-weight: bold;'>ç½®ä¿¡åº¦<br>{option.confidence_score:.1%}</div>", unsafe_allow_html=True)
        
        # æŠ˜æ‰£å“ç­–ç•¥
        if 'æŠ˜æ‰£å“ç­–ç•¥' in decisions:
            st.write("**ğŸ’° æŠ˜æ‰£å“å»ºè®®**")
            
            discount_options = decisions['æŠ˜æ‰£å“ç­–ç•¥']
            if discount_options:
                for option in discount_options:
                    with st.expander(f"æŠ˜æ‰£æ–¹æ¡ˆ: {option.description}"):
                        
                        # åˆ›å»ºæŒ‡æ ‡å±•ç¤º
                        col1, col2, col3 = st.columns(3)
                        
                        with col1:
                            st.metric(
                                "é¢„æœŸé”€é‡æå‡",
                                f"+{option.expected_outcome.get('é”€é‡æå‡', 0)*100:.0f}%"
                            )
                        
                        with col2:
                            st.metric(
                                "åº“å­˜å‘¨è½¬æ”¹å–„",
                                f"+{option.expected_outcome.get('åº“å­˜å‘¨è½¬', 0)*100:.0f}%"
                            )
                        
                        with col3:
                            impact = option.expected_outcome.get('æ¯›åˆ©ç‡å½±å“', 0)
                            st.metric(
                                "æ¯›åˆ©ç‡å½±å“",
                                f"{impact*100:+.0f}%",
                                delta="é¢„æœŸèŒƒå›´å†…" if abs(impact) < 0.3 else "éœ€è°¨æ…"
                            )
        
        # å®šä»·ç­–ç•¥
        if 'å®šä»·ç­–ç•¥' in decisions:
            st.write("**ğŸ’² å®šä»·ç­–ç•¥åˆ†æ**")
            
            pricing_options = decisions['å®šä»·ç­–ç•¥']
            
            # åˆ›å»ºå®šä»·ç­–ç•¥å¯¹æ¯”è¡¨
            if pricing_options:
                pricing_data = []
                for option in pricing_options:
                    pricing_data.append({
                        'ç­–ç•¥': option.description,
                        'é£é™©ç­‰çº§': f"{option.risk_level:.1%}",
                        'é¢„æœŸå¸‚åœºä»½é¢': f"+{option.expected_outcome.get('å¸‚åœºä»½é¢', 0)*100:.1f}%",
                        'é¢„æœŸæ¯›åˆ©å½±å“': f"{option.expected_outcome.get('æ¯›åˆ©ç‡', 0)*100:+.1f}%",
                        'æ¨èåº¦': f"{option.confidence_score:.1%}"
                    })
                
                pricing_df = pd.DataFrame(pricing_data)
                st.dataframe(pricing_df, width='stretch')

def display_trend_analysis(analysis_result):
    """æ˜¾ç¤ºè¶‹åŠ¿åˆ†æ"""
    st.subheader("ğŸ“ˆ é”€å”®è¶‹åŠ¿é¢„æµ‹")
    
    if 'trend_predictions' in analysis_result:
        predictions = analysis_result['trend_predictions']
        
        # è¶‹åŠ¿å›¾
        if 'predictions' in predictions:
            pred_df = predictions['predictions']
            
            fig = go.Figure()
            
            # ä¸»è¶‹åŠ¿çº¿
            fig.add_trace(go.Scatter(
                x=pred_df['date'],
                y=pred_df['predicted_growth_rate'],
                mode='lines+markers',
                name='é¢„æµ‹å¢é•¿ç‡',
                line=dict(color='#1f77b4', width=3)
            ))
            
            # ç½®ä¿¡åŒºé—´
            fig.add_trace(go.Scatter(
                x=pred_df['date'],
                y=pred_df['confidence_upper'],
                mode='lines',
                line=dict(width=0),
                showlegend=False
            ))
            
            fig.add_trace(go.Scatter(
                x=pred_df['date'],
                y=pred_df['confidence_lower'],
                fill='tonexty',
                mode='lines',
                line=dict(width=0),
                name='ç½®ä¿¡åŒºé—´',
                fillcolor='rgba(31, 119, 180, 0.2)'
            ))
            
            fig.update_layout(
                title="æœªæ¥30å¤©é”€å”®å¢é•¿è¶‹åŠ¿é¢„æµ‹",
                xaxis_title="æ—¥æœŸ",
                yaxis_title="å¢é•¿ç‡",
                hovermode='x unified',
                template='plotly_white'
            )
            
            st.plotly_chart(fig, width='stretch', key='prediction_sales_growth_trend')
        
        # è¶‹åŠ¿æ´å¯Ÿ
        if 'trend_summary' in predictions:
            trend_summary = predictions['trend_summary']
            
            col1, col2, col3 = st.columns(3)
            
            with col1:
                trend_color = "green" if trend_summary['overall_trend'] == "ä¸Šå‡" else "red"
                st.markdown(f"""
                <div class="metric-card">
                    <h4>æ•´ä½“è¶‹åŠ¿</h4>
                    <span style="color: {trend_color}; font-size: 1.5em; font-weight: bold;">
                        {trend_summary['overall_trend']}
                    </span>
                </div>
                """, unsafe_allow_html=True)
            
            with col2:
                volatility_color = "red" if trend_summary['volatility'] == "é«˜" else "green"
                st.markdown(f"""
                <div class="metric-card">
                    <h4>æ³¢åŠ¨æ€§</h4>
                    <span style="color: {volatility_color}; font-size: 1.5em; font-weight: bold;">
                        {trend_summary['volatility']}
                    </span>
                </div>
                """, unsafe_allow_html=True)
            
            with col3:
                peak_count = len(trend_summary['peak_periods'])
                st.markdown(f"""
                <div class="metric-card">
                    <h4>é”€å”®é«˜å³°æœŸ</h4>
                    <span style="color: #1f77b4; font-size: 1.5em; font-weight: bold;">
                        {peak_count} ä¸ª
                    </span>
                </div>
                """, unsafe_allow_html=True)
        
        # å…³é”®æ´å¯Ÿ
        if 'key_insights' in predictions:
            st.write("**ğŸ” å…³é”®æ´å¯Ÿ**")
            for insight in predictions['key_insights']:
                st.markdown(f"â€¢ {insight}")

def display_risk_assessment(analysis_result):
    """æ˜¾ç¤ºé£é™©è¯„ä¼°"""
    st.subheader("âš ï¸ é£é™©è¯„ä¼°åˆ†æ")
    
    if 'risk_assessment' in analysis_result:
        risks = analysis_result['risk_assessment']
        
        # é£é™©çŸ©é˜µå¯è§†åŒ–
        risk_data = []
        all_risks = []
        
        for category, risk_factors in risks.items():
            for factor, risk_info in risk_factors.items():
                risk_data.append({
                    'category': category,
                    'factor': factor,
                    'probability': risk_info['probability'],
                    'impact': risk_info['impact'],
                    'risk_score': risk_info['risk_score']
                })
                all_risks.append(risk_info['risk_score'])
        
        # åˆ›å»ºé£é™©çŸ©é˜µå›¾
        risk_df = pd.DataFrame(risk_data)
        
        fig = px.scatter(
            risk_df,
            x='probability',
            y='impact', 
            size='risk_score',
            color='category',
            hover_data=['factor'],
            title="é£é™©çŸ©é˜µåˆ†æ",
            labels={
                'probability': 'å‘ç”Ÿæ¦‚ç‡',
                'impact': 'å½±å“ç¨‹åº¦',
                'category': 'é£é™©ç±»åˆ«'
            }
        )
        
        fig.update_layout(
            xaxis=dict(range=[0, 1]),
            yaxis=dict(range=[0, 1]),
            template='plotly_white'
        )
        
        st.plotly_chart(fig, width='stretch', key='risk_probability_impact_matrix')
        
        # é«˜é£é™©é¡¹ç›®è­¦ç¤º
        high_risks = [item for item in risk_data if item['risk_score'] > 0.5]
        
        if high_risks:
            st.write("**ğŸš¨ é«˜é£é™©è­¦ç¤º**")
            
            for risk in high_risks:
                risk_level = "high-risk" if risk['risk_score'] > 0.7 else "risk-warning"
                
                st.markdown(f"""
                <div class="{risk_level}">
                    <strong>âš ï¸ {risk['factor']}</strong><br>
                    å‘ç”Ÿæ¦‚ç‡: {risk['probability']:.1%} | å½±å“ç¨‹åº¦: {risk['impact']:.1%} | é£é™©è¯„åˆ†: {risk['risk_score']:.2f}
                </div>
                """, unsafe_allow_html=True)
        
        # ç¼“è§£ç­–ç•¥
        st.write("**ğŸ›¡ï¸ é£é™©ç¼“è§£ç­–ç•¥**")
        
        for category, risk_factors in risks.items():
            with st.expander(f"{category}ç¼“è§£ç­–ç•¥"):
                for factor, risk_info in risk_factors.items():
                    if risk_info['risk_score'] > 0.3:  # æ˜¾ç¤ºä¸­é«˜é£é™©çš„ç¼“è§£ç­–ç•¥
                        st.write(f"**{factor}:**")
                        for suggestion in risk_info['mitigation_suggestions']:
                            st.write(f"â€¢ {suggestion}")

def display_competitor_analysis(analysis_result):
    """æ˜¾ç¤ºç«å¯¹åˆ†æ"""
    st.subheader("ğŸ¢ ç«å¯¹åˆ†æ")
    
    if 'competitor_analysis' in analysis_result:
        competitor_data = analysis_result['competitor_analysis']
        
        # å®šä»·å¯¹æ¯”åˆ†æ
        if 'å®šä»·å¯¹æ¯”' in competitor_data and 'comparison_details' in competitor_data['å®šä»·å¯¹æ¯”']:
            st.write("**ğŸ’° ä»·æ ¼ç«äº‰åŠ›åˆ†æ**")
            
            price_comparisons = competitor_data['å®šä»·å¯¹æ¯”']['comparison_details']
            
            if price_comparisons:
                # åˆ›å»ºä»·æ ¼å¯¹æ¯”å›¾
                comparison_df = pd.DataFrame(price_comparisons)
                
                fig = go.Figure()
                
                # ç«å“ä»·æ ¼
                fig.add_trace(go.Bar(
                    name='ç«å“ä»·æ ¼',
                    x=comparison_df['product'],
                    y=comparison_df['competitor_price'],
                    marker_color='lightcoral'
                ))
                
                # è‡ªå·±ä»·æ ¼
                fig.add_trace(go.Bar(
                    name='æˆ‘æ–¹ä»·æ ¼',
                    x=comparison_df['product'],
                    y=comparison_df['own_price'],
                    marker_color='lightblue'
                ))
                
                fig.update_layout(
                    title='ä»·æ ¼å¯¹æ¯”åˆ†æ',
                    xaxis_title='å•†å“',
                    yaxis_title='ä»·æ ¼ (å…ƒ)',
                    barmode='group',
                    template='plotly_white'
                )
                
                st.plotly_chart(fig, width='stretch', key='strategy_price_comparison')
                
                # ä»·æ ¼å»ºè®®è¡¨
                st.write("**ä»·æ ¼è°ƒæ•´å»ºè®®**")
                
                recommendation_data = []
                for item in price_comparisons:
                    recommendation_data.append({
                        'å•†å“': item['product'],
                        'ç«å“ä»·æ ¼': f"Â¥{item['competitor_price']:.2f}",
                        'æˆ‘æ–¹ä»·æ ¼': f"Â¥{item['own_price']:.2f}",
                        'ä»·å·®': f"{item['price_gap_pct']:.1%}",
                        'å»ºè®®': item['recommendation']
                    })
                
                rec_df = pd.DataFrame(recommendation_data)
                st.dataframe(rec_df, width='stretch')
        
        # æˆæœ¬åˆ©æ¶¦å€’æ¨
        if 'æˆæœ¬åˆ©æ¶¦å€’æ¨' in competitor_data:
            st.write("**ğŸ“Š ç«å“ç›ˆåˆ©èƒ½åŠ›åˆ†æ**")
            
            profitability = competitor_data['æˆæœ¬åˆ©æ¶¦å€’æ¨']
            
            if 'high_margin_products' in profitability:
                high_margin = profitability['high_margin_products']
                
                if high_margin:
                    st.write("ç«å“é«˜åˆ©æ¶¦å•†å“TOP5:")
                    
                    margin_df = pd.DataFrame(high_margin[:5])
                    
                    fig = px.bar(
                        margin_df,
                        x='product',
                        y='margin',
                        title='ç«å“é«˜åˆ©æ¶¦å•†å“åˆ†æ',
                        labels={'product': 'å•†å“', 'margin': 'æ¯›åˆ©ç‡'}
                    )
                    
                    st.plotly_chart(fig, width='stretch', key='strategy_competitor_high_margin')
            
            if 'estimated_monthly_revenue' in profitability:
                estimated_revenue = profitability['estimated_monthly_revenue']
                st.metric(
                    "ç«å“é¢„ä¼°æœˆè¥æ”¶",
                    f"Â¥{estimated_revenue:,.0f}",
                    help="åŸºäºå”®ä»·å’Œæœˆé”€é‡ä¼°ç®—"
                )
        
        # é€‰å€å»ºè®®
        if 'é€‰å€å»ºè®®' in competitor_data:
            location_rec = competitor_data['é€‰å€å»ºè®®']
            
            st.write("**ğŸ¢ é€‰å€ç­–ç•¥å»ºè®®**")
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown(f"""
                <div class="recommendation-box">
                    <h4>é€‰å€ç­–ç•¥</h4>
                    {location_rec['proximity_strategy']}
                </div>
                """, unsafe_allow_html=True)
            
            with col2:
                if 'risk_assessment' in location_rec:
                    risks = location_rec['risk_assessment']
                    
                    fig = go.Figure(go.Bar(
                        x=list(risks.keys()),
                        y=list(risks.values()),
                        marker_color=['red' if v > 0.6 else 'orange' if v > 0.4 else 'green' for v in risks.values()]
                    ))
                    
                    fig.update_layout(
                        title='é€‰å€é£é™©è¯„ä¼°',
                        yaxis_title='é£é™©ç¨‹åº¦',
                        template='plotly_white'
                    )
                    
                    st.plotly_chart(fig, width='stretch', key='strategy_location_risk_assessment')

def display_hypothesis_validation(analysis_result):
    """æ˜¾ç¤ºå‡è®¾éªŒè¯"""
    st.subheader("ğŸ”¬ å•†ä¸šå‡è®¾éªŒè¯")
    
    if 'hypothesis_analysis' in analysis_result:
        hypotheses = analysis_result['hypothesis_analysis']
        
        if hypotheses:
            for hyp_id, hypothesis in hypotheses.items():
                with st.expander(f"å‡è®¾ {hyp_id}: {hypothesis['description']}"):
                    
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        st.write("**å‡è®¾è¯¦æƒ…**")
                        st.write(f"å‡è®¾ID: {hypothesis['hypothesis_id']}")
                        st.write(f"ç½®ä¿¡åº¦: {hypothesis['confidence_level']:.1%}")
                        
                        if hypothesis['validation_result'] is not None:
                            status = "âœ… å·²éªŒè¯" if hypothesis['validation_result'] else "âŒ æœªé€šè¿‡"
                            st.write(f"éªŒè¯çŠ¶æ€: {status}")
                    
                    with col2:
                        st.write("**æµ‹è¯•æŒ‡æ ‡**")
                        for metric in hypothesis['test_metrics']:
                            st.write(f"â€¢ {metric}")
                    
                    st.write("**æ”¯æŒæ•°æ®**")
                    supporting_data = hypothesis['supporting_data']
                    
                    # åˆ›å»ºæ”¯æŒæ•°æ®çš„å¯è§†åŒ–
                    if supporting_data:
                        data_items = list(supporting_data.items())
                        if len(data_items) > 0:
                            
                            # æ•°å€¼å‹æ•°æ®ç”¨å›¾è¡¨å±•ç¤º
                            numeric_data = {k: v for k, v in data_items if isinstance(v, (int, float))}
                            
                            if numeric_data:
                                fig = go.Figure(go.Bar(
                                    x=list(numeric_data.keys()),
                                    y=list(numeric_data.values()),
                                    marker_color='lightblue'
                                ))
                                
                                fig.update_layout(
                                    title='å‡è®¾æ”¯æŒæ•°æ®',
                                    template='plotly_white'
                                )
                                
                                st.plotly_chart(fig, width='stretch', key=f'hypothesis_chart_{hyp_id}')
                            else:
                                # éæ•°å€¼æ•°æ®ç”¨è¡¨æ ¼å±•ç¤º
                                st.json(supporting_data)
        else:
            st.info("æš‚æ— å•†ä¸šå‡è®¾æ•°æ®ï¼Œç³»ç»Ÿå°†åŸºäºå®é™…ç»è¥æ•°æ®è‡ªåŠ¨ç”Ÿæˆå‡è®¾")

def display_learning_effects(analysis_result, dashboard_instance):
    """æ˜¾ç¤ºå­¦ä¹ æ•ˆæœåˆ†æ"""
    st.subheader("ğŸ§  AIå­¦ä¹ æ•ˆæœåˆ†æ")
    
    # æ£€æŸ¥å­¦ä¹ å…ƒæ•°æ®
    learning_metadata = analysis_result.get('learning_metadata', {})
    
    if not learning_metadata.get('learning_enabled', False):
        st.warning("âš ï¸ AIå­¦ä¹ ç³»ç»Ÿæœªå¯ç”¨æˆ–è¿è¡Œå¼‚å¸¸")
        if 'error' in learning_metadata:
            st.error(f"é”™è¯¯ä¿¡æ¯: {learning_metadata['error']}")
        return
    
    # 1. å­¦ä¹ çŠ¶æ€æ¦‚è§ˆ
    st.write("**ğŸ“Š å­¦ä¹ çŠ¶æ€æ¦‚è§ˆ**")
    
    learning_stats = learning_metadata.get('learning_statistics', {})
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        total_sessions = learning_stats.get('total_learning_sessions', 0)
        st.metric("æ€»å­¦ä¹ æ¬¡æ•°", total_sessions, 
                 delta="ç´¯ç§¯ç»éªŒ" if total_sessions > 0 else "å¾…å¼€å§‹")
    
    with col2:
        online_updates = learning_stats.get('online_updates', 0)
        st.metric("åœ¨çº¿å­¦ä¹ ", online_updates,
                 delta="å®æ—¶ä¼˜åŒ–" if online_updates > 0 else "æš‚æ— ")
    
    with col3:
        batch_updates = learning_stats.get('batch_updates', 0)
        st.metric("æ‰¹é‡è®­ç»ƒ", batch_updates,
                 delta="æ·±åº¦å­¦ä¹ " if batch_updates > 0 else "æš‚æ— ")
    
    with col4:
        recent_activity = learning_stats.get('recent_activity', {})
        recent_sessions = recent_activity.get('total_sessions', 0)
        st.metric("è¿‘7å¤©æ´»åŠ¨", recent_sessions,
                 delta="æ´»è·ƒ" if recent_sessions > 5 else "ç¨³å®š" if recent_sessions > 0 else "å¾…æ¿€æ´»")
    
    # 2. æ¨¡å‹æ€§èƒ½è¶‹åŠ¿
    if 'performance_trends' in learning_stats:
        st.write("**ğŸ“ˆ æ¨¡å‹æ€§èƒ½è¶‹åŠ¿**")
        
        performance_trends = learning_stats['performance_trends']
        
        if performance_trends:
            # åˆ›å»ºæ€§èƒ½è¶‹åŠ¿å›¾è¡¨
            trend_data = []
            for model_name, trend_info in performance_trends.items():
                trend_data.append({
                    'Model': model_name,
                    'Direction': trend_info['direction'],
                    'Rate': trend_info['rate'],
                    'Current_MAE': trend_info['current_mae'],
                    'Sample_Count': trend_info['sample_count']
                })
            
            trend_df = pd.DataFrame(trend_data)
            
            # æ€§èƒ½æ–¹å‘é¥¼å›¾
            direction_counts = trend_df['Direction'].value_counts()
            
            fig_pie = px.pie(
                values=direction_counts.values,
                names=direction_counts.index,
                title="æ¨¡å‹æ€§èƒ½è¶‹åŠ¿åˆ†å¸ƒ",
                color_discrete_map={
                    'improving': '#2E8B57',
                    'declining': '#DC143C',
                    'stable': '#4682B4'
                }
            )
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.plotly_chart(fig_pie, key="performance_pie")
            
            with col2:
                # æ€§èƒ½è¯¦ç»†è¡¨æ ¼
                st.write("**æ¨¡å‹æ€§èƒ½è¯¦æƒ…**")
                
                display_df = trend_df.copy()
                display_df['Direction'] = display_df['Direction'].map({
                    'improving': 'ğŸ“ˆ æ”¹å–„ä¸­',
                    'declining': 'ğŸ“‰ ä¸‹é™ä¸­',
                    'stable': 'â¡ï¸ ç¨³å®š'
                })
                display_df['Rate'] = display_df['Rate'].apply(lambda x: f"{x:.1%}")
                display_df['Current_MAE'] = display_df['Current_MAE'].apply(lambda x: f"{x:.4f}")
                
                st.dataframe(display_df, key="performance_table")
        else:
            st.info("æš‚æ— æ¨¡å‹æ€§èƒ½è¶‹åŠ¿æ•°æ®")
    
    # 3. å¢å¼ºé¢„æµ‹ç»“æœ
    if 'enhanced_predictions' in analysis_result:
        st.write("**ğŸ”® AIå¢å¼ºé¢„æµ‹ç»“æœ**")
        
        enhanced_predictions = analysis_result['enhanced_predictions']
        prediction_meta = enhanced_predictions.get('meta', {})
        
        # æ˜¾ç¤ºé¢„æµ‹å…ƒä¿¡æ¯
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric(
                "é¢„æµ‹æ—¶é—´",
                prediction_meta.get('prediction_time', 'N/A')[:19] if prediction_meta.get('prediction_time') else 'N/A',
                delta="æœ€æ–°"
            )
        
        with col2:
            st.metric(
                "ç‰¹å¾ç»´åº¦", 
                prediction_meta.get('feature_count', 0),
                delta="å¤šç»´åˆ†æ"
            )
        
        with col3:
            models_used = prediction_meta.get('models_used', [])
            st.metric(
                "ä½¿ç”¨æ¨¡å‹", 
                len(models_used),
                delta="é›†æˆé¢„æµ‹"
            )
        
        # æ˜¾ç¤ºå„æ¨¡å‹é¢„æµ‹ç»“æœ
        for model_name, prediction_stats in enhanced_predictions.items():
            if model_name == 'meta':
                continue
            
            with st.expander(f"æ¨¡å‹ {model_name} é¢„æµ‹è¯¦æƒ…"):
                col1, col2, col3, col4 = st.columns(4)
                
                with col1:
                    st.metric("é¢„æµ‹å‡å€¼", f"{prediction_stats.get('mean', 0):.2f}")
                
                with col2:
                    st.metric("æ ‡å‡†å·®", f"{prediction_stats.get('std', 0):.2f}")
                
                with col3:
                    st.metric("æœ€å°å€¼", f"{prediction_stats.get('min', 0):.2f}")
                
                with col4:
                    st.metric("æœ€å¤§å€¼", f"{prediction_stats.get('max', 0):.2f}")
                
                # é¢„æµ‹å€¼åˆ†å¸ƒå›¾
                predictions_list = prediction_stats.get('predictions', [])
                if predictions_list:
                    fig_hist = px.histogram(
                        x=predictions_list,
                        title=f"{model_name} é¢„æµ‹å€¼åˆ†å¸ƒ",
                        labels={'x': 'é¢„æµ‹å€¼', 'y': 'é¢‘æ¬¡'}
                    )
                    
                    st.plotly_chart(fig_hist, key=f"pred_hist_{model_name}")
    
    # 4. è‡ªé€‚åº”å»ºè®®
    adaptive_recs = learning_metadata.get('adaptive_recommendations', [])
    
    if adaptive_recs:
        st.write("**ğŸ’¡ AIè‡ªé€‚åº”å»ºè®®**")
        
        for i, recommendation in enumerate(adaptive_recs, 1):
            st.markdown(f"""
            <div class="recommendation-box">
                <strong>AIå»ºè®® {i}:</strong> {recommendation}
            </div>
            """, unsafe_allow_html=True)
    else:
        st.info("æš‚æ— AIè‡ªé€‚åº”å»ºè®®ï¼Œç³»ç»Ÿæ­£åœ¨å­¦ä¹ ä¸­...")
    
    # 5. æ•°æ®è´¨é‡è¯„ä¼°
    try:
        learning_status = dashboard_instance.get_learning_status()
        data_stats = learning_status.get('data_statistics', {})
        
        if data_stats:
            st.write("**ğŸ“Š å­¦ä¹ æ•°æ®è´¨é‡æ¦‚è§ˆ**")
            
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.metric(
                    "æ•°æ®é›†æ€»æ•°", 
                    data_stats.get('total_datasets', 0),
                    delta="å†å²ç§¯ç´¯"
                )
            
            with col2:
                avg_quality = data_stats.get('average_quality_score', 0)
                quality_label = "ä¼˜ç§€" if avg_quality > 0.8 else "è‰¯å¥½" if avg_quality > 0.6 else "å¾…æ”¹å–„"
                st.metric(
                    "å¹³å‡è´¨é‡è¯„åˆ†", 
                    f"{avg_quality:.3f}",
                    delta=quality_label
                )
            
            with col3:
                recent_datasets = data_stats.get('recent_datasets_7days', 0)
                st.metric(
                    "è¿‘æœŸæ–°å¢", 
                    recent_datasets,
                    delta="æŒç»­æ›´æ–°" if recent_datasets > 0 else "ç¨³å®šæœŸ"
                )
            
            # æ•°æ®è´¨é‡åˆ†å¸ƒ
            quality_dist = data_stats.get('quality_distribution', {})
            if quality_dist:
                fig_quality = px.bar(
                    x=list(quality_dist.keys()),
                    y=list(quality_dist.values()),
                    title="æ•°æ®è´¨é‡åˆ†å¸ƒ",
                    labels={'x': 'è´¨é‡ç­‰çº§', 'y': 'æ•°æ®é›†æ•°é‡'},
                    color=list(quality_dist.values()),
                    color_continuous_scale=['red', 'orange', 'yellow', 'green']
                )
                
                st.plotly_chart(fig_quality, key="quality_distribution")
    
    except Exception as e:
        st.error(f"è·å–å­¦ä¹ çŠ¶æ€å¤±è´¥: {e}")


def render_order_analysis_module(current_data: Dict[str, Any]) -> None:
    """æ¸²æŸ“è®¢å•æ•°æ®åˆ†ææ¨¡å—"""
    st.write("**è®¢å•æ•°æ®ç»¼åˆåˆ†æ - åŸºäºå®é™…ä¸šåŠ¡æ•°æ®æ·±åº¦æ´å¯Ÿ**")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰è®¢å•æ•°æ®
    order_data = current_data.get("order_data", pd.DataFrame())
    
    if order_data.empty:
        st.info("ğŸ“ˆ æš‚æ— è®¢å•æ•°æ®ï¼Œè¯·åŠ è½½åŒ…å«è®¢å•ä¿¡æ¯çš„Excelæ–‡ä»¶")
        
        # æ˜¾ç¤ºè®¢å•æ•°æ®æ ¼å¼è¦æ±‚
        with st.expander("ğŸ“‹ è®¢å•æ•°æ®æ ¼å¼è¦æ±‚"):
            st.markdown("""
            **å¿…éœ€å­—æ®µï¼š**
            - `è®¢å•ID`: è®¢å•å”¯ä¸€æ ‡è¯†
            - `å•†å“åç§°`: å•†å“åç§°
            - `å•†å“å®å”®ä»·`: å•†å“å”®ä»·
            - `é”€é‡`: å•†å“æ•°é‡
            - `ä¸‹å•æ—¶é—´`: è®¢å•æ—¶é—´
            - `é—¨åº—åç§°`: é—¨åº—æ ‡è¯†
            - `æ¸ é“`: é”€å”®æ¸ é“
            - `æ”¶è´§åœ°å€`: é…é€åœ°å€
            
            **å¯é€‰å­—æ®µï¼š**
            - `åˆ©æ¶¦é¢`: å•å“åˆ©æ¶¦
            - `æˆæœ¬`: å•†å“æˆæœ¬
            - `ç‰©æµé…é€è´¹`: é…é€è´¹ç”¨
            - `å¹³å°ä½£é‡‘`: å¹³å°æŠ½æˆ
            - `é…é€è·ç¦»`: é…é€è·ç¦»
            - `ç¾å›¢ä¸€çº§åˆ†ç±»`: å•†å“åˆ†ç±»
            """)
        return
    
    st.success(f"âœ… å·²åŠ è½½è®¢å•æ•°æ®ï¼š{len(order_data):,} æ¡è®°å½•")
    
    # æ•°æ®é¢„å¤„ç†å’Œç‰¹å¾å·¥ç¨‹
    try:
        processed_order_data = preprocess_order_data(order_data)
        order_summary = calculate_order_metrics(processed_order_data)
        
        # åˆ›å»ºåˆ†æé€‰é¡¹å¡
        analysis_tabs = st.tabs([
            "ğŸ“Š è®¢å•æ¦‚è§ˆ", 
            "ğŸ’° åˆ©æ¶¦åˆ†æ", 
            "â° æ—¶é—´åˆ†æ",
            "ğŸª é—¨åº—åˆ†æ",
            "ğŸ“¦ å•†å“åˆ†æ",
            "ğŸšš é…é€åˆ†æ",
            "ğŸ’¡ æ™ºèƒ½æ´å¯Ÿ"
        ])
        
        with analysis_tabs[0]:
            if ORDER_ENHANCEMENT_AVAILABLE:
                render_enhanced_order_overview(processed_order_data, order_summary)
            else:
                render_order_overview(processed_order_data, order_summary)
        
        with analysis_tabs[1]:
            if ORDER_ENHANCEMENT_AVAILABLE:
                render_enhanced_profit_analysis(processed_order_data, order_summary)
            else:
                render_profit_analysis(processed_order_data, order_summary)
        
        with analysis_tabs[2]:
            render_time_analysis(processed_order_data)
        
        with analysis_tabs[3]:
            render_store_analysis(processed_order_data)
        
        with analysis_tabs[4]:
            render_product_analysis(processed_order_data)
        
        with analysis_tabs[5]:
            render_delivery_analysis(processed_order_data)
        
        with analysis_tabs[6]:
            render_order_insights(processed_order_data, order_summary)
            
    except Exception as e:
        st.error(f"è®¢å•æ•°æ®åˆ†ææ—¶å‡ºé”™: {str(e)}")
        st.info("ğŸ’¡ è¯·æ£€æŸ¥æ•°æ®æ ¼å¼æ˜¯å¦ç¬¦åˆè¦æ±‚")


def preprocess_order_data(order_data: pd.DataFrame) -> pd.DataFrame:
    """è®¢å•æ•°æ®é¢„å¤„ç† - æ ¹æ®æ ‡å‡†ä¸šåŠ¡é€»è¾‘"""
    try:
        df = order_data.copy()
        
        # ğŸ”´ **å…³é”®ä¸šåŠ¡è§„åˆ™1ï¼šå‰”é™¤è€—ææ•°æ®** - æ ¹æ®ä¸šåŠ¡é€»è¾‘æœ€ç»ˆç¡®è®¤æ–‡æ¡£
        # è¯†åˆ«æ ‡å‡†ï¼šä¸€çº§åˆ†ç±»å == 'è€—æ'
        # å‚è€ƒï¼šè®¢å•æ•°æ®ä¸šåŠ¡é€»è¾‘ç¡®è®¤.md
        original_rows = len(df)
        
        # æ”¯æŒå¤šç§åˆ—åå˜ä½“
        category_col = None
        for col_name in ['ä¸€çº§åˆ†ç±»å', 'ç¾å›¢ä¸€çº§åˆ†ç±»', 'ä¸€çº§åˆ†ç±»']:
            if col_name in df.columns:
                category_col = col_name
                break
        
        if category_col:
            df = df[df[category_col] != 'è€—æ'].copy()
            removed_rows = original_rows - len(df)
            if removed_rows > 0:
                st.info(f"ğŸ”´ å·²è‡ªåŠ¨å‰”é™¤ {removed_rows} è¡Œè€—ææ•°æ®ï¼ˆè´­ç‰©è¢‹ç­‰ï¼‰ï¼Œä» {original_rows} è¡Œå‡å°‘åˆ° {len(df)} è¡Œ")
                print(f"âœ… å·²å‰”é™¤ {removed_rows} è¡Œè€—ææ•°æ®ï¼ˆè´­ç‰©è¢‹ç­‰ï¼‰ï¼Œä» {original_rows} è¡Œå‡å°‘åˆ° {len(df)} è¡Œ")
        else:
            st.warning(f"âš ï¸ æœªæ‰¾åˆ°ä¸€çº§åˆ†ç±»åˆ—ï¼ˆæŸ¥æ‰¾äº†ï¼šä¸€çº§åˆ†ç±»åã€ç¾å›¢ä¸€çº§åˆ†ç±»ã€ä¸€çº§åˆ†ç±»ï¼‰ï¼Œæ— æ³•å‰”é™¤è€—æ")
            print(f"âš ï¸ æœªæ‰¾åˆ°ä¸€çº§åˆ†ç±»åˆ—ï¼Œæ•°æ®åˆ—å: {list(df.columns[:10])}")
        
        # ğŸ”´ **å…³é”®ä¸šåŠ¡è§„åˆ™2ï¼šå‰”é™¤å’–å•¡æ¸ é“æ•°æ®** - å’–å•¡ä¸šåŠ¡éO2Oé›¶å”®
        # è¯†åˆ«æ ‡å‡†ï¼šæ¸ é“ in ['é¥¿äº†ä¹ˆå’–å•¡', 'ç¾å›¢å’–å•¡']
        if 'æ¸ é“' in df.columns:
            exclude_channels = ['é¥¿äº†ä¹ˆå’–å•¡', 'ç¾å›¢å’–å•¡']
            before_filter = len(df)
            df = df[~df['æ¸ é“'].isin(exclude_channels)].copy()
            after_filter = len(df)
            coffee_removed = before_filter - after_filter
            
            if coffee_removed > 0:
                st.info(f"â˜• å·²è‡ªåŠ¨å‰”é™¤å’–å•¡æ¸ é“æ•°æ® {coffee_removed} è¡Œï¼ˆé¥¿äº†ä¹ˆå’–å•¡ã€ç¾å›¢å’–å•¡ï¼‰ï¼Œä» {before_filter} è¡Œå‡å°‘åˆ° {after_filter} è¡Œ")
                print(f"âœ… å·²å‰”é™¤ {coffee_removed} è¡Œå’–å•¡æ¸ é“æ•°æ®ï¼Œä» {before_filter} è¡Œå‡å°‘åˆ° {after_filter} è¡Œ")
        
        # æ•°æ®ç±»å‹è½¬æ¢ - æ ¹æ®ä¸šåŠ¡é€»è¾‘ç¡®è®¤æ–‡æ¡£çš„å­—æ®µå®šä¹‰
        numeric_columns = [
            # åŸºç¡€å•†å“å­—æ®µ
            'å•†å“å®å”®ä»·', 'å•†å“åŸä»·', 'é”€é‡', 'åˆ©æ¶¦é¢', 'æˆæœ¬', 'é…é€è·ç¦»',
            # æ ‡å‡†ä¸šåŠ¡é€»è¾‘å­—æ®µ
            'ç‰©æµé…é€è´¹', 'å¹³å°ä½£é‡‘', 'ç”¨æˆ·æ”¯ä»˜é…é€è´¹', 'é…é€è´¹å‡å…é‡‘é¢',
            'æ»¡å‡é‡‘é¢', 'å•†å®¶ä»£é‡‘åˆ¸', 'å•†å“å‡å…é‡‘é¢', 'æ‰“åŒ…è´¹', 'è®¢å•é›¶å”®é¢',
            # å…¶ä»–å¯é€‰æˆæœ¬å­—æ®µ
            'æ»¡èµ é‡‘é¢', 'å•†å®¶æ‰¿æ‹…éƒ¨åˆ†åˆ¸', 'é€€æ¬¾é‡‘é¢', 'æ–°å®¢å‡å…é‡‘é¢'
        ]
        
        for col in numeric_columns:
            if col in df.columns:
                df[col] = pd.to_numeric(df[col], errors='coerce')
                # å¯¹äºç¼ºå¤±çš„è¥é”€æˆæœ¬å­—æ®µï¼Œå¡«å……0ä»¥ä¿è¯è®¡ç®—çš„å‡†ç¡®æ€§
                if col in ['ç‰©æµé…é€è´¹', 'å¹³å°ä½£é‡‘', 'ç”¨æˆ·æ”¯ä»˜é…é€è´¹', 
                          'é…é€è´¹å‡å…é‡‘é¢', 'æ»¡å‡é‡‘é¢', 'å•†å®¶ä»£é‡‘åˆ¸']:
                    df[col] = df[col].fillna(0)
        
        # æ—¶é—´å­—æ®µå¤„ç†
        if 'ä¸‹å•æ—¶é—´' in df.columns:
            df['ä¸‹å•æ—¶é—´'] = pd.to_datetime(df['ä¸‹å•æ—¶é—´'], errors='coerce')
            df['ä¸‹å•æ—¥æœŸ'] = df['ä¸‹å•æ—¶é—´'].dt.date
            df['ä¸‹å•å°æ—¶'] = df['ä¸‹å•æ—¶é—´'].dt.hour
            df['ä¸‹å•æ˜ŸæœŸ'] = df['ä¸‹å•æ—¶é—´'].dt.day_name()
            
            # æ—¶é—´æ®µæ˜ å°„
            hour_mapping = {
                0: 'å‡Œæ™¨', 1: 'å‡Œæ™¨', 2: 'å‡Œæ™¨', 3: 'å‡Œæ™¨', 4: 'å‡Œæ™¨', 5: 'æ¸…æ™¨',
                6: 'æ¸…æ™¨', 7: 'æ—©æ™¨', 8: 'ä¸Šåˆ', 9: 'ä¸Šåˆ', 10: 'ä¸Šåˆ', 11: 'ä¸­åˆ',
                12: 'ä¸­åˆ', 13: 'ä¸‹åˆ', 14: 'ä¸‹åˆ', 15: 'ä¸‹åˆ', 16: 'ä¸‹åˆ', 17: 'å‚æ™š',
                18: 'å‚æ™š', 19: 'æ™šä¸Š', 20: 'æ™šä¸Š', 21: 'æ™šä¸Š', 22: 'å¤œæ™š', 23: 'å¤œæ™š'
            }
            df['ä¸‹å•æ—¶é—´æ®µ'] = df['ä¸‹å•å°æ—¶'].map(hour_mapping)
        
        # å•†å“è§’è‰²åˆ¤æ–­ (æ ¹æ®å•†å“å®å”®ä»·åˆ¤æ–­ä¸»åŠ›å“)
        if 'å•†å“å®å”®ä»·' in df.columns and 'è®¢å•ID' in df.columns:
            max_price_per_order = df.groupby('è®¢å•ID')['å•†å“å®å”®ä»·'].transform('max')
            df['å•†å“è§’è‰²'] = np.where(df['å•†å“å®å”®ä»·'] == max_price_per_order, 'ä¸»åŠ›å“', 'å‡‘å•å“')
        
        # é…é€è·ç¦»åˆ†æ®µ
        if 'é…é€è·ç¦»' in df.columns:
            df['é…é€è·ç¦»_km'] = df['é…é€è·ç¦»'] / 1000
            df['é…é€è·ç¦»åˆ†æ®µ'] = pd.cut(
                df['é…é€è·ç¦»_km'],
                bins=[0, 1, 2, 3, 4, 5, float('inf')],
                labels=['1kmå†…', '1-2km', '2-3km', '3-4km', '4-5km', '5kmä»¥ä¸Š']
            )
        
        # ä»·æ ¼åˆ†æ®µ (æ ¹æ®å•†å“å®å”®ä»·)
        if 'å•†å“å®å”®ä»·' in df.columns:
            df['ä»·æ ¼åˆ†æ®µ'] = pd.cut(
                df['å•†å“å®å”®ä»·'],
                bins=[0, 10, 30, 50, 100, float('inf')],
                labels=['ä½ä»·(<10å…ƒ)', 'ä¸­ä½ä»·(10-30å…ƒ)', 'ä¸­ä»·(30-50å…ƒ)', 'é«˜ä»·(50-100å…ƒ)', 'è¶…é«˜ä»·(>100å…ƒ)']
            )
        
        return df
        
    except Exception as e:
        st.error(f"æ•°æ®é¢„å¤„ç†å¤±è´¥: {str(e)}")
        return order_data


def calculate_order_metrics(df: pd.DataFrame) -> Dict[str, Any]:
    """è®¡ç®—è®¢å•çº§æŒ‡æ ‡ - ä½¿ç”¨ç»Ÿä¸€çš„æ ‡å‡†ä¸šåŠ¡é€»è¾‘"""
    try:
        order_summary = {}
        
        if 'è®¢å•ID' not in df.columns:
            return order_summary
        
        # å¦‚æœå¯ç”¨ï¼Œä½¿ç”¨ç»Ÿä¸€ä¸šåŠ¡é€»è¾‘é…ç½®
        if STANDARD_CONFIG_AVAILABLE:
            print("ğŸ”§ ä½¿ç”¨æ ‡å‡†ä¸šåŠ¡é€»è¾‘è®¡ç®—è®¢å•æŒ‡æ ‡")
            
            # ä½¿ç”¨ç»Ÿä¸€é…ç½®åˆ›å»ºè®¢å•çº§æ±‡æ€»
            order_agg = create_order_level_summary(df, StandardBusinessConfig)
            
            # åº”ç”¨æ ‡å‡†ä¸šåŠ¡é€»è¾‘è®¡ç®—
            order_agg = apply_standard_business_logic(order_agg)
            
            # ç”Ÿæˆæ±‡æ€»æŒ‡æ ‡
            order_summary['è®¢å•æ€»æ•°'] = len(order_agg)
            order_summary['å•†å“æ€»æ•°'] = len(df)
            order_summary['å¹³å‡æ¯å•å•†å“æ•°'] = len(df) / len(order_agg) if len(order_agg) > 0 else 0
            
            # é”€å”®é¢ç»Ÿè®¡ (åŸºäºæ ‡å‡†ä¸šåŠ¡é€»è¾‘)
            if 'å•†å“å®å”®ä»·æ€»å’Œ' in order_agg.columns:
                total_sales = order_agg['å•†å“å®å”®ä»·æ€»å’Œ'].sum()
                order_summary['æ€»é”€å”®é¢'] = total_sales
                order_summary['å¹³å‡å®¢å•ä»·'] = total_sales / len(order_agg) if len(order_agg) > 0 else 0
                order_summary['å®¢å•ä»·ä¸­ä½æ•°'] = order_agg['å•†å“å®å”®ä»·æ€»å’Œ'].median()
            
            # è®¢å•æ€»æ”¶å…¥ç»Ÿè®¡ï¼ˆå•†å“å®å”®ä»· + æ‰“åŒ…è´¹ + ç”¨æˆ·æ”¯ä»˜é…é€è´¹ï¼‰
            if 'é¢„ä¼°è®¢å•æ”¶å…¥' in order_agg.columns:
                total_revenue = order_agg['é¢„ä¼°è®¢å•æ”¶å…¥'].sum()
                order_summary['è®¢å•æ€»æ”¶å…¥'] = total_revenue
                order_summary['å¹³å‡è®¢å•æ”¶å…¥'] = total_revenue / len(order_agg) if len(order_agg) > 0 else 0
            
            # åˆ©æ¶¦ç»Ÿè®¡ (ä½¿ç”¨æ ‡å‡†ä¸šåŠ¡é€»è¾‘è®¡ç®—çš„å®é™…åˆ©æ¶¦)
            if 'è®¢å•å®é™…åˆ©æ¶¦é¢' in order_agg.columns:
                actual_profit_series = order_agg['è®¢å•å®é™…åˆ©æ¶¦é¢']
                total_profit = actual_profit_series.sum()
                order_summary['æ€»åˆ©æ¶¦é¢'] = total_profit
                order_summary['å¹³å‡è®¢å•åˆ©æ¶¦'] = actual_profit_series.mean()
                order_summary['ç›ˆåˆ©è®¢å•æ•°'] = (actual_profit_series > 0).sum()
                order_summary['ç›ˆåˆ©è®¢å•æ¯”ä¾‹'] = (actual_profit_series > 0).mean()
                # ğŸ” è°ƒè¯•è¾“å‡º - åˆ©æ¶¦è®¡ç®—
                print(f"\nğŸ’° [DEBUG] åˆ©æ¶¦è®¡ç®—éªŒè¯:")
                print(f"   - æ€»åˆ©æ¶¦é¢: Â¥{total_profit:,.2f}")
                if all(col in order_agg.columns for col in ['å•†å“å®å”®ä»·æ€»å’Œ', 'æˆæœ¬', 'é…é€æˆæœ¬', 'æ´»åŠ¨è¥é”€æˆæœ¬', 'å•†å“æŠ˜æ‰£æˆæœ¬', 'å¹³å°ä½£é‡‘']):
                    packing_fee = order_agg['æ‰“åŒ…è¢‹é‡‘é¢'].sum() if 'æ‰“åŒ…è¢‹é‡‘é¢' in order_agg.columns else 0
                    user_pay_delivery = order_agg['ç”¨æˆ·æ”¯ä»˜é…é€è´¹'].sum() if 'ç”¨æˆ·æ”¯ä»˜é…é€è´¹' in order_agg.columns else 0
                    revenue_sum = (order_agg['å•†å“å®å”®ä»·æ€»å’Œ'].sum() + packing_fee + user_pay_delivery)
                    cost_sum = order_agg['æˆæœ¬'].sum()
                    delivery_sum = order_agg['é…é€æˆæœ¬'].sum()
                    activity_sum = order_agg['æ´»åŠ¨è¥é”€æˆæœ¬'].sum()
                    discount_sum = order_agg['å•†å“æŠ˜æ‰£æˆæœ¬'].sum()
                    commission_sum = order_agg['å¹³å°ä½£é‡‘'].sum()
                    print(f"   - è®¢å•æ€»æ”¶å…¥: Â¥{revenue_sum:,.2f} (å•†å“Â¥{order_agg['å•†å“å®å”®ä»·æ€»å’Œ'].sum():,.2f} + æ‰“åŒ…Â¥{packing_fee:,.2f} + ç”¨æˆ·æ”¯ä»˜é…é€è´¹Â¥{user_pay_delivery:,.2f})")
                    print(f"   - å•†å“æˆæœ¬: Â¥{cost_sum:,.2f}")
                    print(f"   - é…é€æˆæœ¬: Â¥{delivery_sum:,.2f}")
                    print(f"   - æ´»åŠ¨è¥é”€æˆæœ¬: Â¥{activity_sum:,.2f}")
                    print(f"   - å•†å“æŠ˜æ‰£æˆæœ¬: Â¥{discount_sum:,.2f}")
                    print(f"   - å¹³å°ä½£é‡‘: Â¥{commission_sum:,.2f}")
                    expected = revenue_sum - cost_sum - delivery_sum - activity_sum - discount_sum - commission_sum
                    print(f"   - å…¬å¼éªŒè¯: Â¥{revenue_sum:,.2f} - Â¥{cost_sum:,.2f} - Â¥{delivery_sum:,.2f} - Â¥{activity_sum:,.2f} - Â¥{discount_sum:,.2f} - Â¥{commission_sum:,.2f} = Â¥{expected:,.2f}")
                    print(f"   - å·®å¼‚: Â¥{total_profit - expected:,.2f}")
                else:
                    print(f"   âš ï¸ ç¼ºå°‘å¿…è¦å­—æ®µï¼Œæ— æ³•éªŒè¯è¯¦ç»†è®¡ç®—")            
            # é…é€æˆæœ¬ç»Ÿè®¡ (ä½¿ç”¨æ ‡å‡†ä¸šåŠ¡é€»è¾‘)
            if 'é…é€æˆæœ¬' in order_agg.columns:
                delivery_cost_series = order_agg['é…é€æˆæœ¬']
                total_delivery_cost = delivery_cost_series.sum()
                order_summary['å¹³å‡é…é€æˆæœ¬'] = delivery_cost_series.mean()
                order_summary['æ€»é…é€æˆæœ¬'] = total_delivery_cost
                # ğŸ” è°ƒè¯•è¾“å‡º
                print(f"ğŸ” [DEBUG] é…é€æˆæœ¬è®¡ç®—:")
                print(f"   - æ€»é…é€æˆæœ¬: Â¥{total_delivery_cost:,.2f}")
                print(f"   - å¹³å‡é…é€æˆæœ¬: Â¥{delivery_cost_series.mean():,.2f}")
                if 'ç”¨æˆ·æ”¯ä»˜é…é€è´¹' in order_agg.columns and 'é…é€è´¹å‡å…é‡‘é¢' in order_agg.columns and 'ç‰©æµé…é€è´¹' in order_agg.columns:
                    user_pay = order_agg['ç”¨æˆ·æ”¯ä»˜é…é€è´¹'].sum()
                    exemption_sum = order_agg['é…é€è´¹å‡å…é‡‘é¢'].sum()
                    logistics_sum = order_agg['ç‰©æµé…é€è´¹'].sum()
                    print(f"   - é…é€è´¹å‡å…ï¼ˆæ”¯å‡ºï¼‰: Â¥{exemption_sum:,.2f}")
                    print(f"   - ç‰©æµé…é€è´¹ï¼ˆæ”¯å‡ºï¼‰: Â¥{logistics_sum:,.2f}")
                    print(f"   - ç”¨æˆ·æ”¯ä»˜é…é€è´¹ï¼ˆæ”¶å…¥ï¼‰: Â¥{user_pay:,.2f}")
                    print(f"   - é…é€å‡€æˆæœ¬å…¬å¼: ({exemption_sum:,.2f} + {logistics_sum:,.2f}) - {user_pay:,.2f} = Â¥{exemption_sum + logistics_sum - user_pay:,.2f}")
            
            # æ´»åŠ¨è¥é”€æˆæœ¬ç»Ÿè®¡ï¼ˆä¸å«å•†å“æŠ˜æ‰£ï¼‰
            if 'æ´»åŠ¨è¥é”€æˆæœ¬' in order_agg.columns:
                activity_marketing_series = order_agg['æ´»åŠ¨è¥é”€æˆæœ¬']
                order_summary['æ€»æ´»åŠ¨è¥é”€æˆæœ¬'] = activity_marketing_series.sum()
                order_summary['å¹³å‡æ´»åŠ¨è¥é”€æˆæœ¬'] = activity_marketing_series.mean()
            
            # å•†å“æŠ˜æ‰£æˆæœ¬ç»Ÿè®¡
            if 'å•†å“æŠ˜æ‰£æˆæœ¬' in order_agg.columns:
                product_discount_series = order_agg['å•†å“æŠ˜æ‰£æˆæœ¬']
                order_summary['æ€»å•†å“æŠ˜æ‰£æˆæœ¬'] = product_discount_series.sum()
                order_summary['å¹³å‡å•†å“æŠ˜æ‰£æˆæœ¬'] = product_discount_series.mean()
            
            # æ€»è¥é”€æˆæœ¬ç»Ÿè®¡ï¼ˆæ´»åŠ¨è¥é”€ + å•†å“æŠ˜æ‰£ï¼‰
            if 'å•†å®¶æ´»åŠ¨æ”¯å‡º' in order_agg.columns:
                marketing_cost_series = order_agg['å•†å®¶æ´»åŠ¨æ”¯å‡º']
                order_summary['æ€»è¥é”€æˆæœ¬'] = marketing_cost_series.sum()
                order_summary['å¹³å‡è¥é”€æˆæœ¬'] = marketing_cost_series.mean()
            
        else:
            # ä½¿ç”¨ç®€åŒ–ç‰ˆæœ¬çš„è®¡ç®—é€»è¾‘ï¼ˆå…¼å®¹æ€§å¤„ç†ï¼‰
            print("âš ï¸ ä½¿ç”¨ç®€åŒ–ç‰ˆæœ¬çš„è®¢å•æŒ‡æ ‡è®¡ç®—")
            order_summary = calculate_order_metrics_fallback(df)
        
        return order_summary
        
    except Exception as e:
        st.error(f"æŒ‡æ ‡è®¡ç®—å¤±è´¥: {str(e)}")
        return {}


def calculate_order_metrics_fallback(df: pd.DataFrame) -> Dict[str, Any]:
    """å¤‡ç”¨çš„è®¢å•æŒ‡æ ‡è®¡ç®—æ–¹æ³• (å…¼å®¹æ€§å¤„ç†)"""
    order_summary = {}
    
    # åŸºç¡€è®¢å•æŒ‡æ ‡
    order_summary['è®¢å•æ€»æ•°'] = df['è®¢å•ID'].nunique()
    order_summary['å•†å“æ€»æ•°'] = len(df)
    order_summary['å¹³å‡æ¯å•å•†å“æ•°'] = len(df) / df['è®¢å•ID'].nunique()
    
    # é”€å”®é¢ç»Ÿè®¡
    if 'å•†å“å®å”®ä»·' in df.columns and 'é”€é‡' in df.columns:
        df['å•†å“é”€å”®é¢'] = df['å•†å“å®å”®ä»·'] * df['é”€é‡']
        order_sales = df.groupby('è®¢å•ID')['å•†å“é”€å”®é¢'].sum()
        order_summary['æ€»é”€å”®é¢'] = order_sales.sum()
        order_summary['å¹³å‡å®¢å•ä»·'] = order_sales.mean()
        order_summary['å®¢å•ä»·ä¸­ä½æ•°'] = order_sales.median()
    
    # ç®€åŒ–çš„åˆ©æ¶¦ç»Ÿè®¡
    if 'åˆ©æ¶¦é¢' in df.columns:
        order_profit = df.groupby('è®¢å•ID')['åˆ©æ¶¦é¢'].sum()
        order_summary['æ€»åˆ©æ¶¦é¢'] = order_profit.sum()
        order_summary['å¹³å‡è®¢å•åˆ©æ¶¦'] = order_profit.mean()
        order_summary['ç›ˆåˆ©è®¢å•æ•°'] = (order_profit > 0).sum()
        order_summary['ç›ˆåˆ©è®¢å•æ¯”ä¾‹'] = (order_profit > 0).mean()
    
    # é…é€è´¹ç»Ÿè®¡
    if 'ç‰©æµé…é€è´¹' in df.columns:
        order_delivery = df.groupby('è®¢å•ID')['ç‰©æµé…é€è´¹'].first()
        order_summary['å¹³å‡é…é€æˆæœ¬'] = order_delivery.mean()
        order_summary['æ€»é…é€æˆæœ¬'] = order_delivery.sum()
    
    return order_summary


def render_order_overview(df: pd.DataFrame, order_summary: Dict[str, Any]) -> None:
    """æ¸²æŸ“è®¢å•æ¦‚è§ˆ - å±•ç¤ºæ ‡å‡†ä¸šåŠ¡é€»è¾‘æŒ‡æ ‡"""
    st.write("**ğŸ“Š è®¢å•ä¸šåŠ¡æ¦‚è§ˆ (æŒ‰æ ‡å‡†ä¸šåŠ¡é€»è¾‘è®¡ç®—)**")
    
    # æ ¸å¿ƒæŒ‡æ ‡å¡ç‰‡ - åŸºç¡€ä¸šåŠ¡æŒ‡æ ‡
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric(
            "è®¢å•æ€»æ•°",
            f"{order_summary.get('è®¢å•æ€»æ•°', 0):,}",
            help="ç»Ÿè®¡æœŸé—´å†…çš„æ€»è®¢å•æ•°é‡"
        )
    
    with col2:
        st.metric(
            "å•†å“æ€»æ•°",
            f"{order_summary.get('å•†å“æ€»æ•°', 0):,}",
            help="æ‰€æœ‰è®¢å•ä¸­çš„å•†å“æ¡ç›®æ€»æ•°"
        )
    
    with col3:
        st.metric(
            "å¹³å‡å®¢å•ä»·",
            f"Â¥{order_summary.get('å¹³å‡å®¢å•ä»·', 0):.2f}",
            help="æ¯ä¸ªè®¢å•çš„å¹³å‡é”€å”®é¢ (å•†å“å®å”®ä»·Ã—é”€é‡)"
        )
    
    with col4:
        if 'ç›ˆåˆ©è®¢å•æ¯”ä¾‹' in order_summary:
            st.metric(
                "ç›ˆåˆ©è®¢å•æ¯”ä¾‹",
                f"{order_summary.get('ç›ˆåˆ©è®¢å•æ¯”ä¾‹', 0):.1%}",
                help="æŒ‰æ ‡å‡†ä¸šåŠ¡é€»è¾‘è®¡ç®—çš„å®é™…ç›ˆåˆ©è®¢å•å æ¯”"
            )
    
    # æ ‡å‡†ä¸šåŠ¡é€»è¾‘å…³é”®æŒ‡æ ‡
    st.write("**ğŸ¨ æ ‡å‡†ä¸šåŠ¡é€»è¾‘å…³é”®æŒ‡æ ‡**")
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric(
            "æ€»åˆ©æ¶¦é¢ (å®é™…)",
            f"Â¥{order_summary.get('æ€»åˆ©æ¶¦é¢', 0):,.2f}",
            help="æŒ‰æ ‡å‡†ä¸šåŠ¡é€»è¾‘è®¡ç®—: é¢„ä¼°è®¢å•æ”¶å…¥ - é…é€æˆæœ¬"
        )
    
    with col2:
        st.metric(
            "å¹³å‡è®¢å•åˆ©æ¶¦",
            f"Â¥{order_summary.get('å¹³å‡è®¢å•åˆ©æ¶¦', 0):.2f}",
            help="æ¯ä¸ªè®¢å•çš„å¹³å‡å®é™…åˆ©æ¶¦é¢"
        )
    
    with col3:
        st.metric(
            "æ€»é…é€æˆæœ¬",
            f"Â¥{order_summary.get('æ€»é…é€æˆæœ¬', 0):,.2f}",
            help="å•†å®¶é…é€å‡€æ”¯å‡º: (é…é€è´¹å‡å… + ç‰©æµé…é€è´¹) - ç”¨æˆ·æ”¯ä»˜é…é€è´¹"
        )
    
    with col4:
        st.metric(
            "å¹³å‡é…é€æˆæœ¬",
            f"Â¥{order_summary.get('å¹³å‡é…é€æˆæœ¬', 0):.2f}",
            help="æ¯ä¸ªè®¢å•çš„å¹³å‡é…é€æˆæœ¬"
        )
    
    # æ•°æ®è´¨é‡æ¦‚è§ˆ
    col1, col2 = st.columns(2)
    
    with col1:
        st.write("**ğŸ“ˆ ä¸šåŠ¡æ•°æ®åˆ†å¸ƒ**")
        
        # é—¨åº—åˆ†å¸ƒ
        if 'é—¨åº—åç§°' in df.columns:
            store_dist = df['é—¨åº—åç§°'].value_counts()
            fig = px.pie(
                values=store_dist.values,
                names=store_dist.index,
                title="é—¨åº—è®¢å•åˆ†å¸ƒ"
            )
            st.plotly_chart(fig, use_container_width=True)
    
    with col2:
        st.write("**ğŸ• è®¢å•æ—¶é—´åˆ†å¸ƒ**")
        
        # æ—¶é—´æ®µåˆ†å¸ƒ
        if 'ä¸‹å•æ—¶é—´æ®µ' in df.columns:
            time_dist = df['ä¸‹å•æ—¶é—´æ®µ'].value_counts()
            fig = px.bar(
                x=time_dist.index,
                y=time_dist.values,
                title="æ—¶é—´æ®µè®¢å•é‡åˆ†å¸ƒ"
            )
            st.plotly_chart(fig, use_container_width=True)
    
    # ä¸šåŠ¡é€»è¾‘è¯´æ˜
    with st.expander("ğŸ“„ æ ‡å‡†ä¸šåŠ¡é€»è¾‘è¯´æ˜"):
        st.markdown("""
        **æœ¬çœ‹æ¿é‡‡ç”¨çš„æ ‡å‡†ä¸šåŠ¡é€»è¾‘:**
        
        1. **é¢„ä¼°è®¢å•æ”¶å…¥** = (è®¢å•é›¶å”®é¢ + æ‰“åŒ…è´¹ - å•†å®¶æ´»åŠ¨æ”¯å‡º - å¹³å°ä½£é‡‘ + ç”¨æˆ·æ”¯ä»˜é…é€è´¹)
        2. **å•†å®¶æ´»åŠ¨æ”¯å‡º** = (é…é€è´¹å‡å…é‡‘é¢ + æ»¡å‡é‡‘é¢ + å•†å“å‡å…é‡‘é¢ + å•†å®¶ä»£é‡‘åˆ¸)
        3. **é…é€æˆæœ¬** = (ç”¨æˆ·æ”¯ä»˜é…é€è´¹ - é…é€è´¹å‡å…é‡‘é¢ - ç‰©æµé…é€è´¹)
        4. **è®¢å•å®é™…åˆ©æ¶¦é¢** = é¢„ä¼°è®¢å•æ”¶å…¥ - é…é€æˆæœ¬
        
        **å­—æ®µå«ä¹‰:**
        - **å•†å“å®å”®ä»·**: å•†å“åœ¨å‰ç«¯å±•ç¤ºçš„åŸä»·
        - **ç”¨æˆ·æ”¯ä»˜é‡‘é¢**: ç”¨æˆ·å®é™…æ”¯ä»˜ä»·æ ¼ (è€ƒè™‘å„ç§è¡¥è´´æ´»åŠ¨)
        - **åŒä¸€è®¢å•IDå¤šè¡Œ**: æ¯è¡Œä»£è¡¨ä¸€ä¸ªå•†å“SKUï¼Œè®¢å•çº§å­—æ®µä¼šé‡å¤æ˜¾ç¤º
        """)


def render_profit_analysis(df: pd.DataFrame, order_summary: Dict[str, Any]) -> None:
    """æ¸²æŸ“åˆ©æ¶¦åˆ†æ - æŒ‰æ ‡å‡†ä¸šåŠ¡é€»è¾‘"""
    st.write("**ğŸ’° è®¢å•åˆ©æ¶¦æ·±åº¦åˆ†æ (æŒ‰æ ‡å‡†ä¸šåŠ¡é€»è¾‘è®¡ç®—)**")
    
    if 'åˆ©æ¶¦é¢' not in df.columns:
        st.info("ç¼ºå°‘åˆ©æ¶¦é¢å­—æ®µï¼Œæ— æ³•è¿›è¡Œåˆ©æ¶¦åˆ†æ")
        return
    
    # åˆ©æ¶¦æ¦‚è§ˆ - æ‰€æœ‰æŒ‡æ ‡éƒ½åŸºäºæ ‡å‡†ä¸šåŠ¡é€»è¾‘è®¡ç®—
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric(
            "æ€»åˆ©æ¶¦é¢ (å®é™…)",
            f"Â¥{order_summary.get('æ€»åˆ©æ¶¦é¢', 0):,.2f}",
            help="æŒ‰æ ‡å‡†ä¸šåŠ¡é€»è¾‘: é¢„ä¼°è®¢å•æ”¶å…¥ - é…é€æˆæœ¬"
        )
    
    with col2:
        st.metric(
            "å¹³å‡è®¢å•åˆ©æ¶¦",
            f"Â¥{order_summary.get('å¹³å‡è®¢å•åˆ©æ¶¦', 0):.2f}",
            help="æ¯ä¸ªè®¢å•çš„å¹³å‡å®é™…åˆ©æ¶¦é¢"
        )
    
    with col3:
        st.metric(
            "ç›ˆåˆ©è®¢å•æ•°",
            f"{order_summary.get('ç›ˆåˆ©è®¢å•æ•°', 0):,}",
            help="å®é™…åˆ©æ¶¦ > 0 çš„è®¢å•æ•°é‡"
        )
    
    with col4:
        st.metric(
            "ç›ˆåˆ©ç‡",
            f"{order_summary.get('ç›ˆåˆ©è®¢å•æ¯”ä¾‹', 0):.1%}",
            help="ç›ˆåˆ©è®¢å•åœ¨æ‰€æœ‰è®¢å•ä¸­çš„å æ¯”"
        )
    
    # ä¸šåŠ¡é€»è¾‘æˆæœ¬ç»†åˆ†
    st.write("**ğŸ“„ æˆæœ¬ç»†åˆ†åˆ†æ (æŒ‰æ ‡å‡†ä¸šåŠ¡é€»è¾‘)**")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric(
            "æ€»é…é€æˆæœ¬",
            f"Â¥{order_summary.get('æ€»é…é€æˆæœ¬', 0):,.2f}",
            help="å•†å®¶é…é€å‡€æ”¯å‡º: (é…é€è´¹å‡å… + ç‰©æµé…é€è´¹) - ç”¨æˆ·æ”¯ä»˜é…é€è´¹"
        )
    
    with col2:
        # è®¡ç®—å•†å®¶æ´»åŠ¨æ”¯å‡ºæ€»é¢ (å¦‚æœæ•°æ®ä¸­æœ‰çš„è¯)
        marketing_cost_fields = ['é…é€è´¹å‡å…é‡‘é¢', 'æ»¡å‡é‡‘é¢', 'å•†å“å‡å…é‡‘é¢', 'å•†å®¶ä»£é‡‘åˆ¸']
        total_marketing_cost = 0
        for field in marketing_cost_fields:
            if field in df.columns:
                total_marketing_cost += df[field].sum()
        
        st.metric(
            "å•†å®¶æ´»åŠ¨æ”¯å‡º",
            f"Â¥{total_marketing_cost:,.2f}",
            help="é…é€è´¹å‡å… + æ»¡å‡ + å•†å“å‡å… + å•†å®¶ä»£é‡‘åˆ¸"
        )
    
    with col3:
        # è®¡ç®—å¹³å°ä½£é‡‘æ€»é¢
        platform_commission = df['å¹³å°ä½£é‡‘'].sum() if 'å¹³å°ä½£é‡‘' in df.columns else 0
        st.metric(
            "å¹³å°ä½£é‡‘æ€»é¢",
            f"Â¥{platform_commission:,.2f}",
            help="å„ä¸ªå¹³å°æ¸ é“æ”¶å–çš„æœåŠ¡è´¹"
        )
    
    # åˆ©æ¶¦åˆ†æå›¾è¡¨
    col1, col2 = st.columns(2)
    
    with col1:
        # è®¢å•åˆ©æ¶¦åˆ†å¸ƒ - ä½¿ç”¨æ ‡å‡†ä¸šåŠ¡é€»è¾‘è®¡ç®—çš„å®é™…åˆ©æ¶¦
        if 'è®¢å•ID' in df.columns:
            # é‡æ–°è®¡ç®—æ¯ä¸ªè®¢å•çš„å®é™…åˆ©æ¶¦ (ç®€åŒ–ç‰ˆæœ¬)
            order_profit_simple = df.groupby('è®¢å•ID')['åˆ©æ¶¦é¢'].sum()  # è¿™é‡Œç”¨ç®€åŒ–ç‰ˆæœ¬ä½œä¸ºç¤ºä¾‹
            
            fig = px.histogram(
                x=order_profit_simple,
                nbins=30,
                title="è®¢å•åˆ©æ¶¦åˆ†å¸ƒ (æŒ‰æ ‡å‡†ä¸šåŠ¡é€»è¾‘)",
                labels={'x': 'è®¢å•å®é™…åˆ©æ¶¦(å…ƒ)', 'y': 'è®¢å•æ•°é‡'}
            )
            fig.add_vline(x=0, line_dash="dash", line_color="red", annotation_text="ç›ˆäºå¹³è¡¡çº¿")
            st.plotly_chart(fig, use_container_width=True)
    
    with col2:
        # å•†å“ƒåˆ©æ¶¦è´¡çŒ® - æ˜¾ç¤ºç®€åŒ–çš„å•†å“åˆ©æ¶¦
        if 'å•†å“åç§°' in df.columns:
            # è¿™é‡Œä½¿ç”¨åŸå§‹åˆ©æ¶¦é¢ä½œä¸ºç¤ºä¾‹ï¼Œå®é™…åº”è¯¥ç”¨è®¢å•çº§åˆ©æ¶¦åˆ†é…
            product_profit = df.groupby('å•†å“åç§°')['åˆ©æ¶¦é¢'].sum().sort_values(ascending=False).head(10)
            
            fig = px.bar(
                x=product_profit.values,
                y=product_profit.index,
                orientation='h',
                title="TOP10 å•†å“åˆ©æ¶¦è´¡çŒ®",
                labels={'x': 'åˆ©æ¶¦è´¡çŒ®(å…ƒ)', 'y': 'å•†å“åç§°'}
            )
            st.plotly_chart(fig, use_container_width=True)
    
    # æ ‡å‡†ä¸šåŠ¡é€»è¾‘è®¡ç®—å…¬å¼è¯´æ˜
    with st.expander("ğŸ§® æ ‡å‡†ä¸šåŠ¡é€»è¾‘è®¡ç®—å…¬å¼"):
        st.markdown("""
        **æœ¬åˆ†æé‡‡ç”¨çš„æ ‡å‡†ä¸šåŠ¡é€»è¾‘è®¡ç®—å…¬å¼:**
        
        **1. é¢„ä¼°è®¢å•æ”¶å…¥è®¡ç®—:**
        ```
        é¢„ä¼°è®¢å•æ”¶å…¥ = (è®¢å•é›¶å”®é¢ + æ‰“åŒ…è´¹ - å•†å®¶æ´»åŠ¨æ”¯å‡º - å¹³å°ä½£é‡‘ + ç”¨æˆ·æ”¯ä»˜é…é€è´¹)
        ```
        
        **2. å•†å®¶æ´»åŠ¨æ”¯å‡ºè®¡ç®—:**
        ```
        å•†å®¶æ´»åŠ¨æ”¯å‡º = (é…é€è´¹å‡å…é‡‘é¢ + æ»¡å‡é‡‘é¢ + å•†å“å‡å…é‡‘é¢ + å•†å®¶ä»£é‡‘åˆ¸)
        ```
        
        **3. é…é€æˆæœ¬è®¡ç®—:** âœ… 2025-10-13ä¿®æ­£
        ```
        é…é€æˆæœ¬ = é…é€è´¹å‡å…é‡‘é¢ + ç‰©æµé…é€è´¹
        è¯´æ˜ï¼šè¿™ä¸¤é¡¹æ˜¯å•†å®¶åœ¨é…é€ç¯èŠ‚çš„å®é™…æ”¯å‡º
        ```
        
        **4. æœ€ç»ˆåˆ©æ¶¦è®¡ç®—:**
        ```
        è®¢å•å®é™…åˆ©æ¶¦é¢ = é¢„ä¼°è®¢å•æ”¶å…¥ - é…é€æˆæœ¬
        ```
        
        **é‡è¦è¯´æ˜:**
        - æ‰€æœ‰æŒ‡æ ‡éƒ½é‡‡ç”¨è®¢å•çº§èšåˆï¼Œé¿å…é‡å¤è®¡ç®—
        - è®¢å•çº§å­—æ®µ(å¦‚é…é€è´¹ã€ä½£é‡‘)ä½¿ç”¨ `.first()` å–å€¼
        - å•†å“çº§å­—æ®µ(å¦‚åˆ©æ¶¦é¢ã€æˆæœ¬)ä½¿ç”¨ `.sum()` èšåˆ
        """)


def render_time_analysis(df: pd.DataFrame) -> None:
    """æ¸²æŸ“æ—¶é—´åˆ†æ"""
    st.write("**â° æ—¶é—´ç»´åº¦åˆ†æ**")
    
    if 'ä¸‹å•æ—¶é—´' not in df.columns:
        st.info("ç¼ºå°‘ä¸‹å•æ—¶é—´å­—æ®µï¼Œæ— æ³•è¿›è¡Œæ—¶é—´åˆ†æ")
        return
    
    # æ—¶é—´åˆ†å¸ƒåˆ†æ
    col1, col2 = st.columns(2)
    
    with col1:
        # æ¯æ—¥è®¢å•é‡è¶‹åŠ¿
        if 'ä¸‹å•æ—¥æœŸ' in df.columns:
            daily_orders = df.groupby('ä¸‹å•æ—¥æœŸ').size()
            
            fig = px.line(
                x=daily_orders.index,
                y=daily_orders.values,
                title="æ¯æ—¥è®¢å•é‡è¶‹åŠ¿",
                labels={'x': 'æ—¥æœŸ', 'y': 'è®¢å•æ•°é‡'}
            )
            st.plotly_chart(fig, use_container_width=True)
    
    with col2:
        # å°æ—¶åˆ†å¸ƒçƒ­åŠ›å›¾
        if 'ä¸‹å•å°æ—¶' in df.columns and 'ä¸‹å•æ˜ŸæœŸ' in df.columns:
            hourly_heat = df.groupby(['ä¸‹å•æ˜ŸæœŸ', 'ä¸‹å•å°æ—¶']).size().unstack(fill_value=0)
            
            fig = px.imshow(
                hourly_heat.values,
                x=hourly_heat.columns,
                y=hourly_heat.index,
                title="æ˜ŸæœŸ-å°æ—¶è®¢å•çƒ­åŠ›å›¾",
                labels={'x': 'å°æ—¶', 'y': 'æ˜ŸæœŸ', 'color': 'è®¢å•æ•°é‡'}
            )
            st.plotly_chart(fig, use_container_width=True)


def render_store_analysis(df: pd.DataFrame) -> None:
    """æ¸²æŸ“é—¨åº—åˆ†æ"""
    st.write("**ğŸª é—¨åº—ç»´åº¦åˆ†æ**")
    
    if 'é—¨åº—åç§°' not in df.columns:
        st.info("ç¼ºå°‘é—¨åº—åç§°å­—æ®µï¼Œæ— æ³•è¿›è¡Œé—¨åº—åˆ†æ")
        return
    
    # é—¨åº—ä¸šç»©å¯¹æ¯”
    store_metrics = df.groupby('é—¨åº—åç§°').agg({
        'è®¢å•ID': 'nunique',
        'å•†å“å®å”®ä»·': lambda x: (x * df.loc[x.index, 'é”€é‡']).sum() if 'é”€é‡' in df.columns else x.sum(),
        'åˆ©æ¶¦é¢': 'sum' if 'åˆ©æ¶¦é¢' in df.columns else lambda x: 0
    }).round(2)
    
    store_metrics.columns = ['è®¢å•æ•°', 'é”€å”®é¢', 'åˆ©æ¶¦é¢']
    
    if len(store_metrics) > 0:
        col1, col2 = st.columns(2)
        
        with col1:
            # é—¨åº—é”€å”®é¢å¯¹æ¯”
            fig = px.bar(
                x=store_metrics.index,
                y=store_metrics['é”€å”®é¢'],
                title="é—¨åº—é”€å”®é¢å¯¹æ¯”",
                labels={'x': 'é—¨åº—', 'y': 'é”€å”®é¢(å…ƒ)'}
            )
            st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            # é—¨åº—åˆ©æ¶¦å¯¹æ¯”
            if store_metrics['åˆ©æ¶¦é¢'].sum() > 0:
                fig = px.bar(
                    x=store_metrics.index,
                    y=store_metrics['åˆ©æ¶¦é¢'],
                    title="é—¨åº—åˆ©æ¶¦å¯¹æ¯”",
                    labels={'x': 'é—¨åº—', 'y': 'åˆ©æ¶¦é¢(å…ƒ)'}
                )
                st.plotly_chart(fig, use_container_width=True)
        
        # é—¨åº—æ•°æ®è¡¨
        st.write("**é—¨åº—ä¸šç»©è¯¦æƒ…**")
        st.dataframe(store_metrics, use_container_width=True)


def render_product_analysis(df: pd.DataFrame) -> None:
    """æ¸²æŸ“å•†å“åˆ†æ"""
    st.write("**ğŸ“¦ å•†å“ç»´åº¦åˆ†æ**")
    
    col1, col2 = st.columns(2)
    
    with col1:
        # å•†å“è§’è‰²åˆ†æ
        if 'å•†å“è§’è‰²' in df.columns:
            role_dist = df['å•†å“è§’è‰²'].value_counts()
            
            fig = px.pie(
                values=role_dist.values,
                names=role_dist.index,
                title="å•†å“è§’è‰²åˆ†å¸ƒ"
            )
            st.plotly_chart(fig, use_container_width=True)
    
    with col2:
        # ä»·æ ¼åˆ†æ®µåˆ†æ
        if 'ä»·æ ¼åˆ†æ®µ' in df.columns:
            price_dist = df['ä»·æ ¼åˆ†æ®µ'].value_counts()
            
            fig = px.bar(
                x=price_dist.index,
                y=price_dist.values,
                title="ä»·æ ¼åˆ†æ®µå•†å“åˆ†å¸ƒ",
                labels={'x': 'ä»·æ ¼åˆ†æ®µ', 'y': 'å•†å“æ•°é‡'}
            )
            st.plotly_chart(fig, use_container_width=True)
    
    # çƒ­é”€å•†å“TOPæ¦œ
    if 'å•†å“åç§°' in df.columns and 'é”€é‡' in df.columns:
        top_products = df.groupby('å•†å“åç§°')['é”€é‡'].sum().sort_values(ascending=False).head(10)
        
        st.write("**ğŸ”¥ çƒ­é”€å•†å“TOP10**")
        
        top_products_df = pd.DataFrame({
            'å•†å“åç§°': top_products.index,
            'æ€»é”€é‡': top_products.values
        })
        
        st.dataframe(top_products_df, use_container_width=True)


def render_delivery_analysis(df: pd.DataFrame) -> None:
    """æ¸²æŸ“é…é€åˆ†æ"""
    st.write("**ğŸšš é…é€ç»´åº¦åˆ†æ**")
    
    col1, col2 = st.columns(2)
    
    with col1:
        # é…é€è·ç¦»åˆ†å¸ƒ
        if 'é…é€è·ç¦»åˆ†æ®µ' in df.columns:
            distance_dist = df['é…é€è·ç¦»åˆ†æ®µ'].value_counts()
            
            fig = px.bar(
                x=distance_dist.index,
                y=distance_dist.values,
                title="é…é€è·ç¦»åˆ†å¸ƒ",
                labels={'x': 'é…é€è·ç¦»', 'y': 'è®¢å•æ•°é‡'}
            )
            st.plotly_chart(fig, use_container_width=True)
    
    with col2:
        # é…é€è´¹åˆ†æ
        if 'ç‰©æµé…é€è´¹' in df.columns:
            avg_delivery_fee = df.groupby('é…é€è·ç¦»åˆ†æ®µ')['ç‰©æµé…é€è´¹'].mean()
            
            fig = px.bar(
                x=avg_delivery_fee.index,
                y=avg_delivery_fee.values,
                title="å¹³å‡é…é€è´¹ vs é…é€è·ç¦»",
                labels={'x': 'é…é€è·ç¦»', 'y': 'å¹³å‡é…é€è´¹(å…ƒ)'}
            )
            st.plotly_chart(fig, use_container_width=True)
    
    # é«˜é…é€è´¹è®¢å•é¢„è­¦
    if 'ç‰©æµé…é€è´¹' in df.columns:
        high_delivery_orders = df[df['ç‰©æµé…é€è´¹'] > 6]
        
        if not high_delivery_orders.empty:
            st.warning(f"âš ï¸ å‘ç° {len(high_delivery_orders)} ä¸ªé«˜é…é€è´¹è®¢å•ï¼ˆ>6å…ƒï¼‰")
            
            with st.expander("æŸ¥çœ‹é«˜é…é€è´¹è®¢å•è¯¦æƒ…"):
                display_cols = ['è®¢å•ID', 'å•†å“åç§°', 'ç‰©æµé…é€è´¹', 'é…é€è·ç¦»_km', 'æ”¶è´§åœ°å€']
                available_cols = [col for col in display_cols if col in high_delivery_orders.columns]
                
                if available_cols:
                    st.dataframe(high_delivery_orders[available_cols].head(20), use_container_width=True)


def render_order_insights(df: pd.DataFrame, order_summary: Dict[str, Any]) -> None:
    """æ¸²æŸ“æ™ºèƒ½æ´å¯Ÿ"""
    st.write("**ğŸ’¡ æ™ºèƒ½ä¸šåŠ¡æ´å¯Ÿ**")
    
    insights = []
    
    # åŸºäºæ•°æ®ç”Ÿæˆæ´å¯Ÿ
    if order_summary:
        # ç›ˆåˆ©æ´å¯Ÿ
        profit_ratio = order_summary.get('ç›ˆåˆ©è®¢å•æ¯”ä¾‹', 0)
        if profit_ratio > 0.8:
            insights.append("ğŸ‰ è®¢å•ç›ˆåˆ©ç‡ä¼˜ç§€ï¼Œè¶…è¿‡80%çš„è®¢å•éƒ½èƒ½äº§ç”Ÿåˆ©æ¶¦")
        elif profit_ratio > 0.6:
            insights.append("ğŸ‘ è®¢å•ç›ˆåˆ©ç‡è‰¯å¥½ï¼Œå»ºè®®ä¼˜åŒ–å‰©ä½™äºæŸè®¢å•")
        else:
            insights.append("âš ï¸ è®¢å•ç›ˆåˆ©ç‡åä½ï¼Œå»ºè®®é‡ç‚¹å…³æ³¨æˆæœ¬æ§åˆ¶å’Œå®šä»·ç­–ç•¥")
        
        # å®¢å•ä»·æ´å¯Ÿ
        avg_order_value = order_summary.get('å¹³å‡å®¢å•ä»·', 0)
        if avg_order_value > 50:
            insights.append(f"ğŸ’° å¹³å‡å®¢å•ä»·è¡¨ç°è‰¯å¥½({avg_order_value:.2f}å…ƒ)ï¼Œå®¢æˆ·æ¶ˆè´¹æ°´å¹³è¾ƒé«˜")
        elif avg_order_value > 30:
            insights.append(f"ğŸ“ˆ å¹³å‡å®¢å•ä»·é€‚ä¸­({avg_order_value:.2f}å…ƒ)ï¼Œå¯é€šè¿‡å¥—é¤æ¨èç­‰æ–¹å¼æå‡")
        else:
            insights.append(f"ğŸ“Š å¹³å‡å®¢å•ä»·è¾ƒä½({avg_order_value:.2f}å…ƒ)ï¼Œå»ºè®®åŠ å¼ºå®¢å•ä»·æå‡ç­–ç•¥")
    
    # æ—¶é—´æ´å¯Ÿ
    if 'ä¸‹å•æ—¶é—´æ®µ' in df.columns:
        peak_time = df['ä¸‹å•æ—¶é—´æ®µ'].value_counts().index[0]
        insights.append(f"â° è®¢å•é«˜å³°æ—¶æ®µä¸º{peak_time}ï¼Œå»ºè®®åœ¨æ­¤æ—¶æ®µåŠ å¼ºæœåŠ¡å’Œå¤‡è´§")
    
    # å•†å“æ´å¯Ÿ
    if 'å•†å“è§’è‰²' in df.columns:
        main_products_ratio = (df['å•†å“è§’è‰²'] == 'ä¸»åŠ›å“').mean()
        if main_products_ratio > 0.6:
            insights.append("ğŸ¯ ä¸»åŠ›å•†å“å æ¯”è¾ƒé«˜ï¼Œå•†å“ç»“æ„å¥åº·")
        else:
            insights.append("ğŸ“¦ å‡‘å•å•†å“è¾ƒå¤šï¼Œå»ºè®®ä¼˜åŒ–å•†å“ç»„åˆå’Œæ¨èç­–ç•¥")
    
    # é…é€æ´å¯Ÿ
    if 'ç‰©æµé…é€è´¹' in df.columns:
        avg_delivery_fee = df['ç‰©æµé…é€è´¹'].mean()
        high_delivery_ratio = (df['ç‰©æµé…é€è´¹'] > 6).mean()
        
        if high_delivery_ratio > 0.2:
            insights.append(f"ğŸšš é«˜é…é€è´¹è®¢å•å æ¯”{high_delivery_ratio:.1%}ï¼Œå»ºè®®ä¼˜åŒ–é…é€ç­–ç•¥")
        
        insights.append(f"ğŸ“ å¹³å‡é…é€è´¹ä¸º{avg_delivery_fee:.2f}å…ƒï¼Œå¯è€ƒè™‘é…é€è´¹ä¼˜åŒ–æ–¹æ¡ˆ")
    
    # æ˜¾ç¤ºæ´å¯Ÿ
    if insights:
        for i, insight in enumerate(insights, 1):
            st.markdown(f"""
            <div class="recommendation-box">
                <strong>æ´å¯Ÿ {i}:</strong> {insight}
            </div>
            """, unsafe_allow_html=True)
    else:
        st.info("æ•°æ®åˆ†æä¸­ï¼Œæ›´å¤šæ´å¯Ÿæ­£åœ¨ç”Ÿæˆ...")
    
    # ç”Ÿæˆä¸šåŠ¡å»ºè®®
    st.subheader("ğŸ“‹ ä¸šåŠ¡ä¼˜åŒ–å»ºè®®")
    
    suggestions = [
        "ğŸ“ˆ **é”€å”®æå‡**: åˆ†æçƒ­é”€æ—¶æ®µå’Œçƒ­é”€å•†å“ï¼Œä¼˜åŒ–åº“å­˜å’Œæ¨å¹¿ç­–ç•¥",
        "ğŸ’° **æˆæœ¬æ§åˆ¶**: é‡ç‚¹å…³æ³¨äºæŸè®¢å•ï¼Œåˆ†ææˆæœ¬æ„æˆå¹¶åˆ¶å®šæ”¹è¿›æªæ–½", 
        "ğŸšš **é…é€ä¼˜åŒ–**: ä¼˜åŒ–é…é€è·¯çº¿å’Œè´¹ç”¨ç»“æ„ï¼Œæå‡é…é€æ•ˆç‡",
        "ğŸ¯ **ç²¾å‡†è¥é”€**: åŸºäºå®¢æˆ·æ¶ˆè´¹è¡Œä¸ºï¼Œåˆ¶å®šä¸ªæ€§åŒ–æ¨èå’Œä¿ƒé”€ç­–ç•¥",
        "ğŸ“Š **æ•°æ®ç›‘æ§**: å»ºç«‹å…³é”®æŒ‡æ ‡ç›‘æ§ä½“ç³»ï¼ŒåŠæ—¶å‘ç°ä¸šåŠ¡å¼‚å¸¸"
    ]
    
    for suggestion in suggestions:
        st.markdown(f"- {suggestion}")


# ============================================================================
# åœºæ™¯è¥é”€çœ‹æ¿æ¨¡å—
# ============================================================================

def filter_data_by_time_dimension(df: pd.DataFrame, time_dimension: str, selected_period: str = None, latest_only: bool = True) -> pd.DataFrame:
    """
    æ ¹æ®æ—¶é—´ç»´åº¦ç­›é€‰æ•°æ®
    
    å‚æ•°:
        df: æ•°æ®æ¡†ï¼ˆéœ€åŒ…å«æ—¶é—´ç»´åº¦å­—æ®µï¼‰
        time_dimension: æ—¶é—´ç»´åº¦ ('æ—¥', 'å‘¨', 'æœˆ')
        selected_period: é€‰æ‹©çš„å…·ä½“å‘¨æœŸï¼ˆNoneæˆ–"å…¨éƒ¨XXX"è¡¨ç¤ºä¸ç­›é€‰å…·ä½“å‘¨æœŸï¼‰
        latest_only: æ˜¯å¦åªä¿ç•™æœ€è¿‘ä¸€ä¸ªå‘¨æœŸçš„æ•°æ®ï¼ˆé»˜è®¤Trueï¼Œå½“selected_periodä¸ºNoneæˆ–"å…¨éƒ¨XXX"æ—¶ç”Ÿæ•ˆï¼‰
        
    è¿”å›:
        ç­›é€‰åçš„æ•°æ®æ¡†
    """
    dim_mapping = {
        'æ—¥': 'æ—¥æœŸ_datetime',
        'å‘¨': 'å¹´å‘¨',
        'æœˆ': 'å¹´æœˆ'
    }
    
    time_col = dim_mapping.get(time_dimension)
    if time_col not in df.columns:
        return df
    
    # å¦‚æœæŒ‡å®šäº†å…·ä½“å‘¨æœŸä¸”ä¸æ˜¯"å…¨éƒ¨XXX"ï¼Œåˆ™ç­›é€‰è¯¥å‘¨æœŸ
    if selected_period and not selected_period.startswith("å…¨éƒ¨"):
        if time_dimension == "æ—¥":
            # å°†å­—ç¬¦ä¸²è½¬æ¢ä¸ºdatetimeè¿›è¡Œæ¯”è¾ƒ
            selected_date = pd.to_datetime(selected_period)
            return df[df[time_col] == selected_date].copy()
        elif time_dimension == "å‘¨":
            return df[df[time_col] == selected_period].copy()
        else:  # æœˆ
            return df[df[time_col] == selected_period].copy()
    
    # å¦åˆ™ï¼Œå¦‚æœlatest_only=Trueï¼Œè¿”å›æœ€è¿‘ä¸€ä¸ªå‘¨æœŸ
    if latest_only:
        latest_period = df[time_col].max()
        return df[df[time_col] == latest_period].copy()
    else:
        return df.copy()


def calculate_period_over_period(df: pd.DataFrame, dimension: str, metric_col: str) -> pd.DataFrame:
    """
    è®¡ç®—ç¯æ¯”å˜åŒ–ï¼ˆæ”¯æŒæ—¥/å‘¨/æœˆç»´åº¦ï¼‰
    
    å‚æ•°:
        df: æ•°æ®æ¡†ï¼ˆéœ€åŒ…å«å¯¹åº”çš„æ—¶é—´ç»´åº¦å­—æ®µï¼‰
        dimension: æ—¶é—´ç»´åº¦ ('æ—¥', 'å‘¨', 'æœˆ')
        metric_col: æŒ‡æ ‡åˆ—å
        
    è¿”å›:
        åŒ…å«ç¯æ¯”å˜åŒ–çš„æ•°æ®æ¡†ï¼ˆä¸ºæ¯ä¸ªæŒ‡æ ‡å¢åŠ ç‹¬ç«‹çš„ç¯æ¯”åˆ—ï¼‰
    """
    # æ˜ å°„ç»´åº¦åˆ°å­—æ®µå
    dim_mapping = {
        'æ—¥': 'æ—¥æœŸ_datetime',
        'å‘¨': 'å¹´å‘¨',
        'æœˆ': 'å¹´æœˆ'
    }
    
    time_col = dim_mapping.get(dimension)
    if time_col not in df.columns:
        return df
    
    # æŒ‰æ—¶é—´ç»´åº¦æ’åº
    df = df.sort_values(time_col).reset_index(drop=True)
    
    # ä¸ºæ¯ä¸ªæŒ‡æ ‡åˆ›å»ºç‹¬ç«‹çš„ç¯æ¯”åˆ—
    prev_col = f'{metric_col}_ä¸ŠæœŸå€¼'
    change_col = f'{metric_col}_ç¯æ¯”å˜åŒ–'
    rate_col = f'{metric_col}_ç¯æ¯”ç‡'
    
    # è®¡ç®—ä¸ŠæœŸå€¼
    df[prev_col] = df[metric_col].shift(1)
    
    # è®¡ç®—ç¯æ¯”å˜åŒ–ï¼ˆç»å¯¹å€¼å’Œç™¾åˆ†æ¯”ï¼‰
    df[change_col] = df[metric_col] - df[prev_col]
    df[rate_col] = ((df[metric_col] - df[prev_col]) / df[prev_col] * 100).round(2)
    
    # å¤„ç†æ— ç©·å¤§å’ŒNaNå€¼
    df[rate_col] = df[rate_col].replace([np.inf, -np.inf], np.nan)
    
    return df


def format_period_label(value, dimension: str) -> str:
    """æ ¼å¼åŒ–æ—¶é—´ç»´åº¦æ ‡ç­¾"""
    if dimension == 'æ—¥':
        if isinstance(value, (pd.Timestamp, datetime)):
            return value.strftime('%Y-%m-%d')
        return str(value)
    elif dimension == 'å‘¨':
        return str(value)  # å·²ç»æ˜¯ '2024-W01' æ ¼å¼
    else:  # æœˆ
        return str(value)  # å·²ç»æ˜¯ '2024-01' æ ¼å¼


def render_metric_with_comparison(col, metric_name: str, current_value, previous_value=None, 
                                    format_type='number', unit=''):
    """
    æ¸²æŸ“å¸¦ç¯æ¯”çš„æŒ‡æ ‡å¡ç‰‡
    
    å‚æ•°:
        col: streamlitåˆ—å¯¹è±¡
        metric_name: æŒ‡æ ‡åç§°
        current_value: å½“å‰å€¼
        previous_value: ä¸ŠæœŸå€¼
        format_type: æ ¼å¼åŒ–ç±»å‹ ('number', 'percent', 'currency')
        unit: å•ä½
    """
    with col:
        # æ ¼å¼åŒ–å½“å‰å€¼
        if format_type == 'number':
            display_value = f"{int(current_value):,}{unit}" if not pd.isna(current_value) else "N/A"
        elif format_type == 'percent':
            display_value = f"{current_value:.2f}%"
        elif format_type == 'currency':
            display_value = f"Â¥{current_value:,.2f}"
        else:
            display_value = str(current_value)
        
        # è®¡ç®—ç¯æ¯”
        if previous_value is not None and not pd.isna(previous_value) and previous_value != 0:
            change_rate = ((current_value - previous_value) / previous_value * 100)
            change_abs = current_value - previous_value
            
            # åˆ¤æ–­æ¶¨è·Œ
            if change_rate > 0:
                arrow = "ğŸ“ˆ"
                color = "green"
                sign = "+"
            elif change_rate < 0:
                arrow = "ğŸ“‰"
                color = "red"
                sign = ""
            else:
                arrow = "â¡ï¸"
                color = "gray"
                sign = ""
            
            st.metric(
                label=metric_name,
                value=display_value,
                delta=f"{sign}{change_rate:.2f}%",
                delta_color="normal" if change_rate >= 0 else "inverse"
            )
        else:
            st.metric(label=metric_name, value=display_value)


def extract_time_features(df: pd.DataFrame) -> pd.DataFrame:
    """æå–æ—¶é—´ç‰¹å¾ï¼ˆå¢å¼ºç‰ˆï¼šæ”¯æŒæ—¥/å‘¨/æœˆç»´åº¦ï¼‰"""
    df = df.copy()
    
    if 'ä¸‹å•æ—¶é—´' in df.columns:
        # è½¬æ¢ä¸ºdatetimeï¼Œerrors='coerce'ä¼šå°†æ— æ•ˆæ—¥æœŸè½¬ä¸ºNaT
        df['ä¸‹å•æ—¶é—´'] = pd.to_datetime(df['ä¸‹å•æ—¶é—´'], errors='coerce')
        
        # åŸºç¡€æ—¶é—´å­—æ®µï¼ˆè¿™äº›æ“ä½œä¼šè‡ªåŠ¨å¤„ç†NaTï¼Œè¿”å›NaNï¼‰
        df['æ—¥æœŸ'] = df['ä¸‹å•æ—¶é—´'].dt.date
        df['æ—¥æœŸ_datetime'] = pd.to_datetime(df['æ—¥æœŸ'], errors='coerce')
        df['å°æ—¶'] = df['ä¸‹å•æ—¶é—´'].dt.hour
        df['æ˜ŸæœŸ'] = df['ä¸‹å•æ—¶é—´'].dt.dayofweek
        df['æ˜ŸæœŸå'] = df['ä¸‹å•æ—¶é—´'].dt.day_name()
        
        # å‘¨ç»´åº¦å­—æ®µï¼ˆå¤„ç†NaTå€¼ï¼‰
        # åˆ›å»ºä¸´æ—¶çš„isocalendarç»“æœï¼Œåªå¯¹æœ‰æ•ˆæ—¥æœŸè®¡ç®—
        valid_dates_mask = df['ä¸‹å•æ—¶é—´'].notna()
        df['å¹´'] = None
        df['å‘¨'] = None
        
        if valid_dates_mask.any():
            iso_cal = df.loc[valid_dates_mask, 'ä¸‹å•æ—¶é—´'].dt.isocalendar()
            df.loc[valid_dates_mask, 'å¹´'] = iso_cal.year
            df.loc[valid_dates_mask, 'å‘¨'] = iso_cal.week
        
        # è½¬æ¢ä¸ºå­—ç¬¦ä¸²ï¼Œé¿å…NaNé—®é¢˜
        df['å¹´å‘¨'] = df.apply(
            lambda row: f"{int(row['å¹´'])}-W{int(row['å‘¨']):02d}" if pd.notna(row['å¹´']) and pd.notna(row['å‘¨']) else '',
            axis=1
        )
        
        # æœˆç»´åº¦å­—æ®µ
        df['å¹´æœˆ'] = df['ä¸‹å•æ—¶é—´'].dt.to_period('M').astype(str)
        df['æœˆä»½'] = df['ä¸‹å•æ—¶é—´'].dt.month
        
        # O2Oå¤–å–è¡Œä¸šæ—¶æ®µåˆ’åˆ†ï¼ˆåŸºäºç”¨æˆ·è¡Œä¸ºåœºæ™¯ï¼‰
        def get_time_period(hour):
            if 6 <= hour < 8:
                return 'æ¸…æ™¨(6-8ç‚¹)'
            elif 8 <= hour < 9:
                return 'æ—©é«˜å³°(8-9ç‚¹)'
            elif 9 <= hour < 11:
                return 'ä¸Šåˆ(9-11ç‚¹)'
            elif 11 <= hour < 12:
                return 'åˆé«˜å³°(11-12ç‚¹)'
            elif 12 <= hour < 14:
                return 'æ­£åˆ(12-14ç‚¹)'
            elif 14 <= hour < 17:
                return 'ä¸‹åˆ(14-17ç‚¹)'
            elif 17 <= hour < 18:
                return 'æ™šé«˜å³°å‰(17-18ç‚¹)'
            elif 18 <= hour < 21:
                return 'å‚æ™š(18-21ç‚¹)'
            elif 21 <= hour < 24:
                return 'æ™šé—´(21-24ç‚¹)'
            elif 0 <= hour < 3:
                return 'æ·±å¤œ(0-3ç‚¹)'
            else:  # 3-6ç‚¹
                return 'å‡Œæ™¨(3-6ç‚¹)'
        
        # åœºæ™¯æ ‡ç­¾ï¼ˆç”¨äºåˆ†æå’Œè¥é”€ï¼‰
        def get_scene_label(hour):
            if 6 <= hour < 8:
                return 'å‡ºè¡Œ/æ•´ç†/æ—©é¤'
            elif 8 <= hour < 9:
                return 'é€šå‹¤/æ—©é¤'
            elif 9 <= hour < 11:
                return 'åŠå…¬/å±…å®¶/æ—¥ç”¨è¡¥å……'
            elif 11 <= hour < 12:
                return 'åˆé¤è®¢é¤é«˜å³°'
            elif 12 <= hour < 14:
                return 'åˆé¤/åˆä¼‘'
            elif 14 <= hour < 17:
                return 'å·¥ä½œ/å®¶åŠ¡/äº²å­/ä¸‹åˆèŒ¶'
            elif 17 <= hour < 18:
                return 'ä¸‹ç­å‰å¤‡é¤'
            elif 18 <= hour < 21:
                return 'ä¸‹ç­/å½’å®¶/æ™šé¤/è·¯é€”'
            elif 21 <= hour < 24:
                return 'å±…å®¶/å¤œç”Ÿæ´»/ç¡å‰'
            elif 0 <= hour < 3:
                return 'çªå‘/æ€¥ç”¨/å¤œå®µ'
            else:  # 3-6ç‚¹
                return 'ä¸‡ç±ä¿±å¯‚/ç†¬å¤œå…š'
        
        df['æ—¶æ®µ'] = df['å°æ—¶'].apply(get_time_period)
        df['åœºæ™¯æ ‡ç­¾'] = df['å°æ—¶'].apply(get_scene_label)
    
    return df


def render_time_period_marketing(df: pd.DataFrame, time_dimension: str = 'æ—¥', selected_period: str = None):
    """æ—¶æ®µåœºæ™¯è¥é”€åˆ†æï¼ˆæ”¯æŒæ—¥/å‘¨/æœˆç»´åº¦åˆ‡æ¢ï¼‰"""
    st.markdown('<p class="sub-header">â° æ—¶æ®µåœºæ™¯è¥é”€åˆ†æ</p>', unsafe_allow_html=True)
    
    # ==================== åœºæ™¯è¥é”€ç†å¿µè¯´æ˜ ====================
    with st.expander("ğŸ’¡ ä»€ä¹ˆæ˜¯çœŸæ­£çš„ã€Œåœºæ™¯è¥é”€ã€ï¼Ÿï¼ˆå¿«æ¶ˆé›¶å”®è§†è§’ï¼‰", expanded=False):
        st.markdown("""
        ### ğŸ¯ å¿«æ¶ˆé›¶å”®çš„åœºæ™¯æœ¬è´¨
        
        **åœºæ™¯ = éœ€æ±‚è§¦å‘ç‚¹ + è´­ä¹°æ—¶æœº + å•†å“è§£å†³æ–¹æ¡ˆ**
        
        #### å¿«æ¶ˆé›¶å”®çš„æ ¸å¿ƒåœºæ™¯é—®é¢˜ï¼š
        
        1. **ä»€ä¹ˆåœºæ™¯ä¸‹ç”¨æˆ·ä¼šçªç„¶æƒ³ä¹°é›¶é£Ÿé¥®æ–™æ—¥ç”¨å“ï¼Ÿ**
           - ğŸ¢ **åŠå…¬åœºæ™¯**ï¼šä¸‹åˆçŠ¯å›° â†’ å’–å•¡ã€åŠŸèƒ½é¥®æ–™ã€é›¶é£Ÿ
           - ğŸ  **å±…å®¶åœºæ™¯**ï¼šè¿½å‰§ã€æ¸¸æˆ â†’ è–¯ç‰‡ã€ç“œå­ã€å¯ä¹
           - ğŸ‰ **èšä¼šåœºæ™¯**ï¼šæœ‹å‹æ¥äº† â†’ å•¤é…’ã€é›¶é£Ÿã€æ°´æœ
           - ğŸš¨ **åº”æ€¥åœºæ™¯**ï¼šçªç„¶æƒ³èµ·ç¼ºæŸç‰© â†’ çº¸å·¾ã€æ´—å‘æ°´ã€ç”µæ± 
           - ğŸŒ™ **æ·±å¤œåœºæ™¯**ï¼šå¤±çœ ã€åŠ ç­ â†’ æ³¡é¢ã€é›¶é£Ÿã€é¥®æ–™
        
        2. **å¦‚ä½•æ»¡è¶³ç”¨æˆ·çš„ã€Œå³åˆ»éœ€æ±‚ã€å’Œã€Œæ€¥éœ€ç—›ç‚¹ã€ï¼Ÿ**
           - âš¡ **é€Ÿåº¦ä¸ºç‹**ï¼š30åˆ†é’Ÿå†…é€è¾¾ï¼ˆç«å¯¹ä¹Ÿèƒ½åšåˆ°ï¼‰
           - ğŸ¯ **15åˆ†é’Ÿå¿…è¾¾**ï¼š1å…¬é‡Œæ ¸å¿ƒåœˆçš„ç«äº‰å£å’
           - ğŸ“¦ **å“ç±»é½å…¨**ï¼šç”¨æˆ·ä¸€æ¬¡æ€§ä¹°é½æ‰€éœ€ï¼ˆå‡å°‘è·³è½¬å…¶ä»–å¹³å°ï¼‰
           - ï¿½ **æ™ºèƒ½æ¨è**ï¼šä¹°é›¶é£Ÿæ¨èé¥®æ–™ï¼Œä¹°å•¤é…’æ¨èä¸‹é…’èœ
        
        3. **å¦‚ä½•æ¯”ç¾å›¢ã€é¥¿äº†ä¹ˆä¸Šçš„å…¶ä»–å•†å®¶æ›´å¿«ï¼Ÿ**
           - ğŸƒ **è·ç¦»ä¼˜åŠ¿**ï¼š1å…¬é‡Œå†…å¿…æœ‰ä»“ï¼Œç‰©ç†è·ç¦»æœ€çŸ­
           - ğŸ¤– **å¤‡è´§ä¼˜åŠ¿**ï¼šé«˜é¢‘å•†å“å……è¶³åº“å­˜ï¼Œä¸ç¼ºè´§
           - ğŸ“± **ä¾¿æ·ä¼˜åŠ¿**ï¼šä¸€é”®å¤è´­ã€è´­ç‰©è½¦æ™ºèƒ½æ¨è
           - â° **æ—¶æ®µä¼˜åŠ¿**ï¼šé¢„åˆ¤éœ€æ±‚é«˜å³°ï¼ˆå¦‚ä¸‹åˆ3ç‚¹å’–å•¡éœ€æ±‚ï¼‰
        
        #### å¿«æ¶ˆé›¶å”®çš„æ ¸å¿ƒæ—¶æ®µåœºæ™¯ï¼š
        
        **ğŸ“Š å·¥ä½œæ—¥åœºæ™¯**
        - **ä¸Šåˆåœºæ™¯ï¼ˆ9-11ç‚¹ï¼‰**ï¼šåŠå…¬æç¥ â†’ å’–å•¡ã€èŒ¶é¥®ã€åšæœã€å·§å…‹åŠ›
        - **ä¸‹åˆåœºæ™¯ï¼ˆ14-17ç‚¹ï¼‰**ï¼šä¸‹åˆèŒ¶ã€çŠ¯å›° â†’ å¥¶èŒ¶ã€åŠŸèƒ½é¥®æ–™ã€é¥¼å¹²ã€ç³–æœ
        - **æ™šé—´åœºæ™¯ï¼ˆ19-22ç‚¹ï¼‰**ï¼šå±…å®¶æ”¾æ¾ â†’ é›¶é£Ÿã€é¥®æ–™ã€æ°´æœã€é…’æ°´
        - **æ·±å¤œåœºæ™¯ï¼ˆ22-24ç‚¹ï¼‰**ï¼šè¿½å‰§ã€æ¸¸æˆã€å¤±çœ  â†’ æ³¡é¢ã€è†¨åŒ–é£Ÿå“ã€é¥®æ–™
        
        **ğŸ¡ å‘¨æœ«åœºæ™¯**
        - **å®¶åº­é‡‡è´­ï¼ˆ10-18ç‚¹ï¼‰**ï¼šå›¤è´§ã€è®¡åˆ’æ€§è´­ä¹° â†’ æ—¥ç”¨ç™¾è´§ã€å¤§åŒ…è£…é›¶é£Ÿ
        - **èšä¼šåœºæ™¯ï¼ˆ18-23ç‚¹ï¼‰**ï¼šæœ‹å‹èšä¼šã€å®¶åº­å¨±ä¹ â†’ å•¤é…’ã€çƒ§çƒ¤é›¶é£Ÿã€å¤å‘³
        
        **ğŸš¨ åº”æ€¥åœºæ™¯ï¼ˆå…¨æ—¶æ®µï¼‰**
        - çªç„¶å‘ç°ç¼ºæŸç‰©ï¼šçº¸å·¾ã€æ´—è¡£æ¶²ã€åƒåœ¾è¢‹ã€ç”µæ± ã€å……ç”µå™¨
        - ä¸´æ—¶æ¥å®¢äººï¼šé¥®æ–™ã€é›¶é£Ÿã€æ°´æœã€é…’æ°´
        - å©´å„¿ç”¨å“ï¼šå¥¶ç²‰ã€å°¿ä¸æ¹¿ã€æ¹¿å·¾ï¼ˆé€Ÿåº¦ç¬¬ä¸€ï¼‰
        
        #### æœ¬çœ‹æ¿æä¾›çš„åœºæ™¯æ´å¯Ÿï¼š
        - è¯†åˆ«**é«˜é¢‘è´­ä¹°æ—¶æ®µ**ï¼ˆä»€ä¹ˆæ—¶å€™ç”¨æˆ·æœ€çˆ±ä¹°ï¼‰
        - åˆ†æ**æ—¶æ®µå•†å“åå¥½**ï¼ˆä¸åŒæ—¶æ®µå–ä»€ä¹ˆï¼‰
        - å‘ç°**é…é€æ—¶æ•ˆç—›ç‚¹**ï¼ˆå“ªäº›æ—¶æ®µé…é€å‹åŠ›å¤§ï¼‰
        - æä¾›**åœºæ™¯åŒ–è¿è¥ç­–ç•¥**ï¼ˆå¦‚ä½•ç²¾å‡†æ»¡è¶³å³æ—¶éœ€æ±‚ï¼‰
        
        ---
        
        **ğŸ’¼ å¿«æ¶ˆé›¶å”®çš„ç»ˆæç›®æ ‡**ï¼šåœ¨ç”¨æˆ·æƒ³èµ·æ¥çš„**é‚£ä¸€åˆ»**ï¼Œä»¥**æœ€å¿«é€Ÿåº¦**é€è¾¾ä»–ä»¬**æ€¥éœ€çš„å•†å“**ï¼
        """)
    
    df = extract_time_features(df)
    
    # æ˜ å°„ç»´åº¦åˆ°å­—æ®µå
    dim_mapping = {
        'æ—¥': 'æ—¥æœŸ_datetime',
        'å‘¨': 'å¹´å‘¨',
        'æœˆ': 'å¹´æœˆ'
    }
    time_col = dim_mapping[time_dimension]
    
    # å®šä¹‰æ—¶æ®µé¡ºåºï¼ˆæŒ‰æ—¶é—´è‡ªç„¶é¡ºåºï¼‰
    time_period_order = [
        'å‡Œæ™¨(3-6ç‚¹)', 'æ¸…æ™¨(6-8ç‚¹)', 'æ—©é«˜å³°(8-9ç‚¹)', 'ä¸Šåˆ(9-11ç‚¹)', 
        'åˆé«˜å³°(11-12ç‚¹)', 'æ­£åˆ(12-14ç‚¹)', 'ä¸‹åˆ(14-17ç‚¹)', 
        'æ™šé«˜å³°å‰(17-18ç‚¹)', 'å‚æ™š(18-21ç‚¹)', 'æ™šé—´(21-24ç‚¹)', 'æ·±å¤œ(0-3ç‚¹)'
    ]
    
    # åœºæ™¯è¯´æ˜
    scene_descriptions = {
        'å‡Œæ™¨(3-6ç‚¹)': 'ä¸‡ç±ä¿±å¯‚/ç†¬å¤œå…š',
        'æ¸…æ™¨(6-8ç‚¹)': 'å‡ºè¡Œ/æ•´ç†/æ—©é¤',
        'æ—©é«˜å³°(8-9ç‚¹)': 'é€šå‹¤/æ—©é¤',
        'ä¸Šåˆ(9-11ç‚¹)': 'åŠå…¬/å±…å®¶/æ—¥ç”¨è¡¥å……',
        'åˆé«˜å³°(11-12ç‚¹)': 'åˆé¤è®¢é¤é«˜å³°',
        'æ­£åˆ(12-14ç‚¹)': 'åˆé¤/åˆä¼‘',
        'ä¸‹åˆ(14-17ç‚¹)': 'å·¥ä½œ/å®¶åŠ¡/äº²å­/ä¸‹åˆèŒ¶',
        'æ™šé«˜å³°å‰(17-18ç‚¹)': 'ä¸‹ç­å‰å¤‡é¤',
        'å‚æ™š(18-21ç‚¹)': 'ä¸‹ç­/å½’å®¶/æ™šé¤/è·¯é€”',
        'æ™šé—´(21-24ç‚¹)': 'å±…å®¶/å¤œç”Ÿæ´»/ç¡å‰',
        'æ·±å¤œ(0-3ç‚¹)': 'çªå‘/æ€¥ç”¨/å¤œå®µ'
    }
    
    # ==================== æ ¸å¿ƒæŒ‡æ ‡å¡ç‰‡ï¼ˆå¸¦ç¯æ¯”ï¼‰ ====================
    st.markdown(f"### ğŸ“ˆ æ ¸å¿ƒæŒ‡æ ‡æ€»è§ˆï¼ˆæŒ‰{time_dimension}ï¼‰")
    
    # æŒ‰æ—¶é—´ç»´åº¦èšåˆæ•°æ®
    if time_col in df.columns:
        # å®‰å…¨åœ°è·å–åˆ—ï¼Œé¿å…é‡å¤åˆ—åé—®é¢˜
        try:
            # æ£€æŸ¥å¹¶å¤„ç†é‡å¤åˆ—å
            if isinstance(df['è®¢å•ID'], pd.DataFrame):
                # å¦‚æœæ˜¯DataFrameï¼Œè¯´æ˜æœ‰é‡å¤åˆ—åï¼Œå–ç¬¬ä¸€åˆ—
                order_id_series = df['è®¢å•ID'].iloc[:, 0]
            else:
                order_id_series = df['è®¢å•ID']
            
            if isinstance(df['å•†å“å®å”®ä»·'], pd.DataFrame):
                price_series = df['å•†å“å®å”®ä»·'].iloc[:, 0]
            else:
                price_series = df['å•†å“å®å”®ä»·']
            
            if isinstance(df['æ”¶è´§åœ°å€'], pd.DataFrame):
                address_series = df['æ”¶è´§åœ°å€'].iloc[:, 0]
            else:
                address_series = df['æ”¶è´§åœ°å€']
            
            # åˆ›å»ºä¸´æ—¶DataFrameç”¨äºèšåˆ
            temp_df = pd.DataFrame({
                time_col: df[time_col],
                'è®¢å•ID_temp': order_id_series,
                'å•†å“å®å”®ä»·_temp': price_series,
                'æ”¶è´§åœ°å€_temp': address_series
            })
            
            time_agg = temp_df.groupby(time_col).agg({
                'è®¢å•ID_temp': 'nunique',
                'å•†å“å®å”®ä»·_temp': 'sum',
                'æ”¶è´§åœ°å€_temp': 'nunique'
            }).reset_index()
            time_agg.columns = [time_col, 'è®¢å•æ•°', 'é”€å”®é¢', 'å®¢æˆ·æ•°']
        except Exception as e:
            st.error(f"èšåˆæ•°æ®æ—¶å‡ºé”™: {str(e)}")
            st.info("ä½¿ç”¨ç®€åŒ–çš„æ•°æ®èšåˆæ–¹å¼")
            # ä½¿ç”¨æœ€ç®€å•çš„æ–¹å¼èšåˆ
            time_agg = df.groupby(time_col).size().reset_index(name='è®¢å•æ•°')
            time_agg['é”€å”®é¢'] = 0
            time_agg['å®¢æˆ·æ•°'] = 0

        
        # è®¡ç®—ç¯æ¯”
        time_agg = calculate_period_over_period(time_agg, time_dimension, 'è®¢å•æ•°')
        time_agg = calculate_period_over_period(time_agg, time_dimension, 'é”€å”®é¢')
        time_agg = calculate_period_over_period(time_agg, time_dimension, 'å®¢æˆ·æ•°')
        
        # è·å–å½“å‰æœŸå’Œä¸Šä¸€æœŸæ•°æ®ï¼ˆæ ¹æ®ç”¨æˆ·é€‰æ‹©æˆ–æœ€è¿‘ä¸€æœŸï¼‰
        if len(time_agg) >= 1:
            # å¦‚æœç”¨æˆ·é€‰æ‹©äº†å…·ä½“å‘¨æœŸï¼Œä½¿ç”¨é€‰æ‹©çš„å‘¨æœŸï¼›å¦åˆ™ä½¿ç”¨æœ€è¿‘ä¸€æœŸ
            if selected_period and not selected_period.startswith("å…¨éƒ¨"):
                if time_dimension == "æ—¥":
                    selected_date = pd.to_datetime(selected_period)
                    latest_idx = time_agg[time_agg[time_col] == selected_date].index
                else:
                    latest_idx = time_agg[time_agg[time_col] == selected_period].index
                
                if len(latest_idx) > 0:
                    latest = time_agg.loc[latest_idx[0]]
                    # è·å–ä¸Šä¸€æœŸæ•°æ®
                    current_position = latest_idx[0]
                    previous = time_agg.iloc[current_position - 1] if current_position > 0 else None
                else:
                    latest = time_agg.iloc[-1]
                    previous = time_agg.iloc[-2] if len(time_agg) >= 2 else None
            else:
                # æœªé€‰æ‹©å…·ä½“å‘¨æœŸï¼Œä½¿ç”¨æœ€è¿‘ä¸€æœŸ
                latest = time_agg.iloc[-1]
                previous = time_agg.iloc[-2] if len(time_agg) >= 2 else None
            
            col1, col2, col3, col4 = st.columns(4)
            
            # å½“å‰å‘¨æœŸ
            with col1:
                period_label = format_period_label(latest[time_col], time_dimension)
                st.metric(label=f"å½“å‰{time_dimension}", value=period_label)
            
            # è®¢å•æ•°ï¼ˆå¸¦ç¯æ¯”ï¼‰
            render_metric_with_comparison(
                col2, f"è®¢å•æ•°",
                latest['è®¢å•æ•°'],
                previous['è®¢å•æ•°'] if previous is not None else None,
                format_type='number', unit='å•'
            )
            
            # é”€å”®é¢ï¼ˆå¸¦ç¯æ¯”ï¼‰
            render_metric_with_comparison(
                col3, f"é”€å”®é¢",
                latest['é”€å”®é¢'],
                previous['é”€å”®é¢'] if previous is not None else None,
                format_type='currency'
            )
            
            # å®¢æˆ·æ•°ï¼ˆå¸¦ç¯æ¯”ï¼‰
            render_metric_with_comparison(
                col4, f"å®¢æˆ·æ•°",
                latest['å®¢æˆ·æ•°'],
                previous['å®¢æˆ·æ•°'] if previous is not None else None,
                format_type='number', unit='äºº'
            )
        
        st.markdown("---")
        
        # ==================== è¶‹åŠ¿å›¾ï¼ˆå¤šæœŸå¯¹æ¯”ï¼‰ ====================
        st.markdown(f"### ğŸ“Š {time_dimension}åº¦è¶‹åŠ¿åˆ†æ")
        
        tab1, tab2, tab3 = st.tabs(["è®¢å•é‡è¶‹åŠ¿", "é”€å”®é¢è¶‹åŠ¿", "å®¢æˆ·æ•°è¶‹åŠ¿"])
        
        with tab1:
            fig = px.line(
                time_agg, 
                x=time_col, 
                y='è®¢å•æ•°',
                title=f'è®¢å•æ•°{time_dimension}åº¦è¶‹åŠ¿',
                markers=True
            )
            fig.update_traces(line=dict(color='#1f77b4', width=3))
            fig.update_layout(height=400)
            st.plotly_chart(fig, use_container_width=True)
            
            # ç¯æ¯”å˜åŒ–è¡¨æ ¼
            if 'è®¢å•æ•°_ç¯æ¯”ç‡' in time_agg.columns:
                st.write("**ç¯æ¯”å˜åŒ–è¯¦æƒ…**")
                display_df = time_agg[[time_col, 'è®¢å•æ•°', 'è®¢å•æ•°_ä¸ŠæœŸå€¼', 'è®¢å•æ•°_ç¯æ¯”å˜åŒ–', 'è®¢å•æ•°_ç¯æ¯”ç‡']].tail(10)
                display_df.columns = ['æ—¶é—´å‘¨æœŸ', 'å½“å‰è®¢å•æ•°', 'ä¸ŠæœŸè®¢å•æ•°', 'ç¯æ¯”å˜åŒ–é‡', 'ç¯æ¯”å˜åŒ–ç‡(%)']
                st.dataframe(display_df.style.format({
                    'å½“å‰è®¢å•æ•°': '{:.0f}',
                    'ä¸ŠæœŸè®¢å•æ•°': '{:.0f}',
                    'ç¯æ¯”å˜åŒ–é‡': '{:+.0f}',
                    'ç¯æ¯”å˜åŒ–ç‡(%)': '{:+.2f}%'
                }), use_container_width=True)
        
        with tab2:
            fig = px.line(
                time_agg, 
                x=time_col, 
                y='é”€å”®é¢',
                title=f'é”€å”®é¢{time_dimension}åº¦è¶‹åŠ¿',
                markers=True
            )
            fig.update_traces(line=dict(color='#2ca02c', width=3))
            fig.update_layout(height=400)
            st.plotly_chart(fig, use_container_width=True)
            
            # ç¯æ¯”å˜åŒ–è¡¨æ ¼
            if 'é”€å”®é¢_ç¯æ¯”ç‡' in time_agg.columns:
                st.write("**ç¯æ¯”å˜åŒ–è¯¦æƒ…**")
                display_df = time_agg[[time_col, 'é”€å”®é¢', 'é”€å”®é¢_ä¸ŠæœŸå€¼', 'é”€å”®é¢_ç¯æ¯”å˜åŒ–', 'é”€å”®é¢_ç¯æ¯”ç‡']].tail(10)
                display_df.columns = ['æ—¶é—´å‘¨æœŸ', 'å½“å‰é”€å”®é¢', 'ä¸ŠæœŸé”€å”®é¢', 'ç¯æ¯”å˜åŒ–é¢', 'ç¯æ¯”å˜åŒ–ç‡(%)']
                st.dataframe(display_df.style.format({
                    'å½“å‰é”€å”®é¢': 'Â¥{:,.2f}',
                    'ä¸ŠæœŸé”€å”®é¢': 'Â¥{:,.2f}',
                    'ç¯æ¯”å˜åŒ–é¢': 'Â¥{:+,.2f}',
                    'ç¯æ¯”å˜åŒ–ç‡(%)': '{:+.2f}%'
                }), use_container_width=True)
        
        with tab3:
            fig = px.line(
                time_agg, 
                x=time_col, 
                y='å®¢æˆ·æ•°',
                title=f'å®¢æˆ·æ•°{time_dimension}åº¦è¶‹åŠ¿',
                markers=True
            )
            fig.update_traces(line=dict(color='#ff7f0e', width=3))
            fig.update_layout(height=400)
            st.plotly_chart(fig, use_container_width=True)
            
            # ç¯æ¯”å˜åŒ–è¡¨æ ¼
            if 'å®¢æˆ·æ•°_ç¯æ¯”ç‡' in time_agg.columns:
                st.write("**ç¯æ¯”å˜åŒ–è¯¦æƒ…**")
                display_df = time_agg[[time_col, 'å®¢æˆ·æ•°', 'å®¢æˆ·æ•°_ä¸ŠæœŸå€¼', 'å®¢æˆ·æ•°_ç¯æ¯”å˜åŒ–', 'å®¢æˆ·æ•°_ç¯æ¯”ç‡']].tail(10)
                display_df.columns = ['æ—¶é—´å‘¨æœŸ', 'å½“å‰å®¢æˆ·æ•°', 'ä¸ŠæœŸå®¢æˆ·æ•°', 'ç¯æ¯”å˜åŒ–é‡', 'ç¯æ¯”å˜åŒ–ç‡(%)']
                st.dataframe(display_df.style.format({
                    'å½“å‰å®¢æˆ·æ•°': '{:.0f}',
                    'ä¸ŠæœŸå®¢æˆ·æ•°': '{:.0f}',
                    'ç¯æ¯”å˜åŒ–é‡': '{:+.0f}',
                    'ç¯æ¯”å˜åŒ–ç‡(%)': '{:+.2f}%'
                }), use_container_width=True)
    
    st.markdown("---")
    
    # ==================== æ—¶æ®µåˆ†å¸ƒï¼ˆæ ¹æ®é€‰å®šçš„æ—¶é—´ç»´åº¦ç­›é€‰æœ€è¿‘ä¸€æœŸï¼‰ ====================
    st.markdown(f"### â° åˆ†æ—¶æ®µåœºæ™¯åˆ†æï¼ˆå½“å‰{time_dimension}æ•°æ®ï¼‰")
    
    # ç­›é€‰æœ€è¿‘ä¸€ä¸ªå‘¨æœŸçš„æ•°æ®ç”¨äºæ—¶æ®µåˆ†æ
    filtered_df = filter_data_by_time_dimension(df, time_dimension, selected_period, latest_only=True)
    
    if len(filtered_df) == 0:
        st.warning(f"âš ï¸ å½“å‰{time_dimension}æš‚æ— æ•°æ®")
        return
    
    # æ˜¾ç¤ºå½“å‰åˆ†æçš„æ—¶é—´èŒƒå›´
    if time_col in filtered_df.columns:
        current_period = filtered_df[time_col].iloc[0]
        period_label = format_period_label(current_period, time_dimension)
        st.info(f"ğŸ“… å½“å‰åˆ†ææ—¶é—´ï¼š{period_label}")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.write("**ğŸ“Š åˆ†æ—¶æ®µè®¢å•é‡åˆ†å¸ƒ**")
        if 'æ—¶æ®µ' in filtered_df.columns:
            # åˆå§‹åŒ–å˜é‡
            peak_period = "N/A"
            peak_orders = 0
            low_period = "N/A"
            low_orders = 0
            
            try:
                # åˆ›å»ºä¸´æ—¶DataFrameå¤„ç†é‡å¤åˆ—å
                temp_df = filtered_df.copy()
                if isinstance(temp_df['è®¢å•ID'], pd.DataFrame):
                    temp_df['è®¢å•ID'] = temp_df['è®¢å•ID'].iloc[:, 0]
                if isinstance(temp_df['æ—¶æ®µ'], pd.DataFrame):
                    temp_df['æ—¶æ®µ'] = temp_df['æ—¶æ®µ'].iloc[:, 0]
                
                # æŒ‰æ—¶æ®µç»Ÿè®¡å”¯ä¸€è®¢å•æ•°
                order_by_period = temp_df.groupby('æ—¶æ®µ')['è®¢å•ID'].nunique()
                
                # é‡æ–°ç´¢å¼•åˆ°æ‰€æœ‰æ—¶æ®µ
                if len(order_by_period) > 0:
                    order_by_period = order_by_period.reindex(time_period_order, fill_value=0)
                    
                    fig = px.bar(
                        x=order_by_period.index,
                        y=order_by_period.values,
                        labels={'x': 'æ—¶æ®µ', 'y': 'è®¢å•é‡'},
                        title=f'å„æ—¶æ®µè®¢å•é‡å¯¹æ¯”ï¼ˆ{period_label}ï¼‰',
                        color=order_by_period.values,
                        color_continuous_scale='Blues'
                    )
                    fig.update_layout(showlegend=False, height=400)
                    st.plotly_chart(fig, use_container_width=True)
                    
                    peak_period = order_by_period.idxmax()
                    peak_orders = int(order_by_period.max())
                    low_period = order_by_period.idxmin()
                    low_orders = int(order_by_period.min())
                else:
                    st.info("æš‚æ— æ—¶æ®µæ•°æ®")
            except Exception as e:
                st.error(f"ç»˜åˆ¶æ—¶æ®µåˆ†å¸ƒå›¾æ—¶å‡ºé”™: {str(e)}")
                st.write(f"è°ƒè¯•ä¿¡æ¯ - filtered_dfå½¢çŠ¶: {filtered_df.shape}")
                if 'æ—¶æ®µ' in filtered_df.columns:
                    st.write(f"æ—¶æ®µåˆ—å”¯ä¸€å€¼: {filtered_df['æ—¶æ®µ'].unique()}")
            
            # åªæœ‰åœ¨æœ‰æœ‰æ•ˆæ•°æ®æ—¶æ‰æ˜¾ç¤ºæ´å¯Ÿ
            if peak_period != "N/A":
                st.markdown(f"""
                <div class="insight-box">
                <b>ğŸ’¡ å…³é”®æ´å¯Ÿï¼š</b><br>
                â€¢ é«˜å³°æ—¶æ®µï¼š<b>{peak_period}</b>ï¼ˆ{peak_orders:,}å•ï¼‰<br>
                â€¢ ä½è°·æ—¶æ®µï¼š<b>{low_period}</b>ï¼ˆ{low_orders:,}å•ï¼‰<br>
                â€¢ å³°è°·å·®å¼‚ï¼š{(peak_orders - low_orders):,}å•ï¼ˆ{(peak_orders/max(low_orders, 1) - 1)*100:.1f}%ï¼‰
                </div>
                """, unsafe_allow_html=True)
        else:
            st.info("æ— æ—¶é—´æ•°æ®")
    
    with col2:
        st.write("**ğŸ’° åˆ†æ—¶æ®µå®¢å•ä»·åˆ†å¸ƒ**")
        if 'æ—¶æ®µ' in filtered_df.columns:
            try:
                # åˆ›å»ºä¸´æ—¶DataFrameï¼Œå¤„ç†é‡å¤åˆ—å
                temp_df = filtered_df.copy()
                if isinstance(temp_df['è®¢å•ID'], pd.DataFrame):
                    temp_df['è®¢å•ID'] = temp_df['è®¢å•ID'].iloc[:, 0]
                if isinstance(temp_df['å•†å“å®å”®ä»·'], pd.DataFrame):
                    temp_df['å•†å“å®å”®ä»·'] = temp_df['å•†å“å®å”®ä»·'].iloc[:, 0]
                
                period_sales = temp_df.groupby(['æ—¶æ®µ', 'è®¢å•ID'])['å•†å“å®å”®ä»·'].sum().groupby('æ—¶æ®µ').mean()
                period_sales = period_sales.reindex(time_period_order, fill_value=0)
                
                fig = px.line(
                    x=period_sales.index,
                    y=period_sales.values,
                    labels={'x': 'æ—¶æ®µ', 'y': 'å¹³å‡å®¢å•ä»·(å…ƒ)'},
                    title=f'å„æ—¶æ®µå¹³å‡å®¢å•ä»·è¶‹åŠ¿ï¼ˆ{period_label}ï¼‰',
                    markers=True
                )
                fig.update_traces(line_color='#ff7f0e', marker=dict(size=10))
                fig.update_layout(height=400)
                st.plotly_chart(fig, use_container_width=True)
                
                high_value_period = period_sales.idxmax()
                high_value = period_sales.max()
                
                st.markdown(f"""
                <div class="insight-box">
                <b>ğŸ’¡ å…³é”®æ´å¯Ÿï¼š</b><br>
                â€¢ é«˜ä»·å€¼æ—¶æ®µï¼š<b>{high_value_period}</b>ï¼ˆÂ¥{high_value:.2f}ï¼‰<br>
                â€¢ å…¨å¤©å¹³å‡å®¢å•ä»·ï¼šÂ¥{period_sales.mean():.2f}<br>
                â€¢ å»ºè®®ï¼šé«˜ä»·å€¼æ—¶æ®µå¯å‡å°‘ä¿ƒé”€åŠ›åº¦ï¼Œæå‡åˆ©æ¶¦ç‡
                </div>
                """, unsafe_allow_html=True)
            except Exception as e:
                st.error(f"è®¡ç®—å®¢å•ä»·åˆ†å¸ƒæ—¶å‡ºé”™: {str(e)}")
        else:
            st.info("æ— æ—¶é—´æ•°æ®")
    
    # æ·»åŠ è¯¦ç»†æ—¶æ®µåœºæ™¯åˆ†æè¡¨
    st.write(f"**ğŸ“‹ æ—¶æ®µåœºæ™¯è¯¦ç»†åˆ†æï¼ˆ{period_label}ï¼‰**")
    if 'æ—¶æ®µ' in filtered_df.columns:
        try:
            # åˆ›å»ºä¸´æ—¶DataFrameå¤„ç†é‡å¤åˆ—å
            temp_df = filtered_df.copy()
            if isinstance(temp_df['è®¢å•ID'], pd.DataFrame):
                temp_df['è®¢å•ID'] = temp_df['è®¢å•ID'].iloc[:, 0]
            if isinstance(temp_df['å•†å“å®å”®ä»·'], pd.DataFrame):
                temp_df['å•†å“å®å”®ä»·'] = temp_df['å•†å“å®å”®ä»·'].iloc[:, 0]
            
            period_detail = []
            total_orders = temp_df['è®¢å•ID'].nunique()
            
            for period in time_period_order:
                period_df = temp_df[temp_df['æ—¶æ®µ'] == period]
                if len(period_df) == 0:
                    continue
                
                orders = period_df['è®¢å•ID'].nunique()
                items = len(period_df)
                avg_price = period_df.groupby('è®¢å•ID')['å•†å“å®å”®ä»·'].sum().mean()
                
                period_detail.append({
                    'æ—¶æ®µ': period,
                    'åœºæ™¯': scene_descriptions.get(period, '-'),
                    'è®¢å•é‡': f'{orders:,}',
                    'å•†å“æ•°': f'{items:,}',
                    'å¹³å‡å®¢å•ä»·': f'Â¥{avg_price:.2f}',
                    'è®¢å•å æ¯”': f'{orders/total_orders*100:.1f}%'
                })
            
            if period_detail:
                detail_df = pd.DataFrame(period_detail)
                st.dataframe(detail_df, use_container_width=True, hide_index=True)
            else:
                st.info("æš‚æ— æ—¶æ®µè¯¦ç»†æ•°æ®")
        except Exception as e:
            st.error(f"ç”Ÿæˆæ—¶æ®µè¯¦ç»†åˆ†ææ—¶å‡ºé”™: {str(e)}")
    
    # ==================== åœºæ™¯å•†å“åˆ†æ ====================
    st.markdown(f"### ğŸ›ï¸ åœºæ™¯å•†å“æ´å¯Ÿï¼šä»€ä¹ˆæ—¶æ®µç”¨æˆ·ä¹°ä»€ä¹ˆï¼Ÿ")
    
    if 'æ—¶æ®µ' in filtered_df.columns and 'ä¸‰çº§åˆ†ç±»å' in filtered_df.columns:
        # å®šä¹‰å¿«æ¶ˆé›¶å”®çš„æ ¸å¿ƒåœºæ™¯æ—¶æ®µï¼ˆåŸºäºO2Oé…é€ç‰¹å¾ä¼˜åŒ–ï¼‰
        # âš ï¸ æ³¨æ„ï¼šæ—¶æ®µåç§°å¿…é¡»ä¸extract_time_featureså‡½æ•°ä¸­å®šä¹‰çš„å®Œå…¨ä¸€è‡´
        key_scenes = {
            'æ—©é¤åˆšéœ€': ['æ¸…æ™¨(6-8ç‚¹)', 'æ—©é«˜å³°(8-9ç‚¹)'],  # ä¿®æ­£ï¼šå¯¹åº”6-9ç‚¹æ—©é¤æ—¶æ®µ
            'æ—¥å¸¸è¡¥ç»™': ['ä¸Šåˆ(9-11ç‚¹)', 'ä¸‹åˆ(14-17ç‚¹)'],
            'æ­£é¤é«˜å³°': ['åˆé«˜å³°(11-12ç‚¹)', 'æ­£åˆ(12-14ç‚¹)', 'æ™šé«˜å³°å‰(17-18ç‚¹)', 'å‚æ™š(18-21ç‚¹)'],  # ä¿®æ­£ï¼šåŒ…å«å®Œæ•´åˆé¤å’Œæ™šé¤æ—¶æ®µ
            'ä¼‘é—²å¨±ä¹': ['ä¸‹åˆ(14-17ç‚¹)', 'æ™šé—´(21-24ç‚¹)'],
            'æ·±å¤œåº”æ€¥': ['æ·±å¤œ(0-3ç‚¹)', 'å‡Œæ™¨(3-6ç‚¹)']
        }
        
        tabs = st.tabs(list(key_scenes.keys()))
        
        for idx, (scene_name, time_periods) in enumerate(key_scenes.items()):
            with tabs[idx]:
                scene_df = filtered_df[filtered_df['æ—¶æ®µ'].isin(time_periods)]
                
                if len(scene_df) > 0:
                    # å•†å“é”€é‡TOP10
                    top_products = scene_df.groupby('ä¸‰çº§åˆ†ç±»å').size().sort_values(ascending=False).head(10)
                    
                    col_a, col_b = st.columns([2, 1])
                    
                    with col_a:
                        fig = px.bar(
                            x=top_products.values,
                            y=top_products.index,
                            orientation='h',
                            title=f'{scene_name} - TOP10 çƒ­é”€å•†å“',
                            labels={'x': 'é”€é‡', 'y': 'å•†å“åˆ†ç±»'},
                            color=top_products.values,
                            color_continuous_scale='Oranges'
                        )
                        fig.update_layout(showlegend=False, height=400, yaxis={'categoryorder':'total ascending'})
                        st.plotly_chart(fig, use_container_width=True)
                    
                    with col_b:
                        st.write(f"**{scene_name} æ•°æ®**")
                        scene_orders = scene_df['è®¢å•ID'].nunique()
                        scene_sales = scene_df.groupby('è®¢å•ID')['å•†å“å®å”®ä»·'].sum().sum()
                        scene_avg_price = scene_sales / scene_orders if scene_orders > 0 else 0
                        
                        st.metric("è®¢å•é‡", f"{scene_orders:,}å•")
                        st.metric("é”€å”®é¢", f"Â¥{scene_sales:,.2f}")
                        st.metric("å¹³å‡å®¢å•ä»·", f"Â¥{scene_avg_price:.2f}")
                        
                        # åœºæ™¯ç‰¹å¾å•†å“
                        if len(top_products) >= 3:
                            st.write("**ğŸ¯ åœºæ™¯ç‰¹å¾å•†å“**")
                            for i, (prod, cnt) in enumerate(top_products.head(3).items(), 1):
                                st.markdown(f"{i}. **{prod}**ï¼ˆ{cnt}ä»¶ï¼‰")
                    
                    # O2Oå¿«æ¶ˆé›¶å”®åœºæ™¯ç­–ç•¥å»ºè®®ï¼ˆåŸºäº8æ—¶æ®µæ¡†æ¶ï¼‰
                    scene_strategy = {
                        'æ—©é¤åˆšéœ€': """
                        <div class="insight-box">
                        <b>ğŸ’¡ æ—©é¤åˆšéœ€åœºæ™¯ç­–ç•¥ï¼ˆ6-9ç‚¹ï¼‰</b><br>
                        <b>æ—¶æ®µè¦†ç›–</b>ï¼šæ¸…æ™¨(6-8ç‚¹) + æ—©é«˜å³°(8-9ç‚¹)<br>
                        <b>ç”¨æˆ·ç”»åƒ</b>ï¼šé€šå‹¤ä¸Šç­æ—ã€å­¦ç”Ÿå…šã€æ—©èµ·è¿åŠ¨è€…<br>
                        <b>æ ¸å¿ƒå•†å“</b>ï¼šé¢åŒ…ã€åŒ…å­ã€ç‰›å¥¶ã€è±†æµ†ã€æ²¹æ¡ã€èŒ¶å¶è›‹ã€ç²¥ç±»ã€å’–å•¡<br>
                        <b>è¡Œä¸ºç‰¹å¾</b>ï¼šæ—¶é—´ç´§è¿«ã€å³ä¹°å³èµ°ã€å¤è´­ç‡é«˜ã€å¯¹é€Ÿåº¦æåº¦æ•æ„Ÿ<br>
                        <b>è¿è¥ç­–ç•¥</b>ï¼š<br>
                        â€¢ <b>é€Ÿåº¦è‡³ä¸Š</b>ï¼šæ‰¿è¯º15åˆ†é’Ÿè¾¾ï¼Œè¿Ÿåˆ°ç«‹å‡/å…å•<br>
                        â€¢ <b>æ—©é¤å¥—é¤</b>ï¼šè±†æµ†+æ²¹æ¡ã€é¢åŒ…+ç‰›å¥¶ä¸€é”®ä¸‹å•<br>
                        â€¢ <b>è®¢é˜…æœåŠ¡</b>ï¼šå·¥ä½œæ—¥æ—©é¤åŒ…æœˆï¼Œå›ºå®šæ—¶é—´é€è¾¾<br>
                        â€¢ <b>æå‰å¤‡è´§</b>ï¼š6-8ç‚¹çƒ­é”€å“é¢„å¤‡2å€åº“å­˜
                        </div>
                        """,
                        'æ—¥å¸¸è¡¥ç»™': """
                        <div class="insight-box">
                        <b>ğŸ’¡ æ—¥å¸¸è¡¥ç»™åœºæ™¯ç­–ç•¥ï¼ˆ9-12ç‚¹ & 14-17ç‚¹ï¼‰</b><br>
                        <b>ç”¨æˆ·ç”»åƒ</b>ï¼šå±…å®¶ä¸»å¦‡/ä¸»å¤«ã€è¿œç¨‹åŠå…¬è€…ã€é€€ä¼‘è€äºº<br>
                        <b>æ ¸å¿ƒå•†å“</b>ï¼šè”¬èœæ°´æœã€ç±³é¢ç²®æ²¹ã€è°ƒå‘³å“ã€æ—¥ç”¨å“ã€é›¶é£Ÿé¥®æ–™<br>
                        <b>è¡Œä¸ºç‰¹å¾</b>ï¼šè®¡åˆ’æ€§é‡‡è´­ã€ä»·æ ¼æ•æ„Ÿã€å“ç±»å¤šæ ·ã€å…³æ³¨å“è´¨<br>
                        <b>è¿è¥ç­–ç•¥</b>ï¼š<br>
                        â€¢ <b>æ»¡å‡ä¿ƒé”€</b>ï¼šæ»¡50å‡5ã€æ»¡100å‡15é˜¶æ¢¯ä¼˜æƒ <br>
                        â€¢ <b>ç»„åˆæ¨è</b>ï¼šæ ¹æ®å†å²è®¢å•æ™ºèƒ½æ¨èï¼ˆç•ªèŒ„â†’é¸¡è›‹ï¼‰<br>
                        â€¢ <b>å“è´¨ä¿éšœ</b>ï¼šç”Ÿé²œå“è´¨æ‰¿è¯ºï¼Œä¸æ»¡æ„é€€æ¬¾<br>
                        â€¢ <b>ä¼šå‘˜ç¦åˆ©</b>ï¼šæ—¥å¸¸ç”¨å“ä¼šå‘˜ä»·ï¼Œä¸“å±æŠ˜æ‰£
                        </div>
                        """,
                        'æ­£é¤é«˜å³°': """
                        <div class="insight-box">
                        <b>ğŸ’¡ æ­£é¤é«˜å³°åœºæ™¯ç­–ç•¥ï¼ˆ11-14ç‚¹ & 17-21ç‚¹ï¼‰</b><br>
                        <b>æ—¶æ®µè¦†ç›–</b>ï¼šåˆé«˜å³°(11-12ç‚¹) + æ­£åˆ(12-14ç‚¹) + æ™šé«˜å³°å‰(17-18ç‚¹) + å‚æ™š(18-21ç‚¹)<br>
                        <b>ç”¨æˆ·ç”»åƒ</b>ï¼šä¸Šç­æ—ã€å­¦ç”Ÿã€å®¶åº­èšé¤ã€åŠ ç­äººç¾¤<br>
                        <b>æ ¸å¿ƒå•†å“</b>ï¼šåŠæˆå“èœã€é€Ÿé£Ÿï¼ˆæ³¡é¢/è‡ªçƒ­é¥­ï¼‰ã€é¥®æ–™ã€é…’æ°´ã€è°ƒå‘³æ–™<br>
                        <b>è¡Œä¸ºç‰¹å¾</b>ï¼šé›†ä¸­ä¸‹å•ã€æ—¶é—´ç´§è¿«ã€å®¢å•ä»·é«˜ã€è¿½æ±‚ä¾¿åˆ©<br>
                        <b>è¿è¥ç­–ç•¥</b>ï¼š<br>
                        â€¢ <b>æ­£é¤å¥—é¤</b>ï¼šé€Ÿé£Ÿ+é¥®æ–™ã€åŠæˆå“+è°ƒæ–™ç»„åˆ<br>
                        â€¢ <b>é«˜å³°åŠ æ€¥</b>ï¼š11:30-12:30ä¼˜å…ˆé…é€ï¼Œä¿è¯ç”¨é¤æ—¶é—´<br>
                        â€¢ <b>æ™šé¤æ¨è</b>ï¼š17:30æ¨é€æ™šé¤æé†’+ä¼˜æƒ åˆ¸<br>
                        â€¢ <b>å®¶åº­è£…</b>ï¼š3-4äººä»½å¥—é¤ï¼Œæ€§ä»·æ¯”çªå‡º
                        </div>
                        """,
                        'ä¼‘é—²å¨±ä¹': """
                        <div class="insight-box">
                        <b>ğŸ’¡ ä¼‘é—²å¨±ä¹åœºæ™¯ç­–ç•¥ï¼ˆ14-17ç‚¹ & 21-24ç‚¹ï¼‰</b><br>
                        <b>ç”¨æˆ·ç”»åƒ</b>ï¼šè¿½å‰§å…šã€æ¸¸æˆç©å®¶ã€æœ‹å‹èšä¼šã€å±…å®¶ä¼‘é—²<br>
                        <b>æ ¸å¿ƒå•†å“</b>ï¼šè–¯ç‰‡ã€ç“œå­ã€å¯ä¹ã€å•¤é…’ã€å¤å‘³ã€æ°´æœã€å†°æ·‡æ·‹ã€å¥¶èŒ¶<br>
                        <b>è¡Œä¸ºç‰¹å¾</b>ï¼šå†²åŠ¨æ¶ˆè´¹ã€å“ç±»é›†ä¸­ã€ç¤¾äº¤å±æ€§å¼ºã€å¯¹ä»·æ ¼ä¸æ•æ„Ÿ<br>
                        <b>è¿è¥ç­–ç•¥</b>ï¼š<br>
                        â€¢ <b>åœºæ™¯å¥—é¤</b>ï¼šè¿½å‰§å¥—é¤ã€æ¸¸æˆå¥—é¤ã€èšä¼šå¥—é¤<br>
                        â€¢ <b>ä¹°èµ æ´»åŠ¨</b>ï¼šä¹°é¥®æ–™é€é›¶é£Ÿã€ä¹°2é€1<br>
                        â€¢ <b>ç½‘çº¢æ–°å“</b>ï¼šä¸»æ¨æ–°å¥‡ç‰¹é›¶é£Ÿï¼Œåˆºæ¿€å°é²œ<br>
                        â€¢ <b>ç¤¾äº¤åˆ†äº«</b>ï¼šæ‹¼å›¢ä¼˜æƒ ï¼Œå¤šäººä¸‹å•æ›´åˆ’ç®—
                        </div>
                        """,
                        'æ·±å¤œåº”æ€¥': """
                        <div class="insight-box">
                        <b>ğŸ’¡ æ·±å¤œåº”æ€¥åœºæ™¯ç­–ç•¥ï¼ˆ0-6ç‚¹ï¼‰</b><br>
                        <b>ç”¨æˆ·ç”»åƒ</b>ï¼šå¤œç­å·¥ä½œè€…ã€ç†¬å¤œå…šã€æ–°æ‰‹çˆ¶æ¯ã€å¤±çœ äººç¾¤<br>
                        <b>æ ¸å¿ƒå•†å“</b>ï¼šæ³¡é¢ã€çº¸å·¾ã€ç”µæ± ã€å©´å„¿ç”¨å“ã€åŠŸèƒ½é¥®æ–™ã€å¸¸å¤‡å°è¯<br>
                        <b>è¡Œä¸ºç‰¹å¾</b>ï¼šçªå‘éœ€æ±‚ã€ä»·æ ¼ä¸æ•æ„Ÿã€å“ç±»å•ä¸€ã€é€Ÿåº¦è¦æ±‚é«˜<br>
                        <b>è¿è¥ç­–ç•¥</b>ï¼š<br>
                        â€¢ <b>åº”æ€¥ä¼˜å…ˆ</b>ï¼š24å°æ—¶ä¿éšœæ ¸å¿ƒå“ç±»åº“å­˜<br>
                        â€¢ <b>æ·±å¤œåŠ ä»·</b>ï¼š22ç‚¹åé…é€è´¹+3-5å…ƒï¼ˆåº”æ€¥æº¢ä»·ï¼‰<br>
                        â€¢ <b>å“ç±»ç²¾ç®€</b>ï¼šåªä¿ç•™é«˜é¢‘åº”æ€¥å“ï¼Œå‡å°‘é€‰æ‹©å›°éš¾<br>
                        â€¢ <b>é€Ÿåº¦æ‰¿è¯º</b>ï¼šæ·±å¤œ30åˆ†é’Ÿè¾¾ï¼Œå»ºç«‹ä¿¡ä»»åº¦
                        </div>
                        """
                    }
                    
                    st.markdown(scene_strategy.get(scene_name, ""), unsafe_allow_html=True)
                else:
                    st.info(f"âš ï¸ {scene_name}æš‚æ— æ•°æ®")
    
    st.markdown("---")
    
    # ==================== ğŸ¤– AIåœºæ™¯è¯†åˆ«æ¨¡å‹ ====================
    st.markdown("### ğŸ¤– AIåœºæ™¯è¯†åˆ«ä¸é¢„æµ‹")
    
    if SCENE_INTELLIGENCE_AVAILABLE:
        with st.expander("ğŸ’¡ åŸºäºXGBoostçš„åœºæ™¯è¯†åˆ«æ¨¡å‹", expanded=True):
            st.info("ğŸ“Š ä½¿ç”¨æœºå™¨å­¦ä¹ ç®—æ³•è‡ªåŠ¨è¯†åˆ«è®¢å•åœºæ™¯ï¼Œé¢„æµ‹æœªæ¥è®¢å•çš„åœºæ™¯åˆ†å¸ƒ")
            
            col1, col2 = st.columns([3, 1])
            
            with col2:
                if st.button("ğŸš€ è®­ç»ƒåœºæ™¯è¯†åˆ«æ¨¡å‹", key="train_scene_model"):
                    with st.spinner("â³ æ­£åœ¨è®­ç»ƒæ¨¡å‹..."):
                        try:
                            # æ•°æ®è¯Šæ–­ï¼šè®­ç»ƒå‰æ£€æŸ¥
                            st.info(f"""
                            ğŸ“Š **è®­ç»ƒæ•°æ®æ¦‚å†µ**ï¼š
                            - æ€»è®¢å•æ•°ï¼š{len(df):,}
                            - æ•°æ®åˆ—æ•°ï¼š{len(df.columns)}
                            - æ˜¯å¦åŒ…å«'ä¸‹å•æ—¶é—´'ï¼š{'âœ…' if 'ä¸‹å•æ—¶é—´' in df.columns else 'âŒ'}
                            """)
                            
                            # å¦‚æœæœ‰ä¸‹å•æ—¶é—´ï¼Œæ˜¾ç¤ºæ—¶é—´èŒƒå›´
                            if 'ä¸‹å•æ—¶é—´' in df.columns:
                                time_series = pd.to_datetime(df['ä¸‹å•æ—¶é—´'], errors='coerce')
                                if not time_series.dropna().empty:
                                    min_time = time_series.min()
                                    max_time = time_series.max()
                                    days_span = (max_time - min_time).days + 1
                                    hour_coverage = time_series.dt.hour.nunique()
                                    st.success(f"""
                                    â° **æ—¶é—´èŒƒå›´**ï¼š
                                    - èµ·å§‹ï¼š{min_time.strftime('%Y-%m-%d %H:%M')}
                                    - ç»“æŸï¼š{max_time.strftime('%Y-%m-%d %H:%M')}
                                    - è·¨åº¦ï¼š{days_span}å¤©
                                    - è¦†ç›–æ—¶æ®µï¼š{hour_coverage}/24å°æ—¶
                                    """)
                            
                            # åˆå§‹åŒ–æ¨¡å‹
                            scene_model = SceneRecognitionModel()
                            
                            # è®­ç»ƒæ¨¡å‹ - ä½¿ç”¨å…¨éƒ¨æ•°æ®è€Œéç­›é€‰åçš„æ•°æ®
                            # æ³¨æ„ï¼šè¿™é‡Œä½¿ç”¨ dfï¼ˆå…¨éƒ¨æ•°æ®ï¼‰è€Œä¸æ˜¯ filtered_dfï¼ˆä»…æœ€è¿‘ä¸€ä¸ªå‘¨æœŸï¼‰
                            train_result = scene_model.train(df)
                            
                            if train_result.get('status') == 'success':
                                # ä¿å­˜åˆ°session_stateï¼ˆåŒ…æ‹¬è®­ç»ƒæ•°æ®ç”¨äºè¯Šæ–­ï¼‰
                                st.session_state['scene_model'] = scene_model
                                st.session_state['scene_train_result'] = train_result
                                st.session_state['scene_train_data'] = df  # ä¿å­˜å®Œæ•´çš„è®­ç»ƒæ•°æ®
                                
                                st.success(f"âœ… æ¨¡å‹è®­ç»ƒå®Œæˆï¼æµ‹è¯•å‡†ç¡®ç‡: {train_result['test_score']:.1%}")
                            else:
                                st.error(f"âŒ è®­ç»ƒå¤±è´¥ï¼š{train_result.get('message')}")
                        
                        except Exception as e:
                            st.error(f"âŒ è®­ç»ƒè¿‡ç¨‹å‡ºé”™: {str(e)}")
            
            # å¦‚æœæ¨¡å‹å·²è®­ç»ƒï¼Œæ˜¾ç¤ºç»“æœ
            if 'scene_model' in st.session_state and 'scene_train_result' in st.session_state:
                scene_model = st.session_state['scene_model']
                train_result = st.session_state['scene_train_result']
                
                # åˆ›å»ºæ ‡ç­¾é¡µ
                tab1, tab2, tab3 = st.tabs(["ğŸ“Š æ¨¡å‹æ€§èƒ½", "ğŸ¯ åœºæ™¯é¢„æµ‹", "ğŸ“ˆ ç‰¹å¾é‡è¦æ€§"])
                
                with tab1:
                    st.markdown("#### ğŸ“Š æ¨¡å‹æ€§èƒ½æŒ‡æ ‡")
                    
                    col1, col2, col3 = st.columns(3)
                    
                    with col1:
                        st.metric("è®­ç»ƒé›†å‡†ç¡®ç‡", f"{train_result['train_score']:.1%}")
                    
                    with col2:
                        st.metric("æµ‹è¯•é›†å‡†ç¡®ç‡", f"{train_result['test_score']:.1%}")
                    
                    with col3:
                        overfitting = train_result['train_score'] - train_result['test_score']
                        st.metric("è¿‡æ‹Ÿåˆç¨‹åº¦", f"{overfitting:.1%}", 
                                 delta="ä½" if overfitting < 0.05 else "éœ€å…³æ³¨",
                                 delta_color="inverse")
                    
                    # æ•°æ®è¯Šæ–­ï¼šæ—¶æ®µåˆ†å¸ƒåˆ†æ
                    st.markdown("**â° æ•°æ®æ—¶æ®µè¦†ç›–è¯Šæ–­**")
                    
                    # è·å–è®­ç»ƒæ—¶ä½¿ç”¨çš„æ•°æ®
                    train_data = st.session_state.get('scene_train_data')
                    
                    if train_data is not None and 'ä¸‹å•æ—¶é—´' in train_data.columns:
                        hour_dist = pd.to_datetime(train_data['ä¸‹å•æ—¶é—´'], errors='coerce').dt.hour.value_counts().sort_index()
                        
                        col_diag1, col_diag2 = st.columns([2, 1])
                        
                        with col_diag1:
                            # æ—¶æ®µåˆ†å¸ƒæŸ±çŠ¶å›¾
                            fig_hour = px.bar(
                                x=hour_dist.index, 
                                y=hour_dist.values,
                                labels={'x': 'å°æ—¶', 'y': 'è®¢å•æ•°'},
                                title='è®¢å•æ—¶æ®µåˆ†å¸ƒï¼ˆ0-23ç‚¹ï¼‰'
                            )
                            fig_hour.update_layout(height=250)
                            st.plotly_chart(fig_hour, use_container_width=True)
                        
                        with col_diag2:
                            total_hours_covered = len(hour_dist)
                            main_hours = hour_dist.head(3).index.tolist()
                            
                            st.metric("è¦†ç›–æ—¶æ®µæ•°", f"{total_hours_covered}/24å°æ—¶")
                            st.info(f"**ä¸»è¦æ—¶æ®µï¼š** {', '.join([f'{h}æ—¶' for h in main_hours])}")
                            
                            if total_hours_covered < 12:
                                st.warning(f"âš ï¸ æ•°æ®ä»…è¦†ç›–{total_hours_covered}ä¸ªå°æ—¶ï¼Œåœºæ™¯è¯†åˆ«å¯èƒ½ä¸å¤Ÿä¸°å¯Œ")
                    else:
                        st.info("ğŸ’¡ æ•°æ®è¯Šæ–­éœ€è¦åŒ…å«'ä¸‹å•æ—¶é—´'å­—æ®µ")
                    
                    st.markdown("---")
                    
                    # åœºæ™¯åˆ†å¸ƒ
                    st.markdown("**ğŸ­ è®­ç»ƒæ•°æ®åœºæ™¯åˆ†å¸ƒ**")
                    scene_dist = train_result.get('scene_distribution', {})
                    if scene_dist:
                        dist_df = pd.DataFrame(list(scene_dist.items()), columns=['åœºæ™¯', 'è®¢å•æ•°'])
                        dist_df['å æ¯”'] = (dist_df['è®¢å•æ•°'] / dist_df['è®¢å•æ•°'].sum() * 100).round(1)
                        
                        # åœºæ™¯å¤šæ ·æ€§è¯Šæ–­
                        scene_count = len(scene_dist)
                        if scene_count == 1:
                            st.error(f"ğŸš¨ **æ•°æ®é—®é¢˜**ï¼šä»…è¯†åˆ«å‡º1ä¸ªåœºæ™¯ï¼ˆ{list(scene_dist.keys())[0]}ï¼‰")
                            st.warning("""
                            ğŸ’¡ **å¯èƒ½çš„åŸå› ï¼š**
                            
                            1. **æ•°æ®æ—¶æ®µè¿‡äºé›†ä¸­**ï¼šæ‚¨çš„è®¢å•æ•°æ®å¯èƒ½éƒ½é›†ä¸­åœ¨æŸä¸ªç‰¹å®šæ—¶æ®µï¼ˆå¦‚éƒ½æ˜¯æ·±å¤œä¸‹å•ï¼‰
                            2. **æ•°æ®é‡å¤ªå°‘**ï¼šæ ·æœ¬æ•°é‡ä¸è¶³ï¼Œæ— æ³•è¦†ç›–å¤šä¸ªåœºæ™¯
                            3. **æ•°æ®æ—¶é—´èŒƒå›´å¤ªçª„**ï¼šåªæœ‰æŸä¸€å¤©æˆ–æŸå‡ ä¸ªå°æ—¶çš„æ•°æ®
                            
                            **è§£å†³æ–¹æ³•ï¼š**
                            
                            - ç¡®ä¿æ•°æ®åŒ…å«**æ—©ã€ä¸­ã€æ™š**ä¸åŒæ—¶æ®µçš„è®¢å•
                            - æ‰©å¤§æ•°æ®æ—¶é—´èŒƒå›´ï¼ˆå»ºè®®è‡³å°‘7å¤©ä»¥ä¸Šï¼‰
                            - æ£€æŸ¥ä¸Šæ–¹çš„"æ—¶æ®µè¦†ç›–è¯Šæ–­"ï¼Œçœ‹çœ‹æ•°æ®æ˜¯å¦è¦†ç›–24å°æ—¶
                            """)
                        elif scene_count < 3:
                            st.warning(f"âš ï¸ ä»…è¯†åˆ«å‡º{scene_count}ä¸ªåœºæ™¯ï¼Œå»ºè®®æ‰©å¤§æ•°æ®æ—¶é—´èŒƒå›´ä»¥è¦†ç›–æ›´å¤šåœºæ™¯ã€‚")
                        
                        col_scene1, col_scene2 = st.columns([2, 1])
                        
                        with col_scene1:
                            fig = px.pie(dist_df, values='è®¢å•æ•°', names='åœºæ™¯', title='åœºæ™¯åˆ†å¸ƒ')
                            st.plotly_chart(fig, use_container_width=True)
                        
                        with col_scene2:
                            st.dataframe(dist_df, use_container_width=True, hide_index=True)
                            
                            # æ˜¾ç¤ºåœºæ™¯å®šä¹‰å‚è€ƒ
                            with st.expander("ğŸ“– åœºæ™¯æ—¶æ®µå®šä¹‰"):
                                st.markdown("""
                                - **æ—©é¤åˆšéœ€**ï¼š6-8ç‚¹
                                - **æ—¥å¸¸è¡¥ç»™**ï¼š9-11ç‚¹ã€14-17ç‚¹
                                - **æ­£é¤é«˜å³°**ï¼š12-13ç‚¹ã€18-20ç‚¹
                                - **ä¼‘é—²å¨±ä¹**ï¼š21-23ç‚¹
                                - **æ·±å¤œåº”æ€¥**ï¼š0-5ç‚¹
                                
                                ğŸ’¡ å¦‚æœæ‚¨çš„æ•°æ®åªè¦†ç›–æŸä¸ªæ—¶æ®µï¼Œåœºæ™¯è¯†åˆ«ä¼šç›¸åº”å—é™ã€‚
                                """)
                
                with tab2:
                    st.markdown("#### ğŸ¯ è®¢å•åœºæ™¯é¢„æµ‹")
                    
                    try:
                        # é¢„æµ‹åœºæ™¯ - ä½¿ç”¨å…¨éƒ¨æ•°æ®è¿›è¡Œé¢„æµ‹
                        predictions = scene_model.predict_scene(df)
                        
                        # åœºæ™¯é¢„æµ‹ç»Ÿè®¡
                        pred_dist = predictions['predicted_scene'].value_counts()
                        
                        col1, col2 = st.columns([2, 1])
                        
                        with col1:
                            fig = px.bar(
                                x=pred_dist.values,
                                y=pred_dist.index,
                                orientation='h',
                                title='é¢„æµ‹åœºæ™¯åˆ†å¸ƒ',
                                labels={'x': 'è®¢å•æ•°', 'y': 'åœºæ™¯'},
                                color=pred_dist.values,
                                color_continuous_scale='Viridis'
                            )
                            fig.update_layout(showlegend=False, height=400)
                            st.plotly_chart(fig, use_container_width=True)
                        
                        with col2:
                            st.write("**ğŸ“Š åœºæ™¯é¢„æµ‹ç»Ÿè®¡**")
                            for scene, count in pred_dist.items():
                                pct = count / len(predictions) * 100
                                st.metric(scene, f"{count:,}å•", delta=f"{pct:.1f}%")
                        
                        # æ˜¾ç¤ºé¢„æµ‹æ ·ä¾‹
                        st.markdown("**ğŸ” é¢„æµ‹ç»“æœæ ·ä¾‹ï¼ˆå‰10æ¡ï¼‰**")
                        sample_pred = predictions.head(10)
                        
                        # æ˜¾ç¤ºæ¦‚ç‡æœ€é«˜çš„åœºæ™¯åŠå…¶æ¦‚ç‡
                        prob_cols = [col for col in sample_pred.columns if col.startswith('prob_')]
                        if prob_cols:
                            display_cols = ['è®¢å•ID', 'predicted_scene'] + prob_cols
                            st.dataframe(sample_pred[display_cols], use_container_width=True, hide_index=True)
                        
                    except Exception as e:
                        st.error(f"âŒ é¢„æµ‹å¤±è´¥: {str(e)}")
                
                with tab3:
                    st.markdown("#### ğŸ“ˆ ç‰¹å¾é‡è¦æ€§åˆ†æ")
                    
                    importance_fig = scene_model.visualize_feature_importance()
                    st.plotly_chart(importance_fig, use_container_width=True)
                    
                    st.markdown("""
                    **ç‰¹å¾è¯´æ˜ï¼š**
                    - **hour**: ä¸‹å•å°æ—¶ï¼ˆ0-23ï¼‰
                    - **weekday**: æ˜ŸæœŸå‡ ï¼ˆ0=å‘¨ä¸€ï¼Œ6=å‘¨æ—¥ï¼‰
                    - **é…é€è·ç¦»**: ç”¨æˆ·è·ç¦»é—¨åº—çš„è·ç¦»
                    - **è®¢å•é‡‘é¢**: è®¢å•æ€»é‡‘é¢
                    - **å¹³å‡å•ä»·**: å•†å“å¹³å‡å•ä»·
                    - **å•†å“æ•°**: è®¢å•ä¸­çš„å•†å“ä»¶æ•°
                    - **delivery_fee_ratio**: é…é€è´¹å è®¢å•é‡‘é¢çš„æ¯”ä¾‹
                    """)
    else:
        st.warning("âš ï¸ åœºæ™¯è¥é”€æ™ºèƒ½å†³ç­–å¼•æ“æœªåŠ è½½ï¼Œè¯·ç¡®ä¿å·²å®‰è£…xgboostæˆ–scikit-learn")
    
    st.markdown("---")
    
    # ä¼˜åŒ–åçš„è¥é”€å»ºè®®
    st.markdown("""
    <div class="warning-box">
    <b>ğŸ¯ ç²¾å‡†æ—¶æ®µè¥é”€ç­–ç•¥ï¼š</b><br>
    <br>
    <b>ğŸ“ˆ é«˜å³°æ—¶æ®µç­–ç•¥ï¼š</b><br>
    â€¢ <b>åˆé«˜å³°(11-12ç‚¹)</b>ï¼šæå‰æ¨é€åˆé¤å¥—é¤ï¼Œæ»¡å‡é—¨æ§›é€‚å½“æé«˜ï¼Œä¿éšœé…é€æ•ˆç‡<br>
    â€¢ <b>æ™šé«˜å³°å‰(17-18ç‚¹)</b>ï¼šæ¨é€"æå‰è®¢æ™šé¤"ä¼˜æƒ ï¼Œç¼“è§£18ç‚¹åå‹åŠ›<br>
    â€¢ <b>å‚æ™š(18-21ç‚¹)</b>ï¼šä¸»åŠ›æ—¶æ®µï¼Œå‡å°‘ä¿ƒé”€åŠ›åº¦ï¼Œé‡ç‚¹ä¿éšœæœåŠ¡è´¨é‡<br>
    <br>
    <b>ğŸ“‰ ä½è°·æ—¶æ®µç­–ç•¥ï¼š</b><br>
    â€¢ <b>æ¸…æ™¨(6-8ç‚¹)</b>ï¼šæ¨å‡º"æ—©é¤ä¸“äº«"æŠ˜æ‰£ï¼ŒåŸ¹å…»æ—©é¤å¤–å–ä¹ æƒ¯<br>
    â€¢ <b>ä¸Šåˆ(9-11ç‚¹)</b>ï¼šæ¨é€"ä¸ŠåˆèŒ¶æ­‡"å¥—é¤ï¼Œæ—¥ç”¨å“ç±»æ»¡å‡åˆ¸<br>
    â€¢ <b>ä¸‹åˆ(14-17ç‚¹)</b>ï¼šä¸‹åˆèŒ¶æ—¶æ®µï¼Œæ¨å‡º"ç¬¬äºŒä»¶åŠä»·"ã€ç”œå“é¥®å“ç»„åˆ<br>
    <br>
    <b>ğŸŒ™ ç‰¹æ®Šæ—¶æ®µç­–ç•¥ï¼š</b><br>
    â€¢ <b>æ™šé—´(21-24ç‚¹)</b>ï¼šå¤œå®µå“ç±»ä¸“é¡¹ä¿ƒé”€ï¼Œçƒ§çƒ¤ã€å°åƒã€å®µå¤œå¥—é¤<br>
    â€¢ <b>æ·±å¤œ(0-3ç‚¹)</b>ï¼šåº”æ€¥åœºæ™¯ï¼Œæä¾›"æ·±å¤œæš–å¿ƒ"æœåŠ¡ï¼Œé€‚å½“åŠ æ”¶é…é€è´¹<br>
    â€¢ <b>å‡Œæ™¨(3-6ç‚¹)</b>ï¼šæå°‘è®¢å•ï¼Œå¯æš‚åœé…é€æˆ–ä»…ä¿ç•™ä¾¿åˆ©åº—åˆä½œ<br>
    <br>
    <b>â° åŠ¨æ€æ¨é€ç­–ç•¥ï¼š</b><br>
    â€¢ æå‰30åˆ†é’Ÿæ¨é€ä¸‹ä¸€æ—¶æ®µä¼˜æƒ åˆ¸ï¼ˆå¦‚10:30æ¨é€åˆé¤åˆ¸ï¼‰<br>
    â€¢ é«˜å³°æ—¶æ®µå‰1å°æ—¶æ¨é€"é”™å³°ä¼˜æƒ "ï¼ˆå¦‚10ç‚¹æ¨é€11ç‚¹å‰ä¸‹å•ç«‹å‡ï¼‰<br>
    â€¢ ç»“åˆå¤©æ°”ã€èŠ‚å‡æ—¥è°ƒæ•´æ—¶æ®µç­–ç•¥ï¼ˆé›¨å¤©å¢åŠ é…é€è´¹å‡å…ï¼‰
    </div>
    """, unsafe_allow_html=True)


def render_location_marketing(df: pd.DataFrame, time_dimension: str = 'æ—¥', selected_period: str = None):
    """é—¨åº—å•†åœˆåœºæ™¯è¥é”€ï¼ˆæ”¯æŒæ—¥/å‘¨/æœˆç»´åº¦ï¼‰"""
    st.markdown('<p class="sub-header">ğŸª é—¨åº—å•†åœˆåœºæ™¯åˆ†æ</p>', unsafe_allow_html=True)
    
    # ==================== åœºæ™¯è¥é”€ç†å¿µè¯´æ˜ ====================
    with st.expander("ğŸ’¡ å•†åœˆåœºæ™¯çš„ç«äº‰æœ¬è´¨ï¼šé€Ÿåº¦ä¸ºç‹", expanded=False):
        st.markdown("""
        ### âš¡ é…é€é€Ÿåº¦ = æ ¸å¿ƒç«äº‰åŠ›
        
        #### ä¸ºä»€ä¹ˆé€Ÿåº¦è¿™ä¹ˆé‡è¦ï¼Ÿ
        1. **å³æ—¶éœ€æ±‚**ï¼šå¿˜è®°ä¹°çº¸å·¾ã€æ€¥éœ€é€€çƒ§è¯ã€ä¸´æ—¶æ¥å®¢äºº â†’ 15åˆ†é’Ÿå†…é€è¾¾
        2. **ç”Ÿé²œå“è´¨**ï¼šå†°æ·‡æ·‹ã€çƒ­é£Ÿã€å†·é“¾ â†’ è¶Šå¿«è¶Šæ–°é²œ
        3. **ç”¨æˆ·ä½“éªŒ**ï¼šç­‰å¾…æ—¶é—´æ¯å¢åŠ 5åˆ†é’Ÿï¼Œå¤è´­ç‡ä¸‹é™10%
        4. **ç«äº‰å£å’**ï¼šç¾å›¢ã€é¥¿äº†ä¹ˆã€ç›’é©¬ã€å®å’šä¹°èœéƒ½åœ¨æ‹¼é€Ÿåº¦
        
        #### å¦‚ä½•åšåˆ°æ¯”ç«å¯¹æ›´å¿«ï¼Ÿ
        
        **1. å‰ç½®ä»“å¸ƒå±€ç­–ç•¥**
        - ğŸ¯ **1å…¬é‡Œæ ¸å¿ƒåœˆ**ï¼šè®¢å•å¯†åº¦æœ€é«˜ï¼Œå¿…é¡»15åˆ†é’Ÿè¾¾
        - ğŸƒ **2-3å…¬é‡Œä¸»åŠ›åœˆ**ï¼š30åˆ†é’Ÿè¾¾ï¼Œè¦†ç›–å¤§éƒ¨åˆ†ç”¨æˆ·
        - ğŸš´ **3-5å…¬é‡Œè¾¹ç¼˜åœˆ**ï¼š45åˆ†é’Ÿè¾¾ï¼Œè°¨æ…æ‹“å±•
        - âŒ **5å…¬é‡Œä»¥å¤–**ï¼šå»ºè®®æš‚åœæˆ–é«˜é¢é…é€è´¹
        
        **2. é…é€è´¹æˆæœ¬ä¼˜åŒ–**
        - ğŸ’° **è·ç¦»æˆæœ¬åˆ†æ**ï¼šæ¯å…¬é‡Œå¢åŠ å¤šå°‘é…é€æˆæœ¬ï¼Ÿ
        - ğŸ **å·®å¼‚åŒ–å®šä»·**ï¼š1å…¬é‡Œå†…å…è´¹ï¼Œ3å…¬é‡Œå¤–é€’å¢
        - ğŸ“¦ **æ»¡å‡é—¨æ§›**ï¼šè¿œè·ç¦»æé«˜æ»¡å‡é‡‘é¢ï¼Œå¹³è¡¡æˆæœ¬
        
        **3. å•†åœˆåœºæ™¯åŒ–è¿è¥**
        - ğŸ¢ **åŠå…¬åŒºå•†åœˆ**ï¼šåˆé¤é«˜å³°ï¼Œå›¢è´­ä¼˜å…ˆ
        - ğŸ  **ä½å®…åŒºå•†åœˆ**ï¼šæ™šé¤å¤œå®µï¼Œå®¶åº­å¥—é¤
        - ğŸ« **å­¦æ ¡å•†åœˆ**ï¼šä¸‹åˆèŒ¶ã€å¤œå®µï¼Œå°ä»½ä¼˜æƒ 
        - ğŸ¥ **åŒ»é™¢å•†åœˆ**ï¼šåº”æ€¥åœºæ™¯ï¼Œé€Ÿåº¦ä¼˜å…ˆ
        
        ---
        
        **ğŸ“Š æœ¬çœ‹æ¿æä¾›çš„å†³ç­–ä¾æ®**ï¼š
        - é…é€è·ç¦»åˆ†å¸ƒ â†’ ç¡®å®šæ ¸å¿ƒæœåŠ¡åŠå¾„
        - é…é€è´¹æˆæœ¬åˆ†æ â†’ ä¼˜åŒ–å®šä»·ç­–ç•¥
        - è·ç¦»æ®µå®¢å•ä»· â†’ åˆ¶å®šå·®å¼‚åŒ–æ»¡å‡
        - é«˜ä»·å€¼å•†åœˆè¯†åˆ« â†’ é‡ç‚¹èµ„æºå€¾æ–œ
        """)
    
    if 'é…é€è·ç¦»' not in df.columns:
        st.warning("âš ï¸ æ•°æ®ä¸­ç¼ºå°‘é…é€è·ç¦»å­—æ®µï¼Œæ— æ³•è¿›è¡Œå•†åœˆåˆ†æ")
        return
    
    df = df.copy()
    df = extract_time_features(df)
    
    # æ˜ å°„ç»´åº¦åˆ°å­—æ®µå
    dim_mapping = {
        'æ—¥': 'æ—¥æœŸ_datetime',
        'å‘¨': 'å¹´å‘¨',
        'æœˆ': 'å¹´æœˆ'
    }
    time_col = dim_mapping[time_dimension]
    
    # å°†é…é€è·ç¦»è½¬æ¢ä¸ºå…¬é‡Œï¼ˆå¦‚æœå•ä½æ˜¯ç±³ï¼‰
    # åˆ¤æ–­ï¼šå¦‚æœå¹³å‡è·ç¦»>100ï¼Œåˆ™è®¤ä¸ºå•ä½æ˜¯ç±³ï¼Œéœ€è¦è½¬æ¢ä¸ºå…¬é‡Œ
    avg_distance = df['é…é€è·ç¦»'].mean()
    if avg_distance > 100:
        df['é…é€è·ç¦»_å…¬é‡Œ'] = df['é…é€è·ç¦»'] / 1000
        st.info("ğŸ“ æ£€æµ‹åˆ°é…é€è·ç¦»å•ä½ä¸ºç±³ï¼Œå·²è‡ªåŠ¨è½¬æ¢ä¸ºå…¬é‡Œ")
    else:
        df['é…é€è·ç¦»_å…¬é‡Œ'] = df['é…é€è·ç¦»']
    
    # è®¡ç®—é…é€è´¹æˆæœ¬ï¼ˆè®¢å•çº§ï¼‰
    # é…é€æˆæœ¬ = ç”¨æˆ·æ”¯ä»˜é…é€è´¹ - é…é€è´¹å‡å…é‡‘é¢ - ç‰©æµé…é€è´¹
    if 'ç”¨æˆ·æ”¯ä»˜é…é€è´¹' in df.columns and 'é…é€è´¹å‡å…é‡‘é¢' in df.columns and 'ç‰©æµé…é€è´¹' in df.columns:
        df['é…é€è´¹æˆæœ¬'] = (
            df['ç”¨æˆ·æ”¯ä»˜é…é€è´¹'].fillna(0) - 
            df['é…é€è´¹å‡å…é‡‘é¢'].fillna(0) - 
            df['ç‰©æµé…é€è´¹'].fillna(0)
        )
    elif 'ç‰©æµé…é€è´¹' in df.columns:
        # å¦‚æœç¼ºå°‘æŸäº›å­—æ®µï¼Œç®€åŒ–è®¡ç®—
        df['é…é€è´¹æˆæœ¬'] = -df['ç‰©æµé…é€è´¹'].fillna(0)
        st.info("âš ï¸ éƒ¨åˆ†é…é€è´¹å­—æ®µç¼ºå¤±ï¼Œé…é€æˆæœ¬ä»…åŸºäºç‰©æµé…é€è´¹è®¡ç®—")
    else:
        df['é…é€è´¹æˆæœ¬'] = 0
        st.warning("âš ï¸ ç¼ºå°‘é…é€è´¹ç›¸å…³å­—æ®µï¼Œé…é€æˆæœ¬æ— æ³•è®¡ç®—")
    
    # ==================== æ ¸å¿ƒæŒ‡æ ‡æ€»è§ˆï¼ˆå¸¦ç¯æ¯”ï¼‰ ====================
    st.markdown(f"### ğŸ“ˆ æ ¸å¿ƒæŒ‡æ ‡æ€»è§ˆï¼ˆæŒ‰{time_dimension}ï¼‰")
    
    if time_col in df.columns and 'è®¢å•ID' in df.columns:
        try:
            # å¤„ç†é‡å¤åˆ—å
            temp_df = df.copy()
            if isinstance(temp_df['è®¢å•ID'], pd.DataFrame):
                temp_df['è®¢å•ID'] = temp_df['è®¢å•ID'].iloc[:, 0]
            if isinstance(temp_df['é…é€è·ç¦»_å…¬é‡Œ'], pd.DataFrame):
                temp_df['é…é€è·ç¦»_å…¬é‡Œ'] = temp_df['é…é€è·ç¦»_å…¬é‡Œ'].iloc[:, 0]
            
            # æŒ‰è®¢å•çº§èšåˆï¼ˆé¿å…æ˜ç»†çº§é‡å¤è®¡ç®—ï¼‰
            agg_config = {
                'é…é€è·ç¦»_å…¬é‡Œ': 'first',
                'æ”¶è´§åœ°å€': 'first',
                'é…é€è´¹æˆæœ¬': 'first'
            }
            
            # åŠ¨æ€æ·»åŠ å¯é€‰å­—æ®µ
            for col in ['ç‰©æµé…é€è´¹', 'ç”¨æˆ·æ”¯ä»˜é…é€è´¹', 'é…é€è´¹å‡å…é‡‘é¢']:
                if col in temp_df.columns:
                    if isinstance(temp_df[col], pd.DataFrame):
                        temp_df[col] = temp_df[col].iloc[:, 0]
                    agg_config[col] = 'first'
            
            order_summary = temp_df.groupby(['è®¢å•ID', time_col]).agg(agg_config).reset_index()
        
            # æŒ‰æ—¶é—´ç»´åº¦èšåˆ
            agg_dict = {
                'è®¢å•ID': 'nunique',
                'é…é€è·ç¦»_å…¬é‡Œ': 'mean',
                'æ”¶è´§åœ°å€': 'nunique',
                'é…é€è´¹æˆæœ¬': 'sum'
            }
            
            if 'ç‰©æµé…é€è´¹' in order_summary.columns:
                agg_dict['ç‰©æµé…é€è´¹'] = 'sum'
            if 'ç”¨æˆ·æ”¯ä»˜é…é€è´¹' in order_summary.columns:
                agg_dict['ç”¨æˆ·æ”¯ä»˜é…é€è´¹'] = 'sum'
            if 'é…é€è´¹å‡å…é‡‘é¢' in order_summary.columns:
                agg_dict['é…é€è´¹å‡å…é‡‘é¢'] = 'sum'
            
            time_agg = order_summary.groupby(time_col).agg(agg_dict).reset_index()
            time_agg.columns = [time_col, 'è®¢å•æ•°', 'å¹³å‡é…é€è·ç¦»', 'è¦†ç›–åœ°å€æ•°', 'é…é€è´¹æˆæœ¬'] + \
                              (['ç‰©æµé…é€è´¹'] if 'ç‰©æµé…é€è´¹' in agg_dict else []) + \
                              (['ç”¨æˆ·æ”¯ä»˜é…é€è´¹'] if 'ç”¨æˆ·æ”¯ä»˜é…é€è´¹' in agg_dict else []) + \
                              (['é…é€è´¹å‡å…é‡‘é¢'] if 'é…é€è´¹å‡å…é‡‘é¢' in agg_dict else [])
            
            # è®¡ç®—å¹³å‡é…é€è´¹æˆæœ¬
            time_agg['å¹³å‡é…é€è´¹æˆæœ¬'] = time_agg['é…é€è´¹æˆæœ¬'] / time_agg['è®¢å•æ•°']
        except Exception as e:
            st.error(f"è®¡ç®—æ ¸å¿ƒæŒ‡æ ‡æ—¶å‡ºé”™: {str(e)}")
            time_agg = None
    else:
        time_agg = None
    
    if time_agg is not None:
        time_agg = calculate_period_over_period(time_agg, time_dimension, 'è®¢å•æ•°')
        time_agg = calculate_period_over_period(time_agg, time_dimension, 'å¹³å‡é…é€è·ç¦»')
        time_agg = calculate_period_over_period(time_agg, time_dimension, 'è¦†ç›–åœ°å€æ•°')
        time_agg = calculate_period_over_period(time_agg, time_dimension, 'é…é€è´¹æˆæœ¬')
        time_agg = calculate_period_over_period(time_agg, time_dimension, 'å¹³å‡é…é€è´¹æˆæœ¬')
        
        # è·å–å½“å‰æœŸå’Œä¸Šä¸€æœŸæ•°æ®ï¼ˆæ ¹æ®ç”¨æˆ·é€‰æ‹©æˆ–æœ€è¿‘ä¸€æœŸï¼‰
        if len(time_agg) >= 1:
            # å¦‚æœç”¨æˆ·é€‰æ‹©äº†å…·ä½“å‘¨æœŸï¼Œä½¿ç”¨é€‰æ‹©çš„å‘¨æœŸï¼›å¦åˆ™ä½¿ç”¨æœ€è¿‘ä¸€æœŸ
            if selected_period and not selected_period.startswith("å…¨éƒ¨"):
                if time_dimension == "æ—¥":
                    selected_date = pd.to_datetime(selected_period)
                    latest_idx = time_agg[time_agg[time_col] == selected_date].index
                else:
                    latest_idx = time_agg[time_agg[time_col] == selected_period].index
                
                if len(latest_idx) > 0:
                    latest = time_agg.loc[latest_idx[0]]
                    # è·å–ä¸Šä¸€æœŸæ•°æ®
                    current_position = latest_idx[0]
                    previous = time_agg.iloc[current_position - 1] if current_position > 0 else None
                else:
                    latest = time_agg.iloc[-1]
                    previous = time_agg.iloc[-2] if len(time_agg) >= 2 else None
            else:
                # æœªé€‰æ‹©å…·ä½“å‘¨æœŸï¼Œä½¿ç”¨æœ€è¿‘ä¸€æœŸ
                latest = time_agg.iloc[-1]
                previous = time_agg.iloc[-2] if len(time_agg) >= 2 else None
            
            # ç¬¬ä¸€è¡ŒæŒ‡æ ‡å¡ç‰‡
            col1, col2, col3, col4 = st.columns(4)
            
            # å½“å‰å‘¨æœŸ
            with col1:
                period_label = format_period_label(latest[time_col], time_dimension)
                st.metric(label=f"å½“å‰{time_dimension}", value=period_label)
            
            # è®¢å•æ•°ï¼ˆå¸¦ç¯æ¯”ï¼‰
            render_metric_with_comparison(
                col2, f"è®¢å•æ•°",
                latest['è®¢å•æ•°'],
                previous['è®¢å•æ•°'] if previous is not None else None,
                format_type='number', unit='å•'
            )
            
            # å¹³å‡é…é€è·ç¦»ï¼ˆå¸¦ç¯æ¯”ï¼‰
            with col3:
                current_dist = latest['å¹³å‡é…é€è·ç¦»']
                previous_dist = previous['å¹³å‡é…é€è·ç¦»'] if previous is not None else None
                
                if previous_dist is not None and not pd.isna(previous_dist) and previous_dist != 0:
                    change_rate = ((current_dist - previous_dist) / previous_dist * 100)
                    st.metric(
                        label="å¹³å‡é…é€è·ç¦»",
                        value=f"{current_dist:.2f}å…¬é‡Œ",
                        delta=f"{change_rate:+.2f}%",
                        delta_color="inverse"  # è·ç¦»å¢åŠ æ˜¾ç¤ºä¸ºçº¢è‰²ï¼ˆä¸å¥½ï¼‰
                    )
                else:
                    st.metric(label="å¹³å‡é…é€è·ç¦»", value=f"{current_dist:.2f}å…¬é‡Œ")
            
            # è¦†ç›–åœ°å€æ•°ï¼ˆå¸¦ç¯æ¯”ï¼‰
            render_metric_with_comparison(
                col4, f"è¦†ç›–åœ°å€æ•°",
                latest['è¦†ç›–åœ°å€æ•°'],
                previous['è¦†ç›–åœ°å€æ•°'] if previous is not None else None,
                format_type='number', unit='ä¸ª'
            )
            
            # ç¬¬äºŒè¡Œï¼šé…é€è´¹æˆæœ¬åˆ†æ
            st.markdown("#### ğŸ’° é…é€è´¹æˆæœ¬åˆ†æ")
            col5, col6, col7, col8 = st.columns(4)
            
            # é…é€è´¹æˆæœ¬ï¼ˆå¸¦ç¯æ¯”ï¼‰
            with col5:
                current_cost = latest['é…é€è´¹æˆæœ¬']
                previous_cost = previous['é…é€è´¹æˆæœ¬'] if previous is not None else None
                
                if previous_cost is not None and not pd.isna(previous_cost) and previous_cost != 0:
                    change_rate = ((current_cost - previous_cost) / abs(previous_cost) * 100)
                    st.metric(
                        label="é…é€è´¹æˆæœ¬",
                        value=f"Â¥{current_cost:,.2f}",
                        delta=f"{change_rate:+.2f}%",
                        delta_color="inverse",  # æˆæœ¬å¢åŠ æ˜¾ç¤ºä¸ºçº¢è‰²
                        help="é…é€æˆæœ¬ = ç”¨æˆ·æ”¯ä»˜é…é€è´¹ - é…é€è´¹å‡å… - ç‰©æµé…é€è´¹"
                    )
                else:
                    st.metric(
                        label="é…é€è´¹æˆæœ¬",
                        value=f"Â¥{current_cost:,.2f}",
                        help="é…é€æˆæœ¬ = ç”¨æˆ·æ”¯ä»˜é…é€è´¹ - é…é€è´¹å‡å… - ç‰©æµé…é€è´¹"
                    )
            
            # å¹³å‡é…é€è´¹æˆæœ¬ï¼ˆå¸¦ç¯æ¯”ï¼‰
            with col6:
                current_avg_cost = latest['å¹³å‡é…é€è´¹æˆæœ¬']
                previous_avg_cost = previous['å¹³å‡é…é€è´¹æˆæœ¬'] if previous is not None else None
                
                if previous_avg_cost is not None and not pd.isna(previous_avg_cost) and previous_avg_cost != 0:
                    change_rate = ((current_avg_cost - previous_avg_cost) / abs(previous_avg_cost) * 100)
                    st.metric(
                        label="å•å‡é…é€æˆæœ¬",
                        value=f"Â¥{current_avg_cost:.2f}",
                        delta=f"{change_rate:+.2f}%",
                        delta_color="inverse",
                        help="é…é€è´¹æˆæœ¬ / è®¢å•æ•°"
                    )
                else:
                    st.metric(
                        label="å•å‡é…é€æˆæœ¬",
                        value=f"Â¥{current_avg_cost:.2f}",
                        help="é…é€è´¹æˆæœ¬ / è®¢å•æ•°"
                    )
            
            # ç‰©æµé…é€è´¹ï¼ˆå¦‚æœæœ‰ï¼‰
            if 'ç‰©æµé…é€è´¹' in latest.index:
                with col7:
                    current_logistics = latest['ç‰©æµé…é€è´¹']
                    previous_logistics = previous['ç‰©æµé…é€è´¹'] if previous is not None and 'ç‰©æµé…é€è´¹' in previous.index else None
                    
                    if previous_logistics is not None and not pd.isna(previous_logistics) and previous_logistics != 0:
                        change_rate = ((current_logistics - previous_logistics) / previous_logistics * 100)
                        st.metric(
                            label="ç‰©æµé…é€è´¹",
                            value=f"Â¥{current_logistics:,.2f}",
                            delta=f"{change_rate:+.2f}%",
                            delta_color="inverse",
                            help="æ”¯ä»˜ç»™é…é€å¹³å°çš„è´¹ç”¨"
                        )
                    else:
                        st.metric(
                            label="ç‰©æµé…é€è´¹",
                            value=f"Â¥{current_logistics:,.2f}",
                            help="æ”¯ä»˜ç»™é…é€å¹³å°çš„è´¹ç”¨"
                        )
            
            # é…é€è´¹å‡å…ï¼ˆå¦‚æœæœ‰ï¼‰
            if 'é…é€è´¹å‡å…é‡‘é¢' in latest.index:
                with col8:
                    current_discount = latest['é…é€è´¹å‡å…é‡‘é¢']
                    previous_discount = previous['é…é€è´¹å‡å…é‡‘é¢'] if previous is not None and 'é…é€è´¹å‡å…é‡‘é¢' in previous.index else None
                    
                    if previous_discount is not None and not pd.isna(previous_discount) and previous_discount != 0:
                        change_rate = ((current_discount - previous_discount) / previous_discount * 100)
                        st.metric(
                            label="é…é€è´¹å‡å…",
                            value=f"Â¥{current_discount:,.2f}",
                            delta=f"{change_rate:+.2f}%",
                            help="ç»™ç”¨æˆ·çš„é…é€è´¹ä¼˜æƒ ï¼ˆå·²åœ¨é…é€æˆæœ¬ä¸­æŠµæ‰£ï¼‰"
                        )
                    else:
                        st.metric(
                            label="é…é€è´¹å‡å…",
                            value=f"Â¥{current_discount:,.2f}",
                            help="ç»™ç”¨æˆ·çš„é…é€è´¹ä¼˜æƒ ï¼ˆå·²åœ¨é…é€æˆæœ¬ä¸­æŠµæ‰£ï¼‰"
                        )
        
        st.markdown("---")
        
        # ==================== è¶‹åŠ¿å›¾ ====================
        st.markdown(f"### ğŸ“Š {time_dimension}åº¦è¶‹åŠ¿åˆ†æ")
        
        tab1, tab2, tab3, tab4 = st.tabs(["è®¢å•é‡è¶‹åŠ¿", "å¹³å‡é…é€è·ç¦»è¶‹åŠ¿", "è¦†ç›–åœ°å€æ•°è¶‹åŠ¿", "é…é€è´¹æˆæœ¬è¶‹åŠ¿"])
        
        with tab1:
            fig = px.line(
                time_agg, 
                x=time_col, 
                y='è®¢å•æ•°',
                title=f'è®¢å•æ•°{time_dimension}åº¦è¶‹åŠ¿',
                markers=True
            )
            fig.update_traces(line=dict(color='#3498db', width=3))
            fig.update_layout(height=400)
            st.plotly_chart(fig, use_container_width=True)
        
        with tab2:
            fig = px.line(
                time_agg, 
                x=time_col, 
                y='å¹³å‡é…é€è·ç¦»',
                title=f'å¹³å‡é…é€è·ç¦»{time_dimension}åº¦è¶‹åŠ¿',
                markers=True
            )
            fig.update_traces(line=dict(color='#e67e22', width=3))
            fig.update_layout(height=400, yaxis_title='å¹³å‡é…é€è·ç¦»(å…¬é‡Œ)')
            st.plotly_chart(fig, use_container_width=True)
            
            # ç¯æ¯”å˜åŒ–è¡¨æ ¼
            if 'å¹³å‡é…é€è·ç¦»_ç¯æ¯”ç‡' in time_agg.columns:
                st.write("**ç¯æ¯”å˜åŒ–è¯¦æƒ…**")
                display_df = time_agg[[time_col, 'å¹³å‡é…é€è·ç¦»', 'å¹³å‡é…é€è·ç¦»_ä¸ŠæœŸå€¼', 'å¹³å‡é…é€è·ç¦»_ç¯æ¯”å˜åŒ–', 'å¹³å‡é…é€è·ç¦»_ç¯æ¯”ç‡']].tail(10)
                display_df.columns = ['æ—¶é—´å‘¨æœŸ', 'å½“å‰å¹³å‡è·ç¦»', 'ä¸ŠæœŸå¹³å‡è·ç¦»', 'ç¯æ¯”å˜åŒ–(km)', 'ç¯æ¯”å˜åŒ–ç‡(%)']
                st.dataframe(display_df.style.format({
                    'å½“å‰å¹³å‡è·ç¦»': '{:.2f}å…¬é‡Œ',
                    'ä¸ŠæœŸå¹³å‡è·ç¦»': '{:.2f}å…¬é‡Œ',
                    'ç¯æ¯”å˜åŒ–(km)': '{:+.2f}',
                    'ç¯æ¯”å˜åŒ–ç‡(%)': '{:+.2f}%'
                }), use_container_width=True)
        
        with tab3:
            fig = px.line(
                time_agg, 
                x=time_col, 
                y='è¦†ç›–åœ°å€æ•°',
                title=f'è¦†ç›–åœ°å€æ•°{time_dimension}åº¦è¶‹åŠ¿',
                markers=True
            )
            fig.update_traces(line=dict(color='#27ae60', width=3))
            fig.update_layout(height=400)
            st.plotly_chart(fig, use_container_width=True)
        
        with tab4:
            # é…é€è´¹æˆæœ¬è¶‹åŠ¿å›¾
            fig = px.line(
                time_agg, 
                x=time_col, 
                y='é…é€è´¹æˆæœ¬',
                title=f'é…é€è´¹æˆæœ¬{time_dimension}åº¦è¶‹åŠ¿',
                markers=True
            )
            fig.update_traces(line=dict(color='#e74c3c', width=3))
            fig.update_layout(height=400, yaxis_title='é…é€è´¹æˆæœ¬(å…ƒ)')
            st.plotly_chart(fig, use_container_width=True)
            
            # å¹³å‡é…é€è´¹æˆæœ¬è¶‹åŠ¿å›¾
            fig2 = px.line(
                time_agg, 
                x=time_col, 
                y='å¹³å‡é…é€è´¹æˆæœ¬',
                title=f'å•å‡é…é€æˆæœ¬{time_dimension}åº¦è¶‹åŠ¿',
                markers=True
            )
            fig2.update_traces(line=dict(color='#9b59b6', width=3))
            fig2.update_layout(height=400, yaxis_title='å•å‡é…é€æˆæœ¬(å…ƒ)')
            st.plotly_chart(fig2, use_container_width=True)
            
            # ç¯æ¯”å˜åŒ–è¡¨æ ¼
            if 'é…é€è´¹æˆæœ¬_ç¯æ¯”ç‡' in time_agg.columns:
                st.write("**é…é€è´¹æˆæœ¬ç¯æ¯”è¯¦æƒ…**")
                display_df = time_agg[[time_col, 'é…é€è´¹æˆæœ¬', 'é…é€è´¹æˆæœ¬_ä¸ŠæœŸå€¼', 'é…é€è´¹æˆæœ¬_ç¯æ¯”å˜åŒ–', 'é…é€è´¹æˆæœ¬_ç¯æ¯”ç‡']].tail(10)
                display_df.columns = ['æ—¶é—´å‘¨æœŸ', 'å½“å‰æˆæœ¬', 'ä¸ŠæœŸæˆæœ¬', 'ç¯æ¯”å˜åŒ–(å…ƒ)', 'ç¯æ¯”å˜åŒ–ç‡(%)']
                st.dataframe(display_df.style.format({
                    'å½“å‰æˆæœ¬': 'Â¥{:,.2f}',
                    'ä¸ŠæœŸæˆæœ¬': 'Â¥{:,.2f}',
                    'ç¯æ¯”å˜åŒ–(å…ƒ)': 'Â¥{:+,.2f}',
                    'ç¯æ¯”å˜åŒ–ç‡(%)': '{:+.2f}%'
                }), use_container_width=True)
            
            # é…é€è´¹æˆæœ¬æ„æˆåˆ†æï¼ˆå¦‚æœæœ‰è¯¦ç»†å­—æ®µï¼‰
            if all(col in time_agg.columns for col in ['ç‰©æµé…é€è´¹', 'ç”¨æˆ·æ”¯ä»˜é…é€è´¹', 'é…é€è´¹å‡å…é‡‘é¢']):
                st.write("**é…é€è´¹æˆæœ¬æ„æˆåˆ†æï¼ˆæœ€è¿‘ä¸€æœŸï¼‰**")
                latest_data = time_agg.iloc[-1]
                
                col_a, col_b, col_c = st.columns(3)
                with col_a:
                    st.metric("ç‰©æµé…é€è´¹æ”¯å‡º", f"Â¥{latest_data['ç‰©æµé…é€è´¹']:,.2f}", help="æ”¯ä»˜ç»™é…é€å¹³å°")
                with col_b:
                    st.metric("ç”¨æˆ·æ”¯ä»˜é…é€è´¹", f"Â¥{latest_data['ç”¨æˆ·æ”¯ä»˜é…é€è´¹']:,.2f}", help="ç”¨æˆ·æ‰¿æ‹…éƒ¨åˆ†")
                with col_c:
                    st.metric("é…é€è´¹å‡å…", f"Â¥{latest_data['é…é€è´¹å‡å…é‡‘é¢']:,.2f}", help="ä¼˜æƒ ç»™ç”¨æˆ·")
                
                st.markdown(f"""
                <div class="insight-box">
                <b>ğŸ’¡ é…é€è´¹æˆæœ¬è®¡ç®—å…¬å¼ï¼š</b><br>
                é…é€è´¹æˆæœ¬ = ç”¨æˆ·æ”¯ä»˜(Â¥{latest_data['ç”¨æˆ·æ”¯ä»˜é…é€è´¹']:,.2f}) - 
                é…é€è´¹å‡å…(Â¥{latest_data['é…é€è´¹å‡å…é‡‘é¢']:,.2f}) - 
                ç‰©æµé…é€è´¹(Â¥{latest_data['ç‰©æµé…é€è´¹']:,.2f}) = 
                <b>Â¥{latest_data['é…é€è´¹æˆæœ¬']:,.2f}</b>
                </div>
                """, unsafe_allow_html=True)
    
    st.markdown("---")
    
    # ==================== é…é€è·ç¦»åˆ†å¸ƒï¼ˆæ ¹æ®é€‰å®šçš„æ—¶é—´ç»´åº¦ç­›é€‰æœ€è¿‘ä¸€æœŸï¼‰ ====================
    st.markdown(f"### ğŸ“ é…é€è·ç¦»åˆ†å¸ƒåˆ†æï¼ˆå½“å‰{time_dimension}æ•°æ®ï¼‰")
    
    # ç­›é€‰æœ€è¿‘ä¸€ä¸ªå‘¨æœŸçš„æ•°æ®
    filtered_df = filter_data_by_time_dimension(df, time_dimension, selected_period, latest_only=True)
    
    if len(filtered_df) == 0:
        st.warning(f"âš ï¸ å½“å‰{time_dimension}æš‚æ— æ•°æ®")
        return
    
    # æ˜¾ç¤ºå½“å‰åˆ†æçš„æ—¶é—´èŒƒå›´
    if time_col in filtered_df.columns:
        current_period = filtered_df[time_col].iloc[0]
        period_label = format_period_label(current_period, time_dimension)
        st.info(f"ğŸ“… å½“å‰åˆ†ææ—¶é—´ï¼š{period_label}")
    
    def get_distance_range(distance_km):
        if pd.isna(distance_km):
            return 'æœªçŸ¥'
        elif distance_km < 1:
            return '1å…¬é‡Œä»¥ä¸‹'
        elif distance_km < 2:
            return '1-2å…¬é‡Œ'
        elif distance_km < 3:
            return '2-3å…¬é‡Œ'
        elif distance_km < 4:
            return '3-4å…¬é‡Œ'
        elif distance_km < 5:
            return '4-5å…¬é‡Œ'
        else:
            return '5å…¬é‡Œä»¥ä¸Š'
    
    filtered_df['è·ç¦»åˆ†å±‚'] = filtered_df['é…é€è·ç¦»_å…¬é‡Œ'].apply(get_distance_range)
    distance_order = ['1å…¬é‡Œä»¥ä¸‹', '1-2å…¬é‡Œ', '2-3å…¬é‡Œ', '3-4å…¬é‡Œ', '4-5å…¬é‡Œ', '5å…¬é‡Œä»¥ä¸Š', 'æœªçŸ¥']
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.write("**ğŸ“ é…é€è·ç¦»åˆ†å¸ƒ**")
        distance_orders = filtered_df.groupby('è·ç¦»åˆ†å±‚')['è®¢å•ID'].nunique()
        distance_orders = distance_orders.reindex(distance_order, fill_value=0)
        
        # æ’é™¤"æœªçŸ¥"ç±»åˆ«ç”¨äºå›¾è¡¨æ˜¾ç¤º
        distance_orders_valid = distance_orders[distance_orders.index != 'æœªçŸ¥']
        
        fig = px.pie(
            values=distance_orders_valid.values,
            names=distance_orders_valid.index,
            title=f'è®¢å•é…é€è·ç¦»åˆ†å¸ƒï¼ˆ{period_label}ï¼‰',
            hole=0.4
        )
        fig.update_traces(textposition='inside', textinfo='percent+label')
        st.plotly_chart(fig, use_container_width=True)
        
        # è®¡ç®—æ€»è®¢å•æ•°ï¼ˆæ’é™¤æœªçŸ¥ï¼‰
        total_orders_valid = distance_orders_valid.sum()
        total_orders = filtered_df['è®¢å•ID'].nunique()
        unknown_count = distance_orders.get('æœªçŸ¥', 0)
        
        if unknown_count > 0:
            st.caption(f"â„¹ï¸ æœ‰ {unknown_count} å•è®¢å•ç¼ºå°‘é…é€è·ç¦»æ•°æ®ï¼ˆå·²ä»å›¾è¡¨ä¸­æ’é™¤ï¼‰")
        
        main_ratio = (distance_orders['1å…¬é‡Œä»¥ä¸‹'] + distance_orders['1-2å…¬é‡Œ'] + distance_orders['2-3å…¬é‡Œ'])/total_orders_valid*100
        
        st.markdown(f"""
        <div class="insight-box">
        <b>ğŸ’¡ å…³é”®æ´å¯Ÿï¼š</b><br>
        â€¢ ä¸»è¦æœåŠ¡åŠå¾„ï¼š<b>3å…¬é‡Œä»¥å†…</b>å æ¯”{main_ratio:.1f}%<br>
        â€¢ 1å…¬é‡Œä»¥ä¸‹ï¼š<b>{distance_orders['1å…¬é‡Œä»¥ä¸‹']}</b>å•ï¼ˆæ ¸å¿ƒåŒºåŸŸï¼‰<br>
        â€¢ 1-2å…¬é‡Œï¼š<b>{distance_orders['1-2å…¬é‡Œ']}</b>å•ï¼ˆä¸»åŠ›åŒºåŸŸï¼‰<br>
        â€¢ å»ºè®®ï¼š3kmå†…åŒºåŸŸä¸ºæ ¸å¿ƒå•†åœˆï¼Œé‡ç‚¹å¸ƒå±€
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        st.write("**ğŸ’° è·ç¦»æ®µå®¢å•ä»·å¯¹æ¯”**")
        try:
            # å¤„ç†é‡å¤åˆ—å
            temp_df = filtered_df.copy()
            if isinstance(temp_df['è®¢å•ID'], pd.DataFrame):
                temp_df['è®¢å•ID'] = temp_df['è®¢å•ID'].iloc[:, 0]
            if isinstance(temp_df['å•†å“å®å”®ä»·'], pd.DataFrame):
                temp_df['å•†å“å®å”®ä»·'] = temp_df['å•†å“å®å”®ä»·'].iloc[:, 0]
            
            distance_price = temp_df.groupby(['è·ç¦»åˆ†å±‚', 'è®¢å•ID'])['å•†å“å®å”®ä»·'].sum().groupby('è·ç¦»åˆ†å±‚').mean()
            distance_price = distance_price.reindex(distance_order, fill_value=0)
            
            # æ’é™¤"æœªçŸ¥"ç±»åˆ«ç”¨äºå›¾è¡¨æ˜¾ç¤º
            distance_price_valid = distance_price[distance_price.index != 'æœªçŸ¥']
            
            fig = px.bar(
                x=distance_price_valid.index,
                y=distance_price_valid.values,
                labels={'x': 'é…é€è·ç¦»', 'y': 'å¹³å‡å®¢å•ä»·(å…ƒ)'},
                title=f'å„è·ç¦»æ®µå¹³å‡å®¢å•ä»·ï¼ˆ{period_label}ï¼‰',
                color=distance_price_valid.values,
                color_continuous_scale='Greens'
            )
            fig.update_layout(showlegend=False)
            st.plotly_chart(fig, use_container_width=True)
        except Exception as e:
            st.error(f"è®¡ç®—è·ç¦»æ®µå®¢å•ä»·æ—¶å‡ºé”™: {str(e)}")
    
    # è®¡ç®—è·ç¦»æ®µçš„é…é€è´¹æˆæœ¬ï¼ˆæŒ‰è®¢å•çº§èšåˆï¼‰
    if 'é…é€è´¹æˆæœ¬' in filtered_df.columns:
        try:
            # å¤„ç†é‡å¤åˆ—å
            temp_df = filtered_df.copy()
            if isinstance(temp_df['è®¢å•ID'], pd.DataFrame):
                temp_df['è®¢å•ID'] = temp_df['è®¢å•ID'].iloc[:, 0]
            if isinstance(temp_df['é…é€è´¹æˆæœ¬'], pd.DataFrame):
                temp_df['é…é€è´¹æˆæœ¬'] = temp_df['é…é€è´¹æˆæœ¬'].iloc[:, 0]
            
            order_delivery_cost = temp_df.groupby(['è®¢å•ID', 'è·ç¦»åˆ†å±‚'])['é…é€è´¹æˆæœ¬'].first().groupby('è·ç¦»åˆ†å±‚').mean()
            order_delivery_cost = order_delivery_cost.reindex(distance_order, fill_value=0)
        
            st.write("**ğŸšš è·ç¦»æ®µé…é€è´¹æˆæœ¬åˆ†æ**")
            col_a, col_b = st.columns(2)
            
            with col_a:
                # é…é€è´¹æˆæœ¬æŒ‰è·ç¦»æ®µå¯¹æ¯”
                cost_valid = order_delivery_cost[order_delivery_cost.index != 'æœªçŸ¥']
                fig = px.bar(
                    x=cost_valid.index,
                    y=cost_valid.values,
                    labels={'x': 'é…é€è·ç¦»', 'y': 'å•å‡é…é€æˆæœ¬(å…ƒ)'},
                    title=f'å„è·ç¦»æ®µå•å‡é…é€è´¹æˆæœ¬ï¼ˆ{period_label}ï¼‰',
                    color=cost_valid.values,
                    color_continuous_scale='Reds'
                )
                fig.update_layout(showlegend=False)
                st.plotly_chart(fig, use_container_width=True)
            
            with col_b:
                # è·ç¦»ä¸æˆæœ¬å…³ç³»æ´å¯Ÿ
                max_cost_range = cost_valid.idxmax() if not cost_valid.empty else None
                min_cost_range = cost_valid.idxmin() if not cost_valid.empty else None
                
                st.markdown(f"""
                <div class="insight-box">
            <b>ğŸ’¡ é…é€è´¹æˆæœ¬æ´å¯Ÿï¼š</b><br>
            â€¢ æœ€é«˜æˆæœ¬è·ç¦»æ®µï¼š<b>{max_cost_range}</b>ï¼ˆÂ¥{cost_valid.get(max_cost_range, 0):.2f}/å•ï¼‰<br>
            â€¢ æœ€ä½æˆæœ¬è·ç¦»æ®µï¼š<b>{min_cost_range}</b>ï¼ˆÂ¥{cost_valid.get(min_cost_range, 0):.2f}/å•ï¼‰<br>
            â€¢ æˆæœ¬å·®å¼‚ï¼šÂ¥{abs(cost_valid.get(max_cost_range, 0) - cost_valid.get(min_cost_range, 0)):.2f}/å•<br>
            â€¢ å»ºè®®ï¼šä¼˜åŒ–è¿œè·ç¦»è®¢å•é…é€ç­–ç•¥ï¼Œé™ä½é…é€æˆæœ¬
            </div>
            """, unsafe_allow_html=True)
                
                # é…é€è´¹æˆæœ¬å å®¢å•ä»·æ¯”ä¾‹
                if len(distance_price_valid) > 0 and len(cost_valid) > 0:
                    st.write("**é…é€æˆæœ¬å å®¢å•ä»·æ¯”ä¾‹**")
                    for dist in cost_valid.index:
                        if dist in distance_price_valid.index:
                            price = distance_price_valid[dist]
                            cost = cost_valid[dist]
                            ratio = (abs(cost) / price * 100) if price > 0 else 0
                            st.progress(min(ratio/20, 1.0), text=f"{dist}: {ratio:.2f}%")
        except Exception as e:
            st.error(f"è®¡ç®—é…é€è´¹æˆæœ¬åˆ†ææ—¶å‡ºé”™: {str(e)}")
            order_delivery_cost = pd.Series(dtype=float)  # ç©ºSeriesä½œä¸ºåå¤‡
    else:
        # å¦‚æœæ²¡æœ‰é…é€è´¹æˆæœ¬åˆ—ï¼Œåˆå§‹åŒ–ä¸ºç©ºSeries
        order_delivery_cost = pd.Series(dtype=float)
    
    # æ·»åŠ è¯¦ç»†æ•°æ®è¡¨æ ¼
    st.write(f"**ğŸ“‹ é…é€è·ç¦»è¯¦ç»†æ•°æ®ï¼ˆ{period_label}ï¼‰**")
    distance_detail = []
    for dist_range in distance_order:
        if dist_range == 'æœªçŸ¥':
            continue
        count = distance_orders.get(dist_range, 0)
        ratio = (count / total_orders_valid * 100) if total_orders_valid > 0 else 0
        avg_price = distance_price.get(dist_range, 0)
        
        detail_row = {
            'è·ç¦»èŒƒå›´': dist_range,
            'è®¢å•æ•°': f'{count:,}',
            'å æ¯”': f'{ratio:.1f}%',
            'å¹³å‡å®¢å•ä»·': f'Â¥{avg_price:.2f}'
        }
        
        # å¦‚æœæœ‰é…é€è´¹æˆæœ¬æ•°æ®ï¼Œæ·»åŠ åˆ°è¡¨æ ¼
        if len(order_delivery_cost) > 0:
            avg_cost = order_delivery_cost.get(dist_range, 0)
            detail_row['å•å‡é…é€æˆæœ¬'] = f'Â¥{avg_cost:.2f}'
            cost_ratio = (abs(avg_cost) / avg_price * 100) if avg_price > 0 else 0
            detail_row['æˆæœ¬å æ¯”'] = f'{cost_ratio:.2f}%'
        
        distance_detail.append(detail_row)
    
    detail_df = pd.DataFrame(distance_detail)
    st.dataframe(detail_df, use_container_width=True, hide_index=True)
    
    st.markdown("""
    <div class="warning-box">
    <b>ğŸ¯ å•†åœˆè¥é”€å»ºè®®ï¼š</b><br>
    1. <b>1å…¬é‡Œä»¥ä¸‹ï¼ˆæ ¸å¿ƒåŒºï¼‰</b>ï¼šå¸¸å®¢åŒºåŸŸï¼Œæ¨VIPä¼šå‘˜ï¼Œæé«˜å¤è´­ç‡<br>
    2. <b>1-2å…¬é‡Œï¼ˆä¸»åŠ›åŒºï¼‰</b>ï¼šè®¢å•é‡æœ€å¤§ï¼Œè®¾ç½®"æ»¡Xå…é…é€è´¹"å¸å¼•è®¢å•<br>
    3. <b>2-3å…¬é‡Œï¼ˆæ¬¡ä¸»åŠ›åŒºï¼‰</b>ï¼šä»æœ‰æ½œåŠ›ï¼Œå¯é€‚å½“æé«˜æ»¡å‡é—¨æ§›<br>
    4. <b>3-5å…¬é‡Œï¼ˆè¾¹ç¼˜åŒºï¼‰</b>ï¼šæé«˜æœ€ä½æ¶ˆè´¹ï¼Œæˆ–ä¸ç¤¾åŒºå›¢è´­åˆä½œ<br>
    5. <b>5å…¬é‡Œä»¥ä¸Šï¼ˆè¿œè·ç¦»ï¼‰</b>ï¼šå»ºè®®æš‚åœé…é€æˆ–æ”¶å–é«˜é¢é…é€è´¹
    </div>
    """, unsafe_allow_html=True)


def render_price_sensitivity_marketing(df: pd.DataFrame, time_dimension: str = 'æ—¥', selected_period: str = None):
    """ä»·æ ¼æ•æ„Ÿåº¦è¥é”€ï¼ˆæ”¯æŒæ—¥/å‘¨/æœˆç»´åº¦ï¼‰"""
    st.markdown('<p class="sub-header">ğŸ’° ä»·æ ¼æ•æ„Ÿåº¦åœºæ™¯åˆ†æ</p>', unsafe_allow_html=True)
    
    # ==================== åœºæ™¯è¥é”€ç†å¿µè¯´æ˜ ====================
    with st.expander("ğŸ’¡ ä»·æ ¼åœºæ™¯ï¼šä¸åŒäººç¾¤çš„ä¸åŒéœ€æ±‚", expanded=False):
        st.markdown("""
        ### ğŸ¯ ä»·æ ¼æ•æ„Ÿåº¦çš„åœºæ™¯æœ¬è´¨
        
        #### è°åœ¨ä»€ä¹ˆåœºæ™¯ä¸‹å¯¹ä»·æ ¼æ•æ„Ÿï¼Ÿ
        
        **1. é«˜ä»·å€¼ç”¨æˆ·ï¼ˆä½ä»·æ ¼æ•æ„Ÿï¼‰**
        - **åœºæ™¯**ï¼šåº”æ€¥ã€å“è´¨éœ€æ±‚ã€æ—¶é—´ç´§è¿«
        - **ç‰¹å¾**ï¼šå®¢å•ä»·é«˜ã€å¤è´­ç‡é«˜ã€å¯¹ä¼˜æƒ ä¸æ•æ„Ÿ
        - **ç­–ç•¥**ï¼šä¼šå‘˜åˆ¶ã€å“è´¨ä¿éšœã€å¿«é€Ÿé…é€ã€ç§¯åˆ†æƒç›Š
        - **ä¸¾ä¾‹**ï¼šå·¥ä½œæ—¥åˆé¤ã€å©´å„¿ç”¨å“ã€è¿›å£é£Ÿå“
        
        **2. ä»·æ ¼æ•æ„Ÿç”¨æˆ·ï¼ˆé«˜ä»·æ ¼æ•æ„Ÿï¼‰**
        - **åœºæ™¯**ï¼šæ—¥å¸¸é‡‡è´­ã€æå‰è®¡åˆ’ã€éç´§æ€¥
        - **ç‰¹å¾**ï¼šå®¢å•ä»·ä½ã€æ¯”ä»·å¤šã€ä¼˜æƒ é©±åŠ¨
        - **ç­–ç•¥**ï¼šæ»¡å‡ã€å›¢è´­ã€ç§’æ€ã€ä¼˜æƒ åˆ¸
        - **ä¸¾ä¾‹**ï¼šå‘¨æœ«å›¤è´§ã€ç”Ÿé²œç‰¹ä»·ã€æ¸…ä»“ä¿ƒé”€
        
        **3. ä¸­é—´ç”¨æˆ·ï¼ˆå¹³è¡¡å‹ï¼‰**
        - **åœºæ™¯**ï¼šå¸¸è§„éœ€æ±‚ã€å“è´¨ä¸ä»·æ ¼å¹¶é‡
        - **ç‰¹å¾**ï¼šå®¢å•ä»·ä¸­ç­‰ã€ç¨³å®šå¤è´­
        - **ç­–ç•¥**ï¼šå¥—é¤ç»„åˆã€ä¼šå‘˜æŠ˜æ‰£ã€å“ç±»æ¨è
        - **ä¸¾ä¾‹**ï¼šå·¥ä½œæ—¥æ™šé¤ã€æ—¥ç”¨å“è¡¥è´§
        
        #### åœºæ™¯åŒ–å®šä»·ç­–ç•¥
        
        **æ—¶æ®µ Ã— ä»·æ ¼åœºæ™¯**
        - â° **é«˜å³°æ—¶æ®µ**ï¼ˆåˆé¤ã€æ™šé¤ï¼‰ï¼šå‡å°‘æŠ˜æ‰£ï¼Œä¿éšœæœåŠ¡
        - ğŸŒ™ **ä½è°·æ—¶æ®µ**ï¼ˆä¸Šåˆã€ä¸‹åˆèŒ¶ï¼‰ï¼šæ»¡å‡ã€ç¬¬äºŒä»¶åŠä»·
        - ğŸŒƒ **æ·±å¤œæ—¶æ®µ**ï¼šæº¢ä»·é…é€ï¼Œåº”æ€¥éœ€æ±‚ä¸æ•æ„Ÿ
        
        **è·ç¦» Ã— ä»·æ ¼åœºæ™¯**
        - ğŸ“ **è¿‘è·ç¦»**ï¼ˆ1kmå†…ï¼‰ï¼šå…é…é€è´¹ï¼ŒåŸ¹å…»é«˜é¢‘
        - ğŸš´ **ä¸­è·ç¦»**ï¼ˆ2-3kmï¼‰ï¼šé€‚åº¦æ»¡å‡ï¼Œå¹³è¡¡æˆæœ¬
        - ğŸš— **è¿œè·ç¦»**ï¼ˆ3km+ï¼‰ï¼šæé«˜é—¨æ§›ï¼Œè¦†ç›–æˆæœ¬
        
        **å“ç±» Ã— ä»·æ ¼åœºæ™¯**
        - ğŸ **ç”Ÿé²œå“ç±»**ï¼šå¼•æµå“ï¼Œä½æ¯›åˆ©é«˜é¢‘
        - ğŸº **é¥®æ–™é›¶é£Ÿ**ï¼šåˆ©æ¶¦å“ï¼Œæ­å”®ç»„åˆ
        - ğŸ  **æ—¥ç”¨ç™¾è´§**ï¼šç¨³å®šå“ï¼Œä¼šå‘˜ä¸“äº«
        
        ---
        
        **ğŸ’¼ æœ¬çœ‹æ¿çš„æ ¸å¿ƒä»·å€¼**ï¼š
        - è¯†åˆ«ä¸åŒä»·æ ¼æ®µçš„ç”¨æˆ·è¡Œä¸º
        - åˆ¶å®šå·®å¼‚åŒ–å®šä»·ç­–ç•¥
        - å¹³è¡¡é”€é‡ä¸åˆ©æ¶¦
        - æå‡æ•´ä½“å®¢å•ä»·
        """)
    
    df = extract_time_features(df)
    
    # æ˜ å°„ç»´åº¦åˆ°å­—æ®µå
    dim_mapping = {
        'æ—¥': 'æ—¥æœŸ_datetime',
        'å‘¨': 'å¹´å‘¨',
        'æœˆ': 'å¹´æœˆ'
    }
    time_col = dim_mapping[time_dimension]
    
    # ==================== æ ¸å¿ƒæŒ‡æ ‡æ€»è§ˆï¼ˆå¸¦ç¯æ¯”ï¼‰ ====================
    st.markdown(f"### ğŸ“ˆ æ ¸å¿ƒæŒ‡æ ‡æ€»è§ˆï¼ˆæŒ‰{time_dimension}ï¼‰")
    
    if time_col in df.columns and 'è®¢å•ID' in df.columns:
        try:
            # å¤„ç†é‡å¤åˆ—å
            temp_df = df.copy()
            if isinstance(temp_df['è®¢å•ID'], pd.DataFrame):
                temp_df['è®¢å•ID'] = temp_df['è®¢å•ID'].iloc[:, 0]
            if isinstance(temp_df['å•†å“å®å”®ä»·'], pd.DataFrame):
                temp_df['å•†å“å®å”®ä»·'] = temp_df['å•†å“å®å”®ä»·'].iloc[:, 0]
            
            # æŒ‰æ—¶é—´ç»´åº¦èšåˆè®¢å•çº§æ•°æ®
            order_level = temp_df.groupby(['è®¢å•ID', time_col]).agg({
                'å•†å“å®å”®ä»·': 'sum'
            }).reset_index()
            order_level.columns = ['è®¢å•ID', time_col, 'å®¢å•ä»·']
            
            # æŒ‰æ—¶é—´ç»´åº¦èšåˆ
            time_agg = order_level.groupby(time_col).agg({
                'è®¢å•ID': 'count',
                'å®¢å•ä»·': 'mean'
            }).reset_index()
            time_agg.columns = [time_col, 'è®¢å•æ•°', 'å¹³å‡å®¢å•ä»·']
        
            # è®¡ç®—ç¯æ¯”
            time_agg = calculate_period_over_period(time_agg, time_dimension, 'è®¢å•æ•°')
            time_agg = calculate_period_over_period(time_agg, time_dimension, 'å¹³å‡å®¢å•ä»·')
        except Exception as e:
            st.error(f"è®¡ç®—æ ¸å¿ƒæŒ‡æ ‡æ—¶å‡ºé”™: {str(e)}")
            time_agg = None
    else:
        time_agg = None
    
    if time_agg is not None:
        
        # è·å–å½“å‰æœŸå’Œä¸Šä¸€æœŸæ•°æ®ï¼ˆæ ¹æ®ç”¨æˆ·é€‰æ‹©æˆ–æœ€è¿‘ä¸€æœŸï¼‰
        if len(time_agg) >= 1:
            # å¦‚æœç”¨æˆ·é€‰æ‹©äº†å…·ä½“å‘¨æœŸï¼Œä½¿ç”¨é€‰æ‹©çš„å‘¨æœŸï¼›å¦åˆ™ä½¿ç”¨æœ€è¿‘ä¸€æœŸ
            if selected_period and not selected_period.startswith("å…¨éƒ¨"):
                if time_dimension == "æ—¥":
                    selected_date = pd.to_datetime(selected_period)
                    latest_idx = time_agg[time_agg[time_col] == selected_date].index
                else:
                    latest_idx = time_agg[time_agg[time_col] == selected_period].index
                
                if len(latest_idx) > 0:
                    latest = time_agg.loc[latest_idx[0]]
                    # è·å–ä¸Šä¸€æœŸæ•°æ®
                    current_position = latest_idx[0]
                    previous = time_agg.iloc[current_position - 1] if current_position > 0 else None
                else:
                    latest = time_agg.iloc[-1]
                    previous = time_agg.iloc[-2] if len(time_agg) >= 2 else None
            else:
                # æœªé€‰æ‹©å…·ä½“å‘¨æœŸï¼Œä½¿ç”¨æœ€è¿‘ä¸€æœŸ
                latest = time_agg.iloc[-1]
                previous = time_agg.iloc[-2] if len(time_agg) >= 2 else None
            
            col1, col2, col3 = st.columns(3)
            
            # å½“å‰å‘¨æœŸ
            with col1:
                period_label = format_period_label(latest[time_col], time_dimension)
                st.metric(label=f"å½“å‰{time_dimension}", value=period_label)
            
            # è®¢å•æ•°ï¼ˆå¸¦ç¯æ¯”ï¼‰
            render_metric_with_comparison(
                col2, f"è®¢å•æ•°",
                latest['è®¢å•æ•°'],
                previous['è®¢å•æ•°'] if previous is not None else None,
                format_type='number', unit='å•'
            )
            
            # å¹³å‡å®¢å•ä»·ï¼ˆå¸¦ç¯æ¯”ï¼‰
            render_metric_with_comparison(
                col3, f"å¹³å‡å®¢å•ä»·",
                latest['å¹³å‡å®¢å•ä»·'],
                previous['å¹³å‡å®¢å•ä»·'] if previous is not None else None,
                format_type='currency'
            )
        
        st.markdown("---")
        
        # ==================== è¶‹åŠ¿å›¾ ====================
        st.markdown(f"### ğŸ“Š {time_dimension}åº¦è¶‹åŠ¿åˆ†æ")
        
        tab1, tab2 = st.tabs(["å®¢å•ä»·è¶‹åŠ¿", "è®¢å•é‡è¶‹åŠ¿"])
        
        with tab1:
            fig = px.line(
                time_agg, 
                x=time_col, 
                y='å¹³å‡å®¢å•ä»·',
                title=f'å¹³å‡å®¢å•ä»·{time_dimension}åº¦è¶‹åŠ¿',
                markers=True
            )
            fig.update_traces(line=dict(color='#e74c3c', width=3))
            fig.update_layout(height=400)
            st.plotly_chart(fig, use_container_width=True)
            
            # ç¯æ¯”å˜åŒ–è¡¨æ ¼
            if 'å¹³å‡å®¢å•ä»·_ç¯æ¯”ç‡' in time_agg.columns:
                st.write("**ç¯æ¯”å˜åŒ–è¯¦æƒ…**")
                display_df = time_agg[[time_col, 'å¹³å‡å®¢å•ä»·', 'å¹³å‡å®¢å•ä»·_ä¸ŠæœŸå€¼', 'å¹³å‡å®¢å•ä»·_ç¯æ¯”å˜åŒ–', 'å¹³å‡å®¢å•ä»·_ç¯æ¯”ç‡']].tail(10)
                display_df.columns = ['æ—¶é—´å‘¨æœŸ', 'å½“å‰å®¢å•ä»·', 'ä¸ŠæœŸå®¢å•ä»·', 'ç¯æ¯”å˜åŒ–é¢', 'ç¯æ¯”å˜åŒ–ç‡(%)']
                st.dataframe(display_df.style.format({
                    'å½“å‰å®¢å•ä»·': 'Â¥{:,.2f}',
                    'ä¸ŠæœŸå®¢å•ä»·': 'Â¥{:,.2f}',
                    'ç¯æ¯”å˜åŒ–é¢': 'Â¥{:+,.2f}',
                    'ç¯æ¯”å˜åŒ–ç‡(%)': '{:+.2f}%'
                }), use_container_width=True)
        
        with tab2:
            fig = px.line(
                time_agg, 
                x=time_col, 
                y='è®¢å•æ•°',
                title=f'è®¢å•æ•°{time_dimension}åº¦è¶‹åŠ¿',
                markers=True
            )
            fig.update_traces(line=dict(color='#3498db', width=3))
            fig.update_layout(height=400)
            st.plotly_chart(fig, use_container_width=True)
    
    st.markdown("---")
    
    # ==================== ä»·æ ¼æ•æ„Ÿåº¦åˆ†å±‚ï¼ˆæ ¹æ®é€‰å®šçš„æ—¶é—´ç»´åº¦ç­›é€‰æœ€è¿‘ä¸€æœŸï¼‰ ====================
    st.markdown(f"### ğŸ’° å®¢å•ä»·åˆ†å±‚åˆ†æï¼ˆå½“å‰{time_dimension}æ•°æ®ï¼‰")
    
    # ç­›é€‰æœ€è¿‘ä¸€ä¸ªå‘¨æœŸçš„æ•°æ®
    filtered_df = filter_data_by_time_dimension(df, time_dimension, selected_period, latest_only=True)
    
    if len(filtered_df) == 0:
        st.warning(f"âš ï¸ å½“å‰{time_dimension}æš‚æ— æ•°æ®")
        return
    
    # æ˜¾ç¤ºå½“å‰åˆ†æçš„æ—¶é—´èŒƒå›´
    if time_col in filtered_df.columns:
        current_period = filtered_df[time_col].iloc[0]
        period_label = format_period_label(current_period, time_dimension)
        st.info(f"ğŸ“… å½“å‰åˆ†ææ—¶é—´ï¼š{period_label}")
    
    order_prices = filtered_df.groupby('è®¢å•ID')['å•†å“å®å”®ä»·'].sum()
    
    def get_price_range(price):
        if price < 20:
            return 'ä½ä»·(<20å…ƒ)'
        elif price < 40:
            return 'ä¸­ä½(20-40å…ƒ)'
        elif price < 60:
            return 'ä¸­é«˜(40-60å…ƒ)'
        else:
            return 'é«˜ä»·(â‰¥60å…ƒ)'
    
    price_segments = order_prices.apply(get_price_range)
    price_range_order = ['ä½ä»·(<20å…ƒ)', 'ä¸­ä½(20-40å…ƒ)', 'ä¸­é«˜(40-60å…ƒ)', 'é«˜ä»·(â‰¥60å…ƒ)']
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.write("**ğŸ“Š å®¢å•ä»·åˆ†å±‚ç”¨æˆ·åˆ†å¸ƒ**")
        price_dist = price_segments.value_counts().reindex(price_range_order, fill_value=0)
        
        fig = px.bar(
            x=price_dist.index,
            y=price_dist.values,
            labels={'x': 'å®¢å•ä»·åŒºé—´', 'y': 'è®¢å•æ•°'},
            title=f'å®¢å•ä»·åˆ†å¸ƒï¼ˆ{period_label}ï¼‰',
            color=price_dist.values,
            color_continuous_scale='Greens'
        )
        fig.update_layout(showlegend=False)
        st.plotly_chart(fig, use_container_width=True)
        
        main_segment = price_dist.idxmax()
        main_ratio = price_dist.max() / price_dist.sum() * 100
        
        st.markdown(f"""
        <div class="insight-box">
        <b>ğŸ’¡ å®¢ç¾¤æ´å¯Ÿï¼š</b><br>
        â€¢ ä¸»è¦å®¢ç¾¤ï¼š<b>{main_segment}</b>ï¼ˆ{main_ratio:.1f}%ï¼‰<br>
        â€¢ å¹³å‡å®¢å•ä»·ï¼šÂ¥{order_prices.mean():.2f}<br>
        â€¢ å®¢å•ä»·ä¸­ä½æ•°ï¼šÂ¥{order_prices.median():.2f}
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        st.write("**ğŸ æ»¡å‡é—¨æ§›è¾¾æˆåˆ†æ**")
        manjian_thresholds = [20, 30, 40, 50, 60, 80]
        threshold_reach = []
        
        for threshold in manjian_thresholds:
            reach_orders = (order_prices >= threshold).sum()
            reach_ratio = reach_orders / len(order_prices) * 100
            threshold_reach.append({'é—¨æ§›': f'{threshold}å…ƒ', 'è¾¾æ ‡ç‡': reach_ratio})
        
        threshold_df = pd.DataFrame(threshold_reach)
        
        fig = px.line(
            threshold_df,
            x='é—¨æ§›',
            y='è¾¾æ ‡ç‡',
            title=f'æ»¡å‡é—¨æ§›è¾¾æ ‡ç‡ï¼ˆ{period_label}ï¼‰',
            markers=True
        )
        fig.update_traces(line_color='#e74c3c', marker=dict(size=10))
        fig.update_layout(yaxis_title='è¾¾æ ‡ç‡(%)')
        st.plotly_chart(fig, use_container_width=True)
        
        # æ‰¾åˆ°60-80%ä¹‹é—´çš„é—¨æ§›
        optimal = None
        for item in threshold_reach:
            if 60 <= item['è¾¾æ ‡ç‡'] <= 80:
                optimal = item['é—¨æ§›']
                break
        
        if optimal:
            st.markdown(f"""
            <div class="insight-box">
            <b>ğŸ’¡ æœ€ä¼˜æ»¡å‡å»ºè®®ï¼š</b><br>
            â€¢ å»ºè®®è®¾ç½®æ»¡å‡é—¨æ§›ï¼š<b>æ»¡{optimal}</b><br>
            â€¢ ç†ç”±ï¼šè¾¾æ ‡ç‡åœ¨60-80%ä¹‹é—´ï¼Œå¹³è¡¡åˆºæ¿€ä¸è¡¥è´´
            </div>
            """, unsafe_allow_html=True)
    
    st.markdown("""
    <div class="warning-box">
    <b>ğŸ¯ ä»·æ ¼è¥é”€å»ºè®®ï¼š</b><br>
    1. <b>ä½ä»·å®¢ç¾¤</b>ï¼šæ¨é€å°é¢åˆ¸ï¼ˆ5-8å…ƒï¼‰ï¼ŒåŸ¹å…»æ¶ˆè´¹ä¹ æƒ¯<br>
    2. <b>ä¸­ä»·å®¢ç¾¤</b>ï¼šæ»¡å‡æ´»åŠ¨ä¸ºä¸»ï¼Œæå‡å®¢å•ä»·<br>
    3. <b>é«˜ä»·å®¢ç¾¤</b>ï¼šå‡å°‘ä¿ƒé”€ï¼Œæä¾›ä¼˜è´¨æœåŠ¡å’Œä¼šå‘˜æƒç›Š<br>
    4. <b>åŠ¨æ€å®šä»·</b>ï¼šé«˜å³°æ—¶æ®µå‡å°‘æŠ˜æ‰£ï¼Œä½å³°æ—¶æ®µåŠ å¤§åŠ›åº¦
    </div>
    """, unsafe_allow_html=True)
    
    # ==================== ğŸ¤– RFMå®¢æˆ·åˆ†ç¾¤åˆ†æ ====================
    st.markdown("---")
    st.markdown("### ğŸ¤– RFMå®¢æˆ·åˆ†ç¾¤ä¸ç”»åƒ")
    
    if SCENE_INTELLIGENCE_AVAILABLE:
        with st.expander("ğŸ’¡ åŸºäºRFM+K-Meansçš„å®¢æˆ·åˆ†ç¾¤", expanded=True):
            st.info("ğŸ“Š ç»“åˆRFMæ¨¡å‹ä¸èšç±»ç®—æ³•ï¼Œè¯†åˆ«é«˜é¢‘åº”æ€¥ã€è®¡åˆ’å›¤è´§ã€ä»·æ ¼æ•æ„Ÿã€å¶å‘å°é²œå››ç±»ç”¨æˆ·")
            
            col1, col2 = st.columns([3, 1])
            
            with col2:
                if st.button("ğŸš€ è¿è¡Œå®¢æˆ·åˆ†ç¾¤", key="run_rfm_clustering"):
                    with st.spinner("â³ æ­£åœ¨è®¡ç®—RFMç‰¹å¾å¹¶èšç±»..."):
                        try:
                            # åˆå§‹åŒ–åˆ†ç¾¤æ¨¡å‹
                            rfm_model = RFMCustomerSegmentation(n_clusters=4)
                            
                            # è®¡ç®—RFM
                            rfm_data = rfm_model.calculate_rfm(filtered_df)
                            
                            # æ‰§è¡Œèšç±»
                            segment_result = rfm_model.segment_customers()
                            
                            if segment_result.get('status') == 'success':
                                # ä¿å­˜åˆ°session_state
                                st.session_state['rfm_model'] = rfm_model
                                st.session_state['rfm_result'] = segment_result
                                
                                st.success(f"âœ… åˆ†ç¾¤å®Œæˆï¼è¯†åˆ«{segment_result['n_clusters']}ä¸ªå®¢æˆ·ç¾¤ç»„")
                            else:
                                st.error(f"âŒ åˆ†ç¾¤å¤±è´¥ï¼š{segment_result.get('message')}")
                        
                        except Exception as e:
                            st.error(f"âŒ åˆ†ç¾¤è¿‡ç¨‹å‡ºé”™: {str(e)}")
                            import traceback
                            st.code(traceback.format_exc())
            
            # å¦‚æœåˆ†ç¾¤å·²å®Œæˆï¼Œæ˜¾ç¤ºç»“æœ
            if 'rfm_model' in st.session_state and 'rfm_result' in st.session_state:
                rfm_model = st.session_state['rfm_model']
                segment_result = st.session_state['rfm_result']
                
                # åˆ›å»ºæ ‡ç­¾é¡µ
                tab1, tab2, tab3 = st.tabs(["ğŸ‘¥ å®¢æˆ·ç¾¤ç»„", "ğŸ“Š 3Då¯è§†åŒ–", "ğŸ“‹ ç­–ç•¥å»ºè®®"])
                
                with tab1:
                    st.markdown("#### ğŸ‘¥ å®¢æˆ·ç¾¤ç»„ç”»åƒ")
                    
                    # åˆ†ç¾¤è´¨é‡æŒ‡æ ‡
                    col1, col2, col3 = st.columns(3)
                    
                    with col1:
                        st.metric("å®¢æˆ·ç¾¤ç»„æ•°", segment_result['n_clusters'])
                    
                    with col2:
                        st.metric("è½®å»“ç³»æ•°", f"{segment_result['silhouette_score']:.3f}",
                                 help="è½®å»“ç³»æ•°è¶Šæ¥è¿‘1ï¼Œåˆ†ç¾¤è´¨é‡è¶Šå¥½")
                    
                    with col3:
                        total_customers = sum(segment_result['distribution'].values())
                        st.metric("æ€»å®¢æˆ·æ•°", f"{total_customers:,}")
                    
                    # ç¾¤ç»„æ‘˜è¦è¡¨
                    st.markdown("**ğŸ“Š å„å®¢æˆ·ç¾¤ç»„ç‰¹å¾**")
                    summary_df = rfm_model.get_cluster_summary()
                    st.dataframe(summary_df, use_container_width=True, hide_index=True)
                    
                    # ç¾¤ç»„åˆ†å¸ƒé¥¼å›¾
                    st.markdown("**ğŸ“ˆ å®¢æˆ·ç¾¤ç»„åˆ†å¸ƒ**")
                    dist_df = pd.DataFrame(list(segment_result['distribution'].items()), 
                                          columns=['ç¾¤ç»„ID', 'ç”¨æˆ·æ•°'])
                    dist_df['ç¾¤ç»„åç§°'] = dist_df['ç¾¤ç»„ID'].map(
                        lambda x: segment_result['cluster_profiles'][x]['name']
                    )
                    
                    fig = px.pie(dist_df, values='ç”¨æˆ·æ•°', names='ç¾¤ç»„åç§°', 
                                title='å®¢æˆ·ç¾¤ç»„å æ¯”')
                    st.plotly_chart(fig, use_container_width=True)
                
                with tab2:
                    st.markdown("#### ğŸ“Š RFM 3Då¯è§†åŒ–")
                    st.caption("*Xè½´=æœ€è¿‘è´­ä¹°å¤©æ•°ï¼ŒYè½´=è´­ä¹°é¢‘æ¬¡ï¼ŒZè½´=è´­ä¹°é‡‘é¢*")
                    
                    cluster_3d_fig = rfm_model.visualize_clusters()
                    st.plotly_chart(cluster_3d_fig, use_container_width=True)
                    
                    st.markdown("""
                    **ç»´åº¦è¯´æ˜ï¼š**
                    - **Recencyï¼ˆæœ€è¿‘è´­ä¹°ï¼‰**: è·ç¦»ä¸Šæ¬¡è´­ä¹°çš„å¤©æ•°ï¼Œè¶Šå°è¶Šæ´»è·ƒ
                    - **Frequencyï¼ˆè´­ä¹°é¢‘æ¬¡ï¼‰**: æ€»è´­ä¹°æ¬¡æ•°ï¼Œè¶Šå¤šè¶Šå¿ è¯š
                    - **Monetaryï¼ˆè´­ä¹°é‡‘é¢ï¼‰**: ç´¯è®¡æ¶ˆè´¹é‡‘é¢ï¼Œè¶Šé«˜è¶Šæœ‰ä»·å€¼
                    - **Avg Distanceï¼ˆå¹³å‡è·ç¦»ï¼‰**: å¹³å‡é…é€è·ç¦»ï¼Œåæ˜ ä¾¿åˆ©æ€§éœ€æ±‚
                    - **Avg Fee Ratioï¼ˆé…é€è´¹å æ¯”ï¼‰**: é…é€è´¹å è®¢å•é‡‘é¢æ¯”ä¾‹ï¼Œåæ˜ åº”æ€¥ç¨‹åº¦
                    """)
                
                with tab3:
                    st.markdown("#### ğŸ“‹ å·®å¼‚åŒ–è¥é”€ç­–ç•¥")
                    
                    for cluster_id, profile in segment_result['cluster_profiles'].items():
                        with st.container():
                            st.markdown(f"### {profile['name']}")
                            
                            col1, col2 = st.columns([1, 2])
                            
                            with col1:
                                st.metric("ç”¨æˆ·æ•°", f"{profile['size']:,}")
                                st.metric("å æ¯”", f"{profile['percentage']:.1f}%")
                                
                                # è·å–æ•°æ®å‘¨æœŸå’ŒåŸå§‹è®¢å•æ•°
                                data_days = int(profile.get('data_span_days', 30))
                                avg_total_orders = profile.get('avg_total_orders', profile['avg_frequency'])
                                
                                # æ˜¾ç¤ºå‘¨æœŸå†…è®¢å•æ•°ï¼ˆæ›´ç›´è§‚ï¼‰
                                st.metric(
                                    f"{data_days}å¤©å†…è®¢å•", 
                                    f"{avg_total_orders:.1f}å•",
                                    help=f"è¯¥ç¾¤ç»„ç”¨æˆ·åœ¨{data_days}å¤©å†…å¹³å‡ä¸‹å•æ¬¡æ•°"
                                )
                                
                                # æ˜¾ç¤ºæ ‡å‡†åŒ–é¢‘æ¬¡ï¼ˆç”¨äºèšç±»ï¼‰
                                st.metric(
                                    "è´­ä¹°é¢‘æ¬¡", 
                                    f"{profile['avg_frequency']:.2f}æ¬¡/å‘¨",
                                    help="æ ‡å‡†åŒ–åçš„æ¯å‘¨å¹³å‡è®¢å•æ•°ï¼Œç”¨äºä¸åŒå‘¨æœŸæ•°æ®å¯¹æ¯”"
                                )
                                
                                st.metric("å¹³å‡æ¶ˆè´¹", f"Â¥{profile['avg_monetary']:.0f}")
                            
                            with col2:
                                st.markdown(f"""
                                <div class="insight-box">
                                <b>ï¿½ ç¾¤ç»„å®šä¹‰ï¼š</b><br>
                                {profile.get('definition', 'æš‚æ— å®šä¹‰')}<br>
                                <br>
                                <b>ğŸ“Š å…³é”®ç‰¹å¾ï¼ˆç¾¤ç»„å¹³å‡å€¼ï¼‰ï¼š</b><br>
                                â€¢ å¹³å‡æœ€è¿‘è´­ä¹°: {profile['avg_recency']:.0f}å¤©å‰<br>
                                â€¢ å¹³å‡é…é€è·ç¦»: {profile['avg_distance']:.1f}km<br>
                                â€¢ å¹³å‡é…é€è´¹å æ¯”: {profile['avg_fee_ratio']*100:.1f}%<br>
                                â€¢ å¹³å‡å•†å“æ•°: {profile.get('avg_items_per_order', 0):.1f}ä»¶/å•<br>
                                â€¢ å¹³å‡å“ç±»æ•°: {profile.get('avg_categories_per_order', 0):.1f}ç§/å•<br>
                                <br>
                                <b>ğŸ¯ è¥é”€ç­–ç•¥ï¼š</b><br>
                                {profile['strategy']}
                                </div>
                                """, unsafe_allow_html=True)
                            
                            st.markdown("---")
    else:
        st.warning("âš ï¸ åœºæ™¯è¥é”€æ™ºèƒ½å†³ç­–å¼•æ“æœªåŠ è½½ï¼Œè¯·ç¡®ä¿å·²å®‰è£…scikit-learn")


def render_product_combination_marketing(df: pd.DataFrame, time_dimension: str = 'æ—¥', selected_period: str = None):
    """å•†å“ç»„åˆåœºæ™¯è¥é”€ï¼ˆæ”¯æŒæ—¥/å‘¨/æœˆç»´åº¦ï¼‰"""
    st.markdown('<p class="sub-header">ğŸ“¦ å•†å“ç»„åˆåœºæ™¯åˆ†æ</p>', unsafe_allow_html=True)
    
    # ==================== åœºæ™¯è¥é”€ç†å¿µè¯´æ˜ ====================
    with st.expander("ğŸ’¡ å•†å“ç»„åˆï¼šå¿«æ¶ˆé›¶å”®çš„åœºæ™¯åŒ–éœ€æ±‚æ»¡è¶³", expanded=False):
        st.markdown("""
        ### ğŸ¯ å¿«æ¶ˆé›¶å”®å•†å“ç»„åˆçš„åœºæ™¯é€»è¾‘
        
        #### ä¸ºä»€ä¹ˆè¦åšå•†å“ç»„åˆï¼Ÿ
        
        **1. åœºæ™¯å®Œæ•´æ€§**
        - âŒ **å•å“æ€ç»´**ï¼šç”¨æˆ·ä¹°è–¯ç‰‡ï¼Œè¿˜å¾—å•ç‹¬ä¹°å¯ä¹
        - âœ… **åœºæ™¯æ€ç»´**ï¼šç›´æ¥æ¨"è¿½å‰§å¥—é¤"ï¼ˆè–¯ç‰‡+å¯ä¹+ç“œå­ï¼‰ï¼Œä¸€é”®ä¸‹å•
        
        **2. é™ä½å†³ç­–æˆæœ¬**
        - ç”¨æˆ·ä¸ç”¨æ€è€ƒ"è¿˜éœ€è¦ä»€ä¹ˆ"
        - ç³»ç»Ÿæ™ºèƒ½æ¨è"ä¹°è¿™ä¸ªçš„äººè¿˜ä¹°äº†..."
        - å‡å°‘è´­ç‰©è½¦å¼ƒå•ç‡
        
        **3. æå‡å®¢å•ä»·**
        - å•å“è´­ä¹°ï¼šå¹³å‡25å…ƒ
        - ç»„åˆè´­ä¹°ï¼šå¹³å‡40å…ƒï¼ˆæå‡60%ï¼‰
        - äº¤å‰é”€å”®ï¼šå¸¦åŠ¨ä½é¢‘å“ç±»
        
        #### å¿«æ¶ˆé›¶å”®çš„åœºæ™¯åŒ–å•†å“ç»„åˆç­–ç•¥
        
        **ğŸ¿ è¿½å‰§æ”¾æ¾åœºæ™¯ç»„åˆ**
        ```
        æ ¸å¿ƒåœºæ™¯ï¼šæ™šé—´åœ¨å®¶è¿½å‰§ã€æ”¾æ¾å¨±ä¹
        å…¸å‹ç»„åˆï¼š
        - åŸºç¡€å¥—é¤ï¼šè–¯ç‰‡ + å¯ä¹ + çº¸å·¾ï¼ˆÂ¥18ï¼‰
        - å‡çº§å¥—é¤ï¼šè†¨åŒ–é£Ÿå“ + é¥®æ–™ + åšæœ + æ°´æœï¼ˆÂ¥35ï¼‰
        - åˆ†äº«å¥—é¤ï¼šå¤§åŒ…è£…é›¶é£Ÿ + 2å‡è£…é¥®æ–™ï¼ˆÂ¥45ï¼‰
        
        å…³è”æ¨èï¼šä¹°è–¯ç‰‡ â†’ æ¨èå¯ä¹ã€é¥®æ–™
        ```
        
        **ğŸ® æ¸¸æˆèšä¼šåœºæ™¯ç»„åˆ**
        ```
        æ ¸å¿ƒåœºæ™¯ï¼šæœ‹å‹èšä¼šã€æ¸¸æˆå¨±ä¹
        å…¸å‹ç»„åˆï¼š
        - èšä¼šå¥—é¤ï¼šå•¤é…’ + å¤å‘³ + èŠ±ç”Ÿ + è–¯ç‰‡ï¼ˆÂ¥68ï¼‰
        - æ¸¸æˆå¥—é¤ï¼šé¥®æ–™ + é›¶é£Ÿ + æ°´æœæ‹¼ç›˜ï¼ˆÂ¥45ï¼‰
        - å¤œå®µå¥—é¤ï¼šçƒ¤è‚  + é¸­è„– + å•¤é…’ï¼ˆÂ¥55ï¼‰
        
        å…³è”æ¨èï¼šä¹°å•¤é…’ â†’ æ¨èå¤å‘³ã€èŠ±ç”Ÿã€çƒ¤è‚ 
        ```
        
        **â˜• åŠå…¬æç¥åœºæ™¯ç»„åˆ**
        ```
        æ ¸å¿ƒåœºæ™¯ï¼šä¸Šåˆ/ä¸‹åˆåŠå…¬å®¤å·¥ä½œ
        å…¸å‹ç»„åˆï¼š
        - æç¥å¥—é¤ï¼šå’–å•¡ + åšæœ + å·§å…‹åŠ›ï¼ˆÂ¥25ï¼‰
        - ä¸‹åˆèŒ¶å¥—é¤ï¼šå¥¶èŒ¶ + é¥¼å¹² + ç³–æœï¼ˆÂ¥20ï¼‰
        - èƒ½é‡å¥—é¤ï¼šåŠŸèƒ½é¥®æ–™ + èƒ½é‡æ£’ + å£é¦™ç³–ï¼ˆÂ¥22ï¼‰
        
        å…³è”æ¨èï¼šä¹°å’–å•¡ â†’ æ¨èåšæœã€å·§å…‹åŠ›
        ```
        
        **ğŸ  å®¶åº­æ—¥å¸¸åœºæ™¯ç»„åˆ**
        ```
        æ ¸å¿ƒåœºæ™¯ï¼šå‘¨æœ«å®¶åº­å›¤è´§ã€æ—¥å¸¸è¡¥å……
        å…¸å‹ç»„åˆï¼š
        - æ—¥ç”¨å¥—é¤ï¼šçº¸å·¾ + æ´—è¡£æ¶² + åƒåœ¾è¢‹ï¼ˆÂ¥45ï¼‰
        - æ¸…æ´å¥—é¤ï¼šæ´—æ´ç²¾ + æ´—æ‰‹æ¶² + æŠ½çº¸ï¼ˆÂ¥35ï¼‰
        - æ´—æŠ¤å¥—é¤ï¼šæ´—å‘æ°´ + æ²æµ´éœ² + ç‰™è†ï¼ˆÂ¥68ï¼‰
        
        å…³è”æ¨èï¼šä¹°çº¸å·¾ â†’ æ¨èåƒåœ¾è¢‹ã€æ´—è¡£æ¶²
        ```
        
        **ğŸš¨ åº”æ€¥åœºæ™¯ç»„åˆ**
        ```
        æ ¸å¿ƒåœºæ™¯ï¼šçªç„¶å‘ç°ç¼ºæŸç‰©ã€ä¸´æ—¶éœ€æ±‚
        å…¸å‹ç»„åˆï¼š
        - åº”æ€¥åŒ…ï¼šçº¸å·¾ + åƒåœ¾è¢‹ + ç”µæ± ï¼ˆÂ¥20ï¼‰
        - ä¸´æ—¶å®¢äººï¼šé¥®æ–™ + é›¶é£Ÿ + æ°´æœï¼ˆÂ¥35ï¼‰
        - å©´å„¿åº”æ€¥ï¼šå°¿ä¸æ¹¿ + æ¹¿å·¾ + çº¸å·¾ï¼ˆÂ¥58ï¼‰
        
        å…³è”æ¨èï¼šä¹°çº¸å·¾ â†’ æ¨èå…¶ä»–æ—¥ç”¨å“
        ```
        
        #### æ™ºèƒ½æ¨èç­–ç•¥ï¼ˆåŸºäºè´­ç‰©ç¯®åˆ†æï¼‰
        
        **1. é«˜é¢‘å…³è”ç»„åˆ**
        - ğŸº å•¤é…’ â†’ å¤å‘³ã€èŠ±ç”Ÿã€è–¯ç‰‡ï¼ˆå…³è”åº¦80%ï¼‰
        - ğŸ¿ è–¯ç‰‡ â†’ å¯ä¹ã€é¥®æ–™ã€ç“œå­ï¼ˆå…³è”åº¦75%ï¼‰
        - â˜• å’–å•¡ â†’ åšæœã€å·§å…‹åŠ›ã€é¥¼å¹²ï¼ˆå…³è”åº¦70%ï¼‰
        - ğŸ§» çº¸å·¾ â†’ åƒåœ¾è¢‹ã€æ´—è¡£æ¶²ã€æŠ½çº¸ï¼ˆå…³è”åº¦65%ï¼‰
        
        **2. åœºæ™¯è§¦å‘æ¨è**
        - æ™šä¸Š19-23ç‚¹ä¸‹å• â†’ è‡ªåŠ¨æ¨èè¿½å‰§å¥—é¤
        - å‘¨æœ«10-18ç‚¹ä¸‹å• â†’ è‡ªåŠ¨æ¨èå®¶åº­å›¤è´§å¥—é¤
        - åŠå…¬åŒºåœ°å€ â†’ è‡ªåŠ¨æ¨èæç¥å¥—é¤
        
        **3. ç”¨æˆ·ç”»åƒæ¨è**
        - é«˜é¢‘ç”¨æˆ· â†’ æ¨èä¼šå‘˜ä¸“äº«ç»„åˆ
        - ä½é¢‘ç”¨æˆ· â†’ æ¨èæ–°äººä¼˜æƒ å¥—é¤
        - å®¶åº­ç”¨æˆ· â†’ æ¨èå¤§åŒ…è£…ç»„åˆ
        
        ---
        
        **ğŸ“Š æœ¬çœ‹æ¿æä¾›çš„ç»„åˆæ´å¯Ÿ**ï¼š
        - å‘ç°é«˜é¢‘å•†å“å…³è”ï¼ˆå“ªäº›å•†å“ç»å¸¸ä¸€èµ·ä¹°ï¼‰
        - è¯†åˆ«åœºæ™¯åŒ–éœ€æ±‚ï¼ˆä»€ä¹ˆåœºæ™¯ä¹°ä»€ä¹ˆç»„åˆï¼‰
        - ä¼˜åŒ–å¥—é¤è®¾è®¡ï¼ˆè®¾è®¡é«˜å®¢å•ä»·ç»„åˆï¼‰
        - æå‡è¿å¸¦é”€å”®ï¼ˆæ™ºèƒ½æ¨èå…³è”å•†å“ï¼‰
        """)
    
    df = extract_time_features(df)
    
    # æ˜ å°„ç»´åº¦åˆ°å­—æ®µå
    dim_mapping = {
        'æ—¥': 'æ—¥æœŸ_datetime',
        'å‘¨': 'å¹´å‘¨',
        'æœˆ': 'å¹´æœˆ'
    }
    time_col = dim_mapping[time_dimension]
    
    # ==================== æ ¸å¿ƒæŒ‡æ ‡æ€»è§ˆï¼ˆå¸¦ç¯æ¯”ï¼‰ ====================
    st.markdown(f"### ğŸ“ˆ æ ¸å¿ƒæŒ‡æ ‡æ€»è§ˆï¼ˆæŒ‰{time_dimension}ï¼‰")
    
    if time_col in df.columns and 'è®¢å•ID' in df.columns:
        try:
            # å¤„ç†é‡å¤åˆ—å
            temp_df = df.copy()
            if isinstance(temp_df['è®¢å•ID'], pd.DataFrame):
                temp_df['è®¢å•ID'] = temp_df['è®¢å•ID'].iloc[:, 0]
            
            # è®¡ç®—æ¯ä¸ªè®¢å•çš„å•†å“ä»¶æ•°
            items_per_order = temp_df.groupby(['è®¢å•ID', time_col]).size().reset_index(name='å•†å“ä»¶æ•°')
            
            # æŒ‰æ—¶é—´ç»´åº¦èšåˆ
            time_agg = items_per_order.groupby(time_col).agg({
                'è®¢å•ID': 'count',
                'å•†å“ä»¶æ•°': 'mean'
            }).reset_index()
            time_agg.columns = [time_col, 'è®¢å•æ•°', 'å¹³å‡ä»¶æ•°']
            
            # è®¡ç®—ç»„åˆè®¢å•æ¯”ä¾‹ï¼ˆä»¶æ•°>1ï¼‰
            combo_orders = items_per_order[items_per_order['å•†å“ä»¶æ•°'] > 1].groupby(time_col).size().reset_index(name='ç»„åˆè®¢å•æ•°')
            time_agg = time_agg.merge(combo_orders, on=time_col, how='left')
            time_agg['ç»„åˆè®¢å•æ•°'] = time_agg['ç»„åˆè®¢å•æ•°'].fillna(0)
            time_agg['ç»„åˆè®¢å•æ¯”ä¾‹'] = (time_agg['ç»„åˆè®¢å•æ•°'] / time_agg['è®¢å•æ•°'] * 100).round(2)
        
            # è®¡ç®—ç¯æ¯”
            time_agg = calculate_period_over_period(time_agg, time_dimension, 'è®¢å•æ•°')
            time_agg = calculate_period_over_period(time_agg, time_dimension, 'å¹³å‡ä»¶æ•°')
            time_agg = calculate_period_over_period(time_agg, time_dimension, 'ç»„åˆè®¢å•æ¯”ä¾‹')
        except Exception as e:
            st.error(f"è®¡ç®—æ ¸å¿ƒæŒ‡æ ‡æ—¶å‡ºé”™: {str(e)}")
            time_agg = None
    else:
        time_agg = None
    
    if time_agg is not None:
        
        # è·å–å½“å‰æœŸå’Œä¸Šä¸€æœŸæ•°æ®ï¼ˆæ ¹æ®ç”¨æˆ·é€‰æ‹©æˆ–æœ€è¿‘ä¸€æœŸï¼‰
        if len(time_agg) >= 1:
            # å¦‚æœç”¨æˆ·é€‰æ‹©äº†å…·ä½“å‘¨æœŸï¼Œä½¿ç”¨é€‰æ‹©çš„å‘¨æœŸï¼›å¦åˆ™ä½¿ç”¨æœ€è¿‘ä¸€æœŸ
            if selected_period and not selected_period.startswith("å…¨éƒ¨"):
                if time_dimension == "æ—¥":
                    selected_date = pd.to_datetime(selected_period)
                    latest_idx = time_agg[time_agg[time_col] == selected_date].index
                else:
                    latest_idx = time_agg[time_agg[time_col] == selected_period].index
                
                if len(latest_idx) > 0:
                    latest = time_agg.loc[latest_idx[0]]
                    # è·å–ä¸Šä¸€æœŸæ•°æ®
                    current_position = latest_idx[0]
                    previous = time_agg.iloc[current_position - 1] if current_position > 0 else None
                else:
                    latest = time_agg.iloc[-1]
                    previous = time_agg.iloc[-2] if len(time_agg) >= 2 else None
            else:
                # æœªé€‰æ‹©å…·ä½“å‘¨æœŸï¼Œä½¿ç”¨æœ€è¿‘ä¸€æœŸ
                latest = time_agg.iloc[-1]
                previous = time_agg.iloc[-2] if len(time_agg) >= 2 else None
            
            col1, col2, col3, col4 = st.columns(4)
            
            # å½“å‰å‘¨æœŸ
            with col1:
                period_label = format_period_label(latest[time_col], time_dimension)
                st.metric(label=f"å½“å‰{time_dimension}", value=period_label)
            
            # å¹³å‡ä»¶æ•°ï¼ˆå¸¦ç¯æ¯”ï¼‰
            render_metric_with_comparison(
                col2, f"å¹³å‡ä»¶æ•°/å•",
                latest['å¹³å‡ä»¶æ•°'],
                previous['å¹³å‡ä»¶æ•°'] if previous is not None else None,
                format_type='number', unit='ä»¶'
            )
            
            # ç»„åˆè®¢å•æ¯”ä¾‹ï¼ˆå¸¦ç¯æ¯”ï¼‰
            render_metric_with_comparison(
                col3, f"ç»„åˆè®¢å•æ¯”ä¾‹",
                latest['ç»„åˆè®¢å•æ¯”ä¾‹'],
                previous['ç»„åˆè®¢å•æ¯”ä¾‹'] if previous is not None else None,
                format_type='percent'
            )
            
            # è®¢å•æ•°ï¼ˆå¸¦ç¯æ¯”ï¼‰
            render_metric_with_comparison(
                col4, f"è®¢å•æ•°",
                latest['è®¢å•æ•°'],
                previous['è®¢å•æ•°'] if previous is not None else None,
                format_type='number', unit='å•'
            )
        
        st.markdown("---")
        
        # ==================== è¶‹åŠ¿å›¾ ====================
        st.markdown(f"### ğŸ“Š {time_dimension}åº¦è¶‹åŠ¿åˆ†æ")
        
        tab1, tab2, tab3 = st.tabs(["å¹³å‡ä»¶æ•°è¶‹åŠ¿", "ç»„åˆè®¢å•æ¯”ä¾‹è¶‹åŠ¿", "è®¢å•é‡è¶‹åŠ¿"])
        
        with tab1:
            fig = px.line(
                time_agg, 
                x=time_col, 
                y='å¹³å‡ä»¶æ•°',
                title=f'å¹³å‡ä»¶æ•°{time_dimension}åº¦è¶‹åŠ¿',
                markers=True
            )
            fig.update_traces(line=dict(color='#9b59b6', width=3))
            fig.update_layout(height=400)
            st.plotly_chart(fig, use_container_width=True)
            
            # ç¯æ¯”å˜åŒ–è¡¨æ ¼
            if 'å¹³å‡ä»¶æ•°_ç¯æ¯”ç‡' in time_agg.columns:
                st.write("**ç¯æ¯”å˜åŒ–è¯¦æƒ…**")
                display_df = time_agg[[time_col, 'å¹³å‡ä»¶æ•°', 'å¹³å‡ä»¶æ•°_ä¸ŠæœŸå€¼', 'å¹³å‡ä»¶æ•°_ç¯æ¯”å˜åŒ–', 'å¹³å‡ä»¶æ•°_ç¯æ¯”ç‡']].tail(10)
                display_df.columns = ['æ—¶é—´å‘¨æœŸ', 'å½“å‰å¹³å‡ä»¶æ•°', 'ä¸ŠæœŸå¹³å‡ä»¶æ•°', 'ç¯æ¯”å˜åŒ–é‡', 'ç¯æ¯”å˜åŒ–ç‡(%)']
                st.dataframe(display_df.style.format({
                    'å½“å‰å¹³å‡ä»¶æ•°': '{:.2f}',
                    'ä¸ŠæœŸå¹³å‡ä»¶æ•°': '{:.2f}',
                    'ç¯æ¯”å˜åŒ–é‡': '{:+.2f}',
                    'ç¯æ¯”å˜åŒ–ç‡(%)': '{:+.2f}%'
                }), use_container_width=True)
        
        with tab2:
            fig = px.line(
                time_agg, 
                x=time_col, 
                y='ç»„åˆè®¢å•æ¯”ä¾‹',
                title=f'ç»„åˆè®¢å•æ¯”ä¾‹{time_dimension}åº¦è¶‹åŠ¿',
                markers=True
            )
            fig.update_traces(line=dict(color='#16a085', width=3))
            fig.update_layout(height=400, yaxis_title='ç»„åˆè®¢å•æ¯”ä¾‹(%)')
            st.plotly_chart(fig, use_container_width=True)
        
        with tab3:
            fig = px.line(
                time_agg, 
                x=time_col, 
                y='è®¢å•æ•°',
                title=f'è®¢å•æ•°{time_dimension}åº¦è¶‹åŠ¿',
                markers=True
            )
            fig.update_traces(line=dict(color='#3498db', width=3))
            fig.update_layout(height=400)
            st.plotly_chart(fig, use_container_width=True)
    
    st.markdown("---")
    
    # ==================== å•†å“ç»„åˆåˆ†æï¼ˆæ ¹æ®é€‰å®šçš„æ—¶é—´ç»´åº¦ç­›é€‰æœ€è¿‘ä¸€æœŸï¼‰ ====================
    st.markdown(f"### ğŸ›’ è´­ç‰©ç¯®åˆ†æ - å•†å“å…³è”å‘ç°ï¼ˆå½“å‰{time_dimension}æ•°æ®ï¼‰")
    
    # ç­›é€‰æœ€è¿‘ä¸€ä¸ªå‘¨æœŸçš„æ•°æ®
    filtered_df = filter_data_by_time_dimension(df, time_dimension, selected_period, latest_only=True)
    
    if len(filtered_df) == 0:
        st.warning(f"âš ï¸ å½“å‰{time_dimension}æš‚æ— æ•°æ®")
        return
    
    # æ˜¾ç¤ºå½“å‰åˆ†æçš„æ—¶é—´èŒƒå›´
    if time_col in filtered_df.columns:
        current_period = filtered_df[time_col].iloc[0]
        period_label = format_period_label(current_period, time_dimension)
        st.info(f"ğŸ“… å½“å‰åˆ†ææ—¶é—´ï¼š{period_label}")
    
    if 'ä¸€çº§åˆ†ç±»å' in filtered_df.columns:
        from itertools import combinations
        order_categories = filtered_df.groupby('è®¢å•ID')['ä¸€çº§åˆ†ç±»å'].apply(list)
        
        category_pairs = {}
        for order_id, categories in order_categories.items():
            unique_cats = list(set(categories))
            if len(unique_cats) >= 2:
                for pair in combinations(sorted(unique_cats), 2):
                    key = f"{pair[0]} + {pair[1]}"
                    category_pairs[key] = category_pairs.get(key, 0) + 1
        
        if category_pairs:
            top_pairs = sorted(category_pairs.items(), key=lambda x: x[1], reverse=True)[:10]
            
            col1, col2 = st.columns([2, 1])
            
            with col1:
                pairs_df = pd.DataFrame(top_pairs, columns=['å•†å“ç»„åˆ', 'å…±ç°æ¬¡æ•°'])
                
                fig = px.bar(
                    pairs_df,
                    x='å…±ç°æ¬¡æ•°',
                    y='å•†å“ç»„åˆ',
                    orientation='h',
                    title=f'Top 10 å•†å“åˆ†ç±»ç»„åˆï¼ˆ{period_label}ï¼‰',
                    color='å…±ç°æ¬¡æ•°',
                    color_continuous_scale='Blues'
                )
                fig.update_layout(showlegend=False, height=400)
                st.plotly_chart(fig, use_container_width=True)
            
            with col2:
                st.write("**ğŸ” Top 5 çƒ­é—¨ç»„åˆ**")
                for i, (pair, count) in enumerate(top_pairs[:5], 1):
                    st.markdown(f"""
                    <div class="metric-card">
                    <b>{i}. {pair}</b><br>
                    å…±ç° {count} æ¬¡
                    </div>
                    """, unsafe_allow_html=True)
            
            top_pair = top_pairs[0]
            st.markdown(f"""
            <div class="insight-box">
            <b>ğŸ’¡ å¥—é¤è®¾è®¡å»ºè®®ï¼š</b><br>
            â€¢ æœ€ä½³ç»„åˆï¼š<b>{top_pair[0]}</b>ï¼ˆå…±ç°{top_pair[1]}æ¬¡ï¼‰<br>
            â€¢ å»ºè®®ï¼šå°†è¿™ä¸¤ç±»å•†å“æ‰“åŒ…ä¸ºå¥—é¤ï¼Œå®šä»·ç•¥ä½äºå•ä¹°æ€»ä»·<br>
            â€¢ é¢„æœŸï¼šæå‡å®¢å•ä»·10-15%ï¼Œæé«˜ç”¨æˆ·æ»¡æ„åº¦
            </div>
            """, unsafe_allow_html=True)
    
    # å•å“vsç»„åˆè®¢å•å¯¹æ¯”
    st.write(f"**ğŸ“Š å•å“è®¢å• vs ç»„åˆè®¢å•å¯¹æ¯”ï¼ˆ{period_label}ï¼‰**")
    items_per_order = filtered_df.groupby('è®¢å•ID').size()
    single_item_orders = items_per_order[items_per_order == 1].index
    combo_orders = items_per_order[items_per_order > 1].index
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        single_count = len(single_item_orders)
        total_orders = filtered_df['è®¢å•ID'].nunique()
        st.metric("å•å“è®¢å•", f"{single_count:,}",
                 delta=f"{single_count/total_orders*100:.1f}%")
    
    with col2:
        combo_count = len(combo_orders)
        st.metric("ç»„åˆè®¢å•", f"{combo_count:,}",
                 delta=f"{combo_count/total_orders*100:.1f}%")
    
    with col3:
        avg_items_combo = items_per_order[items_per_order > 1].mean()
        st.metric("ç»„åˆè®¢å•å¹³å‡ä»¶æ•°", f"{avg_items_combo:.1f}ä»¶")
    
    st.markdown("""
    <div class="warning-box">
    <b>ğŸ¯ å•†å“ç»„åˆè¥é”€å»ºè®®ï¼š</b><br>
    1. <b>å¥—é¤è®¾è®¡</b>ï¼šå¼•æµå“+åˆ©æ¶¦å“ï¼Œå®ç°é”€é‡ä¸åˆ©æ¶¦å¹³è¡¡<br>
    2. <b>äº¤å‰é”€å”®</b>ï¼šè´­ä¹°Aå•†å“åæ¨èå¸¸æ­é…çš„Bå•†å“<br>
    3. <b>æ»¡ä»¶ä¼˜æƒ </b>ï¼š"ç¬¬äºŒä»¶åŠä»·"ä¿ƒè¿›å¤šä»¶è´­ä¹°<br>
    4. <b>æ™ºèƒ½æ¨è</b>ï¼šåŸºäºè´­ç‰©ç¯®åˆ†æï¼Œç²¾å‡†æ¨èç»„åˆå•†å“
    </div>
    """, unsafe_allow_html=True)
    
    # ==================== ğŸ¤– AIæ™ºèƒ½å†³ç­–åˆ†æ ====================
    st.markdown("---")
    st.markdown("### ğŸ¤– AIæ™ºèƒ½å•†å“ç»„åˆæŒ–æ˜")
    
    if SCENE_INTELLIGENCE_AVAILABLE:
        with st.expander("ğŸ’¡ åŸºäºFP-Growthç®—æ³•çš„å…³è”è§„åˆ™æŒ–æ˜", expanded=True):
            st.info("ğŸ“Š ä½¿ç”¨æœºå™¨å­¦ä¹ ç®—æ³•è‡ªåŠ¨å‘ç°å•†å“è´­ä¹°å…³è”è§„åˆ™ï¼Œç”Ÿæˆåœºæ™¯åŒ–å¥—é¤å»ºè®®")
            
            # è¿è¡ŒæŒ‰é’®
            if st.button("ğŸš€ å¼€å§‹æ™ºèƒ½åˆ†æ", key="run_product_mining"):
                with st.spinner("â³ æ­£åœ¨åˆ†æå•†å“ç»„åˆè§„å¾‹..."):
                    try:
                        # æ•°æ®é‡æ£€æŸ¥
                        total_orders = filtered_df['è®¢å•ID'].nunique()
                        st.info(f"ğŸ“¦ è®¢å•æ•°é‡: {total_orders} | å•†å“ç§ç±»: {filtered_df['å•†å“åç§°'].nunique()}")
                        
                        # æ ¹æ®æ•°æ®é‡åŠ¨æ€è°ƒæ•´é˜ˆå€¼
                        if total_orders < 100:
                            min_sup, min_conf = 0.02, 0.2  # è¶…å°æ•°æ®é›†
                        elif total_orders < 500:
                            min_sup, min_conf = 0.01, 0.25  # å°æ•°æ®é›†
                        else:
                            min_sup, min_conf = 0.005, 0.3  # æ­£å¸¸æ•°æ®é›†
                        
                        # åˆå§‹åŒ–æŒ–æ˜å¼•æ“
                        miner = ProductCombinationMiner(
                            min_support=min_sup,
                            min_confidence=min_conf
                        )
                        
                        st.caption(f"âš™ï¸ å½“å‰é˜ˆå€¼: æ”¯æŒåº¦â‰¥{min_sup*100:.1f}%, ç½®ä¿¡åº¦â‰¥{min_conf*100:.0f}%")
                        
                        # æ‰§è¡ŒæŒ–æ˜
                        result = miner.mine_from_orders(filtered_df)
                        
                        if result.get('status') == 'success':
                            st.success(f"âœ… åˆ†æå®Œæˆï¼å‘ç° {result['stats']['rules_count']} æ¡å…³è”è§„åˆ™")
                            
                            # åˆ›å»ºæ ‡ç­¾é¡µ
                            tab1, tab2, tab3, tab4 = st.tabs([
                                "ğŸ“Š TOPå…³è”è§„åˆ™", 
                                "ğŸ åœºæ™¯åŒ–å¥—é¤", 
                                "ğŸ•¸ï¸ å…³è”ç½‘ç»œ", 
                                "ğŸ“ˆ ç»Ÿè®¡æ‘˜è¦"
                            ])
                            
                            with tab1:
                                st.markdown("#### ğŸ” TOP 10 å…³è”è§„åˆ™")
                                st.caption("*è§„åˆ™æ ¼å¼: å•†å“A â†’ å•†å“Bï¼ˆå¦‚æœè´­ä¹°Aï¼Œåˆ™æ¨èBï¼‰*")
                                
                                top_rules = miner.get_top_rules(top_n=10, sort_by='lift')
                                if not top_rules.empty:
                                    # æ ¼å¼åŒ–æ˜¾ç¤º
                                    display_rules = top_rules.copy()
                                    display_rules['æ”¯æŒåº¦'] = display_rules['support'].apply(lambda x: f"{x*100:.2f}%")
                                    display_rules['ç½®ä¿¡åº¦'] = display_rules['confidence'].apply(lambda x: f"{x*100:.1f}%")
                                    display_rules['æå‡åº¦'] = display_rules['lift'].apply(lambda x: f"{x:.2f}x")
                                    
                                    st.dataframe(
                                        display_rules[['rule', 'æ”¯æŒåº¦', 'ç½®ä¿¡åº¦', 'æå‡åº¦']],
                                        use_container_width=True,
                                        hide_index=True
                                    )
                                    
                                    # è§£é‡Šè¯´æ˜
                                    st.markdown("""
                                    **æŒ‡æ ‡è¯´æ˜ï¼š**
                                    - **æ”¯æŒåº¦**: è¯¥å•†å“ç»„åˆåœ¨æ‰€æœ‰è®¢å•ä¸­å‡ºç°çš„é¢‘ç‡
                                    - **ç½®ä¿¡åº¦**: è´­ä¹°å‰é¡¹å•†å“åï¼Œè´­ä¹°åé¡¹å•†å“çš„æ¦‚ç‡
                                    - **æå‡åº¦**: ç›¸æ¯”éšæœºæƒ…å†µï¼Œè¯¥è§„åˆ™çš„æ¨èæ•ˆæœï¼ˆ>1è¡¨ç¤ºæ­£ç›¸å…³ï¼‰
                                    """)
                                else:
                                    st.warning(f"""
                                    âš ï¸ **æœªæ‰¾åˆ°æ»¡è¶³æ¡ä»¶çš„å…³è”è§„åˆ™**
                                    
                                    å½“å‰é˜ˆå€¼: æ”¯æŒåº¦â‰¥{min_sup*100:.1f}%, ç½®ä¿¡åº¦â‰¥{min_conf*100:.0f}%
                                    
                                    **å¯èƒ½åŸå› ï¼š**
                                    - è®¢å•æ•°é‡è¾ƒå°‘ï¼ˆå½“å‰{total_orders}ä¸ªè®¢å•ï¼‰
                                    - å•†å“ç»„åˆè¾ƒåˆ†æ•£ï¼Œç¼ºä¹æ˜æ˜¾å…³è”
                                    - æ¯ä¸ªè®¢å•å•†å“æ•°é‡è¾ƒå°‘
                                    
                                    **å»ºè®®ï¼š**
                                    1. å¢åŠ åˆ†ææ—¶é—´èŒƒå›´ï¼Œè·å–æ›´å¤šè®¢å•æ•°æ®
                                    2. èšç„¦ç‰¹å®šå“ç±»æˆ–åœºæ™¯è¿›è¡Œåˆ†æ
                                    3. æŸ¥çœ‹"ç»Ÿè®¡æ‘˜è¦"äº†è§£æ•°æ®åˆ†å¸ƒæƒ…å†µ
                                    """)
                            
                            with tab2:
                                st.markdown("#### ğŸ åœºæ™¯åŒ–å¥—é¤æ¨è")
                                
                                scene_packages = result.get('scene_packages', {})
                                if scene_packages:
                                    for scene_name, packages in scene_packages.items():
                                        with st.container():
                                            st.markdown(f"**{scene_name}**")
                                            
                                            for i, pkg in enumerate(packages[:3], 1):
                                                items_str = " + ".join(pkg['items'])
                                                support = pkg['support']
                                                st.markdown(f"""
                                                <div class="metric-card">
                                                <b>å¥—é¤ {i}ï¼š</b>{items_str}<br>
                                                <small>æ”¯æŒåº¦: {support*100:.2f}% | åŒ¹é…åº¦: â­{'â­' * pkg['match_score']}</small>
                                                </div>
                                                """, unsafe_allow_html=True)
                                else:
                                    st.info("ğŸ’¡ æç¤ºï¼šå¯è°ƒæ•´åœºæ™¯å…³é”®è¯ä»¥è¯†åˆ«æ›´å¤šåœºæ™¯å¥—é¤")
                            
                            with tab3:
                                st.markdown("#### ğŸ•¸ï¸ å•†å“å…³è”ç½‘ç»œå›¾")
                                st.caption("*å±•ç¤ºå•†å“ä¹‹é—´çš„å…³è”å…³ç³»ï¼Œçº¿æ¡ç²—ç»†è¡¨ç¤ºå…³è”å¼ºåº¦*")
                                
                                network_fig = miner.visualize_rules_network(top_n=15)
                                st.plotly_chart(network_fig, use_container_width=True)
                            
                            with tab4:
                                st.markdown("#### ğŸ“ˆ æŒ–æ˜ç»Ÿè®¡æ‘˜è¦")
                                
                                stats = result.get('stats', {})
                                col1, col2, col3 = st.columns(3)
                                
                                with col1:
                                    st.metric("åˆ†æè®¢å•æ•°", f"{stats.get('total_baskets', 0):,}")
                                    st.caption(f"å¹³å‡æ¯å• {filtered_df.groupby('è®¢å•ID').size().mean():.1f} ä»¶å•†å“")
                                
                                with col2:
                                    st.metric("é¢‘ç¹é¡¹é›†æ•°", f"{stats.get('frequent_itemsets_count', 0):,}")
                                    st.caption(f"å•†å“ç§ç±»: {filtered_df['å•†å“åç§°'].nunique()}")
                                
                                with col3:
                                    st.metric("å…³è”è§„åˆ™æ•°", f"{stats.get('rules_count', 0):,}")
                                    st.caption(f"å½“å‰é˜ˆå€¼: {min_sup*100:.1f}%/{min_conf*100:.0f}%")
                                
                                # æ•°æ®è´¨é‡è¯Šæ–­
                                st.markdown("---")
                                st.markdown("**ğŸ“Š æ•°æ®è´¨é‡è¯Šæ–­**")
                                
                                order_sizes = filtered_df.groupby('è®¢å•ID').size()
                                quality_col1, quality_col2 = st.columns(2)
                                
                                with quality_col1:
                                    st.markdown(f"""
                                    - å•å•†å“è®¢å•: **{(order_sizes == 1).sum()}** å• ({(order_sizes == 1).sum()/len(order_sizes)*100:.1f}%)
                                    - 2-3ä»¶è®¢å•: **{((order_sizes >= 2) & (order_sizes <= 3)).sum()}** å•
                                    - 4+ä»¶è®¢å•: **{(order_sizes >= 4).sum()}** å•
                                    """)
                                
                                with quality_col2:
                                    if stats.get('rules_count', 0) == 0:
                                        st.warning("""
                                        **ğŸ’¡ ä¼˜åŒ–å»ºè®®ï¼š**
                                        - å•å•†å“è®¢å•å æ¯”è¿‡é«˜ä¼šé™ä½å…³è”æ€§
                                        - å»ºè®®ç­›é€‰å¤šä»¶è®¢å•å†åˆ†æ
                                        - æˆ–æ‰©å¤§æ—¶é—´èŒƒå›´å¢åŠ æ•°æ®é‡
                                        """)
                                    else:
                                        st.success("âœ… æ•°æ®è´¨é‡è‰¯å¥½ï¼Œå…³è”åˆ†ææœ‰æ•ˆ")
                                
                                # TOPå•†å“ç»„åˆ
                                st.markdown("---")
                                st.markdown("**ğŸ” TOP 5 é«˜é¢‘å•†å“ç»„åˆ**")
                                top_combos = miner.get_top_combinations(top_n=5)
                                if not top_combos.empty:
                                    for idx, row in top_combos.iterrows():
                                        st.markdown(f"- {row['items_str']} (æ”¯æŒåº¦: {row['support']*100:.2f}%)")
                        
                        elif result.get('status') == 'warning':
                            st.warning(f"âš ï¸ {result.get('message')}")
                            st.info("ğŸ’¡ å»ºè®®ï¼šé™ä½æœ€å°æ”¯æŒåº¦é˜ˆå€¼ï¼ˆå¦‚0.005ï¼‰ä»¥å‘ç°æ›´å¤šè§„åˆ™")
                        
                        else:
                            st.error(f"âŒ åˆ†æå¤±è´¥ï¼š{result.get('message')}")
                            
                    except Exception as e:
                        st.error(f"âŒ åˆ†æè¿‡ç¨‹å‡ºé”™: {str(e)}")
                        import traceback
                        st.code(traceback.format_exc())
    else:
        st.warning("âš ï¸ åœºæ™¯è¥é”€æ™ºèƒ½å†³ç­–å¼•æ“æœªåŠ è½½ï¼Œè¯·ç¡®ä¿å·²å®‰è£…mlxtendåº“: `pip install mlxtend`")


def display_scenario_marketing_dashboard(current_data: Dict):
    """åœºæ™¯è¥é”€çœ‹æ¿ä¸»å…¥å£ï¼ˆå¢å¼ºç‰ˆï¼šæ”¯æŒæ—¥/å‘¨/æœˆç»´åº¦åˆ‡æ¢ï¼‰"""
    st.markdown('<p class="sub-header">ğŸ¯ åœºæ™¯è¥é”€çœ‹æ¿</p>', unsafe_allow_html=True)
    
    # è·å–åŸå§‹æ•°æ®ï¼ˆä¼˜å…ˆä»current_dataï¼Œå…¶æ¬¡ä»session_stateï¼‰
    raw_data = current_data.get('raw_data')
    
    # å¦‚æœcurrent_dataä¸­æ²¡æœ‰æ•°æ®ï¼Œå°è¯•ä»session_stateè·å–ï¼ˆä¸Šä¼ æ•°æ®çš„æƒ…å†µï¼‰
    if raw_data is None or (isinstance(raw_data, pd.DataFrame) and raw_data.empty):
        if 'current_data' in st.session_state:
            raw_data = st.session_state['current_data'].get('raw_data')
    
    # æ£€æŸ¥æ˜¯å¦æœ‰å¯ç”¨æ•°æ®
    if raw_data is None or (isinstance(raw_data, pd.DataFrame) and raw_data.empty):
        st.warning("âš ï¸ è¯·å…ˆåŠ è½½æ•°æ®åï¼Œæ‰èƒ½æŸ¥çœ‹åœºæ™¯è¥é”€åˆ†æ")
        st.info("""
        ğŸ’¡ **åœºæ™¯è¥é”€çœ‹æ¿åŠŸèƒ½ï¼š**
        
        1. â° **æ—¶æ®µåœºæ™¯è¥é”€** - è¯†åˆ«é»„é‡‘é”€å”®æ—¶æ®µï¼Œä¼˜åŒ–è¥é”€æŠ•æ”¾
        2. ğŸª **é—¨åº—å•†åœˆåœºæ™¯** - å‘ç°é«˜ä»·å€¼å•†åœˆï¼Œä¼˜åŒ–é—¨åº—å¸ƒå±€
        3. ğŸ’° **ä»·æ ¼æ•æ„Ÿåº¦** - ç²¾å‡†å®šä»·ç­–ç•¥ï¼Œæå‡å®¢å•ä»·
        4. ğŸ“¦ **å•†å“ç»„åˆåœºæ™¯** - å‘ç°å•†å“å…³è”ï¼Œè®¾è®¡ç»„åˆå¥—é¤
        
        **ä¸¤ç§åŠ è½½æ–¹å¼ï¼š**
        - æ–¹å¼1ï¼šåœ¨å·¦ä¾§ç‚¹å‡»"ğŸš€ å¼€å§‹æ™ºèƒ½åˆ†æ"åŠ è½½å®é™…æ•°æ®
        - æ–¹å¼2ï¼šåœ¨"ğŸ’¹ æ¯”ä»·çœ‹æ¿"æ ‡ç­¾é¡µä¸Šä¼ è®¢å•æ•°æ®Excelæ–‡ä»¶
        """)
        return
    
    # ========== æ•°æ®è¿‡æ»¤ï¼šå‰”é™¤å’–å•¡æ¸ é“ ==========
    if 'æ¸ é“' in raw_data.columns:
        exclude_channels = ['é¥¿äº†ä¹ˆå’–å•¡', 'ç¾å›¢å’–å•¡']
        original_count = len(raw_data)
        raw_data = raw_data[~raw_data['æ¸ é“'].isin(exclude_channels)].copy()
        filtered_count = len(raw_data)
        excluded_count = original_count - filtered_count
        
        if excluded_count > 0:
            st.info(f"â„¹ï¸ å·²è‡ªåŠ¨å‰”é™¤å’–å•¡æ¸ é“æ•°æ® {excluded_count} è¡Œï¼ˆ{excluded_count/original_count*100:.1f}%ï¼‰ï¼Œä¿ç•™O2Oé›¶å”®æ•°æ® {filtered_count} è¡Œ")
    
    # è°ƒè¯•: æ£€æŸ¥åŸå§‹æ•°æ®æ—¶é—´åˆ†å¸ƒ
    if 'ä¸‹å•æ—¶é—´' in raw_data.columns:
        with st.expander("ğŸ” åŸå§‹æ•°æ®æ—¶é—´è¯Šæ–­ï¼ˆç‚¹å‡»å±•å¼€ï¼‰", expanded=False):
            st.write("**ä¸‹å•æ—¶é—´æ ·æœ¬ï¼ˆå‰10æ¡ï¼‰ï¼š**")
            time_samples = raw_data['ä¸‹å•æ—¶é—´'].head(10)
            st.dataframe(pd.DataFrame({'ä¸‹å•æ—¶é—´': time_samples}), use_container_width=True)
            
            # è½¬æ¢ä¸ºdatetimeå¹¶æ˜¾ç¤ºå°æ—¶åˆ†å¸ƒ
            time_series = pd.to_datetime(raw_data['ä¸‹å•æ—¶é—´'], errors='coerce')
            if not time_series.dropna().empty:
                hour_dist = time_series.dt.hour.value_counts().sort_index()
                st.write(f"**æ—¶é—´èŒƒå›´ï¼š** {time_series.min()} ~ {time_series.max()}")
                st.write(f"**è¦†ç›–å°æ—¶æ•°ï¼š** {len(hour_dist)}/24")
                st.write("**å„å°æ—¶è®¢å•æ•°ï¼š**")
                st.bar_chart(hour_dist)
    
    # æå–æ—¶é—´ç‰¹å¾ï¼ˆæ”¯æŒæ—¥/å‘¨/æœˆç»´åº¦ï¼‰
    raw_data = extract_time_features(raw_data)
    
    # æ£€æŸ¥æ˜¯å¦æˆåŠŸæå–æ—¶é—´ç‰¹å¾
    if 'æ—¥æœŸ_datetime' not in raw_data.columns:
        st.error("âš ï¸ æ•°æ®æ ¼å¼é”™è¯¯ï¼šæ— æ³•æå–æ—¶é—´ç‰¹å¾")
        st.warning("""
        **å¯èƒ½çš„åŸå› ï¼š**
        1. æ•°æ®ä¸­ç¼ºå°‘ 'ä¸‹å•æ—¶é—´' åˆ—
        2. 'ä¸‹å•æ—¶é—´' åˆ—çš„æ ¼å¼ä¸æ­£ç¡®
        
        **è¯·æ£€æŸ¥ï¼š**
        - ç¡®ä¿ Excel æ–‡ä»¶ä¸­æœ‰ 'ä¸‹å•æ—¶é—´' åˆ—
        - ç¡®ä¿æ—¶é—´æ ¼å¼æ­£ç¡®ï¼ˆå¦‚ï¼š2025-01-01 12:00:00ï¼‰
        """)
        st.info(f"å½“å‰æ•°æ®åˆ—å: {list(raw_data.columns)[:30]}")
        return
    
    # æ—¶é—´ç»´åº¦é€‰æ‹©å™¨
    st.markdown("### ğŸ“… æ•°æ®åˆ†æç»´åº¦")
    col1, col2, col3 = st.columns([1, 2, 2])
    
    with col1:
        time_dimension = st.selectbox(
            "é€‰æ‹©æ—¶é—´ç»´åº¦",
            ["æ—¥", "å‘¨", "æœˆ"],
            help="é€‰æ‹©ä¸åŒçš„æ—¶é—´ç»´åº¦æŸ¥çœ‹æ•°æ®è¶‹åŠ¿å’Œç¯æ¯”å˜åŒ–",
            key="scenario_marketing_time_dimension"
        )
    
    # æ ¹æ®ç»´åº¦åŠ¨æ€ç”Ÿæˆæ—¶é—´å‘¨æœŸé€‰æ‹©å™¨
    selected_period = None
    with col2:
        if time_dimension == "æ—¥":
            available_dates = sorted(raw_data['æ—¥æœŸ_datetime'].dropna().unique(), reverse=True)
            date_options = ["å…¨éƒ¨æ—¥æœŸ"] + [d.strftime('%Y-%m-%d') for d in available_dates]
            selected_period = st.selectbox(
                "é€‰æ‹©å…·ä½“æ—¥æœŸ",
                date_options,
                help="é€‰æ‹©æŸ¥çœ‹æŸä¸€å¤©çš„æ•°æ®ï¼Œæˆ–æŸ¥çœ‹å…¨éƒ¨æ—¥æœŸçš„è¶‹åŠ¿",
                key="scenario_marketing_date_selector"
            )
        elif time_dimension == "å‘¨":
            available_weeks = sorted(raw_data['å¹´å‘¨'].dropna().unique(), reverse=True)
            week_options = ["å…¨éƒ¨å‘¨"] + [f"{w}" for w in available_weeks]
            selected_period = st.selectbox(
                "é€‰æ‹©å…·ä½“å‘¨",
                week_options,
                help="é€‰æ‹©æŸ¥çœ‹æŸä¸€å‘¨çš„æ•°æ®ï¼Œæˆ–æŸ¥çœ‹å…¨éƒ¨å‘¨çš„è¶‹åŠ¿",
                key="scenario_marketing_week_selector"
            )
        else:  # æœˆ
            available_months = sorted(raw_data['å¹´æœˆ'].dropna().unique(), reverse=True)
            month_options = ["å…¨éƒ¨æœˆä»½"] + [f"{m}" for m in available_months]
            selected_period = st.selectbox(
                "é€‰æ‹©å…·ä½“æœˆä»½",
                month_options,
                help="é€‰æ‹©æŸ¥çœ‹æŸä¸€æœˆçš„æ•°æ®ï¼Œæˆ–æŸ¥çœ‹å…¨éƒ¨æœˆä»½çš„è¶‹åŠ¿",
                key="scenario_marketing_month_selector"
            )
    
    with col3:
        # æ˜¾ç¤ºæ•°æ®èŒƒå›´å’Œé€‰æ‹©çŠ¶æ€è¯´æ˜
        if 'ä¸‹å•æ—¶é—´' in raw_data.columns:
            min_date = raw_data['ä¸‹å•æ—¶é—´'].min().strftime('%Y-%m-%d')
            max_date = raw_data['ä¸‹å•æ—¶é—´'].max().strftime('%Y-%m-%d')
            total_days = (raw_data['ä¸‹å•æ—¶é—´'].max() - raw_data['ä¸‹å•æ—¶é—´'].min()).days + 1
            
            # æ ¹æ®ç”¨æˆ·é€‰æ‹©æ˜¾ç¤ºä¸åŒä¿¡æ¯
            if selected_period and not selected_period.startswith("å…¨éƒ¨"):
                # é€‰æ‹©äº†å…·ä½“å‘¨æœŸ
                if time_dimension == "æ—¥":
                    st.info(f"ğŸ“Š å·²é€‰æ‹©ï¼š{selected_period}ï½œæŸ¥çœ‹å•æ—¥æ•°æ®")
                elif time_dimension == "å‘¨":
                    st.info(f"ğŸ“Š å·²é€‰æ‹©ï¼š{selected_period}ï½œæŸ¥çœ‹å•å‘¨æ•°æ®")
                else:  # æœˆ
                    st.info(f"ğŸ“Š å·²é€‰æ‹©ï¼š{selected_period}ï½œæŸ¥çœ‹å•æœˆæ•°æ®")
            else:
                # æœªé€‰æ‹©å…·ä½“å‘¨æœŸï¼Œæ˜¾ç¤ºå…¨é‡æ•°æ®èŒƒå›´
                if time_dimension == "æ—¥":
                    st.info(f"ğŸ“Š æ•°æ®èŒƒå›´ï¼š{min_date} è‡³ {max_date}ï¼ˆå…±{total_days}å¤©ï¼‰ï½œç¯æ¯”ï¼šä¸å‰ä¸€æ—¥å¯¹æ¯”")
                elif time_dimension == "å‘¨":
                    total_weeks = raw_data['å¹´å‘¨'].nunique()
                    st.info(f"ğŸ“Š æ•°æ®èŒƒå›´ï¼š{min_date} è‡³ {max_date}ï¼ˆå…±{total_weeks}å‘¨ï¼‰ï½œç¯æ¯”ï¼šä¸ä¸Šå‘¨å¯¹æ¯”")
                else:  # æœˆ
                    total_months = raw_data['å¹´æœˆ'].nunique()
                    st.info(f"ğŸ“Š æ•°æ®èŒƒå›´ï¼š{min_date} è‡³ {max_date}ï¼ˆå…±{total_months}æœˆï¼‰ï½œç¯æ¯”ï¼šä¸ä¸Šæœˆå¯¹æ¯”")
    
    st.markdown("---")
    
    # åœºæ™¯é€‰æ‹©ï¼ˆç§»é™¤é—®é¢˜è¯Šæ–­ï¼Œå·²ç‹¬ç«‹ä¸ºä¸»Tabï¼‰
    scenario = st.radio(
        "é€‰æ‹©è¥é”€åœºæ™¯",
        ["â° æ—¶æ®µåœºæ™¯è¥é”€", "ğŸª é—¨åº—å•†åœˆåœºæ™¯", "ğŸ’° ä»·æ ¼æ•æ„Ÿåº¦", "ğŸ“¦ å•†å“ç»„åˆåœºæ™¯"],
        horizontal=True,
        key="scenario_marketing_radio"
    )
    
    st.markdown("---")
    
    # æ¸²æŸ“å¯¹åº”åœºæ™¯ï¼ˆä¼ é€’æ—¶é—´ç»´åº¦å’Œé€‰å®šå‘¨æœŸå‚æ•°ï¼‰
    if scenario == "â° æ—¶æ®µåœºæ™¯è¥é”€":
        render_time_period_marketing(raw_data, time_dimension, selected_period)
    elif scenario == "ğŸª é—¨åº—å•†åœˆåœºæ™¯":
        render_location_marketing(raw_data, time_dimension, selected_period)
    elif scenario == "ğŸ’° ä»·æ ¼æ•æ„Ÿåº¦":
        render_price_sensitivity_marketing(raw_data, time_dimension, selected_period)
    elif scenario == "ğŸ“¦ å•†å“ç»„åˆåœºæ™¯":
        render_product_combination_marketing(raw_data, time_dimension, selected_period)


# ==================== é—®é¢˜è¯Šæ–­ä¸­å¿ƒæ¨¡å— ====================
def display_problem_diagnostic_center(data_dict: Dict):
    """
    æ˜¾ç¤ºé—®é¢˜è¯Šæ–­ä¸­å¿ƒ
    
    Parameters:
    -----------
    data_dict : Dict
        åŒ…å«åŸå§‹æ•°æ®çš„å­—å…¸
    """
    st.markdown('<h2 class="section-header">ğŸ“‹ é—®é¢˜è¯Šæ–­ä¸­å¿ƒ</h2>', unsafe_allow_html=True)
    
    if not PROBLEM_DIAGNOSTIC_AVAILABLE:
        st.error("âš ï¸ é—®é¢˜è¯Šæ–­å¼•æ“æœªåŠ è½½ï¼Œè¯·æ£€æŸ¥ä¾èµ–é¡¹")
        return
    
    # è·å–æ•°æ®ï¼ˆä¸åœºæ™¯è¥é”€çœ‹æ¿ä¿æŒä¸€è‡´çš„æ•°æ®è·å–é€»è¾‘ï¼‰
    raw_data = data_dict.get('raw_data')
    
    # å¦‚æœcurrent_dataä¸­æ²¡æœ‰æ•°æ®ï¼Œå°è¯•ä»session_stateè·å–ï¼ˆä¸Šä¼ æ•°æ®çš„æƒ…å†µï¼‰
    if raw_data is None or (isinstance(raw_data, pd.DataFrame) and raw_data.empty):
        if 'current_data' in st.session_state:
            raw_data = st.session_state['current_data'].get('raw_data')
    
    # æ£€æŸ¥æ˜¯å¦æœ‰å¯ç”¨æ•°æ®
    if raw_data is None or (isinstance(raw_data, pd.DataFrame) and raw_data.empty):
        st.warning("âš ï¸ è¯·å…ˆåŠ è½½æ•°æ®åï¼Œæ‰èƒ½ä½¿ç”¨é—®é¢˜è¯Šæ–­åŠŸèƒ½")
        st.info("""
        ğŸ’¡ **é—®é¢˜è¯Šæ–­ä¸­å¿ƒåŠŸèƒ½ï¼š**
        
        1. ğŸ“‰ **é”€é‡ä¸‹æ»‘è¯Šæ–­** - è¯†åˆ«é”€é‡ä¸‹é™çš„å•†å“åŠåŸå› 
        2. ğŸ’° **å®¢å•ä»·å½’å› åˆ†æ** - åˆ†æå®¢å•ä»·å˜åŒ–çš„å…·ä½“å•†å“
        3. ğŸš¨ **è´Ÿæ¯›åˆ©å•†å“é¢„è­¦** - è‡ªåŠ¨è¯†åˆ«äºæœ¬å•†å“
        4. ğŸšš **é«˜é…é€è´¹ä¼˜åŒ–** - ä¼˜åŒ–é…é€æˆæœ¬
        5. âš–ï¸ **å•†å“è§’è‰²å¤±è¡¡** - æ£€æµ‹æµé‡å“/åˆ©æ¶¦å“é…æ¯”
        6. ğŸ“Š **å¼‚å¸¸æ³¢åŠ¨é¢„è­¦** - è¯†åˆ«çˆ†å•/æ»é”€å•†å“
        
        **ä¸¤ç§åŠ è½½æ–¹å¼ï¼š**
        - æ–¹å¼1ï¼šåœ¨å·¦ä¾§ç‚¹å‡»"ğŸš€ å¼€å§‹æ™ºèƒ½åˆ†æ"åŠ è½½å®é™…æ•°æ®
        - æ–¹å¼2ï¼šåœ¨"ğŸ’¹ æ¯”ä»·çœ‹æ¿"æ ‡ç­¾é¡µä¸Šä¼ è®¢å•æ•°æ®Excelæ–‡ä»¶
        """)
        return
    
    # æ•°æ®éªŒè¯ï¼ˆæ£€æŸ¥å¿…éœ€åˆ—ï¼‰
    required_cols = ['è®¢å•ID', 'ä¸‰çº§åˆ†ç±»å', 'å•†å“å®å”®ä»·']
    missing_cols = [col for col in required_cols if col not in raw_data.columns]
    if missing_cols:
        st.error(f"âš ï¸ æ•°æ®ç¼ºå°‘å¿…è¦åˆ—: {', '.join(missing_cols)}")
        st.info(f"ğŸ“‹ å½“å‰æ•°æ®åˆ—: {', '.join(raw_data.columns.tolist()[:10])}...")
        return
    
    # ğŸ†• è‡ªåŠ¨æ·»åŠ æ—¶æ®µå­—æ®µï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    if 'æ—¶æ®µ' not in raw_data.columns and 'ä¸‹å•æ—¶é—´' in raw_data.columns:
        try:
            # å°†ä¸‹å•æ—¶é—´è½¬æ¢ä¸ºdatetime
            raw_data['ä¸‹å•æ—¶é—´_temp'] = pd.to_datetime(raw_data['ä¸‹å•æ—¶é—´'], errors='coerce')
            
            # å®šä¹‰æ—¶æ®µåˆ†ç±»å‡½æ•°ï¼ˆåŸºäºä¸šåŠ¡ç†è§£çš„8æ—¶æ®µåˆ’åˆ†ï¼‰
            def classify_time_slot(dt):
                """
                æ—¶æ®µåˆ’åˆ†è§„åˆ™ï¼ˆåŸºäºç”¨æˆ·è¡Œä¸ºç‰¹å¾ï¼‰:
                - æ¸…æ™¨(6-8ç‚¹): å‡ºè¡Œ/æ•´ç†/æ—©é¤ - èµ¶æ—¶é—´çš„å¿«èŠ‚å¥æ—¶æ®µ
                - ä¸Šåˆ(9-11ç‚¹): åŠå…¬/å±…å®¶/æ—¥ç”¨è¡¥å…… - å·¥ä½œæˆ–å®¶åŠ¡æ—¶æ®µ
                - æ­£åˆ(12-13ç‚¹): åˆé¤ - åˆé¤é«˜å³°æœŸ
                - ä¸‹åˆ(14-17ç‚¹): å·¥ä½œ/å®¶åŠ¡/äº²å­/å°æ†©/ä¸‹åˆèŒ¶ - å¤šå…ƒåŒ–æ—¶æ®µ
                - å‚æ™š(18-20ç‚¹): ä¸‹ç­/å½’å®¶/æ™šé¤/è·¯é€” - é€šå‹¤ä¸æ™šé¤å åŠ 
                - æ™šé—´(21-23ç‚¹): å±…å®¶/å¤œç”Ÿæ´»å‰ - æ”¾æ¾ä¸ç¤¾äº¤æ—¶æ®µ
                - æ·±å¤œ(0-2ç‚¹): çªå‘/æ€¥ç”¨/å¤œå®µ - åº”æ€¥ä¸å¤œå®µéœ€æ±‚
                - å‡Œæ™¨(3-5ç‚¹): ä¸‡ç±ä¿±å¯‚/ç†¬å¤œå…š - æä½é¢‘ç‰¹æ®Šåœºæ™¯
                """
                if pd.isna(dt):
                    return 'æœªçŸ¥'
                hour = dt.hour
                if 6 <= hour < 9:
                    return 'æ¸…æ™¨(6-9ç‚¹)'
                elif 9 <= hour < 12:
                    return 'ä¸Šåˆ(9-12ç‚¹)'
                elif 12 <= hour < 14:
                    return 'æ­£åˆ(12-14ç‚¹)'
                elif 14 <= hour < 18:
                    return 'ä¸‹åˆ(14-18ç‚¹)'
                elif 18 <= hour < 21:
                    return 'å‚æ™š(18-21ç‚¹)'
                elif 21 <= hour < 24:
                    return 'æ™šé—´(21-24ç‚¹)'
                elif 0 <= hour < 3:
                    return 'æ·±å¤œ(0-3ç‚¹)'
                else:  # 3-5ç‚¹
                    return 'å‡Œæ™¨(3-6ç‚¹)'
            
            # åº”ç”¨æ—¶æ®µåˆ†ç±»
            raw_data['æ—¶æ®µ'] = raw_data['ä¸‹å•æ—¶é—´_temp'].apply(classify_time_slot)
            raw_data.drop('ä¸‹å•æ—¶é—´_temp', axis=1, inplace=True)
            
            st.success("âœ… å·²è‡ªåŠ¨ä»ä¸‹å•æ—¶é—´æ¨æ–­æ—¶æ®µå­—æ®µï¼ˆ8æ—¶æ®µåˆ’åˆ†ï¼‰")
        except Exception as e:
            st.warning(f"âš ï¸ æ— æ³•è‡ªåŠ¨ç”Ÿæˆæ—¶æ®µå­—æ®µ: {e}")
    
    # ğŸ†• æ™ºèƒ½åœºæ™¯æ¨æ–­ï¼ˆå¦‚æœä¸å­˜åœ¨åœºæ™¯å­—æ®µï¼‰
    if 'åœºæ™¯' not in raw_data.columns and 'æ—¶æ®µ' in raw_data.columns:
        try:
            def infer_scene(row):
                """
                åŸºäºæ—¶æ®µã€å•†å“åç§°ã€å•†å“åˆ†ç±»æ™ºèƒ½æ¨æ–­æ¶ˆè´¹åœºæ™¯
                
                æ¨æ–­é€»è¾‘ï¼š
                1. ä¼˜å…ˆåŸºäºå•†å“åç§°å…³é”®è¯ï¼ˆæœ€ç²¾å‡†ï¼‰
                2. å…¶æ¬¡åŸºäºå•†å“åˆ†ç±»ï¼ˆä¸­ç­‰ç²¾å‡†ï¼‰
                3. æœ€ååŸºäºæ—¶æ®µï¼ˆå…œåº•æ–¹æ¡ˆï¼‰
                """
                time_slot = row.get('æ—¶æ®µ', '')
                product_name = str(row.get('å•†å“åç§°', '')).lower()
                category_1 = str(row.get('ä¸€çº§åˆ†ç±»å', '')).lower()
                category_3 = str(row.get('ä¸‰çº§åˆ†ç±»å', '')).lower()
                
                # === 1. åŸºäºå•†å“åç§°å…³é”®è¯ï¼ˆæœ€ç²¾å‡†ï¼‰===
                
                # æ—©é¤å…³é”®è¯
                breakfast_keywords = ['è±†æµ†', 'æ²¹æ¡', 'åŒ…å­', 'ç²¥', 'é¸¡è›‹', 'ç…é¥¼', 'é¦’å¤´', 'æ—©é¤', 'ç¨€é¥­']
                if any(kw in product_name for kw in breakfast_keywords):
                    return 'æ—©é¤'
                
                # åˆé¤å…³é”®è¯
                lunch_keywords = ['ç›–æµ‡é¥­', 'å¿«é¤', 'ä¾¿å½“', 'ç‚’é¥­', 'é¢æ¡', 'ç±³çº¿', 'ç›’é¥­', 'å¥—é¤', 'å·¥ä½œé¤']
                if any(kw in product_name for kw in lunch_keywords) and ('12' in time_slot or 'æ­£åˆ' in time_slot or 'ä¸‹åˆ' in time_slot):
                    return 'åˆé¤'
                
                # æ™šé¤å…³é”®è¯
                dinner_keywords = ['æ™šé¤', 'ç‚’èœ', 'ç«é”…', 'çƒ§çƒ¤', 'èšé¤']
                if any(kw in product_name for kw in dinner_keywords):
                    return 'æ™šé¤'
                
                # å¤œå®µå…³é”®è¯
                midnight_keywords = ['å¤œå®µ', 'çƒ§çƒ¤', 'å°é¾™è™¾', 'æ³¡é¢', 'æ–¹ä¾¿é¢', 'å•¤é…’', 'ç‚¸é¸¡']
                if any(kw in product_name for kw in midnight_keywords) and ('æ·±å¤œ' in time_slot or 'æ™šé—´' in time_slot or 'å‡Œæ™¨' in time_slot):
                    return 'å¤œå®µ'
                
                # ä¸‹åˆèŒ¶å…³é”®è¯
                tea_keywords = ['å¥¶èŒ¶', 'å’–å•¡', 'è›‹ç³•', 'ç”œç‚¹', 'é¢åŒ…', 'é¥¼å¹²', 'å†°æ·‡æ·‹', 'æœæ±']
                if any(kw in product_name for kw in tea_keywords) and 'ä¸‹åˆ' in time_slot:
                    return 'ä¸‹åˆèŒ¶'
                
                # é›¶é£Ÿ/ä¼‘é—²å…³é”®è¯
                snack_keywords = ['è–¯ç‰‡', 'ç³–æœ', 'å·§å…‹åŠ›', 'åšæœ', 'ç“œå­', 'é›¶é£Ÿ']
                if any(kw in product_name for kw in snack_keywords):
                    return 'ä¼‘é—²é›¶é£Ÿ'
                
                # æ—¥ç”¨å“å…³é”®è¯
                daily_keywords = ['çº¸å·¾', 'æ´—æ´ç²¾', 'åƒåœ¾è¢‹', 'ç‰™è†', 'æ´—å‘æ°´', 'æ²æµ´éœ²', 'æ´—è¡£æ¶²']
                if any(kw in product_name for kw in daily_keywords):
                    return 'æ—¥ç”¨è¡¥å……'
                
                # åº”æ€¥/çªå‘å…³é”®è¯
                emergency_keywords = ['ç”µæ± ', 'åˆ›å¯è´´', 'è¯', 'æ¶ˆæ¯’', 'å£ç½©', 'å«ç”Ÿå·¾']
                if any(kw in product_name for kw in emergency_keywords):
                    return 'åº”æ€¥è´­ä¹°'
                
                # === 2. åŸºäºå•†å“åˆ†ç±»ï¼ˆä¸­ç­‰ç²¾å‡†ï¼‰===
                
                # çƒŸé…’åˆ†ç±»
                if 'çƒŸé…’' in category_1 or 'çƒŸ' in category_3 or 'é…’' in category_3:
                    if 'æ·±å¤œ' in time_slot or 'æ™šé—´' in time_slot:
                        return 'å¤œé—´ç¤¾äº¤'
                    return 'ç¤¾äº¤å¨±ä¹'
                
                # é¥®æ–™åˆ†ç±»
                if 'é¥®æ–™' in category_1 or 'é¥®å“' in category_3:
                    if 'ä¸‹åˆ' in time_slot:
                        return 'ä¸‹åˆèŒ¶'
                    elif 'æ·±å¤œ' in time_slot or 'æ™šé—´' in time_slot:
                        return 'å¤œé—´é¥®å“'
                    return 'æ—¥å¸¸é¥®å“'
                
                # ä¹³å“åˆ†ç±»
                if 'ä¹³å“' in category_1 or 'å¥¶' in category_3:
                    if 'æ¸…æ™¨' in time_slot:
                        return 'æ—©é¤'
                    return 'è¥å…»è¡¥å……'
                
                # ç²®æ²¹è°ƒå‘³åˆ†ç±»
                if 'ç²®æ²¹' in category_1 or 'è°ƒå‘³' in category_1:
                    return 'å®¶åº­çƒ¹é¥ª'
                
                # ä¼‘é—²é£Ÿå“åˆ†ç±»
                if 'ä¼‘é—²' in category_1 or 'é›¶é£Ÿ' in category_3:
                    return 'ä¼‘é—²é›¶é£Ÿ'
                
                # ä¸ªæŠ¤æ¸…æ´åˆ†ç±»
                if 'ä¸ªæŠ¤' in category_1 or 'æ¸…æ´' in category_1 or 'æ—¥åŒ–' in category_1:
                    return 'æ—¥ç”¨è¡¥å……'
                
                # === 3. åŸºäºæ—¶æ®µï¼ˆå…œåº•æ–¹æ¡ˆï¼‰===
                
                time_to_scene = {
                    'æ¸…æ™¨(6-9ç‚¹)': 'æ—©é¤',
                    'ä¸Šåˆ(9-12ç‚¹)': 'æ—¥å¸¸è´­ç‰©',
                    'æ­£åˆ(12-14ç‚¹)': 'åˆé¤',
                    'ä¸‹åˆ(14-18ç‚¹)': 'ä¸‹åˆèŒ¶',
                    'å‚æ™š(18-21ç‚¹)': 'æ™šé¤',
                    'æ™šé—´(21-24ç‚¹)': 'å±…å®¶æ¶ˆè´¹',
                    'æ·±å¤œ(0-3ç‚¹)': 'å¤œå®µ',
                    'å‡Œæ™¨(3-6ç‚¹)': 'åº”æ€¥è´­ä¹°'
                }
                
                return time_to_scene.get(time_slot, 'æ—¥å¸¸è´­ç‰©')
            
            # åº”ç”¨åœºæ™¯æ¨æ–­
            raw_data['åœºæ™¯'] = raw_data.apply(infer_scene, axis=1)
            
            # ç»Ÿè®¡æ¨æ–­ç»“æœ
            scene_counts = raw_data['åœºæ™¯'].value_counts()
            st.success(f"âœ… å·²æ™ºèƒ½æ¨æ–­åœºæ™¯å­—æ®µï¼ˆå…±è¯†åˆ« {len(scene_counts)} ç§åœºæ™¯ï¼‰")
            
            # æ˜¾ç¤ºåœºæ™¯åˆ†å¸ƒ
            with st.expander("ğŸ“Š æŸ¥çœ‹è‡ªåŠ¨æ¨æ–­çš„åœºæ™¯åˆ†å¸ƒ", expanded=False):
                st.markdown("### åœºæ™¯æ¨æ–­ç»“æœ")
                st.markdown("""
                **æ¨æ–­é€»è¾‘**ï¼š
                1. ğŸ¯ **ä¼˜å…ˆçº§1**ï¼šåŸºäºå•†å“åç§°å…³é”®è¯ï¼ˆæœ€ç²¾å‡†ï¼‰
                2. ğŸ·ï¸ **ä¼˜å…ˆçº§2**ï¼šåŸºäºå•†å“åˆ†ç±»ï¼ˆä¸­ç­‰ç²¾å‡†ï¼‰
                3. â° **ä¼˜å…ˆçº§3**ï¼šåŸºäºæ—¶æ®µï¼ˆå…œåº•æ–¹æ¡ˆï¼‰
                """)
                
                scene_df = pd.DataFrame({
                    'åœºæ™¯': scene_counts.index,
                    'è®¢å•æ•°': scene_counts.values,
                    'å æ¯”': (scene_counts.values / len(raw_data) * 100).round(2)
                })
                scene_df['å æ¯”'] = scene_df['å æ¯”'].astype(str) + '%'
                st.dataframe(scene_df, use_container_width=True)
                
                st.info("""
                ğŸ’¡ **æç¤º**ï¼š
                - å¦‚æœæ¨æ–­ç»“æœä¸å‡†ç¡®ï¼Œå¯ä»¥åœ¨Excelä¸­æ‰‹åŠ¨ä¿®æ­£"åœºæ™¯"åˆ—
                - ç³»ç»Ÿä¼šä¼˜å…ˆä½¿ç”¨æ‚¨æ‰‹åŠ¨æ ‡æ³¨çš„åœºæ™¯æ•°æ®
                - æ™ºèƒ½æ¨æ–­å¯è¦†ç›–90%ä»¥ä¸Šçš„å¸¸è§åœºæ™¯
                """)
                
        except Exception as e:
            st.warning(f"âš ï¸ æ— æ³•è‡ªåŠ¨ç”Ÿæˆåœºæ™¯å­—æ®µ: {e}")
    
    # ğŸ†• åœºæ™¯ç­›é€‰æç¤ºï¼ˆå¦‚æœåœºæ™¯å­—æ®µå·²å­˜åœ¨ï¼‰
    if 'åœºæ™¯' not in raw_data.columns:
        with st.expander("ğŸ’¡ å…³äº'åœºæ™¯'å­—æ®µçš„è¯´æ˜", expanded=False):
            st.markdown("""
            ### æ—¶æ®µ vs åœºæ™¯çš„åŒºåˆ«
            
            **æ—¶æ®µï¼ˆå·²è‡ªåŠ¨ç”Ÿæˆï¼‰**ï¼šåŸºäºæ—¶é—´çš„å®¢è§‚åˆ’åˆ†
            - æ¸…æ™¨(6-9)ã€ä¸Šåˆ(9-12)ã€æ­£åˆ(12-14)ã€ä¸‹åˆ(14-18)
            - å‚æ™š(18-21)ã€æ™šé—´(21-24)ã€æ·±å¤œ(0-3)ã€å‡Œæ™¨(3-6)
            - è‡ªåŠ¨ä»"ä¸‹å•æ—¶é—´"æ¨æ–­ï¼Œæ— éœ€æ‰‹åŠ¨æ·»åŠ 
            
            **åœºæ™¯ï¼ˆéœ€æ‰‹åŠ¨æ ‡æ³¨ï¼‰**ï¼šåŸºäºç”¨æˆ·è¡Œä¸ºçš„ä¸»è§‚æ ‡ç­¾
            - é¤é¥®åœºæ™¯ï¼šæ—©é¤ã€åˆé¤ã€æ™šé¤ã€å¤œå®µã€ä¸‹åˆèŒ¶
            - æ´»åŠ¨åœºæ™¯ï¼šåŠå…¬ã€å±…å®¶ã€å‡ºè¡Œã€åº”æ€¥ã€èšé¤
            - æ¸ é“åœºæ™¯ï¼šå ‚é£Ÿã€å¤–å–ã€è‡ªæã€å›¢è´­
            
            ### å¦‚ä½•æ·»åŠ åœºæ™¯å­—æ®µï¼Ÿ
            
            åœ¨Excelæ•°æ®ä¸­æ·»åŠ "åœºæ™¯"åˆ—ï¼Œç¤ºä¾‹ï¼š
            
            | ä¸‹å•æ—¶é—´ | å•†å“åç§° | **åœºæ™¯** | ä¸šåŠ¡å«ä¹‰ |
            |---------|---------|---------|---------|
            | 08:30 | è±†æµ†æ²¹æ¡ | **æ—©é¤** | æ¸…æ™¨å¿«é¤ |
            | 12:30 | ç›–æµ‡é¥­ | **åˆé¤** | æ­£åˆåˆšéœ€ |
            | 15:00 | å¥¶èŒ¶ | **ä¸‹åˆèŒ¶** | ä¼‘é—²è¡¥å…… |
            | 19:00 | æ±‰å ¡ | **æ™šé¤** | å‚æ™šåˆšéœ€ |
            | 01:30 | æ³¡é¢ | **å¤œå®µ** | æ·±å¤œåº”æ€¥ |
            
            ### æ—¶æ®µçš„å…¸å‹åœºæ™¯æ˜ å°„
            
            ç³»ç»Ÿå·²æ ¹æ®æ‚¨çš„ä¸šåŠ¡ç†è§£è‡ªåŠ¨åˆ’åˆ†æ—¶æ®µï¼Œæ¯ä¸ªæ—¶æ®µå¯¹åº”çš„å…¸å‹åœºæ™¯ï¼š
            - **æ¸…æ™¨(6-9ç‚¹)**ï¼šå‡ºè¡Œ/æ•´ç†/æ—©é¤
            - **ä¸Šåˆ(9-12ç‚¹)**ï¼šåŠå…¬/å±…å®¶/æ—¥ç”¨è¡¥å……
            - **æ­£åˆ(12-14ç‚¹)**ï¼šåˆé¤
            - **ä¸‹åˆ(14-18ç‚¹)**ï¼šå·¥ä½œ/å®¶åŠ¡/äº²å­/å°æ†©/ä¸‹åˆèŒ¶
            - **å‚æ™š(18-21ç‚¹)**ï¼šä¸‹ç­/å½’å®¶/æ™šé¤/è·¯é€”
            - **æ™šé—´(21-24ç‚¹)**ï¼šå±…å®¶/å¤œç”Ÿæ´»å‰
            - **æ·±å¤œ(0-3ç‚¹)**ï¼šçªå‘/æ€¥ç”¨/å¤œå®µ
            - **å‡Œæ™¨(3-6ç‚¹)**ï¼šä¸‡ç±ä¿±å¯‚/ç†¬å¤œå…š
            
            ### ğŸ’¡ ä½¿ç”¨å»ºè®®
            
            - **åªéœ€è¦æ—¶é—´åˆ†æ**ï¼šä½¿ç”¨"æ—¶æ®µç­›é€‰"å³å¯ï¼ˆå·²è‡ªåŠ¨å¯ç”¨ï¼‰
            - **éœ€è¦è¡Œä¸ºåˆ†æ**ï¼šåœ¨Excelä¸­æ·»åŠ "åœºæ™¯"åˆ—ï¼Œå®ç°åŒé‡ç­›é€‰
            """)

    
    st.info("ğŸ” è‡ªåŠ¨è¯Šæ–­è¿è¥é—®é¢˜ï¼Œå¿«é€Ÿå®šä½ä¼˜åŒ–æœºä¼š")
    
    # åˆå§‹åŒ–è¯Šæ–­å¼•æ“
    try:
        diagnostic_engine = ProblemDiagnosticEngine(raw_data)
    except Exception as e:
        st.error(f"âŒ è¯Šæ–­å¼•æ“åˆå§‹åŒ–å¤±è´¥: {str(e)}")
        return
    
    # é¡¶éƒ¨æ§åˆ¶é¢æ¿
    col1, col2, col3 = st.columns([2, 2, 1])
    
    with col1:
        st.markdown("### ğŸ¯ å¿«é€Ÿè¯Šæ–­")
    
    with col2:
        if st.button("ğŸš€ ä¸€é”®ç”Ÿæˆç»¼åˆé—®é¢˜æŠ¥å‘Š", type="primary", use_container_width=True):
            with st.spinner("æ­£åœ¨ç”Ÿæˆç»¼åˆè¯Šæ–­æŠ¥å‘Š..."):
                try:
                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                    output_path = f"é—®é¢˜è¯Šæ–­æŠ¥å‘Š_{timestamp}.xlsx"
                    
                    report = diagnostic_engine.generate_comprehensive_report(output_path)
                    
                    st.success(f"âœ… ç»¼åˆæŠ¥å‘Šå·²ç”Ÿæˆ: {output_path}")
                    
                    # æ˜¾ç¤ºæ‘˜è¦
                    if 'è¯Šæ–­æ‘˜è¦' in report and len(report['è¯Šæ–­æ‘˜è¦']) > 0:
                        st.dataframe(report['è¯Šæ–­æ‘˜è¦'], use_container_width=True)
                    
                    # æä¾›ä¸‹è½½
                    if os.path.exists(output_path):
                        with open(output_path, 'rb') as f:
                            st.download_button(
                                label="â¬‡ï¸ ä¸‹è½½å®Œæ•´è¯Šæ–­æŠ¥å‘Š",
                                data=f,
                                file_name=output_path,
                                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                            )
                except Exception as e:
                    st.error(f"âŒ æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {str(e)}")
    
    with col3:
        total_orders = raw_data['è®¢å•ID'].nunique()
        st.metric("æ€»è®¢å•æ•°", f"{total_orders:,}")
    
    st.markdown("---")
    
    # è¯Šæ–­æ ‡ç­¾é¡µ
    diagnostic_tabs = st.tabs([
        "ğŸ“‰ é”€é‡ä¸‹æ»‘",
        "ğŸ’° å®¢å•ä»·å½’å› ",
        "ğŸš¨ è´Ÿæ¯›åˆ©é¢„è­¦",
        "ğŸšš é«˜é…é€è´¹",
        "âš–ï¸ è§’è‰²å¤±è¡¡",
        "ğŸ“Š å¼‚å¸¸æ³¢åŠ¨"
    ])
    
    # Tab 1: é”€é‡ä¸‹æ»‘è¯Šæ–­
    with diagnostic_tabs[0]:
        st.markdown("### ğŸ“‰ é”€é‡ä¸‹æ»‘å•†å“è¯Šæ–­")
        
        # ç¬¬ä¸€è¡Œï¼šåŸºç¡€é…ç½®
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            time_period = st.selectbox(
                "å¯¹æ¯”å‘¨æœŸ",
                ["day", "week", "month"],
                format_func=lambda x: "æŒ‰æ—¥å¯¹æ¯”" if x == "day" else ("æŒ‰å‘¨å¯¹æ¯”" if x == "week" else "æŒ‰æœˆå¯¹æ¯”"),
                key="decline_period"
            )
        
        with col2:
            threshold = st.slider(
                "ä¸‹æ»‘é˜ˆå€¼%",
                min_value=-80.0,
                max_value=-5.0,
                value=-20.0,
                step=5.0,
                key="decline_threshold"
            )
        
        with col3:
            scene_options = []
            if 'åœºæ™¯' in raw_data.columns:
                scene_options = ['å…¨éƒ¨åœºæ™¯'] + sorted(raw_data['åœºæ™¯'].dropna().unique().tolist())
            scene_filter = st.multiselect(
                "åœºæ™¯ç­›é€‰",
                scene_options,
                default=['å…¨éƒ¨åœºæ™¯'] if scene_options else [],
                key="decline_scene"
            )
        
        with col4:
            time_slot_options = []
            if 'æ—¶æ®µ' in raw_data.columns:
                time_slot_options = ['å…¨éƒ¨æ—¶æ®µ'] + sorted(raw_data['æ—¶æ®µ'].dropna().unique().tolist())
            time_slot_filter = st.multiselect(
                "æ—¶æ®µç­›é€‰",
                time_slot_options,
                default=['å…¨éƒ¨æ—¶æ®µ'] if time_slot_options else [],
                key="decline_timeslot"
            )
        
        # ç¬¬äºŒè¡Œï¼šå‘¨æœŸé€‰æ‹©å™¨ï¼ˆæ–°åŠŸèƒ½ï¼‰
        st.markdown("---")
        st.markdown("#### ğŸ“… è‡ªå®šä¹‰å‘¨æœŸå¯¹æ¯”")
        
        # è·å–å¯ç”¨å‘¨æœŸåˆ—è¡¨
        try:
            available_periods = diagnostic_engine.get_available_periods(time_period)
            
            if len(available_periods) >= 2:
                col5, col6, col7 = st.columns([2, 2, 1])
                
                with col5:
                    # å½“å‰å‘¨æœŸé€‰æ‹©
                    current_options = {p['label']: p['index'] for p in available_periods}
                    current_label = st.selectbox(
                        "ğŸ“ å½“å‰å‘¨æœŸ",
                        options=list(current_options.keys()),
                        index=0,
                        key="current_period_selector",
                        help="é€‰æ‹©è¦åˆ†æçš„å½“å‰å‘¨æœŸ"
                    )
                    current_period_index = current_options[current_label]
                    
                    # æ˜¾ç¤ºæ—¥æœŸèŒƒå›´
                    current_period_info = next(p for p in available_periods if p['index'] == current_period_index)
                    st.caption(f"ğŸ“† {current_period_info['date_range']}")
                
                with col6:
                    # å¯¹æ¯”å‘¨æœŸé€‰æ‹©
                    compare_label = st.selectbox(
                        "ğŸ“ å¯¹æ¯”å‘¨æœŸ",
                        options=list(current_options.keys()),
                        index=1,
                        key="compare_period_selector",
                        help="é€‰æ‹©è¦å¯¹æ¯”çš„å†å²å‘¨æœŸ"
                    )
                    compare_period_index = current_options[compare_label]
                    
                    # æ˜¾ç¤ºæ—¥æœŸèŒƒå›´
                    compare_period_info = next(p for p in available_periods if p['index'] == compare_period_index)
                    st.caption(f"ğŸ“† {compare_period_info['date_range']}")
                
                with col7:
                    st.markdown("<br>", unsafe_allow_html=True)
                    use_custom_period = st.checkbox("å¯ç”¨è‡ªå®šä¹‰", value=False, key="use_custom_period")
            else:
                st.warning("âš ï¸ æ•°æ®æ—¶é—´èŒƒå›´ä¸è¶³ï¼Œæ— æ³•è¿›è¡Œå‘¨æœŸå¯¹æ¯”åˆ†æ")
                use_custom_period = False
                current_period_index = None
                compare_period_index = None
        except Exception as e:
            st.warning(f"âš ï¸ æ— æ³•è·å–å‘¨æœŸåˆ—è¡¨: {str(e)}")
            use_custom_period = False
            current_period_index = None
            compare_period_index = None
        
        st.markdown("---")
        
        if st.button("ğŸ” å¼€å§‹è¯Šæ–­", key="btn_decline"):
            with st.spinner("æ­£åœ¨åˆ†æé”€é‡ä¸‹æ»‘å•†å“..."):
                try:
                    # å¤„ç†ç­›é€‰æ¡ä»¶
                    scene_list = None if 'å…¨éƒ¨åœºæ™¯' in scene_filter else [s for s in scene_filter if s != 'å…¨éƒ¨åœºæ™¯']
                    slot_list = None if 'å…¨éƒ¨æ—¶æ®µ' in time_slot_filter else [s for s in time_slot_filter if s != 'å…¨éƒ¨æ—¶æ®µ']
                    
                    # æ„å»ºå‚æ•°ï¼ˆæ ¹æ®æ˜¯å¦å¯ç”¨è‡ªå®šä¹‰å‘¨æœŸï¼‰
                    diagnose_params = {
                        'time_period': time_period,
                        'threshold': threshold,
                        'scene_filter': scene_list,
                        'time_slot_filter': slot_list
                    }
                    
                    # å¦‚æœå¯ç”¨è‡ªå®šä¹‰å‘¨æœŸï¼Œæ·»åŠ å‘¨æœŸå‚æ•°
                    if use_custom_period and current_period_index is not None and compare_period_index is not None:
                        diagnose_params['current_period_index'] = current_period_index
                        diagnose_params['compare_period_index'] = compare_period_index
                        st.info(f"ğŸ“Š å¯¹æ¯”å‘¨æœŸ: {current_label} vs {compare_label}")
                    
                    result = diagnostic_engine.diagnose_sales_decline(**diagnose_params)
                    
                    if len(result) > 0:
                        st.success(f"âœ… å‘ç° {len(result)} ä¸ªé”€é‡ä¸‹æ»‘å•†å“")
                        
                        # ğŸ¨ å¯è§†åŒ–çœ‹æ¿åŒºåŸŸ
                        st.markdown("---")
                        st.markdown("## ğŸ“Š å¯è§†åŒ–åˆ†æçœ‹æ¿")
                        
                        # å‡†å¤‡å¯è§†åŒ–æ•°æ®ï¼ˆéœ€è¦åŸå§‹æ•°å€¼ï¼Œè€Œéæ ¼å¼åŒ–åçš„å­—ç¬¦ä¸²ï¼‰
                        viz_df = result.copy()
                        
                        # è§£ææ ¼å¼åŒ–çš„æ•°å€¼åˆ—ï¼ˆç”¨äºå¯è§†åŒ–ï¼‰
                        def parse_number(val):
                            """è§£æå¸¦æ ¼å¼çš„æ•°å€¼ï¼ˆå¦‚Â¥1234.5, -50.0%ï¼‰"""
                            if pd.isna(val):
                                return 0
                            if isinstance(val, (int, float)):
                                return float(val)
                            # è½¬æ¢ä¸ºå­—ç¬¦ä¸²å¹¶æ¸…ç†
                            val_str = str(val)
                            # ç§»é™¤æ‰€æœ‰éæ•°å­—å­—ç¬¦ï¼ˆä¿ç•™è´Ÿå·ã€å°æ•°ç‚¹ï¼‰
                            val_str = val_str.replace('Â¥', '').replace('%', '').replace(',', '').replace('N/A', '0')
                            # å¤„ç†é‡å¤çš„å€¼ï¼ˆå¦‚ 'Â¥6.4Â¥6.4' -> '6.46.4'ï¼‰
                            # å¦‚æœå­—ç¬¦ä¸²ä¸­é—´æœ‰é‡å¤ï¼Œå–ç¬¬ä¸€ä¸ªæœ‰æ•ˆæ•°å­—
                            parts = val_str.split()
                            if len(parts) > 0:
                                val_str = parts[0]
                            try:
                                return float(val_str)
                            except:
                                # å¦‚æœè¿˜æ˜¯è§£æå¤±è´¥ï¼Œå°è¯•æå–ç¬¬ä¸€ä¸ªæ•°å­—
                                import re
                                match = re.search(r'-?\d+\.?\d*', val_str)
                                if match:
                                    return float(match.group())
                                return 0
                        
                        # è§£æå„åˆ—æ•°å€¼
                        for col in viz_df.columns:
                            if any(keyword in col for keyword in ['é”€é‡', 'æ”¶å…¥', 'ä»·æ ¼', 'å¹…åº¦', 'æ¯›åˆ©']):
                                viz_df[col] = viz_df[col].apply(parse_number)
                        
                        # ğŸ†• æ™ºèƒ½è®¡ç®—å¹³å‡æ¯›åˆ©ç‡ï¼ˆå¦‚æœæ•°æ®ä¸­æ²¡æœ‰ï¼‰
                        if 'å¹³å‡æ¯›åˆ©ç‡%' not in viz_df.columns or viz_df['å¹³å‡æ¯›åˆ©ç‡%'].isna().all():
                            # å°è¯•ä»åŸå§‹æ•°æ®è®¡ç®—
                            if 'å•†å“åç§°' in viz_df.columns and 'å•†å“åç§°' in raw_data.columns:
                                # è®¡ç®—æ¯ä¸ªå•†å“çš„å¹³å‡æ¯›åˆ©ç‡
                                profit_margins = []
                                
                                for product_name in viz_df['å•†å“åç§°']:
                                    product_data = raw_data[raw_data['å•†å“åç§°'] == product_name]
                                    
                                    if len(product_data) > 0:
                                        # å°è¯•å¤šç§æ–¹å¼è®¡ç®—æ¯›åˆ©ç‡
                                        margin = None
                                        
                                        # æ–¹å¼1: ä½¿ç”¨åˆ©æ¶¦é¢å’Œè®¢å•é›¶å”®é¢
                                        if 'åˆ©æ¶¦é¢' in product_data.columns and 'è®¢å•é›¶å”®é¢' in product_data.columns:
                                            total_profit = product_data['åˆ©æ¶¦é¢'].sum()
                                            total_revenue = product_data['è®¢å•é›¶å”®é¢'].sum()
                                            if total_revenue > 0:
                                                margin = (total_profit / total_revenue) * 100
                                        
                                        # æ–¹å¼2: ä½¿ç”¨å•†å“å®å”®ä»·å’Œæˆæœ¬
                                        if margin is None and 'å•†å“å®å”®ä»·' in product_data.columns:
                                            # å‡è®¾æˆæœ¬ä¸ºå”®ä»·çš„60%ï¼ˆå¦‚æœæ²¡æœ‰æ˜ç¡®æˆæœ¬å­—æ®µï¼‰
                                            avg_price = product_data['å•†å“å®å”®ä»·'].mean()
                                            if pd.notna(avg_price) and avg_price > 0:
                                                # å°è¯•ä»å…¶ä»–å­—æ®µæ¨æ–­æˆæœ¬
                                                if 'å•†å“æˆæœ¬' in product_data.columns:
                                                    avg_cost = product_data['å•†å“æˆæœ¬'].mean()
                                                elif 'è¿›è´§ä»·' in product_data.columns:
                                                    avg_cost = product_data['è¿›è´§ä»·'].mean()
                                                else:
                                                    # ä¼°ç®—ï¼šå‡è®¾å¹³å‡æ¯›åˆ©ç‡30%
                                                    avg_cost = avg_price * 0.7
                                                
                                                if pd.notna(avg_cost) and avg_cost > 0:
                                                    margin = ((avg_price - avg_cost) / avg_price) * 100
                                        
                                        profit_margins.append(margin if margin is not None else 30.0)  # é»˜è®¤30%
                                    else:
                                        profit_margins.append(30.0)  # é»˜è®¤30%
                                
                                viz_df['å¹³å‡æ¯›åˆ©ç‡%'] = profit_margins
                                st.info("ğŸ’¡ **æ™ºèƒ½è®¡ç®—**: å·²æ ¹æ®åŸå§‹æ•°æ®è‡ªåŠ¨è®¡ç®—å•†å“çš„å¹³å‡æ¯›åˆ©ç‡")
                        
                        # åŠ¨æ€è·å–åˆ—å
                        sales_cols = [col for col in viz_df.columns if 'é”€é‡' in col and col != 'é”€é‡å˜åŒ–']
                        
                        # ç¡®ä¿æœ‰åºï¼ˆé€šå¸¸ç¬¬ä¸€ä¸ªæ˜¯å¯¹æ¯”å‘¨æœŸï¼Œç¬¬äºŒä¸ªæ˜¯å½“å‰å‘¨æœŸï¼‰
                        if len(sales_cols) >= 2:
                            compare_sales_col = sales_cols[0]  # ç¬¬ä¸€ä¸ªé”€é‡åˆ—ï¼ˆå¯¹æ¯”å‘¨æœŸï¼‰
                            current_sales_col = sales_cols[1]  # ç¬¬äºŒä¸ªé”€é‡åˆ—ï¼ˆå½“å‰å‘¨æœŸï¼‰
                            
                            # è°ƒè¯•ä¿¡æ¯
                            st.info(f"ğŸ” **æ•°æ®åˆ—ä¿¡æ¯**: æ£€æµ‹åˆ° {len(sales_cols)} ä¸ªé”€é‡åˆ—\n- å¯¹æ¯”å‘¨æœŸ: {compare_sales_col}\n- å½“å‰å‘¨æœŸ: {current_sales_col}")
                        elif len(sales_cols) == 1:
                            current_sales_col = sales_cols[0]
                            compare_sales_col = None
                            st.warning(f"âš ï¸ åªæ£€æµ‹åˆ°1ä¸ªé”€é‡åˆ—: {current_sales_col}ï¼Œæ— æ³•è¿›è¡Œå‘¨æœŸå¯¹æ¯”")
                        else:
                            current_sales_col = None
                            compare_sales_col = None
                            st.error("âŒ æœªæ£€æµ‹åˆ°é”€é‡åˆ—ï¼Œæ— æ³•è¿›è¡Œåˆ†æ")
                        
                        revenue_cols = [col for col in viz_df.columns if 'æ”¶å…¥' in col]
                        current_revenue_col = revenue_cols[0] if len(revenue_cols) > 0 else None
                        compare_revenue_col = revenue_cols[1] if len(revenue_cols) > 1 else None
                        
                        # è®¡ç®—æ´¾ç”ŸæŒ‡æ ‡
                        viz_df['æ”¶å…¥å˜åŒ–'] = 0
                        if current_revenue_col and compare_revenue_col:
                            viz_df['æ”¶å…¥å˜åŒ–'] = viz_df[current_revenue_col] - viz_df[compare_revenue_col]
                        
                        viz_df['åˆ©æ¶¦å˜åŒ–'] = 0
                        if 'å¹³å‡æ¯›åˆ©ç‡%' in viz_df.columns and 'æ”¶å…¥å˜åŒ–' in viz_df.columns:
                            viz_df['åˆ©æ¶¦å˜åŒ–'] = viz_df['æ”¶å…¥å˜åŒ–'] * (viz_df['å¹³å‡æ¯›åˆ©ç‡%'] / 100)
                        
                        # === 1. æ ¸å¿ƒæŒ‡æ ‡å¡ç‰‡ ===
                        st.markdown("### ğŸ“ˆ æ ¸å¿ƒæŒ‡æ ‡æ¦‚è§ˆ")
                        kpi_col1, kpi_col2, kpi_col3, kpi_col4 = st.columns(4)
                        
                        with kpi_col1:
                            decline_count = len(viz_df)
                            st.metric(
                                label="ğŸ“‰ ä¸‹æ»‘å•†å“æ•°",
                                value=f"{decline_count} ä¸ª",
                                delta=None,
                                help="é”€é‡ä¸‹æ»‘çš„å•†å“æ€»æ•°"
                            )
                        
                        with kpi_col2:
                            total_sales_loss = int(viz_df['é”€é‡å˜åŒ–'].sum())
                            st.metric(
                                label="ğŸ“¦ é”€é‡æŸå¤±",
                                value=f"{total_sales_loss} å•",
                                delta=None,
                                help="æ€»é”€é‡å‡å°‘æ•°é‡"
                            )
                        
                        with kpi_col3:
                            total_revenue_loss = viz_df['æ”¶å…¥å˜åŒ–'].sum()
                            st.metric(
                                label="ğŸ’¸ æ”¶å…¥æŸå¤±",
                                value=f"Â¥{total_revenue_loss:,.0f}",
                                delta=f"{total_revenue_loss:.0f}",
                                delta_color="inverse",
                                help="æ€»æ”¶å…¥å‡å°‘é‡‘é¢"
                            )
                        
                        with kpi_col4:
                            total_profit_loss = viz_df['åˆ©æ¶¦å˜åŒ–'].sum()
                            st.metric(
                                label="ğŸ’° åˆ©æ¶¦æŸå¤±",
                                value=f"Â¥{total_profit_loss:,.0f}",
                                delta=f"{total_profit_loss:.0f}",
                                delta_color="inverse",
                                help="æ€»åˆ©æ¶¦å‡å°‘é‡‘é¢"
                            )
                        
                        st.markdown("---")
                        
                        # === 2. å›¾è¡¨åŒºåŸŸï¼ˆå·¦å³åˆ†æ ï¼‰===
                        chart_col_left, chart_col_right = st.columns([1, 1])
                        
                        with chart_col_left:
                            # === å›¾è¡¨1: æ—¶æ®µä¸‹æ»‘åˆ†æ ===
                            if 'æ—¶æ®µ' in raw_data.columns and time_slot_filter and 'å…¨éƒ¨æ—¶æ®µ' in time_slot_filter:
                                st.markdown("#### â° åˆ†æ—¶æ®µä¸‹æ»‘åˆ†æ")
                                
                                # é‡æ–°æŒ‰æ—¶æ®µç»Ÿè®¡ï¼ˆä½¿ç”¨åŸå§‹æ•°æ®ï¼‰
                                time_slot_stats = []
                                for slot in sorted(raw_data['æ—¶æ®µ'].dropna().unique()):
                                    slot_result = diagnostic_engine.diagnose_sales_decline(
                                        time_period=time_period,
                                        threshold=threshold,
                                        scene_filter=scene_list,
                                        time_slot_filter=[slot],
                                        current_period_index=current_period_index if use_custom_period else None,
                                        compare_period_index=compare_period_index if use_custom_period else None
                                    )
                                    
                                    if len(slot_result) > 0:
                                        # è§£ææ•°å€¼
                                        slot_viz = slot_result.copy()
                                        for col in slot_viz.columns:
                                            if any(kw in col for kw in ['é”€é‡', 'æ”¶å…¥', 'å¹…åº¦', 'æ¯›åˆ©']):
                                                slot_viz[col] = slot_viz[col].apply(parse_number)
                                        
                                        slot_revenue_loss = 0
                                        slot_revenue_cols = [col for col in slot_viz.columns if 'æ”¶å…¥' in col]
                                        if len(slot_revenue_cols) >= 2:
                                            slot_revenue_loss = (slot_viz[slot_revenue_cols[0]] - slot_viz[slot_revenue_cols[1]]).sum()
                                        
                                        time_slot_stats.append({
                                            'æ—¶æ®µ': slot,
                                            'ä¸‹æ»‘å•†å“æ•°': len(slot_result),
                                            'é”€é‡æŸå¤±': int(slot_viz['é”€é‡å˜åŒ–'].sum()),
                                            'æ”¶å…¥æŸå¤±': slot_revenue_loss,
                                            'åˆ©æ¶¦æŸå¤±': (slot_revenue_loss * slot_viz['å¹³å‡æ¯›åˆ©ç‡%'].mean() / 100) if 'å¹³å‡æ¯›åˆ©ç‡%' in slot_viz.columns else 0
                                        })
                                
                                if time_slot_stats:
                                    time_slot_df = pd.DataFrame(time_slot_stats)
                                    
                                    # æŒ‡æ ‡é€‰æ‹©å™¨ï¼ˆä¸ä½¿ç”¨formï¼Œä¿æŒå³æ—¶å“åº”ï¼‰
                                    slot_metric = st.selectbox(
                                        "é€‰æ‹©æŒ‡æ ‡",
                                        ['ä¸‹æ»‘å•†å“æ•°', 'é”€é‡æŸå¤±', 'æ”¶å…¥æŸå¤±', 'åˆ©æ¶¦æŸå¤±'],
                                        key='slot_metric_selector'
                                    )
                                    
                                    # å‡†å¤‡æ˜¾ç¤ºæ•°æ®ï¼ˆæŸå¤±ç±»æŒ‡æ ‡å–ç»å¯¹å€¼ï¼‰
                                    display_values = time_slot_df[slot_metric].copy()
                                    if 'æŸå¤±' in slot_metric:
                                        display_values = display_values.abs()
                                    
                                    # æŸ±çŠ¶å›¾ï¼ˆæ‰€æœ‰æŒ‡æ ‡ç»Ÿä¸€ç”¨çº¢è‰²ï¼Œå› ä¸ºéƒ½æ˜¯è´Ÿé¢æŒ‡æ ‡ï¼‰
                                    fig_slot = go.Figure()
                                    
                                    fig_slot.add_trace(go.Bar(
                                        x=time_slot_df['æ—¶æ®µ'],
                                        y=display_values,
                                        marker_color='#d32f2f',
                                        text=display_values.apply(lambda x: f"{x:,.0f}"),
                                        textposition='auto',
                                        hovertemplate='<b>%{x}</b><br>' + slot_metric + ': %{y:,.0f}<extra></extra>'
                                    ))
                                    
                                    # Yè½´æ ‡é¢˜
                                    y_title = slot_metric
                                    if slot_metric == 'é”€é‡æŸå¤±':
                                        y_title = 'é”€é‡æŸå¤±ï¼ˆå•ï¼‰'
                                    elif slot_metric in ['æ”¶å…¥æŸå¤±', 'åˆ©æ¶¦æŸå¤±']:
                                        y_title = slot_metric + 'ï¼ˆå…ƒï¼‰'
                                    
                                    fig_slot.update_layout(
                                        title=f"å„æ—¶æ®µ{slot_metric}åˆ†å¸ƒ",
                                        xaxis_title="æ—¶æ®µ",
                                        yaxis_title=y_title,
                                        template='plotly_white',
                                        height=350,
                                        font=dict(family='Microsoft YaHei', size=11),
                                        showlegend=False
                                    )
                                    
                                    st.plotly_chart(fig_slot, use_container_width=True)
                                    
                                    # æ˜¾ç¤ºæ€»è®¡
                                    total_value = time_slot_df[slot_metric].sum()
                                    if 'æŸå¤±' in slot_metric:
                                        st.info(f"ğŸ’¡ **æ€»è®¡**: {slot_metric} = {abs(total_value):,.0f} {'å…ƒ' if 'æ”¶å…¥' in slot_metric or 'åˆ©æ¶¦' in slot_metric else 'å•'}")
                                    else:
                                        st.info(f"ğŸ’¡ **æ€»è®¡**: {slot_metric} = {total_value:,.0f} ä¸ª")
                            
                            # === å›¾è¡¨2: åœºæ™¯ä¸‹æ»‘åˆ†æï¼ˆé¥¼å›¾ï¼‰===
                            if 'åœºæ™¯' in raw_data.columns and scene_filter and 'å…¨éƒ¨åœºæ™¯' in scene_filter:
                                st.markdown("#### ğŸ­ åˆ†åœºæ™¯ä¸‹æ»‘åˆ†å¸ƒ")
                                
                                # é‡æ–°æŒ‰åœºæ™¯ç»Ÿè®¡
                                scene_stats = []
                                for scene in sorted(raw_data['åœºæ™¯'].dropna().unique()):
                                    scene_result = diagnostic_engine.diagnose_sales_decline(
                                        time_period=time_period,
                                        threshold=threshold,
                                        scene_filter=[scene],
                                        time_slot_filter=slot_list,
                                        current_period_index=current_period_index if use_custom_period else None,
                                        compare_period_index=compare_period_index if use_custom_period else None
                                    )
                                    
                                    if len(scene_result) > 0:
                                        scene_stats.append({
                                            'åœºæ™¯': scene,
                                            'å•†å“æ•°': len(scene_result)
                                        })
                                
                                if scene_stats:
                                    scene_df = pd.DataFrame(scene_stats)
                                    
                                    fig_scene = go.Figure(go.Pie(
                                        labels=scene_df['åœºæ™¯'],
                                        values=scene_df['å•†å“æ•°'],
                                        hole=0.4,
                                        marker=dict(colors=['#d32f2f', '#f57c00', '#fbc02d', '#388e3c', '#1976d2']),
                                        textinfo='label+percent',
                                        hovertemplate='<b>%{label}</b><br>å•†å“æ•°: %{value}<br>å æ¯”: %{percent}<extra></extra>'
                                    ))
                                    
                                    fig_scene.update_layout(
                                        title="å„åœºæ™¯ä¸‹æ»‘å•†å“å æ¯”",
                                        template='plotly_white',
                                        height=350,
                                        font=dict(family='Microsoft YaHei', size=11)
                                    )
                                    
                                    st.plotly_chart(fig_scene, use_container_width=True)
                            
                            # === å›¾è¡¨3: ä¸€çº§åˆ†ç±»TOP5 ===
                            if 'ä¸€çº§åˆ†ç±»å' in viz_df.columns:
                                st.markdown("#### ğŸ“¦ å“ç±»ä¸‹æ»‘TOP5")
                                
                                category_stats = viz_df.groupby('ä¸€çº§åˆ†ç±»å').agg({
                                    'å•†å“åç§°': 'count',
                                    'æ”¶å…¥å˜åŒ–': 'sum'
                                }).rename(columns={'å•†å“åç§°': 'å•†å“æ•°'})
                                
                                category_stats = category_stats.sort_values('æ”¶å…¥å˜åŒ–').head(5)
                                
                                fig_category = go.Figure(go.Bar(
                                    x=category_stats['æ”¶å…¥å˜åŒ–'].abs(),
                                    y=category_stats.index,
                                    orientation='h',
                                    marker_color='coral',
                                    text=category_stats['æ”¶å…¥å˜åŒ–'].apply(lambda x: f"Â¥{abs(x):,.0f}"),
                                    textposition='auto',
                                    hovertemplate='<b>%{y}</b><br>æ”¶å…¥æŸå¤±: Â¥%{x:,.0f}<br>å•†å“æ•°: %{customdata}<extra></extra>',
                                    customdata=category_stats['å•†å“æ•°']
                                ))
                                
                                fig_category.update_layout(
                                    title="æ”¶å…¥æŸå¤±æœ€å¤§çš„5ä¸ªå“ç±»",
                                    xaxis_title="æ”¶å…¥æŸå¤±ï¼ˆå…ƒï¼‰",
                                    yaxis_title="å“ç±»",
                                    template='plotly_white',
                                    height=350,
                                    font=dict(family='Microsoft YaHei', size=11),
                                    showlegend=False
                                )
                                
                                st.plotly_chart(fig_category, use_container_width=True)
                        
                        with chart_col_right:
                            # === å›¾è¡¨4: å„åˆ†ç±»ä¸‹æ»‘TOPå•†å“ ===
                            st.markdown("#### ğŸ”» å„åˆ†ç±»ä¸‹æ»‘TOPå•†å“")
                            
                            if 'ä¸€çº§åˆ†ç±»å' in viz_df.columns:
                                # æŒ‰åˆ†ç±»é€‰æ‹©TOPå•†å“
                                category_top_products = []
                                for category in viz_df['ä¸€çº§åˆ†ç±»å'].unique():
                                    category_df = viz_df[viz_df['ä¸€çº§åˆ†ç±»å'] == category]
                                    # æ¯ä¸ªåˆ†ç±»å–ä¸‹æ»‘æœ€ä¸¥é‡çš„å‰3ä¸ªå•†å“
                                    top3 = category_df.nsmallest(3, 'å˜åŒ–å¹…åº¦%')
                                    for _, row in top3.iterrows():
                                        category_top_products.append({
                                            'åˆ†ç±»': category,
                                            'å•†å“åç§°': row['å•†å“åç§°'],
                                            'å˜åŒ–å¹…åº¦%': row['å˜åŒ–å¹…åº¦%'],
                                            'é”€é‡å˜åŒ–': row['é”€é‡å˜åŒ–']
                                        })
                                
                                if category_top_products:
                                    category_top_df = pd.DataFrame(category_top_products)
                                    # é™åˆ¶æœ€å¤šæ˜¾ç¤º10ä¸ª
                                    category_top_df = category_top_df.head(10)
                                    
                                    # æ·»åŠ åˆ†ç±»æ ‡ç­¾åˆ°å•†å“åç§°
                                    category_top_df['æ˜¾ç¤ºåç§°'] = category_top_df.apply(
                                        lambda x: f"[{x['åˆ†ç±»']}] {x['å•†å“åç§°']}", axis=1
                                    )
                                    
                                    # é¢œè‰²æ˜ å°„ï¼ˆä¸‹æ»‘è¶Šä¸¥é‡é¢œè‰²è¶Šæ·±ï¼‰
                                    colors_top = category_top_df['å˜åŒ–å¹…åº¦%'].apply(
                                        lambda x: '#8b0000' if x <= -50 else ('#d32f2f' if x <= -30 else '#f57c00')
                                    )
                                    
                                    fig_top = go.Figure(go.Bar(
                                        x=category_top_df['å˜åŒ–å¹…åº¦%'],
                                        y=category_top_df['æ˜¾ç¤ºåç§°'],
                                        orientation='h',
                                        marker_color=colors_top,
                                        text=category_top_df.apply(
                                            lambda x: f"{x['å˜åŒ–å¹…åº¦%']:.1f}% ({int(x['é”€é‡å˜åŒ–'])}å•)",
                                            axis=1
                                        ),
                                        textposition='auto',
                                        hovertemplate='<b>%{y}</b><br>å˜åŒ–å¹…åº¦: %{x:.1f}%<extra></extra>'
                                    ))
                                    
                                    fig_top.update_layout(
                                        title="æ¯ä¸ªåˆ†ç±»ä¸‹æ»‘æœ€ä¸¥é‡çš„å•†å“ï¼ˆæ¯ç±»TOP3ï¼‰",
                                        xaxis_title="å˜åŒ–å¹…åº¦ï¼ˆ%ï¼‰",
                                        yaxis_title="å•†å“",
                                        template='plotly_white',
                                        height=400,  # å¢åŠ é«˜åº¦ä»¥å®¹çº³æ›´å¤šå•†å“
                                        font=dict(family='Microsoft YaHei', size=10),
                                        showlegend=False
                                    )
                                    
                                    st.plotly_chart(fig_top, use_container_width=True)
                                    
                                    st.info("ğŸ’¡ **é˜…è¯»æç¤º**: æŒ‰åˆ†ç±»å±•ç¤ºï¼Œæ¯ä¸ªåˆ†ç±»æ˜¾ç¤ºä¸‹æ»‘æœ€ä¸¥é‡çš„3ä¸ªå•†å“ï¼Œé¢œè‰²è¶Šæ·±=ä¸‹æ»‘è¶Šä¸¥é‡")
                                else:
                                    st.warning("âš ï¸ æš‚æ— åˆ†ç±»ä¸‹æ»‘æ•°æ®")
                            else:
                                # é™çº§æ–¹æ¡ˆï¼šå¦‚æœæ²¡æœ‰åˆ†ç±»ï¼Œæ˜¾ç¤ºå…¨å±€TOP10
                                st.markdown("#### ğŸ”» ä¸‹æ»‘æœ€ä¸¥é‡TOP10")
                                
                                top10_decline = viz_df.nsmallest(10, 'å˜åŒ–å¹…åº¦%')
                                
                                colors_top10 = top10_decline['å˜åŒ–å¹…åº¦%'].apply(
                                    lambda x: '#8b0000' if x <= -50 else ('#d32f2f' if x <= -30 else '#f57c00')
                                )
                                
                                fig_top10 = go.Figure(go.Bar(
                                    x=top10_decline['å˜åŒ–å¹…åº¦%'],
                                    y=top10_decline['å•†å“åç§°'],
                                    orientation='h',
                                    marker_color=colors_top10,
                                    text=top10_decline.apply(
                                        lambda x: f"{x['å˜åŒ–å¹…åº¦%']:.1f}% ({int(x['é”€é‡å˜åŒ–'])}å•)",
                                        axis=1
                                    ),
                                    textposition='auto',
                                    hovertemplate='<b>%{y}</b><br>å˜åŒ–å¹…åº¦: %{x:.1f}%<extra></extra>'
                                ))
                                
                                fig_top10.update_layout(
                                    title="ä¸‹æ»‘å¹…åº¦æœ€å¤§çš„10ä¸ªå•†å“",
                                    xaxis_title="å˜åŒ–å¹…åº¦ï¼ˆ%ï¼‰",
                                    yaxis_title="å•†å“",
                                    template='plotly_white',
                                    height=350,
                                    font=dict(family='Microsoft YaHei', size=11),
                                    showlegend=False
                                )
                                
                                st.plotly_chart(fig_top10, use_container_width=True)
                                
                                st.info("ğŸ’¡ **é˜…è¯»æç¤º**: æ¨ªå‘æŸ±çŠ¶å›¾ï¼Œé¢œè‰²è¶Šæ·±=ä¸‹æ»‘è¶Šä¸¥é‡ï¼ˆæ·±çº¢â‰¥50%ï¼Œçº¢è‰²â‰¥30%ï¼‰")
                            
                            # === å›¾è¡¨5: æ”¶å…¥æŸå¤±TOP10 ===
                            st.markdown("#### ğŸ’¸ æ”¶å…¥æŸå¤±TOP10")
                            
                            top10_revenue = viz_df.nsmallest(10, 'æ”¶å…¥å˜åŒ–')
                            
                            fig_revenue = go.Figure(go.Waterfall(
                                name="æ”¶å…¥æŸå¤±",
                                orientation="v",
                                x=top10_revenue['å•†å“åç§°'],
                                y=top10_revenue['æ”¶å…¥å˜åŒ–'].abs(),
                                connector={"line": {"color": "rgb(63, 63, 63)"}},
                                decreasing={"marker": {"color": "#d32f2f"}},
                                text=top10_revenue['æ”¶å…¥å˜åŒ–'].apply(lambda x: f"Â¥{abs(x):,.0f}"),
                                textposition='auto',
                                hovertemplate='<b>%{x}</b><br>æ”¶å…¥æŸå¤±: Â¥%{y:,.0f}<extra></extra>'
                            ))
                            
                            fig_revenue.update_layout(
                                title="æ”¶å…¥æŸå¤±ç´¯ç§¯ç€‘å¸ƒå›¾",
                                xaxis_title="å•†å“",
                                yaxis_title="æ”¶å…¥æŸå¤±ï¼ˆå…ƒï¼‰",
                                template='plotly_white',
                                height=350,
                                font=dict(family='Microsoft YaHei', size=11),
                                showlegend=False
                            )
                            
                            st.plotly_chart(fig_revenue, use_container_width=True)
                            
                            # === å›¾è¡¨6: å‘¨æœŸå¯¹æ¯” ===
                            if current_sales_col and compare_sales_col:
                                st.markdown("#### ğŸ“Š å‘¨æœŸé”€é‡å¯¹æ¯”ï¼ˆTOP10ä¸‹æ»‘å•†å“ï¼‰")
                                
                                top10_compare = viz_df.nsmallest(10, 'å˜åŒ–å¹…åº¦%')
                                
                                # æå–å‘¨æœŸåç§°ï¼ˆå»æ‰"é”€é‡"ä¸¤ä¸ªå­—ï¼Œä¿ç•™å‘¨æœŸæ ‡è¯†ï¼‰
                                current_label = current_sales_col.replace('é”€é‡', '').strip()
                                compare_label = compare_sales_col.replace('é”€é‡', '').strip()
                                
                                fig_compare = go.Figure()
                                
                                # å¯¹æ¯”å‘¨æœŸï¼ˆè“è‰²ï¼‰
                                fig_compare.add_trace(go.Bar(
                                    name=compare_label,
                                    x=top10_compare['å•†å“åç§°'],
                                    y=top10_compare[compare_sales_col],
                                    marker_color='#1976d2',
                                    text=top10_compare[compare_sales_col].apply(lambda x: f"{int(x) if pd.notna(x) and x > 0 else 0}"),
                                    textposition='auto'
                                ))
                                
                                # å½“å‰å‘¨æœŸï¼ˆçº¢è‰²ï¼‰
                                fig_compare.add_trace(go.Bar(
                                    name=current_label,
                                    x=top10_compare['å•†å“åç§°'],
                                    y=top10_compare[current_sales_col],
                                    marker_color='#d32f2f',
                                    text=top10_compare[current_sales_col].apply(lambda x: f"{int(x) if pd.notna(x) and x > 0 else 0}"),
                                    textposition='auto'
                                ))
                                
                                fig_compare.update_layout(
                                    title=f"{compare_label} vs {current_label}",
                                    xaxis_title="å•†å“",
                                    yaxis_title="é”€é‡ï¼ˆå•ï¼‰",
                                    barmode='group',
                                    template='plotly_white',
                                    height=350,
                                    font=dict(family='Microsoft YaHei', size=11),
                                    legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1)
                                )
                                
                                st.plotly_chart(fig_compare, use_container_width=True)
                                
                                st.info(f"ğŸ’¡ **é˜…è¯»æç¤º**: è“è‰²={compare_label}ï¼Œçº¢è‰²={current_label}ï¼Œçº¢è‰²æ˜æ˜¾ä½äºè“è‰²è¡¨ç¤ºä¸‹æ»‘")
                        
                        # === 3. é«˜çº§åˆ†æå›¾è¡¨ï¼ˆå…¨å®½ï¼‰===
                        st.markdown("---")
                        st.markdown("### ğŸ”¬ é«˜çº§åˆ†æ")
                        
                        adv_tab1, adv_tab2, adv_tab3 = st.tabs([
                            "ğŸ’° åˆ©æ¶¦å½±å“åˆ†æ",
                            "ğŸŒ³ åˆ†ç±»æ ‘çŠ¶å›¾",
                            "ğŸ”¥ æ—¶æ®µÃ—åœºæ™¯çƒ­åŠ›å›¾"
                        ])
                        
                        with adv_tab1:
                            # === å›¾è¡¨7: å››ç»´æ•£ç‚¹å›¾ ===
                            st.markdown("#### ğŸ’° é”€é‡å˜åŒ– vs åˆ©æ¶¦æŸå¤±ï¼ˆå››ç»´åˆ†æï¼‰")
                            
                            # æ£€æŸ¥å¿…éœ€å­—æ®µ
                            has_price = 'å•†å“å®å”®ä»·' in viz_df.columns and viz_df['å•†å“å®å”®ä»·'].notna().any()
                            has_margin = 'å¹³å‡æ¯›åˆ©ç‡%' in viz_df.columns and viz_df['å¹³å‡æ¯›åˆ©ç‡%'].notna().any()
                            
                            if has_price and has_margin:
                                # å®Œæ•´ç‰ˆï¼šå››ç»´æ•£ç‚¹å›¾ï¼ˆé”€é‡Ã—åˆ©æ¶¦Ã—å”®ä»·Ã—æ¯›åˆ©ç‡ï¼‰
                                
                                # ç¡®ä¿æ•°æ®æ˜¯æ•°å€¼ç±»å‹å¹¶æ¸…ç†
                                def ensure_numeric(series):
                                    """ç¡®ä¿Seriesæ˜¯çº¯æ•°å€¼ç±»å‹"""
                                    result = []
                                    for val in series:
                                        if pd.isna(val):
                                            result.append(0)
                                        elif isinstance(val, (int, float)):
                                            result.append(float(val))
                                        else:
                                            # æ¸…ç†å­—ç¬¦ä¸²
                                            val_str = str(val).replace('Â¥', '').replace('%', '').replace(',', '')
                                            # æå–ç¬¬ä¸€ä¸ªæ•°å­—
                                            import re
                                            match = re.search(r'-?\d+\.?\d*', val_str)
                                            if match:
                                                result.append(float(match.group()))
                                            else:
                                                result.append(0)
                                    return result
                                
                                # è½¬æ¢ä¸ºçº¯æ•°å€¼åˆ—è¡¨
                                sizes = ensure_numeric(viz_df['å•†å“å®å”®ä»·'])
                                sizes = [s * 2 for s in sizes]  # æ”¾å¤§2å€ä»¥ä¾¿æ˜¾ç¤º
                                colors = ensure_numeric(viz_df['å¹³å‡æ¯›åˆ©ç‡%'])
                                
                                fig_scatter = go.Figure(go.Scatter(
                                    x=viz_df['é”€é‡å˜åŒ–'],
                                    y=viz_df['åˆ©æ¶¦å˜åŒ–'],
                                    mode='markers',
                                    marker=dict(
                                        size=sizes,  # ä½¿ç”¨æ¸…ç†åçš„åˆ—è¡¨
                                        color=colors,  # ä½¿ç”¨æ¸…ç†åçš„åˆ—è¡¨
                                        colorscale='RdYlGn',
                                        showscale=True,
                                        colorbar=dict(title="æ¯›åˆ©ç‡%"),
                                        line=dict(width=1, color='white'),
                                        sizemode='diameter',
                                        sizemin=4
                                    ),
                                    text=viz_df['å•†å“åç§°'].tolist(),
                                    customdata=list(zip(
                                        [s/2 for s in sizes],  # è¿˜åŸå®é™…å”®ä»·
                                        colors
                                    )),
                                    hovertemplate='<b>%{text}</b><br>' +
                                                  'é”€é‡å˜åŒ–: %{x}å•<br>' +
                                                  'åˆ©æ¶¦æŸå¤±: Â¥%{y:,.0f}<br>' +
                                                  'å”®ä»·: Â¥%{customdata[0]:.1f}<br>' +
                                                  'æ¯›åˆ©ç‡: %{customdata[1]:.1f}%<extra></extra>'
                                ))
                                
                                fig_scatter.update_layout(
                                    title="æ°”æ³¡å¤§å°=å”®ä»·ï¼Œé¢œè‰²=æ¯›åˆ©ç‡ï¼ˆç»¿è‰²=é«˜æ¯›åˆ©ï¼Œçº¢è‰²=ä½æ¯›åˆ©ï¼‰",
                                    xaxis_title="é”€é‡å˜åŒ–ï¼ˆå•ï¼‰",
                                    yaxis_title="åˆ©æ¶¦æŸå¤±ï¼ˆå…ƒï¼‰",
                                    template='plotly_white',
                                    height=500,
                                    font=dict(family='Microsoft YaHei', size=11)
                                )
                                
                                st.plotly_chart(fig_scatter, use_container_width=True)
                                
                                st.info("ğŸ’¡ **é˜…è¯»æç¤º**: æ°”æ³¡è¶Šå¤§=å”®ä»·è¶Šé«˜ï¼Œé¢œè‰²è¶Šçº¢=æ¯›åˆ©ç‡è¶Šä½ï¼Œå·¦ä¸‹è§’=é«˜æŸå¤±å•†å“é‡ç‚¹å…³æ³¨")
                            else:
                                # ç®€åŒ–ç‰ˆï¼šåªç”¨é”€é‡å˜åŒ–å’Œåˆ©æ¶¦æŸå¤±
                                st.markdown("#### ğŸ’° é”€é‡å˜åŒ– vs åˆ©æ¶¦æŸå¤±ï¼ˆç®€åŒ–ç‰ˆï¼‰")
                                
                                missing_fields = []
                                if not has_price:
                                    missing_fields.append('å•†å“å®å”®ä»·')
                                if not has_margin:
                                    missing_fields.append('å¹³å‡æ¯›åˆ©ç‡%')
                                
                                fig_scatter_simple = go.Figure(go.Scatter(
                                    x=viz_df['é”€é‡å˜åŒ–'],
                                    y=viz_df['åˆ©æ¶¦å˜åŒ–'],
                                    mode='markers',
                                    marker=dict(
                                        size=10,
                                        color='#d32f2f',
                                        line=dict(width=1, color='white')
                                    ),
                                    text=viz_df['å•†å“åç§°'],
                                    hovertemplate='<b>%{text}</b><br>' +
                                                  'é”€é‡å˜åŒ–: %{x}å•<br>' +
                                                  'åˆ©æ¶¦æŸå¤±: Â¥%{y:,.0f}<extra></extra>'
                                ))
                                
                                fig_scatter_simple.update_layout(
                                    title="é”€é‡å˜åŒ–ä¸åˆ©æ¶¦æŸå¤±å…³ç³»",
                                    xaxis_title="é”€é‡å˜åŒ–ï¼ˆå•ï¼‰",
                                    yaxis_title="åˆ©æ¶¦æŸå¤±ï¼ˆå…ƒï¼‰",
                                    template='plotly_white',
                                    height=500,
                                    font=dict(family='Microsoft YaHei', size=11)
                                )
                                
                                st.plotly_chart(fig_scatter_simple, use_container_width=True)
                                
                                st.warning(f"âš ï¸ **æ•°æ®æç¤º**: ç¼ºå°‘å­—æ®µ {', '.join(missing_fields)}ï¼Œæ˜¾ç¤ºç®€åŒ–ç‰ˆå›¾è¡¨ã€‚")
                                st.info("ğŸ’¡ **è§£å†³æ–¹æ¡ˆ**: åœ¨åŸå§‹æ•°æ®ä¸­æä¾›'å•†å“æˆæœ¬'æˆ–'è¿›è´§ä»·'å­—æ®µï¼Œç³»ç»Ÿå°†è‡ªåŠ¨è®¡ç®—æ¯›åˆ©ç‡å¹¶å±•ç¤ºå®Œæ•´çš„å››ç»´åˆ†æã€‚")
                        
                        with adv_tab2:
                            # === å›¾è¡¨8: ä¸‰çº§åˆ†ç±»æ ‘çŠ¶å›¾ ===
                            if 'ä¸€çº§åˆ†ç±»å' in viz_df.columns and 'ä¸‰çº§åˆ†ç±»å' in viz_df.columns:
                                st.markdown("#### ğŸŒ³ ä¸‰çº§åˆ†ç±»ä¸‹æ»‘çƒ­åŠ›å›¾")
                                
                                # å‡†å¤‡æ ‘çŠ¶å›¾æ•°æ®
                                treemap_df = viz_df[viz_df['æ”¶å…¥å˜åŒ–'] < 0].copy()
                                treemap_df['æ”¶å…¥æŸå¤±ç»å¯¹å€¼'] = treemap_df['æ”¶å…¥å˜åŒ–'].abs()
                                
                                if len(treemap_df) > 0:
                                    fig_treemap = px.treemap(
                                        treemap_df,
                                        path=['ä¸€çº§åˆ†ç±»å', 'ä¸‰çº§åˆ†ç±»å', 'å•†å“åç§°'],
                                        values='æ”¶å…¥æŸå¤±ç»å¯¹å€¼',
                                        color='å˜åŒ–å¹…åº¦%',
                                        color_continuous_scale='Reds',
                                        hover_data={
                                            'æ”¶å…¥æŸå¤±ç»å¯¹å€¼': ':,.0f',
                                            'å˜åŒ–å¹…åº¦%': ':.1f',
                                            'é”€é‡å˜åŒ–': True
                                        }
                                    )
                                    
                                    fig_treemap.update_layout(
                                        title="é¢œè‰²è¶Šæ·±=ä¸‹æ»‘è¶Šä¸¥é‡ï¼Œé¢ç§¯è¶Šå¤§=æŸå¤±è¶Šå¤§",
                                        height=500,
                                        font=dict(family='Microsoft YaHei', size=11)
                                    )
                                    
                                    st.plotly_chart(fig_treemap, use_container_width=True)
                                else:
                                    st.info("æš‚æ— æ”¶å…¥æŸå¤±æ•°æ®")
                        
                        with adv_tab3:
                            # === å›¾è¡¨9: æ—¶æ®µÃ—åœºæ™¯çƒ­åŠ›å›¾ ===
                            st.markdown("#### ğŸ”¥ æ—¶æ®µÃ—åœºæ™¯äº¤å‰åˆ†æ")
                            
                            if 'æ—¶æ®µ' in raw_data.columns and 'åœºæ™¯' in raw_data.columns:
                                # æ„å»ºçƒ­åŠ›å›¾æ•°æ®
                                heatmap_data = []
                                all_slots = sorted(raw_data['æ—¶æ®µ'].dropna().unique())
                                all_scenes = sorted(raw_data['åœºæ™¯'].dropna().unique())
                                
                                if len(all_slots) > 0 and len(all_scenes) > 0:
                                    with st.spinner("æ­£åœ¨è®¡ç®—äº¤å‰æ•°æ®..."):
                                        for scene in all_scenes:
                                            row_data = {'åœºæ™¯': scene}
                                            for slot in all_slots:
                                                cross_result = diagnostic_engine.diagnose_sales_decline(
                                                    time_period=time_period,
                                                    threshold=threshold,
                                                    scene_filter=[scene],
                                                    time_slot_filter=[slot],
                                                    current_period_index=current_period_index if use_custom_period else None,
                                                    compare_period_index=compare_period_index if use_custom_period else None
                                                )
                                                row_data[slot] = len(cross_result)
                                            heatmap_data.append(row_data)
                                    
                                    if heatmap_data:
                                        heatmap_df = pd.DataFrame(heatmap_data).set_index('åœºæ™¯')
                                        
                                        fig_heatmap = px.imshow(
                                            heatmap_df,
                                            labels=dict(x="æ—¶æ®µ", y="åœºæ™¯", color="ä¸‹æ»‘å•†å“æ•°"),
                                            x=heatmap_df.columns,
                                            y=heatmap_df.index,
                                            color_continuous_scale='Reds',
                                            aspect='auto',
                                            text_auto=True
                                        )
                                        
                                        fig_heatmap.update_layout(
                                            title="æ·±çº¢è‰²=é—®é¢˜ä¸¥é‡åŒºåŸŸ",
                                            height=400,
                                            font=dict(family='Microsoft YaHei', size=11)
                                        )
                                        
                                        st.plotly_chart(fig_heatmap, use_container_width=True)
                                        
                                        st.info("ğŸ’¡ **é˜…è¯»æç¤º**: æ‰¾åˆ°æ·±çº¢è‰²åŒºåŸŸï¼Œé’ˆå¯¹æ€§ä¼˜åŒ–è¯¥æ—¶æ®µ+åœºæ™¯çš„å•†å“")
                                        
                                        # ========== ğŸ†• äº¤äº’å¼å•†å“æ˜ç»†æŸ¥çœ‹ ==========
                                        st.markdown("---")
                                        
                                        # æ·»åŠ HTMLé”šç‚¹ï¼Œç”¨äºå®šä½
                                        st.markdown('<div id="detail-list-anchor"></div>', unsafe_allow_html=True)
                                        
                                        # åˆ›å»ºä¸€ä¸ªå ä½ç¬¦ç”¨äºæ˜¾ç¤ºæç¤ºä¿¡æ¯
                                        filter_message_placeholder = st.empty()
                                        
                                        with st.expander("ğŸ“‹ ä¸‹æ»‘å•†å“æ˜ç»†åˆ—è¡¨ï¼ˆç‚¹å‡»å±•å¼€/æ”¶èµ·ï¼‰", expanded=True):
                                            
                                            # ä½¿ç”¨formæ¥é¿å…æ¯æ¬¡é€‰æ‹©éƒ½åˆ·æ–°é¡µé¢
                                            with st.form(key="detail_filter_form"):
                                                st.markdown("#### ğŸ” ç­›é€‰æ¡ä»¶è®¾ç½®")
                                                # åˆ›å»ºç­›é€‰å™¨
                                                filter_col1, filter_col2, filter_col3 = st.columns(3)
                                                
                                                with filter_col1:
                                                    selected_scenes = st.multiselect(
                                                        "ğŸ¯ ç­›é€‰åœºæ™¯",
                                                        options=['å…¨éƒ¨'] + list(all_scenes),
                                                        default=['å…¨éƒ¨']
                                                    )
                                                
                                                with filter_col2:
                                                    selected_slots = st.multiselect(
                                                        "â° ç­›é€‰æ—¶æ®µ",
                                                        options=['å…¨éƒ¨'] + list(all_slots),
                                                        default=['å…¨éƒ¨']
                                                    )
                                                
                                                with filter_col3:
                                                    sort_by = st.selectbox(
                                                        "ğŸ“Š æ’åºæ–¹å¼",
                                                        options=['ä¸‹æ»‘å¹…åº¦æœ€å¤§', 'é”€é‡æŸå¤±æœ€å¤š', 'åˆ©æ¶¦æŸå¤±æœ€å¤š', 'å•†å“åç§°']
                                                    )
                                                
                                                # æäº¤æŒ‰é’®
                                                submitted = st.form_submit_button("ğŸ”„ åº”ç”¨ç­›é€‰", use_container_width=True, type="primary")
                                            
                                            # å¦‚æœè¡¨å•æäº¤äº†ï¼Œä½¿ç”¨JavaScriptæ»šåŠ¨åˆ°é”šç‚¹
                                            if submitted:
                                                # ä½¿ç”¨æ›´å¯é çš„æ»šåŠ¨æ–¹æ³•
                                                st.components.v1.html("""
                                                <script>
                                                    window.parent.postMessage({
                                                        type: 'streamlit:setComponentValue',
                                                        value: 'scroll_to_detail'
                                                    }, '*');
                                                    
                                                    // å¤‡ç”¨æ–¹æ¡ˆï¼šç›´æ¥æ»šåŠ¨
                                                    setTimeout(function() {
                                                        const anchor = window.parent.document.getElementById('detail-list-anchor');
                                                        if (anchor) {
                                                            anchor.scrollIntoView({behavior: 'smooth', block: 'start'});
                                                        } else {
                                                            // å¦‚æœæ‰¾ä¸åˆ°é”šç‚¹ï¼Œå°è¯•æ»šåŠ¨åˆ°é¡µé¢åº•éƒ¨
                                                            window.parent.scrollTo({
                                                                top: window.parent.document.body.scrollHeight,
                                                                behavior: 'smooth'
                                                            });
                                                        }
                                                    }, 500);
                                                </script>
                                                """, height=0)
                                            
                                            # è·å–ç­›é€‰åçš„æ˜ç»†æ•°æ®
                                            scene_filter_list = None if 'å…¨éƒ¨' in selected_scenes else selected_scenes
                                            slot_filter_list = None if 'å…¨éƒ¨' in selected_slots else selected_slots
                                            
                                            # å¦‚æœè¡¨å•æäº¤äº†ï¼Œæ˜¾ç¤ºæç¤ºä¿¡æ¯
                                            if submitted:
                                                filter_message_placeholder.success("âœ… ç­›é€‰æ¡ä»¶å·²åº”ç”¨ï¼ç»“æœå·²åœ¨ä¸‹æ–¹æ›´æ–°ã€‚")
                                            
                                            detail_result = diagnostic_engine.diagnose_sales_decline(
                                                time_period=time_period,
                                                threshold=threshold,
                                                scene_filter=scene_filter_list,
                                                time_slot_filter=slot_filter_list,
                                                current_period_index=current_period_index if use_custom_period else None,
                                                compare_period_index=compare_period_index if use_custom_period else None
                                            )
                                            
                                            if len(detail_result) > 0:
                                                # æ’åº
                                                if sort_by == 'ä¸‹æ»‘å¹…åº¦æœ€å¤§':
                                                    detail_result = detail_result.sort_values('å˜åŒ–å¹…åº¦%', ascending=True)
                                                elif sort_by == 'é”€é‡æŸå¤±æœ€å¤š':
                                                    detail_result = detail_result.sort_values('é”€é‡å˜åŒ–', ascending=True)
                                                elif sort_by == 'åˆ©æ¶¦æŸå¤±æœ€å¤š':
                                                    if 'åˆ©æ¶¦å˜åŒ–' in detail_result.columns:
                                                        detail_result = detail_result.sort_values('åˆ©æ¶¦å˜åŒ–', ascending=True)
                                                elif sort_by == 'å•†å“åç§°':
                                                    detail_result = detail_result.sort_values('å•†å“åç§°')
                                                
                                                # å‡†å¤‡å±•ç¤ºåˆ—
                                                display_cols = ['å•†å“åç§°']
                                                if 'æ—¶æ®µ' in detail_result.columns:
                                                    display_cols.append('æ—¶æ®µ')
                                                if 'åœºæ™¯' in detail_result.columns:
                                                    display_cols.append('åœºæ™¯')
                                                if 'ä¸€çº§åˆ†ç±»å' in detail_result.columns:
                                                    display_cols.append('ä¸€çº§åˆ†ç±»å')
                                                
                                                # æ·»åŠ æ•°å€¼åˆ—
                                                value_cols = ['é”€é‡å˜åŒ–', 'å˜åŒ–å¹…åº¦%']
                                                if 'æ”¶å…¥å˜åŒ–' in detail_result.columns:
                                                    value_cols.append('æ”¶å…¥å˜åŒ–')
                                                if 'åˆ©æ¶¦å˜åŒ–' in detail_result.columns:
                                                    value_cols.append('åˆ©æ¶¦å˜åŒ–')
                                                if 'å•†å“å®å”®ä»·' in detail_result.columns:
                                                    value_cols.append('å•†å“å®å”®ä»·')
                                                
                                                display_cols.extend([col for col in value_cols if col in detail_result.columns])
                                                
                                                # æ˜¾ç¤ºç»Ÿè®¡æ‘˜è¦
                                                summary_col1, summary_col2, summary_col3, summary_col4 = st.columns(4)
                                                with summary_col1:
                                                    st.metric("ğŸ“¦ ä¸‹æ»‘å•†å“æ•°", f"{len(detail_result)} ä¸ª")
                                                with summary_col2:
                                                    total_qty_loss = detail_result['é”€é‡å˜åŒ–'].sum()
                                                    st.metric("ğŸ“‰ æ€»é”€é‡æŸå¤±", f"{int(total_qty_loss)} å•")
                                                with summary_col3:
                                                    if 'æ”¶å…¥å˜åŒ–' in detail_result.columns:
                                                        total_revenue_loss = detail_result['æ”¶å…¥å˜åŒ–'].sum()
                                                        st.metric("ğŸ’° æ€»æ”¶å…¥æŸå¤±", f"Â¥{total_revenue_loss:,.0f}")
                                                with summary_col4:
                                                    if 'åˆ©æ¶¦å˜åŒ–' in detail_result.columns:
                                                        total_profit_loss = detail_result['åˆ©æ¶¦å˜åŒ–'].sum()
                                                        st.metric("ğŸ’¸ æ€»åˆ©æ¶¦æŸå¤±", f"Â¥{total_profit_loss:,.0f}")
                                                
                                                # æ˜¾ç¤ºäº¤äº’å¼è¡¨æ ¼
                                                st.dataframe(
                                                    detail_result[display_cols],
                                                    column_config={
                                                        "å•†å“åç§°": st.column_config.TextColumn("å•†å“åç§°", width="large"),
                                                        "æ—¶æ®µ": st.column_config.TextColumn("æ—¶æ®µ", width="medium"),
                                                        "åœºæ™¯": st.column_config.TextColumn("åœºæ™¯", width="medium"),
                                                        "ä¸€çº§åˆ†ç±»å": st.column_config.TextColumn("åˆ†ç±»", width="medium"),
                                                        "é”€é‡å˜åŒ–": st.column_config.NumberColumn("é”€é‡å˜åŒ–", format="%då•"),
                                                        "å˜åŒ–å¹…åº¦%": st.column_config.ProgressColumn(
                                                            "ä¸‹æ»‘å¹…åº¦",
                                                            min_value=-100,
                                                            max_value=0,
                                                            format="%.1f%%"
                                                        ),
                                                        "æ”¶å…¥å˜åŒ–": st.column_config.NumberColumn("æ”¶å…¥å˜åŒ–", format="Â¥%.0f"),
                                                        "åˆ©æ¶¦å˜åŒ–": st.column_config.NumberColumn("åˆ©æ¶¦å˜åŒ–", format="Â¥%.0f"),
                                                        "å•†å“å®å”®ä»·": st.column_config.NumberColumn("å”®ä»·", format="Â¥%.2f")
                                                    },
                                                    use_container_width=True,
                                                    height=400
                                                )
                                                
                                                # ========== ğŸ†• Excelä¸€é”®å¯¼å‡º ==========
                                                st.markdown("---")
                                                st.markdown("### ğŸ“¥ å¯¼å‡ºåŠŸèƒ½")
                                                
                                                export_col1, export_col2 = st.columns([3, 1])
                                                
                                                with export_col1:
                                                    st.info("""
                                                    ğŸ’¡ **å¯¼å‡ºè¯´æ˜**ï¼š
                                                    - ğŸ“Š **Sheet1-æ˜ç»†æ•°æ®**ï¼šåŒ…å«æ‰€æœ‰ä¸‹æ»‘å•†å“çš„è¯¦ç»†ä¿¡æ¯
                                                    - ğŸ“ˆ **Sheet2-æ—¶æ®µæ±‡æ€»**ï¼šæŒ‰æ—¶æ®µç»Ÿè®¡çš„ä¸‹æ»‘æƒ…å†µ
                                                    - ğŸ¯ **Sheet3-åœºæ™¯æ±‡æ€»**ï¼šæŒ‰åœºæ™¯ç»Ÿè®¡çš„ä¸‹æ»‘æƒ…å†µ
                                                    - ğŸ“‹ **Sheet4-åˆ†ç±»æ±‡æ€»**ï¼šæŒ‰å•†å“åˆ†ç±»ç»Ÿè®¡çš„ä¸‹æ»‘æƒ…å†µ
                                                    """)
                                                
                                                with export_col2:
                                                    # ç”ŸæˆExcelæ•°æ®
                                                    from io import BytesIO
                                                    import openpyxl
                                                    from openpyxl.styles import Font, PatternFill, Alignment
                                                    
                                                    output = BytesIO()
                                                    with pd.ExcelWriter(output, engine='openpyxl') as writer:
                                                        # Sheet1: æ˜ç»†æ•°æ®
                                                        detail_result.to_excel(writer, sheet_name='æ˜ç»†æ•°æ®', index=False)
                                                        
                                                        # Sheet2: æ—¶æ®µæ±‡æ€»
                                                        if 'æ—¶æ®µ' in detail_result.columns:
                                                            agg_dict = {'å•†å“åç§°': 'count'}
                                                            if 'é”€é‡å˜åŒ–' in detail_result.columns:
                                                                agg_dict['é”€é‡å˜åŒ–'] = 'sum'
                                                            if 'æ”¶å…¥å˜åŒ–' in detail_result.columns:
                                                                agg_dict['æ”¶å…¥å˜åŒ–'] = 'sum'
                                                            if 'åˆ©æ¶¦å˜åŒ–' in detail_result.columns:
                                                                agg_dict['åˆ©æ¶¦å˜åŒ–'] = 'sum'
                                                            slot_summary = detail_result.groupby('æ—¶æ®µ').agg(agg_dict).rename(columns={'å•†å“åç§°': 'ä¸‹æ»‘å•†å“æ•°'})
                                                            slot_summary.to_excel(writer, sheet_name='æ—¶æ®µæ±‡æ€»')
                                                        
                                                        # Sheet3: åœºæ™¯æ±‡æ€»
                                                        if 'åœºæ™¯' in detail_result.columns:
                                                            agg_dict = {'å•†å“åç§°': 'count'}
                                                            if 'é”€é‡å˜åŒ–' in detail_result.columns:
                                                                agg_dict['é”€é‡å˜åŒ–'] = 'sum'
                                                            if 'æ”¶å…¥å˜åŒ–' in detail_result.columns:
                                                                agg_dict['æ”¶å…¥å˜åŒ–'] = 'sum'
                                                            if 'åˆ©æ¶¦å˜åŒ–' in detail_result.columns:
                                                                agg_dict['åˆ©æ¶¦å˜åŒ–'] = 'sum'
                                                            scene_summary = detail_result.groupby('åœºæ™¯').agg(agg_dict).rename(columns={'å•†å“åç§°': 'ä¸‹æ»‘å•†å“æ•°'})
                                                            scene_summary.to_excel(writer, sheet_name='åœºæ™¯æ±‡æ€»')
                                                        
                                                        # Sheet4: åˆ†ç±»æ±‡æ€»
                                                        if 'ä¸€çº§åˆ†ç±»å' in detail_result.columns:
                                                            agg_dict = {'å•†å“åç§°': 'count'}
                                                            if 'é”€é‡å˜åŒ–' in detail_result.columns:
                                                                agg_dict['é”€é‡å˜åŒ–'] = 'sum'
                                                            if 'æ”¶å…¥å˜åŒ–' in detail_result.columns:
                                                                agg_dict['æ”¶å…¥å˜åŒ–'] = 'sum'
                                                            if 'åˆ©æ¶¦å˜åŒ–' in detail_result.columns:
                                                                agg_dict['åˆ©æ¶¦å˜åŒ–'] = 'sum'
                                                            category_summary = detail_result.groupby('ä¸€çº§åˆ†ç±»å').agg(agg_dict).rename(columns={'å•†å“åç§°': 'ä¸‹æ»‘å•†å“æ•°'})
                                                            category_summary.to_excel(writer, sheet_name='åˆ†ç±»æ±‡æ€»')
                                                    
                                                    excel_data = output.getvalue()
                                                    
                                                    # ä¸‹è½½æŒ‰é’®
                                                    from datetime import datetime
                                                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                                                    st.download_button(
                                                        label="ğŸ“¥ ä¸‹è½½å®Œæ•´æ˜ç»†Excel",
                                                        data=excel_data,
                                                        file_name=f"ä¸‹æ»‘å•†å“æ˜ç»†_{timestamp}.xlsx",
                                                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                                                        type="primary",
                                                        use_container_width=True
                                                    )
                                            
                                            else:
                                                st.success("âœ… å¤ªæ£’äº†ï¼å½“å‰ç­›é€‰æ¡ä»¶ä¸‹æ²¡æœ‰ä¸‹æ»‘å•†å“")
                                    
                                    else:
                                        st.warning("âš ï¸ æ•°æ®ä¸­æ²¡æœ‰æ—¶æ®µæˆ–åœºæ™¯ä¿¡æ¯ï¼Œæ— æ³•ç”Ÿæˆçƒ­åŠ›å›¾")
                            else:
                                # å‹å¥½çš„æç¤ºä¿¡æ¯
                                time_slot_status = "âœ… å·²è‡ªåŠ¨ç”Ÿæˆ" if 'æ—¶æ®µ' in raw_data.columns else "âŒ ç¼ºå¤±"
                                scene_status = "âœ… å·²è‡ªåŠ¨æ¨æ–­" if 'åœºæ™¯' in raw_data.columns else "âŒ ç¼ºå¤±"
                                
                                st.info(f"""
                                ğŸ“Œ **æ—¶æ®µÃ—åœºæ™¯çƒ­åŠ›å›¾ - æ•°æ®çŠ¶æ€**
                                
                                **å½“å‰çŠ¶æ€**:
                                - æ—¶æ®µæ•°æ®: {time_slot_status}
                                - åœºæ™¯æ•°æ®: {scene_status}
                                
                                ---
                                
                                ### ğŸ¤– è‡ªåŠ¨æ•°æ®ç”Ÿæˆè¯´æ˜
                                
                                ç³»ç»Ÿä¼š**è‡ªåŠ¨ç”Ÿæˆ**æ—¶æ®µå’Œåœºæ™¯æ•°æ®ï¼Œæ— éœ€æ‰‹åŠ¨æ·»åŠ ï¼
                                
                                #### âœ… æ—¶æ®µè‡ªåŠ¨ç”Ÿæˆï¼ˆåŸºäºä¸‹å•æ—¶é—´ï¼‰
                                
                                - **è§¦å‘æ¡ä»¶**ï¼šè®¢å•è¡¨ä¸­æœ‰"ä¸‹å•æ—¶é—´"åˆ—
                                - **ç”Ÿæˆè§„åˆ™**ï¼š8æ—¶æ®µè‡ªåŠ¨åˆ’åˆ†
                                  ```
                                  æ¸…æ™¨(6-9ç‚¹)ã€ä¸Šåˆ(9-12ç‚¹)ã€æ­£åˆ(12-14ç‚¹)ã€ä¸‹åˆ(14-18ç‚¹)
                                  å‚æ™š(18-21ç‚¹)ã€æ™šé—´(21-24ç‚¹)ã€æ·±å¤œ(0-3ç‚¹)ã€å‡Œæ™¨(3-6ç‚¹)
                                  ```
                                - **å‡†ç¡®ç‡**ï¼š100%ï¼ˆåŸºäºå®¢è§‚æ—¶é—´ï¼‰
                                
                                #### âœ… åœºæ™¯æ™ºèƒ½æ¨æ–­ï¼ˆåŸºäºæ—¶æ®µ+å•†å“+åˆ†ç±»ï¼‰
                                
                                - **æ¨æ–­é€»è¾‘**ï¼šä¸‰çº§æ™ºèƒ½è¯†åˆ«
                                  1. ğŸ¯ **ä¼˜å…ˆçº§1**ï¼šå•†å“åç§°å…³é”®è¯ï¼ˆå¦‚ï¼šè±†æµ†â†’æ—©é¤ï¼Œå¥¶èŒ¶â†’ä¸‹åˆèŒ¶ï¼‰
                                  2. ğŸ·ï¸ **ä¼˜å…ˆçº§2**ï¼šå•†å“åˆ†ç±»ï¼ˆå¦‚ï¼šé¥®æ–™+ä¸‹åˆâ†’ä¸‹åˆèŒ¶ï¼‰
                                  3. â° **ä¼˜å…ˆçº§3**ï¼šæ—¶æ®µå…œåº•ï¼ˆå¦‚ï¼šæ¸…æ™¨â†’æ—©é¤ï¼Œæ­£åˆâ†’åˆé¤ï¼‰
                                
                                - **è¯†åˆ«åœºæ™¯**ï¼š
                                  - é¤é¥®åœºæ™¯ï¼šæ—©é¤ã€åˆé¤ã€æ™šé¤ã€å¤œå®µã€ä¸‹åˆèŒ¶
                                  - è´­ç‰©åœºæ™¯ï¼šæ—¥å¸¸è´­ç‰©ã€æ—¥ç”¨è¡¥å……ã€åº”æ€¥è´­ä¹°
                                  - ç”Ÿæ´»åœºæ™¯ï¼šä¼‘é—²é›¶é£Ÿã€å®¶åº­çƒ¹é¥ªã€è¥å…»è¡¥å……
                                  - ç¤¾äº¤åœºæ™¯ï¼šç¤¾äº¤å¨±ä¹ã€å¤œé—´ç¤¾äº¤
                                
                                - **å‡†ç¡®ç‡**ï¼šçº¦90%ï¼ˆåŸºäºå…³é”®è¯+ä¸šåŠ¡è§„åˆ™ï¼‰
                                
                                ---
                                
                                ### ğŸ’¡ å¦‚ä½•æŸ¥çœ‹è‡ªåŠ¨æ¨æ–­ç»“æœï¼Ÿ
                                
                                ä¸Šä¼ æ•°æ®åï¼Œç³»ç»Ÿä¼šæ˜¾ç¤ºï¼š
                                - âœ… "å·²è‡ªåŠ¨ä»ä¸‹å•æ—¶é—´æ¨æ–­æ—¶æ®µå­—æ®µï¼ˆ8æ—¶æ®µåˆ’åˆ†ï¼‰"
                                - âœ… "å·²æ™ºèƒ½æ¨æ–­åœºæ™¯å­—æ®µï¼ˆå…±è¯†åˆ« X ç§åœºæ™¯ï¼‰"
                                - ğŸ“Š ç‚¹å‡»"æŸ¥çœ‹è‡ªåŠ¨æ¨æ–­çš„åœºæ™¯åˆ†å¸ƒ"å¯æŸ¥çœ‹è¯¦ç»†åˆ†å¸ƒ
                                
                                ---
                                
                                ### ğŸ”§ å¦‚ä½•ä¼˜åŒ–æ¨æ–­ç»“æœï¼Ÿ
                                
                                å¦‚æœè‡ªåŠ¨æ¨æ–­ä¸å‡†ç¡®ï¼Œå¯ä»¥ï¼š
                                
                                1. **æ‰‹åŠ¨ä¿®æ­£**ï¼ˆExcelä¸­ï¼‰ï¼š
                                   - åœ¨è®¢å•è¡¨ä¸­æ‰‹åŠ¨æ·»åŠ æˆ–ä¿®æ­£"åœºæ™¯"åˆ—
                                   - ç³»ç»Ÿä¼šä¼˜å…ˆä½¿ç”¨æ‚¨æ‰‹åŠ¨æ ‡æ³¨çš„æ•°æ®
                                
                                2. **åé¦ˆä¼˜åŒ–**ï¼š
                                   - è®°å½•æ¨æ–­é”™è¯¯çš„å•†å“åç§°
                                   - æä¾›ç»™å¼€å‘å›¢é˜Ÿä¼˜åŒ–å…³é”®è¯åº“
                                
                                ---
                                
                                ### âš ï¸ å¦‚æœæ•°æ®ä»ç„¶ç¼ºå¤±
                                
                                è¯·æ£€æŸ¥ï¼š
                                1. **æ—¶æ®µç¼ºå¤±**ï¼šè®¢å•è¡¨ä¸­æ˜¯å¦æœ‰"ä¸‹å•æ—¶é—´"åˆ—ï¼Ÿ
                                2. **åœºæ™¯ç¼ºå¤±**ï¼šè®¢å•è¡¨ä¸­æ˜¯å¦æœ‰"å•†å“åç§°"æˆ–"åˆ†ç±»"åˆ—ï¼Ÿ
                                3. **æ ¼å¼é—®é¢˜**ï¼šä¸‹å•æ—¶é—´æ ¼å¼æ˜¯å¦æ­£ç¡®ï¼ˆéœ€åŒ…å«å®Œæ•´æ—¥æœŸæ—¶é—´ï¼‰ï¼Ÿ
                                
                                ğŸ’¡ **å»ºè®®**ï¼šä¸Šä¼ æ•°æ®åï¼ŒæŸ¥çœ‹ç³»ç»Ÿæç¤ºä¿¡æ¯ï¼Œç¡®è®¤æ˜¯å¦æˆåŠŸç”Ÿæˆæ—¶æ®µå’Œåœºæ™¯å­—æ®µã€‚
                                """)
                        
                        st.markdown("---")
                        
                        # æ•°æ®è¡¨æ ¼å±•ç¤º
                        st.markdown("### ğŸ“‹ è¯¦ç»†æ•°æ®è¡¨æ ¼")
                        st.dataframe(
                            result.style.apply(
                                lambda x: ['background-color: #ffcccc' if v == 'ä¸¥é‡' 
                                          else 'background-color: #ffe6cc' if v == 'è­¦å‘Š'
                                          else '' for v in x],
                                subset=['é—®é¢˜ç­‰çº§']
                            ),
                            use_container_width=True,
                            height=400
                        )
                        
                        # æ˜¾ç¤ºåˆ—åæç¤º
                        revenue_cols = [col for col in result.columns if 'é¢„è®¡æ”¶å…¥' in col]
                        if revenue_cols:
                            st.info(f"ğŸ’° å·²åŒ…å«é¢„è®¡æ”¶å…¥æ•°æ®: {', '.join(revenue_cols)}")
                        
                        # å¯¼å‡ºæŒ‰é’® - åˆ›å»ºå¯¼å‡ºä¸“ç”¨ç‰ˆæœ¬ï¼ˆç§»é™¤æ‰€æœ‰æ ¼å¼åŒ–ç¬¦å·ï¼‰
                        export_df = result.copy()
                        
                        # è‡ªåŠ¨æ£€æµ‹å¹¶æ¸…ç†æ‰€æœ‰åŒ…å«Â¥ç¬¦å·çš„åˆ—
                        for col in export_df.columns:
                            if export_df[col].dtype == 'object':  # åªå¤„ç†å­—ç¬¦ä¸²ç±»å‹çš„åˆ—
                                # æ£€æŸ¥æ˜¯å¦åŒ…å«Â¥ç¬¦å·
                                sample_value = export_df[col].iloc[0] if len(export_df) > 0 else ""
                                if isinstance(sample_value, str) and 'Â¥' in sample_value:
                                    try:
                                        # æ¸…ç†Â¥ç¬¦å·ã€åƒåˆ†ä½é€—å·ã€N/Aï¼Œè½¬ä¸ºæ•°å€¼
                                        export_df[col] = (export_df[col]
                                                         .astype(str)
                                                         .str.replace('Â¥', '')
                                                         .str.replace(',', '')
                                                         .str.replace('N/A', '0')
                                                         .replace('', '0')
                                                         .astype(float))
                                    except:
                                        pass  # å¦‚æœè½¬æ¢å¤±è´¥ï¼Œä¿æŒåŸæ ·
                        
                        # ğŸ†• éœ€æ±‚1: ä¿ç•™å˜åŒ–å¹…åº¦%çš„%ç¬¦å·ï¼Œä¸åšæ¸…ç†
                        # æ³¨é‡Šæ‰åŸæœ‰çš„%ç¬¦å·æ¸…ç†é€»è¾‘ï¼Œä¿æŒå˜åŒ–å¹…åº¦%åˆ—åŸæ ·å¯¼å‡º
                        # if 'å˜åŒ–å¹…åº¦%' in export_df.columns:
                        #     try:
                        #         export_df['å˜åŒ–å¹…åº¦%'] = (export_df['å˜åŒ–å¹…åº¦%']
                        #                               .astype(str)
                        #                               .str.replace('%', '')
                        #                               .astype(float))
                        #     except:
                        #         pass
                        
                        # ç”ŸæˆCSV - å…ˆç”Ÿæˆå­—ç¬¦ä¸²ï¼Œå†ç”¨BOMç¼–ç ç¡®ä¿Excelè¯†åˆ«
                        from io import BytesIO
                        
                        # åˆ›å»ºå­—èŠ‚æµç¼“å†²åŒº
                        csv_buffer = BytesIO()
                        
                        # å†™å…¥BOMæ ‡è®°ï¼ˆUTF-8 with BOMï¼‰
                        csv_buffer.write('\ufeff'.encode('utf-8'))
                        
                        # å†™å…¥CSVå†…å®¹
                        csv_string = export_df.to_csv(index=False)
                        csv_buffer.write(csv_string.encode('utf-8'))
                        
                        # è·å–å­—èŠ‚æ•°æ®
                        csv_bytes = csv_buffer.getvalue()
                        
                        st.download_button(
                            label="â¬‡ï¸ å¯¼å‡ºCSVï¼ˆçº¯æ•°å€¼ï¼‰",
                            data=csv_bytes,
                            file_name=f"é”€é‡ä¸‹æ»‘å•†å“_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                            mime="text/csv",
                            help="å¯¼å‡ºçº¯æ•°å€¼CSVï¼ˆæ— Â¥ã€%ç¬¦å·ï¼‰ï¼Œå¯ç”¨Excelç›´æ¥æ‰“å¼€å’Œè®¡ç®—"
                        )
                    else:
                        st.info("âœ¨ æœªå‘ç°ç¬¦åˆæ¡ä»¶çš„é”€é‡ä¸‹æ»‘å•†å“")
                except Exception as e:
                    st.error(f"âŒ è¯Šæ–­å¤±è´¥: {str(e)}")
                    import traceback
                    st.error(traceback.format_exc())
    
    # Tab 2: å®¢å•ä»·å½’å› åˆ†æ
    with diagnostic_tabs[1]:
        st.markdown("### ğŸ’° å®¢å•ä»·ä¸‹æ»‘å½’å› åˆ†æ")
        
        # æ·»åŠ å®¢å•ä»·å®šä¹‰è¯´æ˜
        with st.expander("ğŸ“– å®¢å•ä»·å®šä¹‰ä¸è¯´æ˜", expanded=False):
            st.markdown("""
            **å®¢å•ä»·å®šä¹‰**ï¼š
            - **å®¢å•ä»·** = è®¢å•æ€»é‡‘é¢ Ã· è®¢å•æ•°é‡
            - åæ˜ å¹³å‡æ¯ç¬”è®¢å•çš„æ¶ˆè´¹é‡‘é¢
            
            **åˆ†æç»´åº¦**ï¼š
            - **æŒ‰å‘¨åˆ†æ**ï¼šå¯¹æ¯”ç›¸é‚»å‘¨çš„å®¢å•ä»·å˜åŒ–ï¼ˆå¦‚ç¬¬39å‘¨ vs ç¬¬40å‘¨ï¼‰
            - **æŒ‰æ—¥åˆ†æ**ï¼šå¯¹æ¯”ç›¸é‚»æ—¥çš„å®¢å•ä»·å˜åŒ–ï¼ˆå¦‚09-29 vs 09-30ï¼‰
            
            **åˆ—åè¯´æ˜**ï¼š
            - **ä¹‹å‰å®¢å•ä»·**ï¼šæ—¶é—´ä¸Šæ›´æ—©çš„å‘¨æœŸï¼ˆå¯¹æ¯”åŸºå‡†ï¼‰
            - **å½“å‰å®¢å•ä»·**ï¼šæ—¶é—´ä¸Šæ›´æ–°çš„å‘¨æœŸï¼ˆå½“å‰çŠ¶æ€ï¼‰
            - **ä¸‹æ»‘TOPå•†å“**ï¼šå½“å‰æœŸé”€å”®é¢æœ€é«˜çš„å‰5ä¸ªå•†å“ï¼Œæ˜¾ç¤ºã€åˆ†ç±»ã€‘å•†å“å(å•ä»·)
            
            **é—®é¢˜ç­‰çº§**ï¼š
            - ğŸ”´ **ä¸¥é‡**ï¼šå®¢å•ä»·ä¸‹æ»‘ â‰¥ 10%
            - ğŸŸ  **è­¦å‘Š**ï¼šå®¢å•ä»·ä¸‹æ»‘ < 10%
            """)
        
        # ğŸ†• P2ä¼˜åŒ–: æ·»åŠ å‘¨æœŸé€‰æ‹©åŠŸèƒ½
        col1, col2 = st.columns(2)
        
        with col1:
            price_period = st.selectbox(
                "åˆ†æç²’åº¦",
                ["week", "daily"],
                format_func=lambda x: "æŒ‰å‘¨åˆ†æ" if x == "week" else "æŒ‰æ—¥åˆ†æ",
                key="price_period",
                index=0  # é»˜è®¤é€‰æ‹©"æŒ‰å‘¨åˆ†æ"
            )
        
        with col2:
            price_threshold = st.slider(
                "å®¢å•ä»·ä¸‹æ»‘é˜ˆå€¼%",
                min_value=-30.0,
                max_value=-1.0,
                value=-5.0,
                step=1.0,
                key="price_threshold"
            )
        
        # ğŸ†• P2ä¼˜åŒ–: çµæ´»å‘¨æœŸå¯¹æ¯”é€‰æ‹©
        st.markdown("#### ğŸ“… é€‰æ‹©å¯¹æ¯”å‘¨æœŸ")
        
        # æ·»åŠ åˆ†ææ¨¡å¼é€‰æ‹©
        analysis_mode = st.radio(
            "åˆ†ææ¨¡å¼",
            ["æ‰¹é‡åˆ†æï¼ˆæ‰€æœ‰ä¸‹æ»‘å‘¨æœŸï¼‰", "ç²¾å‡†å¯¹æ¯”ï¼ˆæŒ‡å®šä¸¤ä¸ªå‘¨æœŸï¼‰"],
            key="price_analysis_mode",
            horizontal=True
        )
        
        current_period_idx = None
        compare_period_idx = None
        
        if analysis_mode == "ç²¾å‡†å¯¹æ¯”ï¼ˆæŒ‡å®šä¸¤ä¸ªå‘¨æœŸï¼‰":
            # è·å–å¯ç”¨å‘¨æœŸåˆ—è¡¨
            try:
                available_periods = diagnostic_engine.get_available_price_periods(time_period=price_period)
                
                if len(available_periods) >= 2:
                    col3, col4 = st.columns(2)
                    
                    with col3:
                        current_period_options = {p['index']: f"{p['label']} ({p['date_range']})" 
                                                 for p in available_periods}
                        current_period_idx = st.selectbox(
                            "å½“å‰å‘¨æœŸ",
                            options=list(current_period_options.keys()),
                            format_func=lambda x: current_period_options[x],
                            index=0,  # é»˜è®¤é€‰æ‹©æœ€æ–°å‘¨æœŸ
                            key="price_current_period"
                        )
                    
                    with col4:
                        compare_period_options = {p['index']: f"{p['label']} ({p['date_range']})" 
                                                 for p in available_periods if p['index'] > current_period_idx}
                        compare_period_idx = st.selectbox(
                            "å¯¹æ¯”å‘¨æœŸ",
                            options=list(compare_period_options.keys()) if compare_period_options else [current_period_idx + 1],
                            format_func=lambda x: compare_period_options.get(x, f"ç¬¬{x}å‘¨æœŸ"),
                            index=0,  # é»˜è®¤é€‰æ‹©ç´§é‚»çš„ä¸Šä¸€å‘¨æœŸ
                            key="price_compare_period"
                        )
                else:
                    st.warning("âš ï¸ æ•°æ®é‡ä¸è¶³ï¼Œæ— æ³•è¿›è¡Œå‘¨æœŸå¯¹æ¯”")
            except Exception as e:
                st.error(f"è·å–å‘¨æœŸåˆ—è¡¨å¤±è´¥: {str(e)}")
        else:
            st.info("ğŸ’¡ æ‰¹é‡åˆ†ææ¨¡å¼ï¼šè‡ªåŠ¨éå†æ‰€æœ‰å‘¨æœŸï¼Œæ‰¾å‡ºæ‰€æœ‰å®¢å•ä»·ä¸‹æ»‘çš„å‘¨æœŸ")
        
        if st.button("ğŸ” å¼€å§‹å½’å› ", key="btn_price"):
            with st.spinner("æ­£åœ¨åˆ†æå®¢å•ä»·ä¸‹æ»‘åŸå› ..."):
                try:
                    # ğŸ†• ä½¿ç”¨æ–°çš„åˆ†Sheetæ–¹æ³•
                    sheets_data = diagnostic_engine.diagnose_customer_price_decline_by_sheets(
                        time_period=price_period,
                        threshold=price_threshold,
                        current_period_index=current_period_idx,
                        compare_period_index=compare_period_idx
                    )
                    
                    # æ£€æŸ¥æ˜¯å¦æœ‰æ•°æ®
                    has_data = any(len(df_sheet) > 0 for df_sheet in sheets_data.values())
                    
                    if has_data:
                        # ç»Ÿè®¡æ•°æ®è¡Œæ•°
                        total_rows = sum(len(df_sheet) for df_sheet in sheets_data.values() if len(df_sheet) > 0)
                        st.success(f"âœ… åˆ†æå®Œæˆï¼å…± {len([df for df in sheets_data.values() if len(df) > 0])} ä¸ªç»´åº¦ï¼Œ{total_rows} è¡Œæ•°æ®")
                        
                        # ä½¿ç”¨Tabå±•ç¤ºä¸‰ä¸ªç»´åº¦
                        sheet_tabs = st.tabs(["ğŸ“Š å®¢å•ä»·å˜åŒ–", "ğŸ“‰ ä¸‹æ»‘å•†å“åˆ†æ", "ğŸ“ˆ ä¸Šæ¶¨å•†å“åˆ†æ"])
                        
                        # Tab 1: å®¢å•ä»·å˜åŒ–
                        with sheet_tabs[0]:
                            price_change_df = sheets_data.get('å®¢å•ä»·å˜åŒ–', pd.DataFrame())
                            if len(price_change_df) > 0:
                                st.markdown("#### å®¢å•ä»·å˜åŒ–æ±‡æ€»")
                                st.dataframe(price_change_df, use_container_width=True, height=300)
                            else:
                                st.info("æš‚æ— æ•°æ®")
                        
                        # Tab 2: ä¸‹æ»‘å•†å“åˆ†æ
                        with sheet_tabs[1]:
                            declining_df = sheets_data.get('ä¸‹æ»‘å•†å“åˆ†æ', pd.DataFrame())
                            if len(declining_df) > 0:
                                st.markdown("#### TOP5é—®é¢˜å•†å“")
                                st.markdown("*åªåŒ…å«å”®ç½„ã€æ¶¨ä»·å¯¼è‡´é”€é‡é™ã€é”€é‡ä¸‹æ»‘ç­‰é—®é¢˜å•†å“*")
                                st.dataframe(declining_df, use_container_width=True, height=400)
                            else:
                                st.info("æš‚æ— ä¸‹æ»‘å•†å“")
                        
                        # Tab 3: ä¸Šæ¶¨å•†å“åˆ†æ
                        with sheet_tabs[2]:
                            rising_df = sheets_data.get('ä¸Šæ¶¨å•†å“åˆ†æ', pd.DataFrame())
                            if len(rising_df) > 0:
                                st.markdown("#### TOP5ä¼˜åŠ¿å•†å“")
                                st.markdown("*åªåŒ…å«æ¶¨ä»·(é”€é‡å¢)ã€é™ä»·ä¿ƒé”€æˆåŠŸã€é”€é‡å¢é•¿ç­‰ä¼˜åŠ¿å•†å“*")
                                st.dataframe(rising_df, use_container_width=True, height=400)
                            else:
                                st.info("æš‚æ— ä¸Šæ¶¨å•†å“")
                        
                        # å¯¼å‡ºåŠŸèƒ½ - æä¾›Excelå’ŒCSVä¸¤ç§æ ¼å¼
                        st.markdown("---")
                        st.markdown("### ğŸ“¥ å¯¼å‡ºæ•°æ®")
                        
                        col1, col2 = st.columns(2)
                        
                        # Excelå¯¼å‡ºï¼ˆåˆ†Sheetï¼‰
                        with col1:
                            from io import BytesIO
                            
                            # å‡†å¤‡Excelå¯¼å‡º
                            excel_buffer = BytesIO()
                            with pd.ExcelWriter(excel_buffer, engine='openpyxl') as writer:
                                for sheet_name, df_sheet in sheets_data.items():
                                    if len(df_sheet) > 0:
                                        # æ¸…ç†æ•°æ®ä¸­çš„Â¥ç¬¦å·ç­‰æ ¼å¼
                                        export_df = df_sheet.copy()
                                        for col in export_df.columns:
                                            if export_df[col].dtype == 'object':
                                                sample_value = export_df[col].iloc[0] if len(export_df) > 0 else ""
                                                if isinstance(sample_value, str) and 'Â¥' in sample_value:
                                                    try:
                                                        export_df[col] = (export_df[col]
                                                                         .astype(str)
                                                                         .str.replace('Â¥', '')
                                                                         .str.replace(',', '')
                                                                         .str.replace('N/A', '0')
                                                                         .replace('', '0')
                                                                         .astype(float))
                                                    except:
                                                        pass
                                        
                                        export_df.to_excel(writer, sheet_name=sheet_name, index=False)
                            
                            excel_bytes = excel_buffer.getvalue()
                            
                            st.download_button(
                                label="â¬‡ï¸ å¯¼å‡ºExcelï¼ˆåˆ†Sheetï¼‰",
                                data=excel_bytes,
                                file_name=f"å®¢å•ä»·å½’å› åˆ†æ_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                                help="Excelæ–‡ä»¶åŒ…å«3ä¸ªSheetï¼šå®¢å•ä»·å˜åŒ–ã€ä¸‹æ»‘å•†å“åˆ†æã€ä¸Šæ¶¨å•†å“åˆ†æ"
                            )
                        
                        # CSVå¯¼å‡ºï¼ˆåˆå¹¶æ‰€æœ‰æ•°æ®ï¼‰
                        with col2:
                            # è·å–åŸå§‹çš„åˆå¹¶æ•°æ®
                            result = diagnostic_engine.diagnose_customer_price_decline(
                                time_period=price_period,
                                threshold=price_threshold,
                                current_period_index=current_period_idx,
                                compare_period_index=compare_period_idx
                            )
                            
                            if len(result) > 0:
                                # å‡†å¤‡CSVå¯¼å‡ºæ•°æ®
                                export_df = result.copy()
                                
                                # æ¸…ç†æ•°æ®
                                for col in export_df.columns:
                                    if export_df[col].dtype == 'object':
                                        sample_value = export_df[col].iloc[0] if len(export_df) > 0 else ""
                                        if isinstance(sample_value, str) and 'Â¥' in sample_value:
                                            try:
                                                export_df[col] = (export_df[col]
                                                                 .astype(str)
                                                                 .str.replace('Â¥', '')
                                                                 .str.replace(',', '')
                                                                 .str.replace('N/A', '0')
                                                                 .replace('', '0')
                                                                 .astype(float))
                                            except:
                                                pass
                                
                                # ç”ŸæˆCSV - ä½¿ç”¨BOMç¼–ç ç¡®ä¿Excelè¯†åˆ«ä¸­æ–‡
                                csv_buffer = BytesIO()
                                csv_buffer.write('\ufeff'.encode('utf-8'))  # BOMæ ‡è®°
                                csv_string = export_df.to_csv(index=False)
                                csv_buffer.write(csv_string.encode('utf-8'))
                                csv_bytes = csv_buffer.getvalue()
                                
                                st.download_button(
                                    label="â¬‡ï¸ å¯¼å‡ºCSVï¼ˆå•æ–‡ä»¶ï¼‰",
                                    data=csv_bytes,
                                    file_name=f"å®¢å•ä»·å½’å› _{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                                    mime="text/csv",
                                    help="CSVæ–‡ä»¶åŒ…å«æ‰€æœ‰å­—æ®µï¼ˆå•ä¸ªæ–‡ä»¶ï¼‰"
                                )
                    else:
                        st.info("âœ¨ æœªå‘ç°å®¢å•ä»·æ˜æ˜¾ä¸‹æ»‘å‘¨æœŸ")
                except Exception as e:
                    st.error(f"âŒ åˆ†æå¤±è´¥: {str(e)}")
                    import traceback
                    st.code(traceback.format_exc())
    
    # Tab 3: è´Ÿæ¯›åˆ©å•†å“é¢„è­¦
    with diagnostic_tabs[2]:
        st.markdown("### ğŸš¨ è´Ÿæ¯›åˆ©å•†å“é¢„è­¦")
        
        st.info("ğŸ’¡ è‡ªåŠ¨è¯†åˆ«å”®ä»·ä½äºæˆæœ¬çš„å•†å“ï¼Œå¸®åŠ©åŠæ—¶æ­¢æŸ")
        
        if st.button("ğŸ” ç«‹å³æ£€æµ‹", key="btn_margin"):
            with st.spinner("æ­£åœ¨æ£€æµ‹è´Ÿæ¯›åˆ©å•†å“..."):
                try:
                    result = diagnostic_engine.diagnose_negative_margin_products()
                    
                    if len(result) > 0:
                        total_loss = result['ç´¯è®¡äºæŸé¢'].sum()
                        st.error(f"âš ï¸ å‘ç° {len(result)} ä¸ªè´Ÿæ¯›åˆ©å•†å“ï¼Œç´¯è®¡äºæŸ Â¥{abs(total_loss):.2f}")
                        
                        st.dataframe(
                            result.style.apply(
                                lambda x: ['background-color: #ffcccc' if v == 'ğŸ”´ ä¸¥é‡' 
                                          else 'background-color: #ffe6cc' if v == 'ğŸŸ  è­¦å‘Š'
                                          else '' for v in x],
                                subset=['é—®é¢˜ç­‰çº§']
                            ),
                            use_container_width=True,
                            height=400
                        )
                        
                        csv = result.to_csv(index=False, encoding='utf-8-sig')
                        st.download_button(
                            label="â¬‡ï¸ å¯¼å‡ºCSV",
                            data=csv,
                            file_name=f"è´Ÿæ¯›åˆ©å•†å“_{datetime.now().strftime('%Y%m%d')}.csv",
                            mime="text/csv"
                        )
                    else:
                        st.success("âœ… æœªå‘ç°è´Ÿæ¯›åˆ©å•†å“ï¼Œç»è¥å¥åº·ï¼")
                except Exception as e:
                    st.error(f"âŒ æ£€æµ‹å¤±è´¥: {str(e)}")
    
    # Tab 4: é«˜é…é€è´¹è®¢å•ä¼˜åŒ–
    with diagnostic_tabs[3]:
        st.markdown("### ğŸšš é«˜é…é€è´¹è®¢å•è¯Šæ–­")
        
        col1, col2 = st.columns(2)
        
        with col1:
            fee_threshold = st.slider(
                "é…é€è´¹å æ¯”é˜ˆå€¼%",
                min_value=10.0,
                max_value=50.0,
                value=20.0,
                step=5.0,
                key="fee_threshold"
            )
        
        with col2:
            st.metric("æ­£å¸¸é…é€è´¹å æ¯”", "< 15%", delta="ä¼˜ç§€", delta_color="normal")
        
        if st.button("ğŸ” å¼€å§‹è¯Šæ–­", key="btn_delivery"):
            with st.spinner("æ­£åœ¨åˆ†æé«˜é…é€è´¹è®¢å•..."):
                try:
                    result = diagnostic_engine.diagnose_high_delivery_fee_orders(threshold=fee_threshold)
                    
                    if len(result) > 0:
                        st.warning(f"âš ï¸ å‘ç° {len(result)} ä¸ªåœ°å€é…é€è´¹å æ¯”è¿‡é«˜")
                        
                        st.dataframe(result, use_container_width=True, height=400)
                        
                        csv = result.to_csv(index=False, encoding='utf-8-sig')
                        st.download_button(
                            label="â¬‡ï¸ å¯¼å‡ºCSV",
                            data=csv,
                            file_name=f"é«˜é…é€è´¹è®¢å•_{datetime.now().strftime('%Y%m%d')}.csv",
                            mime="text/csv"
                        )
                    else:
                        st.success("âœ… é…é€è´¹æ§åˆ¶è‰¯å¥½ï¼Œæ— å¼‚å¸¸è®¢å•")
                except Exception as e:
                    st.error(f"âŒ è¯Šæ–­å¤±è´¥: {str(e)}")
    
    # Tab 5: å•†å“è§’è‰²å¤±è¡¡
    with diagnostic_tabs[4]:
        st.markdown("### âš–ï¸ æµé‡å“ & åˆ©æ¶¦å“å¤±è¡¡è¯Šæ–­")
        
        st.info("ğŸ’¡ æ£€æµ‹å„åœºæ™¯ä¸­æµé‡å“å’Œåˆ©æ¶¦å“çš„é…æ¯”æ˜¯å¦åˆç†")
        
        if st.button("ğŸ” å¼€å§‹æ£€æµ‹", key="btn_balance"):
            with st.spinner("æ­£åœ¨åˆ†æå•†å“è§’è‰²é…æ¯”..."):
                try:
                    result = diagnostic_engine.diagnose_product_role_imbalance()
                    
                    if len(result) > 0:
                        st.warning(f"âš ï¸ å‘ç° {len(result)} ä¸ªåœºæ™¯å•†å“è§’è‰²å¤±è¡¡")
                        
                        st.dataframe(result, use_container_width=True, height=400)
                        
                        csv = result.to_csv(index=False, encoding='utf-8-sig')
                        st.download_button(
                            label="â¬‡ï¸ å¯¼å‡ºCSV",
                            data=csv,
                            file_name=f"å•†å“è§’è‰²å¤±è¡¡_{datetime.now().strftime('%Y%m%d')}.csv",
                            mime="text/csv"
                        )
                    else:
                        st.success("âœ… å„åœºæ™¯å•†å“è§’è‰²é…æ¯”åˆç†")
                except Exception as e:
                    st.error(f"âŒ æ£€æµ‹å¤±è´¥: {str(e)}")
    
    # Tab 6: å¼‚å¸¸æ³¢åŠ¨é¢„è­¦
    with diagnostic_tabs[5]:
        st.markdown("### ğŸ“Š å¼‚å¸¸æ³¢åŠ¨å•†å“é¢„è­¦")
        
        col1, col2 = st.columns(2)
        
        with col1:
            fluctuation_threshold = st.slider(
                "æ³¢åŠ¨é˜ˆå€¼ï¼ˆç¯æ¯”%ï¼‰",
                min_value=30.0,
                max_value=100.0,
                value=50.0,
                step=10.0,
                key="fluctuation_threshold"
            )
        
        with col2:
            st.info("ğŸ“ˆ çˆ†å•ï¼šé”€é‡ç¯æ¯”å¢é•¿è¶…è¿‡é˜ˆå€¼\nğŸ“‰ æ»é”€ï¼šé”€é‡ç¯æ¯”ä¸‹é™è¶…è¿‡é˜ˆå€¼")
        
        if st.button("ğŸ” å¼€å§‹é¢„è­¦", key="btn_fluctuation"):
            with st.spinner("æ­£åœ¨æ£€æµ‹å¼‚å¸¸æ³¢åŠ¨å•†å“..."):
                try:
                    result = diagnostic_engine.diagnose_abnormal_fluctuation(threshold=fluctuation_threshold)
                    
                    if len(result) > 0:
                        boom_count = len(result[result['å¼‚å¸¸ç±»å‹'] == 'ğŸ“ˆ çˆ†å•'])
                        slow_count = len(result[result['å¼‚å¸¸ç±»å‹'] == 'ğŸ“‰ æ»é”€'])
                        
                        st.warning(f"âš ï¸ å‘ç° {len(result)} ä¸ªå¼‚å¸¸æ³¢åŠ¨å•†å“ï¼ˆçˆ†å•:{boom_count} | æ»é”€:{slow_count}ï¼‰")
                        
                        st.dataframe(
                            result.style.apply(
                                lambda x: ['background-color: #ccffcc' if v == 'ğŸ“ˆ çˆ†å•' 
                                          else 'background-color: #ffcccc' for v in x],
                                subset=['å¼‚å¸¸ç±»å‹']
                            ),
                            use_container_width=True,
                            height=400
                        )
                        
                        csv = result.to_csv(index=False, encoding='utf-8-sig')
                        st.download_button(
                            label="â¬‡ï¸ å¯¼å‡ºCSV",
                            data=csv,
                            file_name=f"å¼‚å¸¸æ³¢åŠ¨å•†å“_{datetime.now().strftime('%Y%m%d')}.csv",
                            mime="text/csv"
                        )
                    else:
                        st.success("âœ… æœªå‘ç°å¼‚å¸¸æ³¢åŠ¨å•†å“")
                except Exception as e:
                    st.error(f"âŒ é¢„è­¦å¤±è´¥: {str(e)}")


if __name__ == "__main__":
    main()
