"""
P2ä»»åŠ¡ï¼šæ•°æ®æºç®¡ç†å™¨
æ”¯æŒä»Excelæˆ–æ•°æ®åº“åŠ è½½æ•°æ®

âœ… 2025-12-04: ç»Ÿä¸€å­—æ®µæ˜ å°„é…ç½®
- æ‰€æœ‰æ•°æ®åº“å­—æ®µåˆ°ä¸­æ–‡æ˜¾ç¤ºåçš„æ˜ å°„ç»Ÿä¸€åœ¨æ­¤æ–‡ä»¶ç»´æŠ¤
- æ–°å¢å­—æ®µæ—¶åªéœ€åœ¨ DB_FIELD_MAPPING ä¸­æ·»åŠ æ˜ å°„å³å¯
"""

import sys
from pathlib import Path
import pandas as pd
from typing import Literal
from datetime import datetime

PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

from database.connection import get_db
from database.models import Order, Product
from çœŸå®æ•°æ®å¤„ç†å™¨ import RealDataProcessor


# ========================================
# ğŸ“Œ ç»Ÿä¸€å­—æ®µæ˜ å°„é…ç½®è¡¨
# ========================================
# æ ¼å¼: 'ä¸­æ–‡æ˜¾ç¤ºå': ('æ•°æ®åº“å­—æ®µå', é»˜è®¤å€¼, æ˜¯å¦å¿…é¡»hasattræ£€æŸ¥)
# æ–°å¢å­—æ®µæ—¶åªéœ€åœ¨è¿™é‡Œæ·»åŠ ä¸€è¡Œå³å¯ï¼Œæ— éœ€ä¿®æ”¹å…¶ä»–ä»£ç 
# ========================================
DB_FIELD_MAPPING = {
    # ===== åŸºç¡€è®¢å•ä¿¡æ¯ =====
    'è®¢å•ID': ('order_id', '', False),
    'è®¢å•ç¼–å·': ('order_number', '', True),  # âœ… æ–°å¢å­—æ®µç¤ºä¾‹
    'ä¸‹å•æ—¶é—´': ('date', None, False),
    'æ—¥æœŸ': ('date', None, False),  # å…¼å®¹å­—æ®µ
    'é—¨åº—åç§°': ('store_name', '', False),
    'é—¨åº—ID': ('store_id', '', True),
    'åŸå¸‚åç§°': ('city', '', True),
    
    # ===== å•†å“ä¿¡æ¯ =====
    'å•†å“åç§°': ('product_name', '', False),
    'å•†å“æ¡å½¢ç ': ('barcode', '', False),
    'æ¡ç ': ('barcode', '', False),  # å…¼å®¹å­—æ®µ
    'åº—å†…ç ': ('store_code', '', True),  # ç‰¹æ®Šå¤„ç†ï¼Œè§ä¸‹æ–¹
    'ä¸€çº§åˆ†ç±»å': ('category_level1', '', False),
    'ä¸‰çº§åˆ†ç±»å': ('category_level3', '', False),
    
    # ===== ä»·æ ¼æˆæœ¬ =====
    'å•†å“å®å”®ä»·': ('price', 0.0, False),
    'å•†å“åŸä»·': ('original_price', None, False),  # ç‰¹æ®Šå¤„ç†ï¼šfallbackåˆ°price
    'å•†å“é‡‡è´­æˆæœ¬': ('cost', 0.0, False),
    'æˆæœ¬': ('cost', 0.0, False),  # å…¼å®¹å­—æ®µ
    'å®æ”¶ä»·æ ¼': ('actual_price', None, False),  # ç‰¹æ®Šå¤„ç†ï¼šfallbackåˆ°price
    
    # ===== é”€é‡é‡‘é¢ =====
    'é”€é‡': ('quantity', 1, False),
    'é”€å”®æ•°é‡': ('quantity', 1, False),  # å…¼å®¹å­—æ®µ
    'æœˆå”®': ('quantity', 1, False),  # å…¼å®¹å­—æ®µ
    'åº“å­˜': ('remaining_stock', 0, False),
    'å‰©ä½™åº“å­˜': ('remaining_stock', 0, False),
    'é¢„è®¡è®¢å•æ”¶å…¥': ('amount', None, False),  # ç‰¹æ®Šå¤„ç†
    'åˆ©æ¶¦é¢': ('profit', 0.0, False),
    
    # ===== è´¹ç”¨ =====
    'ç‰©æµé…é€è´¹': ('delivery_fee', 0.0, False),
    'å¹³å°ä½£é‡‘': ('commission', 0.0, False),
    'å¹³å°æœåŠ¡è´¹': ('platform_service_fee', 0.0, False),
    
    # ===== è¥é”€æ´»åŠ¨å­—æ®µ =====
    'ç”¨æˆ·æ”¯ä»˜é…é€è´¹': ('user_paid_delivery_fee', 0.0, False),
    'é…é€è´¹å‡å…é‡‘é¢': ('delivery_discount', 0.0, False),
    'æ»¡å‡é‡‘é¢': ('full_reduction', 0.0, False),
    'å•†å“å‡å…é‡‘é¢': ('product_discount', 0.0, False),
    'å•†å®¶ä»£é‡‘åˆ¸': ('merchant_voucher', 0.0, False),
    'å•†å®¶æ‰¿æ‹…éƒ¨åˆ†åˆ¸': ('merchant_share', 0.0, False),
    'æ‰“åŒ…è¢‹é‡‘é¢': ('packaging_fee', 0.0, False),
    'æ»¡èµ é‡‘é¢': ('gift_amount', 0.0, True),
    'å•†å®¶å…¶ä»–ä¼˜æƒ ': ('other_merchant_discount', 0.0, True),
    'æ–°å®¢å‡å…é‡‘é¢': ('new_customer_discount', 0.0, True),
    
    # ===== åˆ©æ¶¦ç»´åº¦å­—æ®µ =====
    'ä¼å®¢åè¿”': ('corporate_rebate', 0.0, True),
    
    # ===== é…é€ä¿¡æ¯ =====
    'é…é€å¹³å°': ('delivery_platform', '', True),
    'é…é€è·ç¦»': ('delivery_distance', 0.0, True),
    'æ”¶è´§åœ°å€': ('address', '', False),  # âœ… æ–°å¢ï¼šå®¢æˆ·åœ°å€å­—æ®µ
    
    # ===== æ¸ é“åœºæ™¯ =====
    'æ¸ é“': ('channel', '', False),
    'åœºæ™¯': ('scene', '', False),
    'æ—¶æ®µ': ('time_period', '', False),
}


def get_field_value(order, field_name: str, default_value, need_hasattr: bool):
    """
    å®‰å…¨è·å–å­—æ®µå€¼
    
    Args:
        order: Orderå¯¹è±¡
        field_name: æ•°æ®åº“å­—æ®µå
        default_value: é»˜è®¤å€¼
        need_hasattr: æ˜¯å¦éœ€è¦æ£€æŸ¥hasattr
    """
    if need_hasattr:
        if hasattr(order, field_name):
            val = getattr(order, field_name)
            return val if val is not None else default_value
        return default_value
    else:
        val = getattr(order, field_name, default_value)
        return val if val is not None else default_value


class DataSourceManager:
    """æ•°æ®æºç®¡ç†å™¨"""
    
    def __init__(self):
        self.processor = RealDataProcessor()
        self.current_source = 'excel'  # é»˜è®¤Excel
    
    def load_from_excel(self, file_path: str = None) -> pd.DataFrame:
        """ä»ExcelåŠ è½½æ•°æ®"""
        if file_path is None:
            file_path = r"é—¨åº—æ•°æ®\æ¯”ä»·çœ‹æ¿æ¨¡å—\è®¢å•æ•°æ®-æœ¬åº—.xlsx"
        
        print(f"[Excel] åŠ è½½æ•°æ®: {file_path}")
        
        try:
            # åŠ è½½
            df = pd.read_excel(file_path)
            print(f"[Excel] åŸå§‹æ•°æ®: {len(df):,} è¡Œ")
            
            # æ ‡å‡†åŒ–
            df = self.processor.standardize_sales_data(df)
            
            # ä¸šåŠ¡è¿‡æ»¤
            if 'ä¸€çº§åˆ†ç±»å' in df.columns:
                df = df[df['ä¸€çº§åˆ†ç±»å'] != 'è€—æ'].copy()
            if 'æ¸ é“' in df.columns:
                df = df[~df['æ¸ é“'].str.contains('å’–å•¡', na=False)].copy()
            
            print(f"[Excel] è¿‡æ»¤å: {len(df):,} è¡Œ")
            
            self.current_source = 'excel'
            return df
            
        except Exception as e:
            print(f"[Excel] åŠ è½½å¤±è´¥: {str(e)}")
            return pd.DataFrame()
    
    def load_from_database(self, 
                          store_name: str = None,
                          start_date: datetime = None,
                          end_date: datetime = None,
                          split_consumables: bool = True,
                          return_dict: bool = True) -> dict:
        """
        ä»æ•°æ®åº“åŠ è½½æ•°æ®
        
        Args:
            store_name: é—¨åº—åç§°
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            split_consumables: æ˜¯å¦åˆ†ç¦»è€—ææ•°æ®
            return_dict: æ˜¯å¦è¿”å›dictæ ¼å¼ï¼ˆTrueï¼‰è¿˜æ˜¯DataFrameæ ¼å¼ï¼ˆFalseï¼‰
                        é»˜è®¤Trueä¿æŒV8.10è¡Œä¸ºï¼ŒFalseå…¼å®¹è€ç‰ˆæœ¬
            
        Returns:
            å¦‚æœreturn_dict=True:
                å¦‚æœsplit_consumables=True:
                    {'full': å®Œæ•´æ•°æ®(å«è€—æ), 'display': å±•ç¤ºæ•°æ®(ä¸å«è€—æ)}
                å¦‚æœsplit_consumables=False:
                    {'full': å®Œæ•´æ•°æ®(å«è€—æ)}
            å¦‚æœreturn_dict=False:
                è¿”å›DataFrameï¼ˆdisplayæ•°æ®ï¼Œå…¼å®¹è€ç‰ˆæœ¬ï¼‰
        """
        print(f"[Database] åŠ è½½æ•°æ®...")
        print(f"[Database] å‚æ•° - é—¨åº—: {store_name}, å¼€å§‹æ—¥æœŸ: {start_date}, ç»“æŸæ—¥æœŸ: {end_date}")
        
        db = next(get_db())
        
        try:
            # æ„å»ºæŸ¥è¯¢ - JOIN Productè¡¨è·å–åº—å†…ç (ä¸å†JOINæˆæœ¬å’Œåº“å­˜,Orderè¡¨å·²æœ‰)
            from database.models import Product
            query = db.query(
                Order, 
                Product.store_code
            ).outerjoin(
                Product, Order.barcode == Product.barcode
            )
            
            # è¿‡æ»¤æ¡ä»¶
            if store_name:
                print(f"[Database] åº”ç”¨é—¨åº—è¿‡æ»¤: {store_name}")
                query = query.filter(Order.store_name == store_name)
            
            # âœ… ä¿®å¤å•æ—¥æŸ¥è¯¢ï¼šç¡®ä¿æ—¥æœŸèŒƒå›´åŒ…å«å®Œæ•´çš„ä¸€å¤©
            if start_date:
                # è½¬æ¢ä¸ºdatetimeå¯¹è±¡ï¼Œè®¾ç½®ä¸ºå½“å¤©00:00:00
                from datetime import datetime, timedelta
                if isinstance(start_date, str):
                    start_date = datetime.fromisoformat(start_date)
                if not isinstance(start_date, datetime):
                    # å¦‚æœæ˜¯dateå¯¹è±¡ï¼Œè½¬æ¢ä¸ºdatetime
                    start_date = datetime.combine(start_date, datetime.min.time())
                
                print(f"[Database] åº”ç”¨å¼€å§‹æ—¥æœŸè¿‡æ»¤: {start_date.date()} 00:00:00")
                query = query.filter(Order.date >= start_date)
            
            if end_date:
                # âœ… ä¿®å¤ï¼šå…ˆè½¬æ¢ç±»å‹ï¼Œå†è®¾ç½®æ—¶é—´ä¸ºå½“å¤©ç»“æŸ
                from datetime import datetime, timedelta
                
                # ç¬¬ä¸€æ­¥ï¼šç»Ÿä¸€è½¬æ¢ä¸ºdatetimeå¯¹è±¡
                if isinstance(end_date, str):
                    end_date = datetime.fromisoformat(end_date)
                elif not isinstance(end_date, datetime):
                    # å¦‚æœæ˜¯dateå¯¹è±¡ï¼Œè½¬æ¢ä¸ºdatetime
                    end_date = datetime.combine(end_date, datetime.min.time())
                
                # ç¬¬äºŒæ­¥ï¼šè®¾ç½®æ—¶é—´ä¸ºå½“å¤©23:59:59
                end_date = datetime.combine(end_date.date(), datetime.max.time())
                
                print(f"[Database] åº”ç”¨ç»“æŸæ—¥æœŸè¿‡æ»¤: {end_date.date()} 23:59:59 (åŒ…å«å½“å¤©)", flush=True)
                query = query.filter(Order.date <= end_date)
            
            # ğŸš¨ V8.9.2: ä¼˜åŒ–å¤§æ•°æ®é‡æŸ¥è¯¢
            # å…ˆæ£€æŸ¥æ•°æ®é‡ï¼ˆä½¿ç”¨å¿«é€Ÿä¼°ç®—ï¼Œé¿å… count() åœ¨å¤§è¡¨ä¸Šå¤ªæ…¢ï¼‰
            print(f"[Database] æ£€æŸ¥æ•°æ®é‡...")
            
            # ä½¿ç”¨ EXPLAIN ä¼°ç®—è¡Œæ•°ï¼ˆæ¯” count() å¿«å¾—å¤šï¼‰
            try:
                from sqlalchemy import text
                explain_query = f"EXPLAIN {str(query.statement.compile(compile_kwargs={'literal_binds': True}))}"
                result = db.execute(text(explain_query))
                # ç®€åŒ–ï¼šç›´æ¥æ‰§è¡ŒæŸ¥è¯¢ï¼Œä¸åšé™åˆ¶
                # å› ä¸ºç”¨æˆ·åé¦ˆè€ç‰ˆæœ¬å¯ä»¥å¤„ç† 1200ä¸‡æ•°æ®
            except:
                pass
            
            # æ‰§è¡ŒæŸ¥è¯¢ï¼ˆå…è®¸å¤§æ•°æ®é‡ï¼Œä½†æ˜¾ç¤ºè¿›åº¦ï¼‰
            print(f"[Database] æ‰§è¡ŒæŸ¥è¯¢...")
            print(f"[Database] ğŸ’¡ æç¤º: å¦‚æœæ•°æ®é‡å¤§ï¼ŒæŸ¥è¯¢å¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´ï¼Œè¯·è€å¿ƒç­‰å¾…...")
            
            import time
            start_time = time.time()
            results = query.all()
            elapsed = time.time() - start_time
            
            print(f"[Database] âœ… æŸ¥è¯¢å®Œæˆï¼Œè·å–åˆ° {len(results):,} æ¡è®°å½• (è€—æ—¶ {elapsed:.1f} ç§’)")
            
            # ğŸ” è°ƒè¯•: æ£€æŸ¥å‰5æ¡è®°å½•çš„è®¢å•ID
            if results:
                print(f"[Database] å‰5æ¡è®°å½•çš„è®¢å•ID:")
                for i, (order, store_code) in enumerate(results[:5]):
                    print(f"   {i+1}. order_id='{order.order_id}' (type={type(order.order_id).__name__})")
            
            # è½¬æ¢ä¸ºDataFrame - ä½¿ç”¨ç»Ÿä¸€çš„å­—æ®µæ˜ å°„
            data = []
            for order, store_code in results:
                row = {}
                
                # è‡ªåŠ¨ä»æ˜ å°„è¡¨è¯»å–å­—æ®µ
                for chinese_name, (db_field, default_val, need_hasattr) in DB_FIELD_MAPPING.items():
                    row[chinese_name] = get_field_value(order, db_field, default_val, need_hasattr)
                
                # ===== ç‰¹æ®Šå¤„ç†çš„å­—æ®µ =====
                # åº—å†…ç : ä¼˜å…ˆä½¿ç”¨Orderè¡¨ï¼Œfallbackåˆ°Productè¡¨
                if not row.get('åº—å†…ç '):
                    row['åº—å†…ç '] = store_code if store_code else ''
                
                # å•†å“åŸä»·: fallbackåˆ°å®å”®ä»·
                if row.get('å•†å“åŸä»·') is None:
                    row['å•†å“åŸä»·'] = row.get('å•†å“å®å”®ä»·', 0)
                
                # å®æ”¶ä»·æ ¼: fallbackåˆ°å®å”®ä»·
                if row.get('å®æ”¶ä»·æ ¼') is None:
                    row['å®æ”¶ä»·æ ¼'] = row.get('å•†å“å®å”®ä»·', 0)
                
                # é¢„è®¡è®¢å•æ”¶å…¥: fallbackåˆ°è®¡ç®—å€¼
                if row.get('é¢„è®¡è®¢å•æ”¶å…¥') is None:
                    row['é¢„è®¡è®¢å•æ”¶å…¥'] = row.get('å•†å“å®å”®ä»·', 0) * row.get('é”€é‡', 1)
                
                # ===== è®¡ç®—å­—æ®µ =====
                price = row.get('å•†å“å®å”®ä»·', 0) or 0
                quantity = row.get('é”€é‡', 1) or 1
                actual_price = row.get('å®æ”¶ä»·æ ¼', 0) or price
                
                row['è®¢å•é›¶å”®é¢'] = price * quantity
                row['å®æ”¶é‡‘é¢'] = actual_price * quantity
                row['ç”¨æˆ·æ”¯ä»˜é‡‘é¢'] = actual_price * quantity
                
                # ===== å…¼å®¹å­—æ®µå¤„ç†å·²é€šè¿‡å­—æ®µæ˜ å°„è‡ªåŠ¨å®Œæˆ =====
                # row['æ”¶è´§åœ°å€'] å·²é€šè¿‡ DB_FIELD_MAPPING è‡ªåŠ¨æ˜ å°„
                
                data.append(row)
            
            df = pd.DataFrame(data)
            
            print(f"[Database] æŸ¥è¯¢ç»“æœ: {len(df):,} è¡Œ")
            
            # ğŸ” æ£€æŸ¥æ¸ é“åˆ†å¸ƒ
            if 'æ¸ é“' in df.columns:
                channel_counts = df['æ¸ é“'].value_counts()
                print(f"[Database] æ¸ é“åˆ†å¸ƒ:")
                for ch, cnt in channel_counts.items():
                    print(f"   {ch}: {cnt:,} è¡Œ")
                    
                # ğŸ” ç‰¹åˆ«æ£€æŸ¥é—ªè´­å°ç¨‹åº
                xiaochengxu_count = (df['æ¸ é“'] == 'é—ªè´­å°ç¨‹åº').sum()
                print(f"[Database] ğŸ” 'é—ªè´­å°ç¨‹åº'æ•°æ®: {xiaochengxu_count} è¡Œ")
            
            # ğŸ”„ 2025-11-19: æ•°æ®åˆ†ç¦»ç­–ç•¥
            # - df_full: å®Œæ•´æ•°æ®(å«è€—æ) â†’ ç”¨äºåˆ©æ¶¦è®¡ç®—
            # - df_display: å±•ç¤ºæ•°æ®(ä¸å«è€—æ) â†’ ç”¨äºåˆ†æå›¾è¡¨
            print(f"[Database] âœ… ä¿ç•™è€—ææ•°æ® (åŒ…å«è´­ç‰©è¢‹ç­‰æˆæœ¬)")
            
            df_full = df.copy()
            
            if split_consumables and 'ä¸€çº§åˆ†ç±»å' in df.columns:
                df_display = df[df['ä¸€çº§åˆ†ç±»å'] != 'è€—æ'].copy()
                consumable_count = len(df_full) - len(df_display)
                
                print(f"[Database] ğŸ“Š æ•°æ®åˆ†ç¦»å®Œæˆ:")
                print(f"   - å®Œæ•´æ•°æ®(å«è€—æ): {len(df_full):,} è¡Œ")
                print(f"   - å±•ç¤ºæ•°æ®(ä¸å«è€—æ): {len(df_display):,} è¡Œ")
                print(f"   - è€—ææ•°æ®: {consumable_count:,} è¡Œ")
                
                self.current_source = 'database'
                
                # V8.10.1: å…¼å®¹æ€§ä¿®å¤ - æ”¯æŒè¿”å›DataFrameæˆ–dict
                if return_dict:
                    return {
                        'full': df_full,
                        'display': df_display
                    }
                else:
                    # å…¼å®¹è€ç‰ˆæœ¬ï¼šç›´æ¥è¿”å›displayæ•°æ®
                    return df_display
            else:
                print(f"[Database] ğŸ“Š è¿”å›å®Œæ•´æ•°æ®: {len(df_full):,} è¡Œ (ä¸åˆ†ç¦»)")
                self.current_source = 'database'
                
                # V8.10.1: å…¼å®¹æ€§ä¿®å¤ - æ”¯æŒè¿”å›DataFrameæˆ–dict
                if return_dict:
                    return {
                        'full': df_full,
                        'display': df_full.copy()
                    }
                else:
                    # å…¼å®¹è€ç‰ˆæœ¬ï¼šç›´æ¥è¿”å›å®Œæ•´æ•°æ®
                    return df_full
            
        except Exception as e:
            print(f"[Database] åŠ è½½å¤±è´¥: {str(e)}")
            return pd.DataFrame()
        finally:
            db.close()
    
    def load_data(self, 
                  source: Literal['excel', 'database'] = 'excel',
                  **kwargs) -> pd.DataFrame:
        """
        ç»Ÿä¸€æ•°æ®åŠ è½½æ¥å£
        
        Args:
            source: æ•°æ®æºç±»å‹ ('excel' æˆ– 'database')
            **kwargs: 
                - file_path: Excelæ–‡ä»¶è·¯å¾„ï¼ˆsource='excel'æ—¶ï¼‰
                - store_name: é—¨åº—åç§°ï¼ˆsource='database'æ—¶ï¼‰
                - start_date: èµ·å§‹æ—¥æœŸï¼ˆsource='database'æ—¶ï¼‰
                - end_date: ç»“æŸæ—¥æœŸï¼ˆsource='database'æ—¶ï¼‰
        """
        if source == 'excel':
            file_path = kwargs.get('file_path')
            return self.load_from_excel(file_path)
        
        elif source == 'database':
            store_name = kwargs.get('store_name')
            start_date = kwargs.get('start_date')
            end_date = kwargs.get('end_date')
            return self.load_from_database(store_name, start_date, end_date)
        
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ•°æ®æº: {source}")
    
    def get_available_stores(self) -> list:
        """è·å–æ•°æ®åº“ä¸­çš„é—¨åº—åˆ—è¡¨"""
        db = next(get_db())
        try:
            stores = db.query(Order.store_name).distinct().all()
            return [s[0] for s in stores if s[0]]
        finally:
            db.close()
    
    def get_date_range(self) -> tuple:
        """è·å–æ•°æ®åº“ä¸­çš„æ—¥æœŸèŒƒå›´"""
        db = next(get_db())
        try:
            from sqlalchemy import func
            result = db.query(
                func.min(Order.date),
                func.max(Order.date)
            ).first()
            return result
        finally:
            db.close()
    
    def get_database_stats(self) -> dict:
        """è·å–æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯"""
        db = next(get_db())
        try:
            stats = {
                'products': db.query(Product).count(),
                'orders': db.query(Order).count(),
                'stores': db.query(Order.store_name).distinct().count(),
            }
            
            date_range = self.get_date_range()
            if date_range[0]:
                stats['start_date'] = date_range[0].strftime('%Y-%m-%d')
                stats['end_date'] = date_range[1].strftime('%Y-%m-%d')
            
            return stats
        finally:
            db.close()
    
    def load_from_database_streaming(self, 
                                     store_name: str = None,
                                     start_date: datetime = None,
                                     end_date: datetime = None,
                                     batch_size: int = 10000,
                                     max_rows: int = 1000000):
        """
        æµå¼åŠ è½½æ•°æ®ï¼Œé¿å…å†…å­˜æº¢å‡º
        
        Args:
            store_name: é—¨åº—åç§°
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            batch_size: æ¯æ‰¹åŠ è½½çš„è¡Œæ•°ï¼Œé»˜è®¤ 10000
            max_rows: æœ€å¤§åŠ è½½è¡Œæ•°ï¼Œé»˜è®¤ 100ä¸‡ï¼ˆé˜²æ­¢å†…å­˜æº¢å‡ºï¼‰
            
        Returns:
            {'full': å®Œæ•´æ•°æ®(å«è€—æ), 'display': å±•ç¤ºæ•°æ®(ä¸å«è€—æ)}
        """
        print(f"[Database] æµå¼åŠ è½½æ•°æ®...")
        print(f"[Database] å‚æ•° - é—¨åº—: {store_name}, æ—¥æœŸ: {start_date} ~ {end_date}")
        print(f"[Database] æ‰¹æ¬¡å¤§å°: {batch_size:,}, æœ€å¤§è¡Œæ•°: {max_rows:,}")
        
        db = next(get_db())
        
        try:
            # æ„å»ºæŸ¥è¯¢
            from database.models import Product
            query = db.query(
                Order, 
                Product.store_code
            ).outerjoin(
                Product, Order.barcode == Product.barcode
            )
            
            # åº”ç”¨è¿‡æ»¤æ¡ä»¶
            if store_name:
                query = query.filter(Order.store_name == store_name)
            
            if start_date:
                from datetime import datetime as dt
                if isinstance(start_date, str):
                    start_date = dt.fromisoformat(start_date)
                if not isinstance(start_date, dt):
                    start_date = dt.combine(start_date, dt.min.time())
                query = query.filter(Order.date >= start_date)
            
            if end_date:
                from datetime import datetime as dt
                if isinstance(end_date, str):
                    end_date = dt.fromisoformat(end_date)
                elif not isinstance(end_date, dt):
                    end_date = dt.combine(end_date, dt.min.time())
                end_date = dt.combine(end_date.date(), dt.max.time())
                query = query.filter(Order.date <= end_date)
            
            # æµå¼åŠ è½½
            all_results = []
            offset = 0
            batch_num = 0
            
            import time
            start_time = time.time()
            
            while True:
                batch_num += 1
                print(f"[Database] åŠ è½½æ‰¹æ¬¡ {batch_num} (offset={offset:,})...")
                
                # åˆ†æ‰¹æŸ¥è¯¢
                batch = query.limit(batch_size).offset(offset).all()
                
                if not batch:
                    print(f"[Database] æ²¡æœ‰æ›´å¤šæ•°æ®")
                    break
                
                all_results.extend(batch)
                offset += batch_size
                
                print(f"[Database] å·²åŠ è½½ {len(all_results):,} æ¡è®°å½•")
                
                # å†…å­˜ä¿æŠ¤ï¼šè¶…è¿‡æœ€å¤§è¡Œæ•°åœæ­¢
                if len(all_results) >= max_rows:
                    print(f"âš ï¸ å·²è¾¾åˆ°æœ€å¤§è¡Œæ•°é™åˆ¶ ({max_rows:,})ï¼Œåœæ­¢åŠ è½½")
                    break
                
                # å¦‚æœæœ¬æ‰¹æ¬¡æ•°æ®å°‘äº batch_sizeï¼Œè¯´æ˜å·²ç»åˆ°æœ«å°¾
                if len(batch) < batch_size:
                    print(f"[Database] å·²åŠ è½½æ‰€æœ‰æ•°æ®")
                    break
            
            elapsed = time.time() - start_time
            print(f"[Database] âœ… æµå¼åŠ è½½å®Œæˆï¼Œå…± {len(all_results):,} æ¡è®°å½• (è€—æ—¶ {elapsed:.1f} ç§’)")
            
            # è½¬æ¢ä¸º DataFrame
            return self._convert_results_to_dataframe(all_results)
            
        finally:
            db.close()
    
    def _convert_results_to_dataframe(self, results):
        """å°†æŸ¥è¯¢ç»“æœè½¬æ¢ä¸º DataFrame"""
        data = []
        for order, store_code in results:
            row = {}
            
            # è‡ªåŠ¨ä»æ˜ å°„è¡¨è¯»å–å­—æ®µ
            for chinese_name, (db_field, default_val, need_hasattr) in DB_FIELD_MAPPING.items():
                row[chinese_name] = get_field_value(order, db_field, default_val, need_hasattr)
            
            # ç‰¹æ®Šå¤„ç†çš„å­—æ®µ
            if not row.get('åº—å†…ç '):
                row['åº—å†…ç '] = store_code if store_code else ''
            
            if row.get('å•†å“åŸä»·') is None:
                row['å•†å“åŸä»·'] = row.get('å•†å“å®å”®ä»·', 0)
            
            data.append(row)
        
        # è½¬æ¢ä¸º DataFrame
        df = pd.DataFrame(data)
        
        # åˆ†ç¦»è€—ææ•°æ®
        full_df = df.copy()
        
        if 'ä¸€çº§åˆ†ç±»å' in df.columns:
            display_df = df[df['ä¸€çº§åˆ†ç±»å'] != 'è€—æ'].copy()
            consumable_count = len(full_df) - len(display_df)
            print(f"[Database] ğŸ“Š æ•°æ®åˆ†ç¦»å®Œæˆ:")
            print(f"   - å®Œæ•´æ•°æ®(å«è€—æ): {len(full_df):,} è¡Œ")
            print(f"   - å±•ç¤ºæ•°æ®(ä¸å«è€—æ): {len(display_df):,} è¡Œ")
            print(f"   - è€—ææ•°æ®: {consumable_count:,} è¡Œ")
        else:
            display_df = full_df.copy()
        
        return {
            'full': full_df,
            'display': display_df
        }
    
    def load_from_database_smart(self,
                                 store_name: str = None,
                                 start_date: datetime = None,
                                 end_date: datetime = None,
                                 split_consumables: bool = True):
        """
        æ™ºèƒ½åŠ è½½ï¼šæ ¹æ®æ•°æ®é‡è‡ªåŠ¨é€‰æ‹©æœ€ä¼˜ç­–ç•¥
        
        ç­–ç•¥é€‰æ‹©:
        - < 10,000 æ¡: å…¨é‡åŠ è½½ (æœ€å¿«)
        - 10,000 - 100,000 æ¡: æµå¼åŠ è½½ (å¹³è¡¡)
        - > 100,000 æ¡: æµå¼åŠ è½½ + è­¦å‘Š (å®‰å…¨)
        
        Args:
            store_name: é—¨åº—åç§°
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            split_consumables: æ˜¯å¦åˆ†ç¦»è€—ææ•°æ®
            
        Returns:
            {'full': å®Œæ•´æ•°æ®, 'display': å±•ç¤ºæ•°æ®, 'strategy': ä½¿ç”¨çš„ç­–ç•¥}
        """
        print(f"[Database] æ™ºèƒ½åŠ è½½æ•°æ®...")
        
        db = next(get_db())
        
        try:
            # æ„å»ºæŸ¥è¯¢ç”¨äºä¼°ç®—
            query = db.query(Order)
            
            if store_name:
                query = query.filter(Order.store_name == store_name)
            
            if start_date:
                from datetime import datetime as dt
                if isinstance(start_date, str):
                    start_date = dt.fromisoformat(start_date)
                if not isinstance(start_date, dt):
                    start_date = dt.combine(start_date, dt.min.time())
                query = query.filter(Order.date >= start_date)
            
            if end_date:
                from datetime import datetime as dt
                if isinstance(end_date, str):
                    end_date = dt.fromisoformat(end_date)
                elif not isinstance(end_date, dt):
                    end_date = dt.combine(end_date, dt.min.time())
                end_date = dt.combine(end_date.date(), dt.max.time())
                query = query.filter(Order.date <= end_date)
            
            # å¿«é€Ÿä¼°ç®—æ•°æ®é‡ï¼ˆä½¿ç”¨ countï¼Œä½†æœ‰è¶…æ—¶ä¿æŠ¤ï¼‰
            print(f"[Database] ä¼°ç®—æ•°æ®é‡...")
            import time
            count_start = time.time()
            
            try:
                estimated_count = query.count()
                count_elapsed = time.time() - count_start
                print(f"[Database] é¢„ä¼°æ•°æ®é‡: {estimated_count:,} æ¡ (è€—æ—¶ {count_elapsed:.1f}ç§’)")
            except Exception as e:
                print(f"[Database] âš ï¸ ä¼°ç®—å¤±è´¥: {e}")
                estimated_count = 50000  # é»˜è®¤ä½¿ç”¨ä¸­ç­‰ç­–ç•¥
            
            # æ ¹æ®æ•°æ®é‡é€‰æ‹©ç­–ç•¥
            if estimated_count < 10000:
                # å°æ•°æ®é‡ï¼šå…¨é‡åŠ è½½
                strategy = "å…¨é‡åŠ è½½"
                print(f"[Database] ç­–ç•¥: {strategy} (æ•°æ®é‡å°ï¼Œé€Ÿåº¦æœ€å¿«)")
                result = self.load_from_database(
                    store_name=store_name,
                    start_date=start_date,
                    end_date=end_date,
                    split_consumables=split_consumables
                )
            
            elif estimated_count < 100000:
                # ä¸­ç­‰æ•°æ®é‡ï¼šæµå¼åŠ è½½
                strategy = "æµå¼åŠ è½½"
                print(f"[Database] ç­–ç•¥: {strategy} (æ•°æ®é‡é€‚ä¸­ï¼Œå¹³è¡¡æ€§èƒ½)")
                result = self.load_from_database_streaming(
                    store_name=store_name,
                    start_date=start_date,
                    end_date=end_date,
                    batch_size=10000,
                    max_rows=100000
                )
            
            else:
                # å¤§æ•°æ®é‡ï¼šæµå¼åŠ è½½ + è­¦å‘Š
                strategy = "æµå¼åŠ è½½(å¤§æ•°æ®)"
                print(f"[Database] ç­–ç•¥: {strategy} (æ•°æ®é‡å¤§ï¼Œé™åˆ¶æœ€å¤§è¡Œæ•°)")
                print(f"âš ï¸ æ•°æ®é‡è¾ƒå¤§ ({estimated_count:,} æ¡)ï¼Œå°†é™åˆ¶åŠ è½½ 100ä¸‡ æ¡")
                print(f"ğŸ’¡ å»ºè®®: ç¼©å°æŸ¥è¯¢èŒƒå›´ä»¥è·å¾—æ›´å¥½çš„æ€§èƒ½")
                result = self.load_from_database_streaming(
                    store_name=store_name,
                    start_date=start_date,
                    end_date=end_date,
                    batch_size=10000,
                    max_rows=1000000
                )
            
            # æ·»åŠ ç­–ç•¥ä¿¡æ¯
            result['strategy'] = strategy
            result['estimated_count'] = estimated_count
            
            return result
            
        finally:
            db.close()


# æµ‹è¯•ä»£ç 
if __name__ == "__main__":
    manager = DataSourceManager()
    
    print("\n=== æµ‹è¯•Excelæ•°æ®æº ===")
    df_excel = manager.load_data(source='excel')
    print(f"Excelæ•°æ®: {len(df_excel)} è¡Œ")
    if not df_excel.empty:
        print(df_excel.head(3))
    
    print("\n=== æµ‹è¯•æ•°æ®åº“æ•°æ®æº ===")
    df_db = manager.load_data(source='database')
    print(f"æ•°æ®åº“æ•°æ®: {len(df_db)} è¡Œ")
    if not df_db.empty:
        print(df_db.head(3))
    
    print("\n=== æ•°æ®åº“ç»Ÿè®¡ ===")
    stats = manager.get_database_stats()
    for key, value in stats.items():
        print(f"{key}: {value}")
    
    print("\n=== å¯ç”¨é—¨åº— ===")
    stores = manager.get_available_stores()
    for store in stores[:5]:
        print(f"  - {store}")

