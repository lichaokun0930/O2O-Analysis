"""
P1ä»»åŠ¡ï¼šæ‰¹é‡åŽ†å²æ•°æ®å¯¼å…¥å·¥å…·
æ”¯æŒå¯¼å…¥æŒ‡å®šç›®å½•ä¸‹çš„æ‰€æœ‰Excelæ–‡ä»¶åˆ°æ•°æ®åº“
"""

import sys
from pathlib import Path
import pandas as pd
from datetime import datetime
import glob
import os

PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

from database.connection import get_db
from database.models import Order, Product, DataUploadHistory
from çœŸå®žæ•°æ®å¤„ç†å™¨ import RealDataProcessor


class BatchDataImporter:
    """æ‰¹é‡æ•°æ®å¯¼å…¥å™¨"""
    
    def __init__(self, data_dir: str):
        self.data_dir = data_dir
        self.processor = RealDataProcessor()
        self.stats = {
            'files_processed': 0,
            'files_success': 0,
            'files_failed': 0,
            'total_orders': 0,
            'total_products': 0,
        }
    
    def find_excel_files(self):
        """æŸ¥æ‰¾æ‰€æœ‰Excelæ–‡ä»¶"""
        patterns = ['*.xlsx', '*.xls', '*.xlsm']
        files = []
        
        for pattern in patterns:
            files.extend(glob.glob(f"{self.data_dir}/**/{pattern}", recursive=True))
        
        # è¿‡æ»¤ä¸´æ—¶æ–‡ä»¶
        files = [f for f in files if not os.path.basename(f).startswith('~$')]
        
        return sorted(files)
    
    def extract_products(self, df: pd.DataFrame):
        """ä»Žè®¢å•æ•°æ®ä¸­æå–å•†å“ä¿¡æ¯"""
        products = []
        seen = set()
        
        for _, row in df.iterrows():
            product_name = str(row.get('å•†å“åç§°', ''))
            if product_name and product_name not in seen:
                seen.add(product_name)
                
                product = {
                    'name': product_name,
                    'barcode': str(row.get('å•†å“æ¡å½¢ç ', '')) if pd.notna(row.get('å•†å“æ¡å½¢ç ')) else None,
                    'category_level1': str(row.get('ä¸€çº§åˆ†ç±»å', '')) if pd.notna(row.get('ä¸€çº§åˆ†ç±»å')) else None,
                    'category_level2': str(row.get('äºŒçº§åˆ†ç±»å', '')) if pd.notna(row.get('äºŒçº§åˆ†ç±»å')) else None,
                    'category_level3': str(row.get('ä¸‰çº§åˆ†ç±»å', '')) if pd.notna(row.get('ä¸‰çº§åˆ†ç±»å')) else None,
                    'price': float(row.get('å•†å“å®žå”®ä»·', 0)) if pd.notna(row.get('å•†å“å®žå”®ä»·')) else 0,
                    'cost': float(row.get('å•†å“é‡‡è´­æˆæœ¬', 0)) if pd.notna(row.get('å•†å“é‡‡è´­æˆæœ¬')) else None,
                }
                products.append(product)
        
        return products
    
    def import_products_batch(self, products: list):
        """æ‰¹é‡å¯¼å…¥å•†å“"""
        db = next(get_db())
        imported = 0
        updated = 0
        
        try:
            for product_data in products:
                # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
                existing = db.query(Product).filter(Product.name == product_data['name']).first()
                
                if existing:
                    # æ›´æ–°
                    for key, value in product_data.items():
                        if key != 'name' and value is not None:
                            setattr(existing, key, value)
                    updated += 1
                else:
                    # æ–°å¢ž
                    db.add(Product(**product_data))
                    imported += 1
                
                # æ¯100æ¡æäº¤ä¸€æ¬¡
                if (imported + updated) % 100 == 0:
                    db.commit()
            
            db.commit()
            return imported, updated
            
        finally:
            db.close()
    
    def import_orders_batch(self, df: pd.DataFrame):
        """æ‰¹é‡å¯¼å…¥è®¢å•"""
        db = next(get_db())
        imported = 0
        updated = 0
        errors = 0
        
        # âœ… æ—¥æœŸåˆ—æ£€æŸ¥ (å·²ç»è¿‡standardize_sales_dataå¤„ç†,åº”è¯¥æ˜¯"æ—¥æœŸ"åˆ—)
        date_col = None
        
        # ä¼˜å…ˆä½¿ç”¨æ ‡å‡†åŒ–åŽçš„"æ—¥æœŸ"åˆ—
        if 'æ—¥æœŸ' in df.columns:
            date_col = 'æ—¥æœŸ'
            print(f"[æ—¥æœŸåˆ—] ä½¿ç”¨æ ‡å‡†åŒ–åˆ—: {date_col}")
        else:
            # å¦‚æžœæ²¡æœ‰,å°è¯•å…¶ä»–å¯èƒ½çš„åˆ—å
            possible_date_cols = ['ä¸‹å•æ—¶é—´', 'é‡‡é›†æ—¶é—´', 'collect_time', 'timestamp', 'æ—¶é—´', 'åˆ›å»ºæ—¶é—´', 'date', 'order_date', 'created_at']
            for possible_col in possible_date_cols:
                if possible_col in df.columns:
                    date_col = possible_col
                    print(f"[æ—¥æœŸåˆ—] ä½¿ç”¨å¤‡ç”¨åˆ—: {date_col}")
                    break
        
        if not date_col:
            print(f"[é”™è¯¯] æœªæ‰¾åˆ°æ—¥æœŸåˆ—!")
            print(f"[å¯ç”¨åˆ—] {list(df.columns)[:10]}")
            raise ValueError("æ•°æ®ç¼ºå°‘æ—¥æœŸåˆ—,æ— æ³•å¯¼å…¥")
        
        try:
            for idx, row in df.iterrows():
                try:
                    order_id = str(row.get('è®¢å•ID', ''))
                    if not order_id or order_id == 'nan':
                        continue
                    
                    existing = db.query(Order).filter(Order.order_id == order_id).first()
                    
                    # âœ… ä½¿ç”¨è¯†åˆ«åˆ°çš„æ—¥æœŸåˆ—å¹¶è¿›è¡Œå®‰å…¨è½¬æ¢
                    order_date = None
                    if date_col and pd.notna(row.get(date_col)):
                        try:
                            order_date = pd.to_datetime(row[date_col])
                            
                            # æ£€æŸ¥æ—¥æœŸæ˜¯å¦æœ‰æ•ˆ
                            if pd.isna(order_date):
                                print(f"[è­¦å‘Š] è®¢å• {order_id} æ—¥æœŸä¸ºNaT: {row.get(date_col)}")
                                order_date = None
                                
                        except Exception as e:
                            print(f"[è­¦å‘Š] è®¢å• {order_id} æ—¥æœŸè½¬æ¢å¤±è´¥: {row.get(date_col)} - {e}")
                            order_date = None
                    
                    # âœ… å¦‚æžœæ—¥æœŸæ— æ•ˆ,è·³è¿‡è¿™æ¡è®°å½•(ä¸ä½¿ç”¨å½“å‰æ—¶é—´)
                    if order_date is None or pd.isna(order_date):
                        print(f"[è·³è¿‡] è®¢å• {order_id} ç¼ºå°‘æœ‰æ•ˆæ—¥æœŸ")
                        errors += 1
                        continue
                    
                    # ðŸ”§ åº“å­˜å­—æ®µå…¼å®¹æ€§å¤„ç†(æ”¯æŒå¤šç§åˆ—å)
                    stock_value = None
                    remaining_stock_value = None
                    
                    # å°è¯•è¯»å–åº“å­˜å­—æ®µ(ä¼˜å…ˆçº§ä»Žé«˜åˆ°ä½Ž)
                    for col in ['åº“å­˜', 'stock', 'æœŸæœ«åº“å­˜']:
                        if col in row.index and pd.notna(row.get(col)):
                            stock_value = float(row[col]) if row[col] != '' else None
                            break
                    
                    # å°è¯•è¯»å–å‰©ä½™åº“å­˜å­—æ®µ
                    for col in ['å‰©ä½™åº“å­˜', 'remaining_stock', 'å½“å‰åº“å­˜']:
                        if col in row.index and pd.notna(row.get(col)):
                            remaining_stock_value = float(row[col]) if row[col] != '' else None
                            break
                    
                    order_data = {
                        'order_id': order_id,
                        'date': order_date,
                        'store_name': str(row.get('é—¨åº—åç§°', 'UNKNOWN')),
                        'product_name': str(row.get('å•†å“åç§°', '')),
                        'barcode': str(row.get('å•†å“æ¡å½¢ç ', '')) if pd.notna(row.get('å•†å“æ¡å½¢ç ')) else None,
                        'category_level1': str(row.get('ä¸€çº§åˆ†ç±»å', '')) if pd.notna(row.get('ä¸€çº§åˆ†ç±»å')) else None,
                        'category_level3': str(row.get('ä¸‰çº§åˆ†ç±»å', '')) if pd.notna(row.get('ä¸‰çº§åˆ†ç±»å')) else None,
                        'price': float(row.get('å•†å“å®žå”®ä»·', 0)) if pd.notna(row.get('å•†å“å®žå”®ä»·')) else 0,
                        'cost': float(row.get('å•†å“é‡‡è´­æˆæœ¬', 0)) if pd.notna(row.get('å•†å“é‡‡è´­æˆæœ¬')) else None,
                        'quantity': int(row.get('é”€å”®æ•°é‡', 1)) if pd.notna(row.get('é”€å”®æ•°é‡')) else 1,
                        'amount': float(row.get('å®žæ”¶é‡‘é¢', 0)) if pd.notna(row.get('å®žæ”¶é‡‘é¢')) else 0,
                        'channel': str(row.get('æ¸ é“', '')) if pd.notna(row.get('æ¸ é“')) else None,
                        'stock': int(stock_value) if stock_value is not None else 0,  # ðŸ”§ åº“å­˜
                        'remaining_stock': float(remaining_stock_value) if remaining_stock_value is not None else 0,  # ðŸ”§ å‰©ä½™åº“å­˜
                    }
                    
                    if existing:
                        for key, value in order_data.items():
                            if key != 'order_id':
                                setattr(existing, key, value)
                        existing.updated_at = datetime.now()
                        updated += 1
                    else:
                        db.add(Order(**order_data))
                        imported += 1
                    
                    # æ¯50æ¡æäº¤ä¸€æ¬¡
                    if (imported + updated) % 50 == 0:
                        db.commit()
                        
                except Exception as e:
                    db.rollback()
                    errors += 1
                    continue
            
            db.commit()
            return imported, updated, errors
            
        finally:
            db.close()
    
    def log_upload_history(self, filename: str, records: int, success: bool, error_msg: str = None):
        """è®°å½•ä¸Šä¼ åŽ†å²"""
        db = next(get_db())
        
        try:
            history = DataUploadHistory(
                filename=filename,
                upload_date=datetime.now(),
                records_count=records,
                status='success' if success else 'failed',
                error_message=error_msg
            )
            db.add(history)
            db.commit()
        except:
            db.rollback()
        finally:
            db.close()
    
    def import_file(self, file_path: str):
        """å¯¼å…¥å•ä¸ªæ–‡ä»¶"""
        filename = os.path.basename(file_path)
        print(f"\n{'='*60}")
        print(f"[FILE] {filename}")
        print(f"{'='*60}")
        
        try:
            # 1. åŠ è½½æ•°æ®
            print(f"[1/4] åŠ è½½Excel...")
            df = pd.read_excel(file_path)
            original_count = len(df)
            print(f"   {original_count:,} è¡Œ")
            
            # 2. æ ‡å‡†åŒ–
            print(f"[2/4] æ ‡å‡†åŒ–å­—æ®µ...")
            df = self.processor.standardize_sales_data(df)
            
            # 3. ä¸šåŠ¡è¿‡æ»¤
            print(f"[3/4] ä¸šåŠ¡è¿‡æ»¤...")
            if 'ä¸€çº§åˆ†ç±»å' in df.columns:
                df = df[df['ä¸€çº§åˆ†ç±»å'] != 'è€—æ'].copy()
            if 'æ¸ é“' in df.columns:
                df = df[~df['æ¸ é“'].str.contains('å’–å•¡', na=False)].copy()
            
            filtered_count = len(df)
            print(f"   ä¿ç•™ {filtered_count:,} è¡Œ")
            
            # 4. å¯¼å…¥æ•°æ®
            print(f"[4/4] å¯¼å…¥æ•°æ®åº“...")
            
            # å¯¼å…¥å•†å“
            products = self.extract_products(df)
            p_imported, p_updated = self.import_products_batch(products)
            print(f"   å•†å“: æ–°å¢ž {p_imported}, æ›´æ–° {p_updated}")
            
            # å¯¼å…¥è®¢å•
            o_imported, o_updated, o_errors = self.import_orders_batch(df)
            print(f"   è®¢å•: æ–°å¢ž {o_imported}, æ›´æ–° {o_updated}, é”™è¯¯ {o_errors}")
            
            # è®°å½•åŽ†å²
            self.log_upload_history(filename, filtered_count, True)
            
            self.stats['files_success'] += 1
            self.stats['total_products'] += p_imported
            self.stats['total_orders'] += o_imported
            
            print(f"âœ… æ–‡ä»¶å¯¼å…¥æˆåŠŸ")
            return True
            
        except Exception as e:
            print(f"âŒ æ–‡ä»¶å¯¼å…¥å¤±è´¥: {str(e)[:100]}")
            self.log_upload_history(filename, 0, False, str(e))
            self.stats['files_failed'] += 1
            return False
    
    def run(self):
        """æ‰§è¡Œæ‰¹é‡å¯¼å…¥"""
        print("\n" + "="*60)
        print("P1ä»»åŠ¡ï¼šæ‰¹é‡åŽ†å²æ•°æ®å¯¼å…¥")
        print("="*60)
        
        # æŸ¥æ‰¾æ–‡ä»¶
        files = self.find_excel_files()
        
        if not files:
            print(f"\næœªæ‰¾åˆ°Excelæ–‡ä»¶: {self.data_dir}")
            return
        
        print(f"\nå‘çŽ° {len(files)} ä¸ªExcelæ–‡ä»¶")
        for i, f in enumerate(files, 1):
            print(f"  {i}. {os.path.basename(f)}")
        
        # ç¡®è®¤å¯¼å…¥
        print(f"\nå³å°†å¯¼å…¥è¿™äº›æ–‡ä»¶åˆ°æ•°æ®åº“ï¼Œç»§ç»­å—ï¼Ÿ")
        print(f"è¾“å…¥ 'yes' ç»§ç»­ï¼Œå…¶ä»–ä»»æ„é”®å–æ¶ˆ: ", end='')
        
        # è‡ªåŠ¨ç¡®è®¤ï¼ˆç”¨äºŽè„šæœ¬æ‰§è¡Œï¼‰
        confirm = 'yes'
        print(confirm)
        
        if confirm.lower() != 'yes':
            print("å·²å–æ¶ˆå¯¼å…¥")
            return
        
        # é€ä¸ªå¯¼å…¥
        for file_path in files:
            self.stats['files_processed'] += 1
            self.import_file(file_path)
        
        # æœ€ç»ˆç»Ÿè®¡
        print(f"\n" + "="*60)
        print("æ‰¹é‡å¯¼å…¥å®Œæˆ")
        print("="*60)
        print(f"æ–‡ä»¶æ€»æ•°: {len(files)}")
        print(f"æˆåŠŸ: {self.stats['files_success']}")
        print(f"å¤±è´¥: {self.stats['files_failed']}")
        print(f"æ–°å¢žå•†å“: {self.stats['total_products']}")
        print(f"æ–°å¢žè®¢å•: {self.stats['total_orders']}")
        
        # éªŒè¯æ•°æ®åº“
        db = next(get_db())
        try:
            total_products = db.query(Product).count()
            total_orders = db.query(Order).count()
            print(f"\næ•°æ®åº“æ€»è®¡:")
            print(f"  å•†å“: {total_products:,}")
            print(f"  è®¢å•: {total_orders:,}")
        finally:
            db.close()


if __name__ == "__main__":
    # é»˜è®¤æ•°æ®ç›®å½•
    data_dir = r"D:\Python1\O2O_Analysis\O2Oæ•°æ®åˆ†æž\æµ‹ç®—æ¨¡åž‹\å®žé™…æ•°æ®"
    
    # å¦‚æžœæä¾›äº†å‘½ä»¤è¡Œå‚æ•°ï¼Œä½¿ç”¨å‚æ•°æŒ‡å®šçš„ç›®å½•
    if len(sys.argv) > 1:
        data_dir = sys.argv[1]
    
    importer = BatchDataImporter(data_dir)
    importer.run()
