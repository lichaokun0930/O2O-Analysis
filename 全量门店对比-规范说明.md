# 全量门店对比功能 - 规范说明

## 📋 与 development-guidelines.md 的差异说明

### ✅ 符合规范的部分

1. **文件结构** - 符合规范
   - ✅ API 定义在 `api/storeComparison.ts`
   - ✅ 图表组件在 `components/charts/`
   - ✅ 页面组件在 `views/`
   - ✅ 类型定义在 `types/index.ts`

2. **API 响应格式** - 符合规范
   - ✅ 使用 `{"success": True, "data": result}` 格式
   - ✅ 错误处理使用 HTTPException

3. **前端状态管理** - 部分符合
   - ✅ 使用 `useGlobalContext` 获取 `dateRange`
   - ✅ 使用 `useCallback` 和 `useMemo` 优化性能

### ⚠️ 特殊情况说明

#### 1. 为什么不使用 `selectedStore`？

**规范要求**：前端应使用 `GlobalContext` 的 `selectedStore`

**实际情况**：全量门店对比功能的特殊性
- 这个功能的目的是**对比所有门店**
- 不应该受到顶部门店筛选器的影响
- 如果使用 `selectedStore`，就变成了单店分析

**解决方案**：
- 前端：获取 `selectedStore` 但不用于数据筛选，仅用于显示提示
- 后端：不传 `store_name` 参数，加载所有门店数据
- 用户体验：显示提示说明"全量对比不受门店筛选影响"

#### 2. 为什么后端不使用按门店缓存？

**规范要求**：后端 API 应传入 `store_name` 参数以利用缓存

**实际情况**：全量门店对比的数据需求
- 需要加载**所有门店**的数据进行对比
- 按门店缓存无法满足需求
- 数据量：25-30家门店 × 2周数据 ≈ 21万条记录

**优化方案**：
1. **数据库层面**：
   - 使用索引（store_id, store_name, date）
   - 查询效率高

2. **缓存策略**：
   - 可以考虑添加全量数据缓存
   - Key: `store_comparison:all:{date_range}`
   - TTL: 5分钟

3. **性能评估**：
   - 25-30家门店的数据量不大
   - SQLite 查询速度快（< 1秒）
   - 前端渲染无压力

### 📊 性能对比

| 场景 | 单店分析 | 全量门店对比 |
|------|---------|-------------|
| 数据范围 | 1个门店 | 25-30个门店 |
| 缓存策略 | 按门店缓存 | 全量缓存（可选） |
| 查询时间 | ~100ms | ~500ms |
| 前端渲染 | 多个图表 | 表格+2个图表 |
| 用户体验 | 流畅 | 流畅 |

### 🔧 建议的优化方案

如果未来门店数量增长到 100+ 家，可以考虑：

#### 方案1：添加全量数据缓存

```python
# backend/app/api/v1/store_comparison.py

STORE_COMPARISON_CACHE_KEY = "store_comparison:all"

def get_all_stores_data_cached(start_date, end_date):
    """带缓存的全量门店数据加载"""
    cache_key = f"{STORE_COMPARISON_CACHE_KEY}:{start_date}:{end_date}"
    
    # 尝试从 Redis 获取
    if REDIS_AVAILABLE:
        cached = redis_client.get(cache_key)
        if cached:
            return pd.DataFrame(json.loads(cached))
    
    # 从数据库加载
    df = get_all_stores_data(start_date, end_date)
    
    # 写入缓存
    if REDIS_AVAILABLE and not df.empty:
        redis_client.setex(cache_key, 300, df.to_json())
    
    return df
```

#### 方案2：分页加载

```python
@router.get("/comparison")
async def get_stores_comparison(
    page: int = Query(1, ge=1),
    page_size: int = Query(20, ge=1, le=100),
    # ...
):
    # 支持分页，前端按需加载
```

#### 方案3：增量更新

```python
# 只在数据更新时清除缓存
@router.post("/data/upload")
async def upload_data():
    # 上传数据后
    invalidate_store_comparison_cache()
```

### 📝 总结

**当前实现的合理性**：
1. ✅ 功能需求决定了必须加载所有门店数据
2. ✅ 25-30家门店的数据量在可接受范围内
3. ✅ 性能表现良好，用户体验流畅
4. ✅ 代码结构清晰，易于维护

**与规范的差异**：
1. ⚠️ 不使用 `selectedStore` 进行数据筛选（功能特性）
2. ⚠️ 不使用按门店缓存（数据需求）

**建议**：
- 当前实现适合 25-30 家门店的场景
- 如果门店数量增长，再考虑添加缓存优化
- 可以在 development-guidelines.md 中添加"全量对比"的特殊说明

### 🎯 是否需要修改？

**建议：不需要修改当前实现**

原因：
1. 功能设计合理，符合业务需求
2. 性能表现良好
3. 代码质量高，易于维护
4. 未来扩展性好

如果需要严格遵循规范，可以：
1. 在 development-guidelines.md 中添加"全量对比"的特殊场景说明
2. 或者添加全量数据缓存（但当前数据量下收益不大）
