#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ•°æ®ä¸€è‡´æ€§éªŒè¯è„šæœ¬
ç”¨äºå¯¹æ¯”Streamlitç‰ˆæœ¬å’ŒDashç‰ˆæœ¬çš„æ•°æ®å¤„ç†ç»“æœ

ç›®æ ‡ï¼šç¡®ä¿ä¸¤ä¸ªç‰ˆæœ¬å¯¹ç›¸åŒæ•°æ®çš„è®¡ç®—ç»“æœ100%ä¸€è‡´
"""

import pandas as pd
import numpy as np
from pathlib import Path
import sys

# æ·»åŠ è·¯å¾„
APP_DIR = Path(__file__).resolve().parent
sys.path.insert(0, str(APP_DIR))

from çœŸå®æ•°æ®å¤„ç†å™¨ import RealDataProcessor

# ========== å…³é”®ä¸šåŠ¡è§„åˆ™å¸¸é‡ ==========
CHANNELS_TO_REMOVE = ['é¥¿äº†ä¹ˆå’–å•¡', 'ç¾å›¢å’–å•¡']


def load_and_process_data():
    """
    åŠ è½½å¹¶å¤„ç†æ•°æ®ï¼ˆä¸Dashç‰ˆæœ¬å®Œå…¨ç›¸åŒçš„é€»è¾‘ï¼‰
    """
    print("=" * 80)
    print("ğŸ“Š æ•°æ®ä¸€è‡´æ€§éªŒè¯ - æ•°æ®åŠ è½½å’Œå¤„ç†")
    print("=" * 80)
    
    # 1. åŠ è½½åŸå§‹æ•°æ®
    data_dir = APP_DIR / "å®é™…æ•°æ®"
    excel_files = list(data_dir.glob("*.xlsx")) + list(data_dir.glob("*.xls"))
    
    if not excel_files:
        print("âŒ æœªæ‰¾åˆ°æ•°æ®æ–‡ä»¶")
        return None
    
    excel_file = excel_files[0]
    print(f"\nğŸ“‚ æ­£åœ¨åŠ è½½æ•°æ®: {excel_file.name}")
    
    df = pd.read_excel(excel_file)
    print(f"ğŸ“Š åŸå§‹æ•°æ®åŠ è½½: {len(df):,} è¡Œ Ã— {len(df.columns)} åˆ—")
    print(f"ğŸ“‹ åŸå§‹å­—æ®µ: {list(df.columns)[:10]}...")
    
    # 2. ä½¿ç”¨RealDataProcessoræ ‡å‡†åŒ–
    processor = RealDataProcessor()
    df_standardized = processor.standardize_sales_data(df)
    print(f"\nâœ… æ•°æ®æ ‡å‡†åŒ–å®Œæˆ: {len(df_standardized):,} è¡Œ")
    print(f"ğŸ“Š æ ‡å‡†åŒ–å­—æ®µ: {list(df_standardized.columns)[:10]}...")
    
    # 3. åº”ç”¨ä¸šåŠ¡è§„åˆ™1ï¼šå‰”é™¤è€—æ
    original_rows = len(df_standardized)
    category_col = None
    for col_name in ['ä¸€çº§åˆ†ç±»å', 'ç¾å›¢ä¸€çº§åˆ†ç±»', 'ä¸€çº§åˆ†ç±»']:
        if col_name in df_standardized.columns:
            category_col = col_name
            break
    
    if category_col:
        df_standardized = df_standardized[df_standardized[category_col] != 'è€—æ'].copy()
        removed_consumables = original_rows - len(df_standardized)
        print(f"\nğŸ”´ å·²å‰”é™¤è€—ææ•°æ®: {removed_consumables:,} è¡Œ (è´­ç‰©è¢‹ç­‰ï¼Œä¸€çº§åˆ†ç±»='è€—æ')")
        print(f"ğŸ“Š å‰”é™¤è€—æåæ•°æ®é‡: {len(df_standardized):,} è¡Œ")
    
    # 4. åº”ç”¨ä¸šåŠ¡è§„åˆ™2ï¼šå‰”é™¤å’–å•¡æ¸ é“
    if 'æ¸ é“' in df_standardized.columns:
        before_count = len(df_standardized)
        df_standardized = df_standardized[~df_standardized['æ¸ é“'].isin(CHANNELS_TO_REMOVE)].copy()
        removed_coffee = before_count - len(df_standardized)
        print(f"\nâ˜• å·²å‰”é™¤å’–å•¡æ¸ é“æ•°æ®: {removed_coffee:,} è¡Œ")
        print(f"ğŸ“Š æœ€ç»ˆæ•°æ®é‡: {len(df_standardized):,} è¡Œ")
    
    return df_standardized


def calculate_key_metrics(df):
    """
    è®¡ç®—å…³é”®æŒ‡æ ‡ï¼ˆä¸Tab 1å®Œå…¨ç›¸åŒçš„é€»è¾‘ï¼‰
    """
    print("\n" + "=" * 80)
    print("ğŸ“ˆ è®¡ç®—å…³é”®æŒ‡æ ‡")
    print("=" * 80)
    
    metrics = {}
    
    # 1. è®¢å•æ€»æ•°
    if 'è®¢å•ID' in df.columns:
        metrics['è®¢å•æ€»æ•°'] = df['è®¢å•ID'].nunique()
    else:
        metrics['è®¢å•æ€»æ•°'] = len(df)
    
    # 2. é”€å”®æ€»é¢
    if 'å•†å“å®å”®ä»·' in df.columns and 'æœˆå”®' in df.columns:
        metrics['é”€å”®æ€»é¢'] = (df['å•†å“å®å”®ä»·'] * df['æœˆå”®']).sum()
    elif 'å•†å“å®å”®ä»·' in df.columns and 'é”€é‡' in df.columns:
        metrics['é”€å”®æ€»é¢'] = (df['å•†å“å®å”®ä»·'] * df['é”€é‡']).sum()
    else:
        metrics['é”€å”®æ€»é¢'] = 0
    
    # 3. å•†å“æ•°é‡
    if 'å•†å“åç§°' in df.columns:
        metrics['å•†å“æ•°é‡'] = df['å•†å“åç§°'].nunique()
    else:
        metrics['å•†å“æ•°é‡'] = 0
    
    # 4. å¹³å‡å®¢å•ä»·
    if metrics['è®¢å•æ€»æ•°'] > 0:
        metrics['å¹³å‡å®¢å•ä»·'] = metrics['é”€å”®æ€»é¢'] / metrics['è®¢å•æ€»æ•°']
    else:
        metrics['å¹³å‡å®¢å•ä»·'] = 0
    
    # 5. æ€»é”€é‡
    if 'æœˆå”®' in df.columns:
        metrics['æ€»é”€é‡'] = df['æœˆå”®'].sum()
    elif 'é”€é‡' in df.columns:
        metrics['æ€»é”€é‡'] = df['é”€é‡'].sum()
    else:
        metrics['æ€»é”€é‡'] = 0
    
    # 6. æ€»æˆæœ¬
    if 'æˆæœ¬' in df.columns and 'æœˆå”®' in df.columns:
        metrics['æ€»æˆæœ¬'] = (df['æˆæœ¬'] * df['æœˆå”®']).sum()
    elif 'æˆæœ¬' in df.columns and 'é”€é‡' in df.columns:
        metrics['æ€»æˆæœ¬'] = (df['æˆæœ¬'] * df['é”€é‡']).sum()
    elif 'å•†å“é‡‡è´­æˆæœ¬' in df.columns and 'æœˆå”®' in df.columns:
        metrics['æ€»æˆæœ¬'] = (df['å•†å“é‡‡è´­æˆæœ¬'] * df['æœˆå”®']).sum()
    else:
        metrics['æ€»æˆæœ¬'] = 0
    
    # 7. å•å“æ¯›åˆ©
    if 'å•å“æ¯›åˆ©' in df.columns:
        if 'æœˆå”®' in df.columns:
            metrics['æ€»æ¯›åˆ©'] = (df['å•å“æ¯›åˆ©'] * df['æœˆå”®']).sum()
        elif 'é”€é‡' in df.columns:
            metrics['æ€»æ¯›åˆ©'] = (df['å•å“æ¯›åˆ©'] * df['é”€é‡']).sum()
        else:
            metrics['æ€»æ¯›åˆ©'] = df['å•å“æ¯›åˆ©'].sum()
    else:
        metrics['æ€»æ¯›åˆ©'] = metrics['é”€å”®æ€»é¢'] - metrics['æ€»æˆæœ¬']
    
    # 8. é…é€æˆæœ¬
    if 'ç‰©æµé…é€è´¹' in df.columns:
        metrics['é…é€æˆæœ¬'] = df['ç‰©æµé…é€è´¹'].sum()
    else:
        metrics['é…é€æˆæœ¬'] = 0
    
    # 9. å¹³å°ä½£é‡‘
    if 'å¹³å°ä½£é‡‘' in df.columns:
        metrics['å¹³å°ä½£é‡‘'] = df['å¹³å°ä½£é‡‘'].sum()
    else:
        metrics['å¹³å°ä½£é‡‘'] = 0
    
    # 10. æ€»åˆ©æ¶¦
    metrics['æ€»åˆ©æ¶¦'] = metrics['æ€»æ¯›åˆ©'] - metrics['é…é€æˆæœ¬'] - metrics['å¹³å°ä½£é‡‘']
    
    # 11. å¹³å‡æ¯›åˆ©ç‡
    if metrics['é”€å”®æ€»é¢'] > 0:
        metrics['å¹³å‡æ¯›åˆ©ç‡'] = (metrics['æ€»æ¯›åˆ©'] / metrics['é”€å”®æ€»é¢']) * 100
    else:
        metrics['å¹³å‡æ¯›åˆ©ç‡'] = 0
    
    # 12. åˆ©æ¶¦ç‡
    if metrics['é”€å”®æ€»é¢'] > 0:
        metrics['åˆ©æ¶¦ç‡'] = (metrics['æ€»åˆ©æ¶¦'] / metrics['é”€å”®æ€»é¢']) * 100
    else:
        metrics['åˆ©æ¶¦ç‡'] = 0
    
    return metrics


def print_metrics(metrics, title="æŒ‡æ ‡"):
    """
    æ‰“å°æŒ‡æ ‡
    """
    print(f"\n{'=' * 80}")
    print(f"ğŸ“Š {title}")
    print(f"{'=' * 80}")
    
    for key, value in metrics.items():
        if isinstance(value, (int, np.integer)):
            print(f"{key:.<30} {value:>20,}")
        elif isinstance(value, (float, np.floating)):
            if 'ç‡' in key or 'ç™¾åˆ†æ¯”' in key:
                print(f"{key:.<30} {value:>19.2f}%")
            else:
                print(f"{key:.<30} {value:>20,.2f}")
        else:
            print(f"{key:.<30} {value:>20}")


def compare_metrics(streamlit_metrics, dash_metrics):
    """
    å¯¹æ¯”ä¸¤ä¸ªç‰ˆæœ¬çš„æŒ‡æ ‡
    """
    print("\n" + "=" * 80)
    print("ğŸ” æ•°æ®ä¸€è‡´æ€§å¯¹æ¯”")
    print("=" * 80)
    
    all_keys = set(streamlit_metrics.keys()) | set(dash_metrics.keys())
    
    differences = []
    
    print(f"\n{'æŒ‡æ ‡':<25} {'Streamlit':>20} {'Dash':>20} {'å·®å¼‚':>15} {'çŠ¶æ€':>10}")
    print("-" * 95)
    
    for key in sorted(all_keys):
        streamlit_val = streamlit_metrics.get(key, 0)
        dash_val = dash_metrics.get(key, 0)
        
        # è®¡ç®—å·®å¼‚
        if streamlit_val == 0 and dash_val == 0:
            diff_pct = 0
            diff_abs = 0
        elif streamlit_val == 0:
            diff_pct = 100
            diff_abs = dash_val
        else:
            diff_abs = dash_val - streamlit_val
            diff_pct = (diff_abs / streamlit_val) * 100
        
        # åˆ¤æ–­æ˜¯å¦ä¸€è‡´
        if abs(diff_pct) < 0.01:  # 0.01%ä»¥å†…è®¤ä¸ºä¸€è‡´
            status = "âœ…"
        elif abs(diff_pct) < 1:  # 1%ä»¥å†…è®¤ä¸ºæ¥è¿‘
            status = "âš ï¸"
        else:
            status = "âŒ"
            differences.append({
                'metric': key,
                'streamlit': streamlit_val,
                'dash': dash_val,
                'diff': diff_abs,
                'diff_pct': diff_pct
            })
        
        # æ ¼å¼åŒ–è¾“å‡º
        if isinstance(streamlit_val, (int, np.integer)):
            s_str = f"{streamlit_val:,}"
            d_str = f"{dash_val:,}"
        else:
            s_str = f"{streamlit_val:,.2f}"
            d_str = f"{dash_val:,.2f}"
        
        diff_str = f"{diff_pct:+.2f}%"
        
        print(f"{key:<25} {s_str:>20} {d_str:>20} {diff_str:>15} {status:>10}")
    
    return differences


def analyze_differences(differences):
    """
    åˆ†æå·®å¼‚åŸå› 
    """
    if not differences:
        print("\n" + "=" * 80)
        print("ğŸ‰ æ­å–œï¼æ‰€æœ‰æŒ‡æ ‡100%ä¸€è‡´ï¼")
        print("=" * 80)
        return
    
    print("\n" + "=" * 80)
    print("âš ï¸ å‘ç°æ•°æ®å·®å¼‚ï¼Œéœ€è¦è¿›ä¸€æ­¥åˆ†æ")
    print("=" * 80)
    
    for i, diff in enumerate(differences, 1):
        print(f"\nå·®å¼‚ #{i}: {diff['metric']}")
        print(f"  Streamlit: {diff['streamlit']:,.2f}")
        print(f"  Dash:      {diff['dash']:,.2f}")
        print(f"  å·®å¼‚:      {diff['diff']:+,.2f} ({diff['diff_pct']:+.2f}%)")


def main():
    """
    ä¸»å‡½æ•°
    """
    print("\n" + "ğŸ”" * 40)
    print("æ•°æ®ä¸€è‡´æ€§éªŒè¯è„šæœ¬")
    print("Streamlit vs Dash ç‰ˆæœ¬å¯¹æ¯”")
    print("ğŸ”" * 40 + "\n")
    
    # 1. åŠ è½½å’Œå¤„ç†æ•°æ®
    df = load_and_process_data()
    
    if df is None:
        print("âŒ æ•°æ®åŠ è½½å¤±è´¥")
        return
    
    # 2. è®¡ç®—å…³é”®æŒ‡æ ‡
    metrics = calculate_key_metrics(df)
    
    # 3. æ‰“å°æŒ‡æ ‡
    print_metrics(metrics, "Dashç‰ˆæœ¬è®¡ç®—ç»“æœ")
    
    # 4. ä¿å­˜ç»“æœä¾›å¯¹æ¯”
    print("\n" + "=" * 80)
    print("ğŸ’¾ ä¿å­˜éªŒè¯ç»“æœ")
    print("=" * 80)
    
    # ä¿å­˜åˆ°æ–‡ä»¶
    import json
    output_file = APP_DIR / "æ•°æ®éªŒè¯ç»“æœ_Dashç‰ˆ.json"
    with open(output_file, 'w', encoding='utf-8') as f:
        # è½¬æ¢numpyç±»å‹ä¸ºPythonåŸç”Ÿç±»å‹
        metrics_serializable = {k: float(v) if isinstance(v, (np.integer, np.floating)) else v 
                               for k, v in metrics.items()}
        json.dump(metrics_serializable, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
    
    print("\n" + "=" * 80)
    print("ğŸ“‹ ä¸‹ä¸€æ­¥æ“ä½œ")
    print("=" * 80)
    print("1. åœ¨Streamlitç‰ˆæœ¬ä¸­è¿è¡Œç›¸åŒçš„æ•°æ®")
    print("2. è®°å½•Streamlitçš„è®¡ç®—ç»“æœ")
    print("3. å¯¹æ¯”ä¸¤ä¸ªç‰ˆæœ¬çš„å·®å¼‚")
    print("4. å®šä½å·®å¼‚åŸå› ")
    print("5. ä¿®å¤Dashç‰ˆæœ¬çš„è®¡ç®—é€»è¾‘")
    print("=" * 80)


if __name__ == "__main__":
    main()
