# -*- coding: utf-8 -*-
"""
ä¼ä¸šçº§æ€§èƒ½ä¼˜åŒ–å®æ–½è„šæœ¬

ä¸‰å±‚ä¼˜åŒ–æ–¹æ¡ˆï¼š
1. æ•°æ®åº“å±‚ï¼šæ·»åŠ /éªŒè¯ç´¢å¼•
2. æŸ¥è¯¢å±‚ï¼šåˆ›å»ºé¢„èšåˆè§†å›¾/ç‰©åŒ–è¡¨
3. ç¼“å­˜å±‚ï¼šä¼˜åŒ– Redis ç¼“å­˜ç­–ç•¥

æ‰§è¡Œåè‡ªåŠ¨éªŒè¯ä¼˜åŒ–æ•ˆæœ

æ”¯æŒ PostgreSQL æ•°æ®åº“
"""

import time
import sys
from pathlib import Path
from datetime import datetime, timedelta

PROJECT_ROOT = Path(__file__).resolve().parent
sys.path.insert(0, str(PROJECT_ROOT))
sys.path.insert(0, str(PROJECT_ROOT / "backend" / "app"))

from database.connection import SessionLocal, engine
from database.models import Order, Base
from sqlalchemy import text, inspect
import pandas as pd


def print_section(title):
    """æ‰“å°åˆ†èŠ‚æ ‡é¢˜"""
    print("\n" + "="*80)
    print(f"ğŸ”§ {title}")
    print("="*80)


# ==================== ç¬¬ä¸€å±‚ï¼šæ•°æ®åº“ç´¢å¼•ä¼˜åŒ– ====================

def optimize_database_indexes():
    """ä¼˜åŒ–æ•°æ®åº“ç´¢å¼•"""
    print_section("ç¬¬ä¸€å±‚ï¼šæ•°æ®åº“ç´¢å¼•ä¼˜åŒ–")
    
    # éœ€è¦åˆ›å»ºçš„ç´¢å¼•ï¼ˆPostgreSQL è¯­æ³•ï¼‰
    indexes_to_create = [
        # æ ¸å¿ƒæŸ¥è¯¢ç´¢å¼•
        ("idx_perf_store_date", "orders", ["store_name", "date"]),
        ("idx_perf_date", "orders", ["date"]),
        ("idx_perf_order_number", "orders", ["order_number"]),
        # èšåˆæŸ¥è¯¢ç´¢å¼•
        ("idx_perf_store_channel_date", "orders", ["store_name", "channel", "date"]),
        # åˆ†ç±»æŸ¥è¯¢ç´¢å¼•
        ("idx_perf_category_store_date", "orders", ["category_level1", "store_name", "date"]),
    ]
    
    session = SessionLocal()
    try:
        # æ£€æŸ¥ç°æœ‰ç´¢å¼•
        result = session.execute(text("""
            SELECT indexname FROM pg_indexes WHERE tablename = 'orders'
        """))
        existing_indexes = {row[0] for row in result.fetchall()}
        print(f"\nç°æœ‰ç´¢å¼•: {len(existing_indexes)} ä¸ª")
        for idx in sorted(existing_indexes)[:10]:
            print(f"   âœ“ {idx}")
        if len(existing_indexes) > 10:
            print(f"   ... è¿˜æœ‰ {len(existing_indexes) - 10} ä¸ª")
        
        # åˆ›å»ºç¼ºå¤±çš„ç´¢å¼•
        created = 0
        for idx_name, table, columns in indexes_to_create:
            if idx_name not in existing_indexes:
                try:
                    cols = ", ".join(columns)
                    sql = f"CREATE INDEX IF NOT EXISTS {idx_name} ON {table} ({cols})"
                    session.execute(text(sql))
                    session.commit()
                    print(f"\n   âœ… åˆ›å»ºç´¢å¼•: {idx_name} ON ({cols})")
                    created += 1
                except Exception as e:
                    print(f"\n   âš ï¸ ç´¢å¼• {idx_name} åˆ›å»ºå¤±è´¥: {e}")
                    session.rollback()
            else:
                print(f"\n   âœ“ ç´¢å¼•å·²å­˜åœ¨: {idx_name}")
        
        # åˆ†æè¡¨ä»¥æ›´æ–°ç»Ÿè®¡ä¿¡æ¯ï¼ˆPostgreSQLï¼‰
        try:
            session.execute(text("ANALYZE orders"))
            session.commit()
            print(f"\n   âœ… å·²æ›´æ–°è¡¨ç»Ÿè®¡ä¿¡æ¯ (ANALYZE)")
        except Exception as e:
            print(f"\n   âš ï¸ ANALYZE å¤±è´¥: {e}")
        
        print(f"\nğŸ“Š ç´¢å¼•ä¼˜åŒ–å®Œæˆ: æ–°å»º {created} ä¸ªç´¢å¼•")
        return True
    except Exception as e:
        print(f"\nâŒ ç´¢å¼•ä¼˜åŒ–å¤±è´¥: {e}")
        return False
    finally:
        session.close()


# ==================== ç¬¬äºŒå±‚ï¼šé¢„èšåˆè¡¨ä¼˜åŒ– ====================

def create_aggregation_tables():
    """åˆ›å»ºé¢„èšåˆè¡¨ï¼ˆPostgreSQL ç‰ˆæœ¬ï¼‰"""
    print_section("ç¬¬äºŒå±‚ï¼šé¢„èšåˆè¡¨ä¼˜åŒ–")
    
    session = SessionLocal()
    try:
        # åˆ›å»ºé—¨åº—æ—¥æ±‡æ€»è¡¨ï¼ˆPostgreSQL è¯­æ³•ï¼‰
        print("\n1. åˆ›å»ºé—¨åº—æ—¥æ±‡æ€»è¡¨ (store_daily_summary)...")
        
        # åˆ é™¤æ—§è¡¨
        session.execute(text("DROP TABLE IF EXISTS store_daily_summary CASCADE"))
        session.commit()
        
        # åˆ›å»ºæ–°è¡¨ï¼ˆPostgreSQL è¯­æ³•ï¼‰
        create_table_sql = """
        CREATE TABLE store_daily_summary (
            id SERIAL PRIMARY KEY,
            store_name VARCHAR(200) NOT NULL,
            summary_date DATE NOT NULL,
            channel VARCHAR(100),
            order_count INTEGER DEFAULT 0,
            total_revenue NUMERIC(15,2) DEFAULT 0,
            total_profit NUMERIC(15,2) DEFAULT 0,
            total_delivery_fee NUMERIC(15,2) DEFAULT 0,
            total_user_paid_delivery NUMERIC(15,2) DEFAULT 0,
            total_delivery_discount NUMERIC(15,2) DEFAULT 0,
            total_corporate_rebate NUMERIC(15,2) DEFAULT 0,
            total_marketing_cost NUMERIC(15,2) DEFAULT 0,
            total_platform_fee NUMERIC(15,2) DEFAULT 0,
            avg_order_value NUMERIC(15,2) DEFAULT 0,
            profit_margin NUMERIC(10,4) DEFAULT 0,
            delivery_net_cost NUMERIC(15,2) DEFAULT 0,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            UNIQUE(store_name, summary_date, channel)
        )
        """
        session.execute(text(create_table_sql))
        session.commit()
        print("   âœ… è¡¨ç»“æ„åˆ›å»ºæˆåŠŸ")
        
        # åˆ›å»ºç´¢å¼•
        session.execute(text("CREATE INDEX IF NOT EXISTS idx_summary_store_date ON store_daily_summary(store_name, summary_date)"))
        session.execute(text("CREATE INDEX IF NOT EXISTS idx_summary_date ON store_daily_summary(summary_date)"))
        session.execute(text("CREATE INDEX IF NOT EXISTS idx_summary_channel ON store_daily_summary(channel)"))
        session.execute(text("CREATE INDEX IF NOT EXISTS idx_summary_store_channel ON store_daily_summary(store_name, channel)"))
        session.commit()
        print("   âœ… ç´¢å¼•åˆ›å»ºæˆåŠŸ")
        
        # å¡«å……æ•°æ®ï¼ˆPostgreSQL è¯­æ³•ï¼‰
        print("\n2. å¡«å……é¢„èšåˆæ•°æ®...")
        
        # âœ… ä½¿ç”¨è®¢å•ç¼–å·å‰ç¼€è¯†åˆ«æ¸ é“ï¼ˆä¸ Dash ç‰ˆæœ¬ä¸€è‡´ï¼‰
        # SG â†’ ç¾å›¢, ELE â†’ é¥¿äº†ä¹ˆ, JD â†’ äº¬ä¸œ
        # âš ï¸ é‡è¦ï¼šå…ˆæŒ‰è®¢å•èšåˆï¼Œå†æŒ‰é—¨åº—+æ—¥æœŸ+æ¸ é“èšåˆ
        # å› ä¸ºä¸€ä¸ªè®¢å•å¯èƒ½æœ‰å¤šä¸ªå•†å“è¡Œï¼Œé…é€è´¹ç­‰å­—æ®µä¸èƒ½é‡å¤è®¡ç®—
        # âš ï¸ è¥é”€å­—æ®µï¼ˆæ»¡å‡é‡‘é¢ç­‰ï¼‰æ˜¯è®¢å•çº§åˆ«å­—æ®µï¼Œä½¿ç”¨MAXè€ŒéSUM
        insert_sql = """
        WITH order_level AS (
            -- ç¬¬ä¸€æ­¥ï¼šæŒ‰è®¢å•èšåˆï¼ˆé¿å…é…é€è´¹ç­‰å­—æ®µé‡å¤è®¡ç®—ï¼‰
            SELECT 
                store_name,
                DATE(date) as order_date,
                order_id,
                order_number,
                CASE 
                    WHEN order_number LIKE 'SG%' THEN 'ç¾å›¢'
                    WHEN order_number LIKE 'ELE%' THEN 'é¥¿äº†ä¹ˆ'
                    WHEN order_number LIKE 'JD%' THEN 'äº¬ä¸œ'
                    ELSE 'å…¶ä»–'
                END as channel,
                SUM(COALESCE(actual_price, 0) * COALESCE(quantity, 1)) as order_revenue,
                SUM(COALESCE(profit, 0)) as order_profit,
                -- é…é€è´¹ç­‰å­—æ®µå–MAXï¼ˆåŒä¸€è®¢å•çš„æ‰€æœ‰å•†å“è¡Œå€¼ç›¸åŒï¼‰
                MAX(COALESCE(delivery_fee, 0)) as order_delivery_fee,
                MAX(COALESCE(user_paid_delivery_fee, 0)) as order_user_paid_delivery,
                MAX(COALESCE(delivery_discount, 0)) as order_delivery_discount,
                MAX(COALESCE(corporate_rebate, 0)) as order_corporate_rebate,
                MAX(COALESCE(platform_service_fee, 0)) as order_platform_fee,
                -- âœ… è¥é”€è´¹ç”¨ä¹Ÿæ˜¯è®¢å•çº§åˆ«å­—æ®µï¼Œä½¿ç”¨MAXï¼ˆä¸Dashç‰ˆæœ¬ä¸€è‡´ï¼‰
                MAX(COALESCE(full_reduction, 0)) + 
                MAX(COALESCE(product_discount, 0)) + 
                MAX(COALESCE(merchant_voucher, 0)) + 
                MAX(COALESCE(merchant_share, 0)) + 
                MAX(COALESCE(gift_amount, 0)) + 
                MAX(COALESCE(other_merchant_discount, 0)) + 
                MAX(COALESCE(new_customer_discount, 0)) as order_marketing_cost
            FROM orders
            GROUP BY store_name, DATE(date), order_id, order_number
        )
        -- ç¬¬äºŒæ­¥ï¼šæŒ‰é—¨åº—+æ—¥æœŸ+æ¸ é“èšåˆ
        INSERT INTO store_daily_summary (
            store_name, summary_date, channel, order_count, 
            total_revenue, total_profit, total_delivery_fee,
            total_user_paid_delivery, total_delivery_discount,
            total_corporate_rebate, total_marketing_cost, total_platform_fee
        )
        SELECT 
            store_name,
            order_date as summary_date,
            channel,
            COUNT(DISTINCT order_id) as order_count,
            SUM(order_revenue) as total_revenue,
            SUM(order_profit) as total_profit,
            SUM(order_delivery_fee) as total_delivery_fee,
            SUM(order_user_paid_delivery) as total_user_paid_delivery,
            SUM(order_delivery_discount) as total_delivery_discount,
            SUM(order_corporate_rebate) as total_corporate_rebate,
            SUM(order_marketing_cost) as total_marketing_cost,
            SUM(order_platform_fee) as total_platform_fee
        FROM order_level
        GROUP BY store_name, order_date, channel
        """
        
        start = time.time()
        session.execute(text(insert_sql))
        session.commit()
        elapsed = time.time() - start
        
        # ç»Ÿè®¡ç»“æœ
        count = session.execute(text("SELECT COUNT(*) FROM store_daily_summary")).scalar()
        print(f"   âœ… æ•°æ®å¡«å……å®Œæˆ: {count} æ¡æ±‡æ€»è®°å½•, è€—æ—¶ {elapsed:.2f}ç§’")
        
        # æ›´æ–°æ´¾ç”Ÿå­—æ®µ
        print("\n3. æ›´æ–°æ´¾ç”ŸæŒ‡æ ‡...")
        update_sql = """
        UPDATE store_daily_summary SET
            avg_order_value = CASE WHEN order_count > 0 THEN total_revenue / order_count ELSE 0 END,
            profit_margin = CASE WHEN total_revenue > 0 THEN total_profit / total_revenue * 100 ELSE 0 END,
            delivery_net_cost = total_delivery_fee - total_user_paid_delivery + total_delivery_discount - total_corporate_rebate
        """
        session.execute(text(update_sql))
        session.commit()
        print("   âœ… æ´¾ç”ŸæŒ‡æ ‡æ›´æ–°å®Œæˆ")
        
        return True
    except Exception as e:
        print(f"\nâŒ é¢„èšåˆè¡¨åˆ›å»ºå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        session.rollback()
        return False
    finally:
        session.close()


# ==================== ç¬¬ä¸‰å±‚ï¼šç¼“å­˜ä¼˜åŒ– ====================

def optimize_cache_strategy():
    """ä¼˜åŒ–ç¼“å­˜ç­–ç•¥"""
    print_section("ç¬¬ä¸‰å±‚ï¼šç¼“å­˜ç­–ç•¥ä¼˜åŒ–")
    
    # æ£€æŸ¥ Redis è¿æ¥
    try:
        import redis
        redis_client = redis.Redis(host='localhost', port=6379, db=0, decode_responses=True)
        redis_client.ping()
        print("\nâœ… Redis è¿æ¥æˆåŠŸ")
        
        # æ¸…é™¤æ—§ç¼“å­˜
        keys = redis_client.keys("order_data*") + redis_client.keys("store_comparison*")
        if keys:
            redis_client.delete(*keys)
            print(f"   æ¸…é™¤æ—§ç¼“å­˜: {len(keys)} ä¸ªé”®")
        
        # é¢„çƒ­ç¼“å­˜ï¼šå°†é¢„èšåˆæ•°æ®åŠ è½½åˆ° Redis
        print("\né¢„çƒ­ç¼“å­˜...")
        
        session = SessionLocal()
        try:
            # è·å–æœ€è¿‘7å¤©çš„æ±‡æ€»æ•°æ®
            result = session.execute(text("""
                SELECT store_name, summary_date, channel,
                       order_count, total_revenue, total_profit,
                       total_delivery_fee, total_user_paid_delivery,
                       total_delivery_discount, total_corporate_rebate,
                       total_marketing_cost, avg_order_value, profit_margin,
                       delivery_net_cost
                FROM store_daily_summary
                WHERE summary_date >= CURRENT_DATE - INTERVAL '7 days'
            """))
            
            rows = result.fetchall()
            print(f"   åŠ è½½ {len(rows)} æ¡æ±‡æ€»è®°å½•åˆ° Redis")
            
            # æŒ‰é—¨åº—+æ—¥æœŸç¼“å­˜
            import json
            for row in rows:
                cache_key = f"store_daily:{row[0]}:{row[1]}:{row[2] or 'all'}"
                cache_data = {
                    'order_count': int(row[3]) if row[3] else 0,
                    'total_revenue': float(row[4]) if row[4] else 0,
                    'total_profit': float(row[5]) if row[5] else 0,
                    'total_delivery_fee': float(row[6]) if row[6] else 0,
                    'total_user_paid_delivery': float(row[7]) if row[7] else 0,
                    'total_delivery_discount': float(row[8]) if row[8] else 0,
                    'total_corporate_rebate': float(row[9]) if row[9] else 0,
                    'total_marketing_cost': float(row[10]) if row[10] else 0,
                    'avg_order_value': float(row[11]) if row[11] else 0,
                    'profit_margin': float(row[12]) if row[12] else 0,
                    'delivery_net_cost': float(row[13]) if row[13] else 0
                }
                redis_client.setex(cache_key, 300, json.dumps(cache_data))  # 5åˆ†é’Ÿè¿‡æœŸ
            
            print(f"   âœ… ç¼“å­˜é¢„çƒ­å®Œæˆ")
        finally:
            session.close()
        
        return True
    except ImportError:
        print("\nâš ï¸ Redis æ¨¡å—æœªå®‰è£…ï¼Œè·³è¿‡ç¼“å­˜ä¼˜åŒ–")
        return False
    except Exception as e:
        print(f"\nâš ï¸ Redis ç¼“å­˜é¢„çƒ­å¤±è´¥: {e}")
        print("   ç¼“å­˜ä¼˜åŒ–è·³è¿‡ï¼Œç³»ç»Ÿå°†ä½¿ç”¨å†…å­˜ç¼“å­˜")
        return False


# ==================== éªŒè¯ä¼˜åŒ–æ•ˆæœ ====================

def verify_optimization():
    """éªŒè¯ä¼˜åŒ–æ•ˆæœ"""
    print_section("éªŒè¯ä¼˜åŒ–æ•ˆæœ")
    
    session = SessionLocal()
    results = {}
    
    try:
        # æµ‹è¯•1: ä½¿ç”¨é¢„èšåˆè¡¨æŸ¥è¯¢
        print("\n1. é¢„èšåˆè¡¨æŸ¥è¯¢æ€§èƒ½:")
        start = time.time()
        result = session.execute(text("""
            SELECT store_name, 
                   SUM(order_count) as orders,
                   SUM(total_revenue) as revenue,
                   SUM(total_profit) as profit,
                   SUM(delivery_net_cost) as delivery_cost,
                   SUM(total_marketing_cost) as marketing_cost
            FROM store_daily_summary
            WHERE summary_date BETWEEN '2026-01-12' AND '2026-01-18'
            GROUP BY store_name
        """))
        rows = result.fetchall()
        agg_time = time.time() - start
        print(f"   é¢„èšåˆè¡¨æŸ¥è¯¢: {agg_time*1000:.1f}ms ({len(rows)} é—¨åº—)")
        results['aggregation_query'] = agg_time
        
        # æµ‹è¯•2: åŸå§‹è¡¨æŸ¥è¯¢ï¼ˆå¯¹æ¯”ï¼‰
        print("\n2. åŸå§‹è¡¨æŸ¥è¯¢æ€§èƒ½ï¼ˆå¯¹æ¯”ï¼‰:")
        start = time.time()
        result = session.execute(text("""
            SELECT store_name, COUNT(DISTINCT order_id) as orders
            FROM orders
            WHERE date BETWEEN '2026-01-12' AND '2026-01-18'
            GROUP BY store_name
        """))
        rows = result.fetchall()
        raw_time = time.time() - start
        print(f"   åŸå§‹è¡¨æŸ¥è¯¢: {raw_time*1000:.1f}ms ({len(rows)} é—¨åº—)")
        results['raw_query'] = raw_time
        
        # æµ‹è¯•3: ç´¢å¼•æ•ˆæœéªŒè¯
        print("\n3. ç´¢å¼•æ•ˆæœéªŒè¯:")
        start = time.time()
        result = session.execute(text("""
            SELECT COUNT(*) FROM orders
            WHERE store_name = 'æƒ å®œé€‰-æ³°å·æ³°å…´åº—'
            AND date BETWEEN '2026-01-12' AND '2026-01-18'
        """))
        count = result.scalar()
        index_time = time.time() - start
        print(f"   ç´¢å¼•æŸ¥è¯¢: {index_time*1000:.1f}ms ({count} æ¡)")
        results['index_query'] = index_time
        
        # è®¡ç®—æå‡æ¯”ä¾‹
        print("\n" + "="*80)
        print("ğŸ“Š ä¼˜åŒ–æ•ˆæœæ€»ç»“")
        print("="*80)
        
        if raw_time > 0:
            improvement = (raw_time - agg_time) / raw_time * 100
            print(f"\né¢„èšåˆè¡¨ vs åŸå§‹è¡¨: æå‡ {improvement:.1f}%")
            print(f"   åŸå§‹è¡¨: {raw_time*1000:.1f}ms")
            print(f"   é¢„èšåˆ: {agg_time*1000:.1f}ms")
        
        if agg_time < 0.1:
            print(f"\nâœ… ä¼˜åŒ–æˆåŠŸï¼æŸ¥è¯¢æ—¶é—´ < 100ms")
        elif agg_time < 0.5:
            print(f"\nâœ… ä¼˜åŒ–æˆåŠŸï¼æŸ¥è¯¢æ—¶é—´ < 500ms")
        else:
            print(f"\nâš ï¸ æŸ¥è¯¢æ—¶é—´ä»è¾ƒé•¿ï¼Œå¯èƒ½éœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–")
        
        return results
    except Exception as e:
        print(f"\nâŒ éªŒè¯å¤±è´¥: {e}")
        return {}
    finally:
        session.close()


def verify_data_accuracy():
    """éªŒè¯æ•°æ®å‡†ç¡®æ€§"""
    print_section("éªŒè¯æ•°æ®å‡†ç¡®æ€§")
    
    session = SessionLocal()
    try:
        # å¯¹æ¯”é¢„èšåˆè¡¨å’ŒåŸå§‹è®¡ç®—çš„ç»“æœ
        print("\nå¯¹æ¯”æƒ å®œé€‰-æ³°å·æ³°å…´åº— (2026-01-12 ~ 2026-01-18):")
        
        # ä»é¢„èšåˆè¡¨è·å–
        result = session.execute(text("""
            SELECT 
                SUM(order_count) as orders,
                SUM(total_revenue) as revenue,
                SUM(delivery_net_cost) as delivery_cost,
                SUM(total_marketing_cost) as marketing_cost
            FROM store_daily_summary
            WHERE store_name = 'æƒ å®œé€‰-æ³°å·æ³°å…´åº—'
            AND summary_date BETWEEN '2026-01-12' AND '2026-01-18'
        """))
        agg_row = result.fetchone()
        
        print(f"\né¢„èšåˆè¡¨ç»“æœ:")
        print(f"   è®¢å•æ•°: {agg_row[0]}")
        print(f"   é”€å”®é¢: Â¥{float(agg_row[1] or 0):,.2f}")
        print(f"   é…é€å‡€æˆæœ¬: Â¥{float(agg_row[2] or 0):,.2f}")
        print(f"   è¥é”€æˆæœ¬: Â¥{float(agg_row[3] or 0):,.2f}")
        
        if agg_row[0] and agg_row[0] > 0:
            print(f"   å•å‡é…é€è´¹: Â¥{float(agg_row[2] or 0)/agg_row[0]:.2f}")
            print(f"   å•å‡è¥é”€è´¹: Â¥{float(agg_row[3] or 0)/agg_row[0]:.2f}")
        
        # åˆ†æ¸ é“éªŒè¯ï¼ˆä½¿ç”¨è®¢å•ç¼–å·å‰ç¼€è¯†åˆ«æ¸ é“ï¼‰
        print("\nåˆ†æ¸ é“éªŒè¯ (åŸºäºè®¢å•ç¼–å·å‰ç¼€):")
        result = session.execute(text("""
            SELECT 
                channel,
                SUM(order_count) as orders,
                SUM(delivery_net_cost) as delivery_cost,
                SUM(total_marketing_cost) as marketing_cost
            FROM store_daily_summary
            WHERE store_name = 'æƒ å®œé€‰-æ³°å·æ³°å…´åº—'
            AND summary_date BETWEEN '2026-01-12' AND '2026-01-18'
            AND channel IN ('ç¾å›¢', 'é¥¿äº†ä¹ˆ', 'äº¬ä¸œ')
            GROUP BY channel
            ORDER BY orders DESC
        """))
        
        for row in result.fetchall():
            channel = row[0] or 'æœªçŸ¥'
            orders = row[1] or 0
            delivery = float(row[2] or 0)
            marketing = float(row[3] or 0)
            
            if orders > 0:
                print(f"\n   {channel}:")
                print(f"      è®¢å•æ•°: {orders}")
                print(f"      å•å‡é…é€è´¹: Â¥{delivery/orders:.2f}")
                print(f"      å•å‡è¥é”€è´¹: Â¥{marketing/orders:.2f}")
        
        print("\nğŸ“‹ Dash ç‰ˆæœ¬å‚è€ƒå€¼:")
        print("   ç¾å›¢å…±æ©™: å•å‡é…é€ Â¥3.89, å•å‡è¥é”€ Â¥5.19")
        print("   é¥¿äº†ä¹ˆ: å•å‡é…é€ Â¥1.61, å•å‡è¥é”€ Â¥5.58")
        
        return True
    except Exception as e:
        print(f"\nâŒ æ•°æ®éªŒè¯å¤±è´¥: {e}")
        return False
    finally:
        session.close()


def main():
    """ä¸»å‡½æ•°"""
    print("\n" + "ğŸš€"*40)
    print("         ä¼ä¸šçº§æ€§èƒ½ä¼˜åŒ–å®æ–½")
    print("ğŸš€"*40)
    
    start_time = time.time()
    
    # ç¬¬ä¸€å±‚ï¼šæ•°æ®åº“ç´¢å¼•ä¼˜åŒ–
    optimize_database_indexes()
    
    # ç¬¬äºŒå±‚ï¼šé¢„èšåˆè¡¨ä¼˜åŒ–
    create_aggregation_tables()
    
    # ç¬¬ä¸‰å±‚ï¼šç¼“å­˜ä¼˜åŒ–
    optimize_cache_strategy()
    
    # éªŒè¯ä¼˜åŒ–æ•ˆæœ
    verify_optimization()
    
    # éªŒè¯æ•°æ®å‡†ç¡®æ€§
    verify_data_accuracy()
    
    total_time = time.time() - start_time
    print(f"\n\n{'='*80}")
    print(f"âœ… ä¼˜åŒ–å®æ–½å®Œæˆï¼æ€»è€—æ—¶: {total_time:.1f}ç§’")
    print(f"{'='*80}")
    
    print("""
ğŸ“‹ åç»­æ­¥éª¤:
1. é‡å¯åç«¯æœåŠ¡ä»¥åŠ è½½æ–°çš„ä¼˜åŒ–ä»£ç 
2. åˆ·æ–°å‰ç«¯é¡µé¢éªŒè¯æ•ˆæœ
3. å¦‚éœ€è¿›ä¸€æ­¥ä¼˜åŒ–ï¼Œå¯ä»¥è€ƒè™‘:
   - æ·»åŠ å®šæ—¶ä»»åŠ¡è‡ªåŠ¨æ›´æ–°é¢„èšåˆè¡¨
   - å®ç°å¢é‡æ›´æ–°æœºåˆ¶
   - ä½¿ç”¨ç‰©åŒ–è§†å›¾è‡ªåŠ¨åˆ·æ–°
""")


if __name__ == "__main__":
    main()
