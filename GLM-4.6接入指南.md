# GLM-4.6å¤§æ¨¡å‹æ¥å…¥æŒ‡å—

> æœ¬æ–‡æ¡£è¯¦ç»†è¯´æ˜å¦‚ä½•åœ¨å…¶ä»–çœ‹æ¿ä¸­é›†æˆæ™ºè°±GLM-4.6å¤§æ¨¡å‹

## ğŸ“¦ ä¸€ã€ç¯å¢ƒå‡†å¤‡

### 1.1 å®‰è£…ä¾èµ–

```bash
# å®‰è£…æ™ºè°±GLMå®˜æ–¹SDK (æ”¯æŒGLM-4.6)
pip install zhipuai

# å¯é€‰: å®‰è£…dotenvç”¨äºç¯å¢ƒå˜é‡ç®¡ç†
pip install python-dotenv
```

### 1.2 è·å–APIå¯†é’¥

1. è®¿é—®æ™ºè°±AIå¼€æ”¾å¹³å°: https://open.bigmodel.cn/usercenter/apikeys
2. æ³¨å†Œ/ç™»å½•è´¦å·
3. åˆ›å»ºAPIå¯†é’¥
4. å¤åˆ¶å¯†é’¥å¤‡ç”¨

### 1.3 é…ç½®ç¯å¢ƒå˜é‡

**æ–¹å¼1: åˆ›å»º`.env`æ–‡ä»¶** (æ¨è)
```ini
# .env
ZHIPU_API_KEY=your_api_key_here
AI_MODEL_TYPE=glm
```

**æ–¹å¼2: ç³»ç»Ÿç¯å¢ƒå˜é‡**
```bash
# Windows PowerShell
$env:ZHIPU_API_KEY="your_api_key_here"

# Linux/Mac
export ZHIPU_API_KEY="your_api_key_here"
```

---

## ğŸ”§ äºŒã€æ ¸å¿ƒæ¨¡å—è¯´æ˜

### 2.1 ai_analyzer.py æ¨¡å—ç»“æ„

```
ai_analyzer.py
â”œâ”€â”€ AIAnalyzer ç±»           # AIåˆ†æå™¨ä¸»ç±»
â”‚   â”œâ”€â”€ __init__()          # åˆå§‹åŒ–,æ”¯æŒå¤šæ¨¡å‹
â”‚   â”œâ”€â”€ _init_glm()         # GLM-4.6åˆå§‹åŒ–
â”‚   â”œâ”€â”€ _generate_content() # ç»Ÿä¸€å†…å®¹ç”Ÿæˆæ¥å£
â”‚   â””â”€â”€ analyze_*()         # å„ç§åˆ†ææ–¹æ³•
â””â”€â”€ get_ai_analyzer()       # å·¥å‚å‡½æ•°
```

### 2.2 GLM-4.6åˆå§‹åŒ–ä»£ç 

```python
def _init_glm(self):
    """åˆå§‹åŒ–æ™ºè°±GLM-4.6"""
    from zhipuai import ZhipuAI
    
    # åˆ›å»ºå®¢æˆ·ç«¯ (ä½¿ç”¨ç¼–ç¨‹å·¥å…·ä¸“ç”¨ç«¯ç‚¹)
    self.client = ZhipuAI(
        api_key=self.api_key,
        base_url="https://open.bigmodel.cn/api/paas/v4/coding"  # GLM-4.6ç¼–ç¨‹å·¥å…·ä¸“ç”¨ç«¯ç‚¹
    )
    
    # è®¾ç½®æ¨¡å‹ç‰ˆæœ¬
    self.model_name = 'glm-4.6'  # æœ€æ–°ç‰ˆæœ¬
    self.use_zai = False
    
    print(f"âœ… å·²é…ç½®GLM-4.6")
```

### 2.3 APIè°ƒç”¨ä»£ç 

```python
def _generate_content(self, prompt: str) -> str:
    """è°ƒç”¨GLM-4.6ç”Ÿæˆå†…å®¹"""
    response = self.client.chat.completions.create(
        model=self.model_name,              # 'glm-4.6'
        messages=[
            {"role": "user", "content": prompt}
        ],
        temperature=0.7,                    # åˆ›é€ æ€§å‚æ•° (0-1)
        max_tokens=4096                     # æœ€å¤§è¾“å‡ºé•¿åº¦
    )
    
    return response.choices[0].message.content
```

---

## ğŸš€ ä¸‰ã€å¿«é€Ÿé›†æˆæ­¥éª¤

### 3.1 å¤åˆ¶æ ¸å¿ƒæ–‡ä»¶

å°†ä»¥ä¸‹æ–‡ä»¶å¤åˆ¶åˆ°æ‚¨çš„é¡¹ç›®ç›®å½•:
```
your_project/
â”œâ”€â”€ ai_analyzer.py              # âœ… å¿…éœ€: AIåˆ†æå™¨æ¨¡å—
â”œâ”€â”€ ai_business_context.py      # å¯é€‰: ä¸šåŠ¡ä¸Šä¸‹æ–‡æç¤ºè¯
â””â”€â”€ .env                        # âœ… å¿…éœ€: APIå¯†é’¥é…ç½®
```

### 3.2 åŸºç¡€ä½¿ç”¨ç¤ºä¾‹

```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç¤ºä¾‹: åœ¨æ‚¨çš„çœ‹æ¿ä¸­é›†æˆGLM-4.6
"""

from ai_analyzer import get_ai_analyzer
import os

# Step 1: åˆå§‹åŒ–AIåˆ†æå™¨
def init_ai_model():
    """åˆå§‹åŒ–GLM-4.6"""
    # ä»ç¯å¢ƒå˜é‡è¯»å–APIå¯†é’¥
    api_key = os.getenv('ZHIPU_API_KEY')
    
    if not api_key:
        print("âš ï¸ è¯·è®¾ç½®ZHIPU_API_KEYç¯å¢ƒå˜é‡")
        return None
    
    # åˆ›å»ºåˆ†æå™¨å®ä¾‹
    analyzer = get_ai_analyzer(api_key=api_key, model_type='glm')
    
    if analyzer and analyzer.is_ready():
        print("âœ… GLM-4.6 å·²å°±ç»ª")
        return analyzer
    else:
        print("âŒ GLM-4.6 åˆå§‹åŒ–å¤±è´¥")
        return None

# Step 2: ä½¿ç”¨åˆ†æå™¨
analyzer = init_ai_model()

if analyzer:
    # ç¤ºä¾‹1: åŸºç¡€æ–‡æœ¬ç”Ÿæˆ
    prompt = "åˆ†æé”€é‡ä¸‹æ»‘çš„å¯èƒ½åŸå› "
    result = analyzer._generate_content(prompt)
    print(result)
    
    # ç¤ºä¾‹2: ç»“æ„åŒ–æ•°æ®åˆ†æ
    product_data = {
        'name': 'å•†å“A',
        'sales_decline': -30.5,
        'avg_price': 89.9,
        'stock': 150
    }
    analysis = analyzer.analyze_sales_decline(product_data)
    print(analysis)
```

### 3.3 åœ¨Streamlitä¸­é›†æˆ

```python
import streamlit as st
from ai_analyzer import get_ai_analyzer
import os

# ç¼“å­˜AIåˆ†æå™¨å®ä¾‹
@st.cache_resource
def load_ai_analyzer():
    """åŠ è½½å¹¶ç¼“å­˜AIåˆ†æå™¨"""
    api_key = os.getenv('ZHIPU_API_KEY')
    if api_key:
        return get_ai_analyzer(api_key=api_key, model_type='glm')
    return None

# ä¸»ç•Œé¢
st.title("ğŸ¤– AIæ™ºèƒ½åˆ†æ")

# åˆå§‹åŒ–
analyzer = load_ai_analyzer()

if analyzer and analyzer.is_ready():
    st.success("âœ… GLM-4.6 å·²è¿æ¥")
    
    # è¾“å…¥æ¡†
    user_input = st.text_area("è¾“å…¥æ‚¨çš„é—®é¢˜:", height=100)
    
    if st.button("ğŸ” å¼€å§‹åˆ†æ"):
        if user_input:
            with st.spinner("æ­£åœ¨åˆ†æ..."):
                result = analyzer._generate_content(user_input)
                st.markdown("### åˆ†æç»“æœ")
                st.write(result)
        else:
            st.warning("è¯·è¾“å…¥é—®é¢˜")
else:
    st.error("âŒ AIåˆ†æå™¨æœªå°±ç»ª,è¯·æ£€æŸ¥APIå¯†é’¥é…ç½®")
    st.info("ğŸ’¡ è®¾ç½®ç¯å¢ƒå˜é‡: ZHIPU_API_KEY=your_key")
```

### 3.4 åœ¨Dashä¸­é›†æˆ

```python
from dash import Dash, html, dcc, Input, Output, State
import dash_bootstrap_components as dbc
from ai_analyzer import get_ai_analyzer
import os

app = Dash(__name__, external_stylesheets=[dbc.themes.BOOTSTRAP])

# å…¨å±€AIåˆ†æå™¨
AI_ANALYZER = None

def init_ai_analyzer():
    """åˆå§‹åŒ–AIåˆ†æå™¨"""
    global AI_ANALYZER
    if AI_ANALYZER is None:
        api_key = os.getenv('ZHIPU_API_KEY')
        AI_ANALYZER = get_ai_analyzer(api_key=api_key, model_type='glm')
    return AI_ANALYZER

# å¸ƒå±€
app.layout = dbc.Container([
    html.H1("ğŸ¤– AIæ™ºèƒ½åˆ†æ", className="text-center my-4"),
    
    dbc.Row([
        dbc.Col([
            dbc.Textarea(
                id='user-input',
                placeholder='è¾“å…¥æ‚¨çš„é—®é¢˜...',
                style={'height': '200px'}
            ),
            dbc.Button(
                "ğŸ” å¼€å§‹åˆ†æ",
                id='analyze-btn',
                color='primary',
                className='mt-3'
            )
        ], width=12)
    ]),
    
    html.Div(id='analysis-result', className='mt-4')
])

# å›è°ƒå‡½æ•°
@app.callback(
    Output('analysis-result', 'children'),
    Input('analyze-btn', 'n_clicks'),
    State('user-input', 'value'),
    prevent_initial_call=True
)
def run_analysis(n_clicks, user_input):
    if not user_input:
        return dbc.Alert("è¯·è¾“å…¥é—®é¢˜", color="warning")
    
    # åˆå§‹åŒ–åˆ†æå™¨
    analyzer = init_ai_analyzer()
    if not analyzer or not analyzer.is_ready():
        return dbc.Alert([
            html.Strong("âŒ AIåˆ†æå™¨æœªå°±ç»ª"),
            html.Br(),
            html.Small("è¯·è®¾ç½® ZHIPU_API_KEY ç¯å¢ƒå˜é‡")
        ], color="danger")
    
    try:
        # è°ƒç”¨AIåˆ†æ
        result = analyzer._generate_content(user_input)
        
        return dbc.Card([
            dbc.CardHeader("ğŸ¤– AIåˆ†æç»“æœ"),
            dbc.CardBody([
                html.P(result, style={'white-space': 'pre-wrap'})
            ])
        ], className="shadow-sm")
        
    except Exception as e:
        return dbc.Alert(f"âŒ åˆ†æå¤±è´¥: {str(e)}", color="danger")

if __name__ == '__main__':
    app.run_server(debug=True, port=8050)
```

---

## ğŸ¯ å››ã€é«˜çº§åŠŸèƒ½

### 4.1 å¤šæ¨¡å‹åˆ‡æ¢

```python
import os

# è®¾ç½®æ¨¡å‹ç±»å‹
os.environ['AI_MODEL_TYPE'] = 'glm'    # æ™ºè°±GLM-4.6
# os.environ['AI_MODEL_TYPE'] = 'qwen'  # é€šä¹‰åƒé—®
# os.environ['AI_MODEL_TYPE'] = 'gemini' # Gemini

# è‡ªåŠ¨é€‰æ‹©æ¨¡å‹
model_type = os.getenv('AI_MODEL_TYPE', 'glm')
analyzer = get_ai_analyzer(model_type=model_type)
```

### 4.2 è‡ªå®šä¹‰ä¸šåŠ¡æç¤ºè¯

```python
# åœ¨è°ƒç”¨å‰æ·»åŠ ä¸šåŠ¡ä¸Šä¸‹æ–‡
business_context = """
æ‚¨æ˜¯ä¸€ä½èµ„æ·±çš„O2Oé›¶å”®ä¸šåŠ¡ä¸“å®¶,ç²¾é€šé—¨åº—è¿è¥å’Œæ•°æ®åˆ†æã€‚
è¯·åŸºäºä»¥ä¸‹ä¸šåŠ¡èƒŒæ™¯è¿›è¡Œåˆ†æ:
- ä¸šåŠ¡ç±»å‹: O2Oé—ªè´­
- ä¸»è¦æ¸ é“: ç¾å›¢å¤–å–ã€é¥¿äº†ä¹ˆ
- é…é€æ¨¡å¼: éª‘æ‰‹é…é€ + ç”¨æˆ·è‡ªæ
"""

user_question = "å¦‚ä½•æå‡å®¢å•ä»·?"

# ç»„åˆå®Œæ•´æç¤ºè¯
full_prompt = f"{business_context}\n\né—®é¢˜: {user_question}"

# è°ƒç”¨åˆ†æ
result = analyzer._generate_content(full_prompt)
```

### 4.3 æµå¼è¾“å‡º (é«˜çº§)

```python
def stream_analysis(analyzer, prompt: str):
    """æµå¼è¾“å‡ºåˆ†æç»“æœ"""
    response = analyzer.client.chat.completions.create(
        model='glm-4.6',
        messages=[{"role": "user", "content": prompt}],
        stream=True  # å¯ç”¨æµå¼è¾“å‡º
    )
    
    for chunk in response:
        if chunk.choices[0].delta.content:
            yield chunk.choices[0].delta.content

# ä½¿ç”¨ç¤ºä¾‹
for text in stream_analysis(analyzer, "åˆ†æé”€é‡è¶‹åŠ¿"):
    print(text, end='', flush=True)
```

### 4.4 é”™è¯¯å¤„ç†ä¸é‡è¯•

```python
import time

def safe_generate(analyzer, prompt: str, max_retries: int = 3) -> str:
    """å¸¦é‡è¯•æœºåˆ¶çš„å†…å®¹ç”Ÿæˆ"""
    for attempt in range(max_retries):
        try:
            result = analyzer._generate_content(prompt)
            return result
        except Exception as e:
            print(f"å°è¯• {attempt + 1}/{max_retries} å¤±è´¥: {e}")
            if attempt < max_retries - 1:
                time.sleep(2 ** attempt)  # æŒ‡æ•°é€€é¿
            else:
                return f"âŒ åˆ†æå¤±è´¥,å·²é‡è¯•{max_retries}æ¬¡"

# ä½¿ç”¨
result = safe_generate(analyzer, "åˆ†ææ•°æ®")
```

---

## ğŸ“Š äº”ã€å®æˆ˜æ¡ˆä¾‹

### 5.1 é”€é‡ä¸‹æ»‘åˆ†æ

```python
def analyze_product_decline(analyzer, product_name: str, data: dict):
    """åˆ†æå•†å“é”€é‡ä¸‹æ»‘åŸå› """
    prompt = f"""
    å•†å“åç§°: {product_name}
    é”€é‡å˜åŒ–: {data['sales_change']}%
    ä»·æ ¼: Â¥{data['price']}
    åº“å­˜: {data['stock']}
    ç«å“æƒ…å†µ: {data.get('competitor_info', 'æœªçŸ¥')}
    
    è¯·åˆ†æå¯èƒ½çš„åŸå› å¹¶æä¾›æ”¹è¿›å»ºè®®ã€‚
    """
    
    return analyzer._generate_content(prompt)

# ä½¿ç”¨ç¤ºä¾‹
product_data = {
    'sales_change': -25.3,
    'price': 89.9,
    'stock': 120,
    'competitor_info': 'ç«å“é™ä»·10%'
}

result = analyze_product_decline(analyzer, "å•†å“A", product_data)
print(result)
```

### 5.2 å®¢å•ä»·ä¼˜åŒ–å»ºè®®

```python
def get_pricing_suggestions(analyzer, current_metrics: dict):
    """è·å–å®¢å•ä»·ä¼˜åŒ–å»ºè®®"""
    prompt = f"""
    å½“å‰è¿è¥æ•°æ®:
    - å¹³å‡å®¢å•ä»·: Â¥{current_metrics['avg_order_value']}
    - è®¢å•æ•°: {current_metrics['order_count']}
    - å•†å“å¹³å‡ä»·æ ¼: Â¥{current_metrics['avg_product_price']}
    - å®¢æˆ·å¤è´­ç‡: {current_metrics['repeat_rate']}%
    
    è¯·æä¾›3-5æ¡å…·ä½“çš„å®¢å•ä»·æå‡ç­–ç•¥ã€‚
    """
    
    return analyzer._generate_content(prompt)
```

### 5.3 åœºæ™¯è¥é”€ç­–ç•¥

```python
def generate_marketing_strategy(analyzer, scene: str, target_group: str):
    """ç”Ÿæˆåœºæ™¯åŒ–è¥é”€ç­–ç•¥"""
    prompt = f"""
    åœºæ™¯: {scene}
    ç›®æ ‡å®¢ç¾¤: {target_group}
    
    è¯·åˆ¶å®šå…·ä½“çš„è¥é”€ç­–ç•¥,åŒ…æ‹¬:
    1. å•†å“ç»„åˆå»ºè®®
    2. ä¿ƒé”€æ´»åŠ¨æ–¹æ¡ˆ
    3. æ¨å¹¿æ¸ é“é€‰æ‹©
    4. é¢„æœŸæ•ˆæœè¯„ä¼°
    """
    
    return analyzer._generate_content(prompt)

# ä½¿ç”¨ç¤ºä¾‹
strategy = generate_marketing_strategy(
    analyzer,
    scene="æ—©é¤åœºæ™¯",
    target_group="ä¸Šç­æ—"
)
```

---

## âš™ï¸ å…­ã€é…ç½®å‚æ•°è¯´æ˜

### 6.1 æ¨¡å‹å‚æ•°

| å‚æ•° | è¯´æ˜ | é»˜è®¤å€¼ | å–å€¼èŒƒå›´ |
|------|------|--------|----------|
| `model` | æ¨¡å‹ç‰ˆæœ¬ | `glm-4.6` | `glm-4`, `glm-4.6` |
| `temperature` | åˆ›é€ æ€§å‚æ•° | `0.7` | 0.0 - 1.0 |
| `max_tokens` | æœ€å¤§è¾“å‡ºé•¿åº¦ | `4096` | 1 - 8192 |
| `top_p` | æ ¸é‡‡æ ·å‚æ•° | `0.7` | 0.0 - 1.0 |

### 6.2 temperatureå‚æ•°å»ºè®®

- **0.0 - 0.3**: ç²¾ç¡®åˆ†æã€æ•°æ®è®¡ç®— (ç¡®å®šæ€§é«˜)
- **0.4 - 0.7**: ä¸šåŠ¡å»ºè®®ã€ç­–ç•¥è§„åˆ’ (å¹³è¡¡)
- **0.8 - 1.0**: åˆ›æ„æ–‡æ¡ˆã€å¤´è„‘é£æš´ (åˆ›é€ æ€§é«˜)

### 6.3 ä½¿ç”¨ç¤ºä¾‹

```python
# ç²¾ç¡®æ•°æ®åˆ†æ
response = analyzer.client.chat.completions.create(
    model='glm-4.6',
    messages=[{"role": "user", "content": prompt}],
    temperature=0.2,  # ä½æ¸©åº¦,æ›´ç²¾ç¡®
    max_tokens=2048
)

# åˆ›æ„è¥é”€æ–‡æ¡ˆ
response = analyzer.client.chat.completions.create(
    model='glm-4.6',
    messages=[{"role": "user", "content": prompt}],
    temperature=0.9,  # é«˜æ¸©åº¦,æ›´æœ‰åˆ›æ„
    max_tokens=4096
)
```

---

## ğŸ” ä¸ƒã€å¸¸è§é—®é¢˜æ’æŸ¥

### 7.1 APIå¯†é’¥æ— æ•ˆ

**é—®é¢˜**: `âŒ 401 Unauthorized`

**è§£å†³æ–¹æ¡ˆ**:
1. æ£€æŸ¥APIå¯†é’¥æ˜¯å¦æ­£ç¡®
2. ç¡®è®¤å¯†é’¥æ˜¯å¦å·²æ¿€æ´»
3. æ£€æŸ¥è´¦æˆ·ä½™é¢æ˜¯å¦å……è¶³

```python
# æµ‹è¯•APIå¯†é’¥
import os
from zhipuai import ZhipuAI

api_key = os.getenv('ZHIPU_API_KEY')
client = ZhipuAI(api_key=api_key)

try:
    response = client.chat.completions.create(
        model='glm-4.6',
        messages=[{"role": "user", "content": "ä½ å¥½"}]
    )
    print("âœ… APIå¯†é’¥æœ‰æ•ˆ")
except Exception as e:
    print(f"âŒ APIå¯†é’¥æµ‹è¯•å¤±è´¥: {e}")
```

### 7.2 è¶…æ—¶é”™è¯¯

**é—®é¢˜**: `âŒ Request timeout`

**è§£å†³æ–¹æ¡ˆ**:
```python
from zhipuai import ZhipuAI
import httpx

# è®¾ç½®è¶…æ—¶æ—¶é—´
client = ZhipuAI(
    api_key=api_key,
    timeout=httpx.Timeout(60.0)  # 60ç§’è¶…æ—¶
)
```

### 7.3 é€Ÿç‡é™åˆ¶

**é—®é¢˜**: `âŒ 429 Too Many Requests`

**è§£å†³æ–¹æ¡ˆ**:
```python
import time

def call_with_retry(client, prompt, max_retries=3):
    for i in range(max_retries):
        try:
            response = client.chat.completions.create(
                model='glm-4.6',
                messages=[{"role": "user", "content": prompt}]
            )
            return response.choices[0].message.content
        except Exception as e:
            if "429" in str(e) and i < max_retries - 1:
                wait_time = 2 ** i  # æŒ‡æ•°é€€é¿
                print(f"é€Ÿç‡é™åˆ¶,ç­‰å¾…{wait_time}ç§’åé‡è¯•...")
                time.sleep(wait_time)
            else:
                raise
```

### 7.4 æ¨¡å‹ç‰ˆæœ¬ä¸æ”¯æŒ

**é—®é¢˜**: `âŒ Model not found: glm-4.6`

**è§£å†³æ–¹æ¡ˆ**:
```python
# é™çº§åˆ°glm-4
self.model_name = 'glm-4'

# æˆ–æ£€æŸ¥å¯ç”¨æ¨¡å‹
available_models = ['glm-4', 'glm-4.6', 'glm-3-turbo']
```

---

## ğŸ“š å…«ã€å‚è€ƒèµ„æº

### 8.1 å®˜æ–¹æ–‡æ¡£

- **æ™ºè°±AIå¼€æ”¾å¹³å°**: https://open.bigmodel.cn/
- **APIæ–‡æ¡£**: https://open.bigmodel.cn/dev/api
- **SDKæ–‡æ¡£**: https://github.com/zhipuai/zhipuai-sdk-python
- **å®šä»·è¯´æ˜**: https://open.bigmodel.cn/pricing

### 8.2 ç¤ºä¾‹ä»£ç 

- **æœ¬é¡¹ç›®å®Œæ•´ä»£ç **: `ai_analyzer.py`
- **Dashé›†æˆç¤ºä¾‹**: `æ™ºèƒ½é—¨åº—çœ‹æ¿_Dashç‰ˆ.py`
- **Streamlitç¤ºä¾‹**: `æ™ºèƒ½é—¨åº—ç»è¥çœ‹æ¿_å¯è§†åŒ–.py`

### 8.3 ç¤¾åŒºæ”¯æŒ

- **GitHub Issues**: https://github.com/zhipuai/zhipuai-sdk-python/issues
- **æŠ€æœ¯è®ºå›**: https://open.bigmodel.cn/forum

---

## âœ… ä¹ã€æ£€æŸ¥æ¸…å•

åœ¨éƒ¨ç½²å‰,è¯·ç¡®è®¤ä»¥ä¸‹äº‹é¡¹:

- [ ] å·²å®‰è£… `zhipuai` SDK
- [ ] å·²è·å–æœ‰æ•ˆçš„APIå¯†é’¥
- [ ] APIå¯†é’¥å·²é…ç½®åˆ°ç¯å¢ƒå˜é‡
- [ ] è´¦æˆ·ä½™é¢å……è¶³
- [ ] å·²æµ‹è¯•åŸºç¡€è°ƒç”¨åŠŸèƒ½
- [ ] å·²å®ç°é”™è¯¯å¤„ç†æœºåˆ¶
- [ ] å·²è®¾ç½®åˆç†çš„è¶…æ—¶æ—¶é—´
- [ ] å·²å¤åˆ¶å¿…è¦çš„æ¨¡å—æ–‡ä»¶

---

## ğŸ‰ åã€æ€»ç»“

é€šè¿‡æœ¬æŒ‡å—,æ‚¨åº”è¯¥èƒ½å¤Ÿ:

1. âœ… åœ¨ä»»ä½•Pythoné¡¹ç›®ä¸­é›†æˆGLM-4.6
2. âœ… ç†è§£APIè°ƒç”¨çš„å®Œæ•´æµç¨‹
3. âœ… å®ç°åŸºç¡€å’Œé«˜çº§åŠŸèƒ½
4. âœ… æ’æŸ¥å¸¸è§é—®é¢˜
5. âœ… ä¼˜åŒ–æ€§èƒ½å’Œç”¨æˆ·ä½“éªŒ

**æ ¸å¿ƒè¦ç‚¹**:
- ä½¿ç”¨å®˜æ–¹ `zhipuai` SDK
- æŒ‡å®šæ¨¡å‹ç‰ˆæœ¬ä¸º `glm-4.6`
- å¦¥å–„ç®¡ç†APIå¯†é’¥
- å®ç°é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶
- æ ¹æ®åœºæ™¯è°ƒæ•´æ¸©åº¦å‚æ•°

**ä¸‹ä¸€æ­¥**:
- æ¢ç´¢æ›´å¤šAIåˆ†æåœºæ™¯
- ä¼˜åŒ–æç¤ºè¯å·¥ç¨‹
- é›†æˆåˆ°å®é™…ä¸šåŠ¡ç³»ç»Ÿ
- ç›‘æ§APIä½¿ç”¨æƒ…å†µå’Œæˆæœ¬

---

*æœ€åæ›´æ–°: 2025å¹´10æœˆ27æ—¥*
*ä½œè€…: GitHub Copilot*
