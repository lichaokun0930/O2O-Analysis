# -*- coding: utf-8 -*-
"""
ä»Šæ—¥å¿…åš - æ˜¨æ—¥ç»è¥è¯Šæ–­åˆ†ææ¨¡å— (V3.2 åŒºé—´åˆ†çº§)

è®¾è®¡ç†å¿µ:
- é—®é¢˜å¯¼å‘ï¼šåªå±•ç¤ºæœ‰é—®é¢˜çš„ï¼Œæ²¡é—®é¢˜çš„ä¸å ä½ç½®
- å¯æ‰§è¡Œï¼šçœ‹åˆ°é—®é¢˜åçŸ¥é“æ€ä¹ˆè¡ŒåŠ¨
- ä¼˜å…ˆçº§æ¸…æ™°ï¼šæœ€ä¸¥é‡çš„é—®é¢˜æœ€é†’ç›®

ä¸¤å±‚æ¶æ„:
ğŸ”´ ç´§æ€¥å¤„ç†ï¼ˆä»Šæ—¥å¿…é¡»å®Œæˆï¼‰
  - ç©¿åº•æ­¢è¡€ï¼šè®¢å•å®é™…åˆ©æ¶¦ < 0 (ä½¿ç”¨ä¸»çœ‹æ¿ç»Ÿä¸€å…¬å¼)
  - é«˜é…é€è´¹é¢„è­¦ï¼šé…é€è´¹ > 6å…ƒ ä¸” åˆ©æ¶¦ < é…é€è´¹
  - çƒ­é”€ç¼ºè´§ï¼šæ˜¨æ—¥çƒ­é”€å“ä»Šæ—¥é›¶é”€é‡

ğŸŸ¡ å…³æ³¨è§‚å¯Ÿï¼ˆæœ¬å‘¨å†…å¤„ç†ï¼‰
  - æµé‡å¼‚å¸¸ï¼šé”€é‡ç¯æ¯”ä¸‹è·Œ >30% (7æ—¥vs7æ—¥)
  - æ–°å¢æ»é”€ï¼šåº“å­˜>0 ä¸” åˆšæ»¡3å¤©æ— é”€é‡ï¼ˆçŠ¶æ€å˜åŒ–ç‚¹ï¼‰
  - æŒç»­æ»é”€ï¼šåº“å­˜>0 ä¸” åˆšæ»¡7å¤©æ— é”€é‡ï¼ˆçŠ¶æ€å˜åŒ–ç‚¹ï¼‰
  - ä¸¥é‡æ»é”€ï¼šåº“å­˜>0 ä¸” åˆšæ»¡15å¤©æ— é”€é‡ï¼ˆçŠ¶æ€å˜åŒ–ç‚¹ï¼‰
  - æ–°å“è¡¨ç°ï¼šæ˜¨æ—¥é¦–æ¬¡äº§ç”Ÿé”€é‡
  
æ³¨ï¼šåº“å­˜=0çš„ä¸ç®—æ»é”€ï¼›åªåœ¨çŠ¶æ€å˜åŒ–æ—¶æé†’ï¼Œé¿å…æ¯å¤©é‡å¤

âš ï¸ æ—¶é—´åŸºå‡†: æ•°æ®æœ€åä¸€å¤© = "æ˜¨æ—¥"

ğŸ“Š æ ¸å¿ƒå…¬å¼ï¼ˆä¸ä¸»çœ‹æ¿ç»Ÿä¸€ï¼‰:
  - è®¢å•å®é™…åˆ©æ¶¦ = åˆ©æ¶¦é¢ - å¹³å°æœåŠ¡è´¹ - ç‰©æµé…é€è´¹ + ä¼å®¢åè¿”
  - ç©¿åº•åˆ¤æ–­ï¼šè®¢å•å®é™…åˆ©æ¶¦ < 0
  
ğŸ“‹ å­—æ®µçº§åˆ«è¯´æ˜:
  - è®¢å•çº§(first): ç‰©æµé…é€è´¹, æ»¡å‡é‡‘é¢, å•†å“å‡å…é‡‘é¢, å•†å®¶ä»£é‡‘åˆ¸, å•†å®¶æ‰¿æ‹…éƒ¨åˆ†åˆ¸, æ»¡èµ é‡‘é¢, å•†å®¶å…¶ä»–ä¼˜æƒ , æ–°å®¢å‡å…é‡‘é¢
  - å•†å“çº§(sum): åˆ©æ¶¦é¢, å¹³å°æœåŠ¡è´¹, ä¼å®¢åè¿”, å®æ”¶ä»·æ ¼, å•†å“é‡‡è´­æˆæœ¬, æœˆå”®
"""

import pandas as pd
import numpy as np
from datetime import timedelta
from typing import Dict, Tuple, Optional, Any, List

# å¯¼å…¥å¼¹æ€§ç³»æ•°å­¦ä¹ æœºåˆ¶
try:
    from .pricing_engine import learn_elasticity_from_price_change
except ImportError:
    learn_elasticity_from_price_change = None

# é…é€è´¹é˜ˆå€¼
DELIVERY_FEE_THRESHOLD = 6  # å…ƒ

# ============ å­—æ®µçº§åˆ«å®šä¹‰ï¼ˆä¸ä¸»çœ‹æ¿ä¿æŒä¸€è‡´ï¼‰============
# è®¢å•çº§å­—æ®µ - ä½¿ç”¨ first() èšåˆ
ORDER_LEVEL_FIELDS = [
    'ç‰©æµé…é€è´¹',
    'æ»¡å‡é‡‘é¢',
    'å•†å“å‡å…é‡‘é¢',
    'å•†å®¶ä»£é‡‘åˆ¸',
    'å•†å®¶æ‰¿æ‹…éƒ¨åˆ†åˆ¸',
    'æ»¡èµ é‡‘é¢',
    'å•†å®¶å…¶ä»–ä¼˜æƒ ',
    'æ–°å®¢å‡å…é‡‘é¢',
    'ç”¨æˆ·æ”¯ä»˜é…é€è´¹',
    'é…é€è´¹å‡å…é‡‘é¢',
    'æ¸ é“',
    'å¹³å°',
    'é—¨åº—',
    'ä¸‹å•æ—¶é—´',
    'æ—¥æœŸ',
]

# å•†å“çº§å­—æ®µ - ä½¿ç”¨ sum() èšåˆ
ITEM_LEVEL_FIELDS = [
    'åˆ©æ¶¦é¢',
    'å¹³å°æœåŠ¡è´¹',
    'ä¼å®¢åè¿”',
    'å®æ”¶ä»·æ ¼',
    'å•†å“å®å”®ä»·',
    'å•†å“é‡‡è´­æˆæœ¬',
    'æˆæœ¬',
    'æœˆå”®',
    'é”€é‡',
]

# æ´»åŠ¨ç±»å‹å­—æ®µæ˜ å°„ï¼ˆå…¨éƒ¨æ˜¯è®¢å•çº§å­—æ®µï¼‰
ACTIVITY_FIELDS = {
    'æ»¡å‡æ´»åŠ¨': 'æ»¡å‡é‡‘é¢',
    'å•†å“å‡å…': 'å•†å“å‡å…é‡‘é¢',
    'æ–°å®¢åˆ¸': 'æ–°å®¢å‡å…é‡‘é¢',
    'å•†å®¶ä»£é‡‘åˆ¸': 'å•†å®¶ä»£é‡‘åˆ¸',
    'å•†å®¶æ‰¿æ‹…åˆ¸': 'å•†å®¶æ‰¿æ‹…éƒ¨åˆ†åˆ¸',
    'æ»¡èµ ': 'æ»¡èµ é‡‘é¢',
    'å…¶ä»–ä¼˜æƒ ': 'å•†å®¶å…¶ä»–ä¼˜æƒ '
}


# ============ è¶‹åŠ¿åˆ†æè¾…åŠ©å‡½æ•° ============

def calculate_trend_indicator(yesterday_value: float, avg_3d_value: float) -> Dict[str, Any]:
    """
    è®¡ç®—è¶‹åŠ¿æŒ‡ç¤ºå™¨ï¼ˆæ˜¨æ—¥ vs 3æ—¥å‡å€¼ï¼‰
    
    è¿”å›:
        {
            'trend': 'up' | 'down' | 'stable',  # è¶‹åŠ¿æ–¹å‘
            'icon': 'â†‘' | 'â†“' | 'â†’',            # è¶‹åŠ¿å›¾æ ‡
            'label': 'æ¶åŒ–' | 'å¥½è½¬' | 'æŒå¹³',  # è¶‹åŠ¿æ ‡ç­¾
            'color': 'red' | 'green' | 'gray',  # é¢œè‰²
            'change_pct': float,                # å˜åŒ–ç™¾åˆ†æ¯”
            'avg_3d': float,                    # 3æ—¥å‡å€¼
            'description': str                  # æè¿°æ–‡å­—
        }
    """
    result = {
        'trend': 'stable',
        'icon': 'â†’',
        'label': 'æŒå¹³',
        'color': 'gray',
        'change_pct': 0,
        'avg_3d': round(avg_3d_value, 1),
        'description': ''
    }
    
    if avg_3d_value <= 0:
        if yesterday_value > 0:
            # ä¹‹å‰æ²¡é—®é¢˜ï¼Œæ˜¨å¤©å‡ºç°äº†
            result['trend'] = 'up'
            result['icon'] = 'âš ï¸'
            result['label'] = 'æ–°å¢'
            result['color'] = 'orange'
            result['description'] = f'è¿‘3æ—¥å‡0ï¼Œæ˜¨æ—¥æ–°å¢{yesterday_value:.0f}'
        return result
    
    change_pct = (yesterday_value - avg_3d_value) / avg_3d_value * 100
    result['change_pct'] = round(change_pct, 1)
    
    # åˆ¤æ–­è¶‹åŠ¿ï¼ˆå¯¹äºè´Ÿé¢æŒ‡æ ‡ï¼šå¢åŠ =æ¶åŒ–ï¼Œå‡å°‘=å¥½è½¬ï¼‰
    if change_pct > 30:
        result['trend'] = 'up'
        result['icon'] = 'â†‘'
        result['label'] = 'æ¶åŒ–'
        result['color'] = 'red'
        result['description'] = f'è¾ƒ3æ—¥å‡({avg_3d_value:.0f})â†‘{change_pct:.0f}%'
    elif change_pct < -30:
        result['trend'] = 'down'
        result['icon'] = 'â†“'
        result['label'] = 'å¥½è½¬'
        result['color'] = 'green'
        result['description'] = f'è¾ƒ3æ—¥å‡({avg_3d_value:.0f})â†“{abs(change_pct):.0f}%'
    else:
        result['trend'] = 'stable'
        result['icon'] = 'â†’'
        result['label'] = 'æŒå¹³'
        result['color'] = 'gray'
        result['description'] = f'ä¸3æ—¥å‡({avg_3d_value:.0f})æŒå¹³'
    
    return result


def calculate_positive_trend_indicator(yesterday_value: float, avg_3d_value: float) -> Dict[str, Any]:
    """
    è®¡ç®—æ­£å‘æŒ‡æ ‡è¶‹åŠ¿ï¼ˆçˆ†æ¬¾å•†å“ç­‰ï¼Œå¢åŠ =å¥½ï¼Œå‡å°‘=å·®ï¼‰
    """
    result = calculate_trend_indicator(yesterday_value, avg_3d_value)
    
    # åè½¬è¯­ä¹‰ï¼ˆå¢åŠ =æŒç»­ï¼Œå‡å°‘=ä¸‹æ»‘ï¼‰
    if result['trend'] == 'up':
        result['label'] = 'æŒç»­ç«çˆ†'
        result['color'] = 'green'
    elif result['trend'] == 'down':
        result['label'] = 'æœ‰æ‰€å›è½'
        result['color'] = 'orange'
    
    return result


def calculate_order_profit(order_agg: pd.DataFrame) -> pd.Series:
    """
    è®¡ç®—è®¢å•å®é™…åˆ©æ¶¦ï¼ˆä¸ä¸»çœ‹æ¿å…¬å¼å®Œå…¨ä¸€è‡´ï¼‰
    
    å…¬å¼: è®¢å•å®é™…åˆ©æ¶¦ = åˆ©æ¶¦é¢ - å¹³å°æœåŠ¡è´¹ - ç‰©æµé…é€è´¹ + ä¼å®¢åè¿”
    
    å‚æ•°:
        order_agg: è®¢å•çº§èšåˆåçš„DataFrameï¼Œå¿…é¡»åŒ…å«ä»¥ä¸‹å­—æ®µ:
            - åˆ©æ¶¦é¢ (å•†å“çº§sumå)
            - ç‰©æµé…é€è´¹ (è®¢å•çº§first)
            - å¹³å°æœåŠ¡è´¹ (å•†å“çº§sumåï¼Œå¯é€‰)
            - ä¼å®¢åè¿” (å•†å“çº§sumåï¼Œå¯é€‰)
    
    è¿”å›:
        Series: è®¢å•å®é™…åˆ©æ¶¦
    """
    # è·å–å¿…éœ€å­—æ®µ
    profit = order_agg.get('åˆ©æ¶¦é¢', pd.Series(0, index=order_agg.index))
    delivery_fee = order_agg.get('ç‰©æµé…é€è´¹', pd.Series(0, index=order_agg.index))
    
    # è·å–å¯é€‰å­—æ®µ
    service_fee = order_agg.get('å¹³å°æœåŠ¡è´¹', pd.Series(0, index=order_agg.index))
    enterprise_rebate = order_agg.get('ä¼å®¢åè¿”', pd.Series(0, index=order_agg.index))
    
    # å¤„ç†NaN
    profit = profit.fillna(0)
    delivery_fee = delivery_fee.fillna(0)
    service_fee = service_fee.fillna(0)
    enterprise_rebate = enterprise_rebate.fillna(0)
    
    # è®¡ç®—è®¢å•å®é™…åˆ©æ¶¦
    result = profit - service_fee - delivery_fee + enterprise_rebate
    
    return result


def get_product_group_key(df: pd.DataFrame) -> str:
    """
    è·å–å•†å“èšåˆçš„keyå­—æ®µå
    
    ä¼˜å…ˆçº§ï¼šåº—å†…ç  > æ¡ç  > å•†å“åç§°
    ä½¿ç”¨åº—å†…ç å¯ä»¥åŒºåˆ†åŒåä½†ä¸åŒè§„æ ¼çš„å•†å“
    """
    if 'åº—å†…ç ' in df.columns and df['åº—å†…ç '].notna().any():
        return 'åº—å†…ç '
    elif 'æ¡ç ' in df.columns and df['æ¡ç '].notna().any():
        return 'æ¡ç '
    else:
        return 'å•†å“åç§°'


def get_base_date(df: pd.DataFrame) -> Optional[pd.Timestamp]:
    """è·å–åŸºå‡†æ—¥æœŸï¼ˆæ˜¨æ—¥ = æ•°æ®æœ€åä¸€å¤©ï¼‰"""
    date_col = 'æ—¥æœŸ' if 'æ—¥æœŸ' in df.columns else 'ä¸‹å•æ—¶é—´'
    if date_col not in df.columns:
        return None
    
    df = df.copy()
    df[date_col] = pd.to_datetime(df[date_col])
    return df[date_col].max().normalize()


def get_channel_distribution(df: pd.DataFrame, mask: pd.Series = None) -> Dict[str, int]:
    """è·å–æ¸ é“åˆ†å¸ƒ"""
    channel_col = next((c for c in ['å¹³å°', 'æ¸ é“', 'platform'] if c in df.columns), None)
    if channel_col is None:
        return {}
    
    if mask is not None:
        df = df[mask]
    
    return df[channel_col].value_counts().to_dict()


# ============ V7.6 æ€§èƒ½ä¼˜åŒ–ï¼šæ‰¹é‡è®¡ç®—è¶‹åŠ¿æ•°æ® ============

def calculate_daily_overflow_batch(df: pd.DataFrame, date_col: str, yesterday, days: int = 3) -> Dict[str, int]:
    """
    æ‰¹é‡è®¡ç®—å¤šå¤©çš„ç©¿åº•è®¢å•æ•°ï¼ˆV7.6æ€§èƒ½ä¼˜åŒ–ï¼‰
    
    ä¼˜åŒ–å‰ï¼šå¾ªç¯3æ¬¡ï¼Œæ¯æ¬¡ç­›é€‰å’Œèšåˆï¼Œè€—æ—¶20-30ç§’
    ä¼˜åŒ–åï¼šä¸€æ¬¡æ€§ç­›é€‰å’Œåˆ†ç»„èšåˆï¼Œè€—æ—¶2-3ç§’
    
    Args:
        df: åŸå§‹æ•°æ®
        date_col: æ—¥æœŸåˆ—å
        yesterday: æ˜¨æ—¥æ—¥æœŸ
        days: æŸ¥è¯¢å¤©æ•°ï¼ˆé»˜è®¤3å¤©ï¼‰
    
    Returns:
        {date: overflow_count} æ¯å¤©çš„ç©¿åº•è®¢å•æ•°
    """
    order_id_col = 'è®¢å•ID' if 'è®¢å•ID' in df.columns else None
    if not order_id_col:
        return {}
    
    # ä¸€æ¬¡æ€§ç­›é€‰å‰Nå¤©çš„æ•°æ®
    start_date = yesterday - timedelta(days=days)
    recent_df = df[df[date_col].dt.normalize() >= start_date].copy()
    
    if recent_df.empty:
        return {}
    
    # å‡†å¤‡èšåˆå­—æ®µ
    sales_field = 'æœˆå”®' if 'æœˆå”®' in recent_df.columns else 'é”€é‡'
    if 'å®æ”¶ä»·æ ¼' in recent_df.columns and sales_field in recent_df.columns:
        recent_df['_å®æ”¶ä»·æ ¼_é”€é‡'] = recent_df['å®æ”¶ä»·æ ¼'].fillna(0) * recent_df[sales_field].fillna(1)
    
    agg_dict = {}
    if 'åˆ©æ¶¦é¢' in recent_df.columns:
        agg_dict['åˆ©æ¶¦é¢'] = pd.NamedAgg(column='åˆ©æ¶¦é¢', aggfunc='sum')
    if 'å¹³å°æœåŠ¡è´¹' in recent_df.columns:
        agg_dict['å¹³å°æœåŠ¡è´¹'] = pd.NamedAgg(column='å¹³å°æœåŠ¡è´¹', aggfunc='sum')
    if 'ä¼å®¢åè¿”' in recent_df.columns:
        agg_dict['ä¼å®¢åè¿”'] = pd.NamedAgg(column='ä¼å®¢åè¿”', aggfunc='sum')
    if 'ç‰©æµé…é€è´¹' in recent_df.columns:
        agg_dict['ç‰©æµé…é€è´¹'] = pd.NamedAgg(column='ç‰©æµé…é€è´¹', aggfunc='first')
    agg_dict['æ—¥æœŸ'] = pd.NamedAgg(column=date_col, aggfunc='first')
    
    if not agg_dict:
        return {}
    
    # æŒ‰è®¢å•IDèšåˆ
    order_data = recent_df.groupby(order_id_col).agg(**agg_dict).reset_index()
    order_data['è®¢å•å®é™…åˆ©æ¶¦'] = calculate_order_profit(order_data)
    
    # æ ‡è®°ç©¿åº•è®¢å•
    overflow_mask = order_data['è®¢å•å®é™…åˆ©æ¶¦'] < 0
    if 'åˆ©æ¶¦é¢' in order_data.columns:
        overflow_mask = overflow_mask & (order_data['åˆ©æ¶¦é¢'] != 0)
    
    # æŒ‰æ—¥æœŸåˆ†ç»„ç»Ÿè®¡
    order_data['æ—¥æœŸ_norm'] = pd.to_datetime(order_data['æ—¥æœŸ']).dt.normalize()
    daily_counts = order_data[overflow_mask].groupby('æ—¥æœŸ_norm').size().to_dict()
    
    return daily_counts


def calculate_daily_delivery_batch(df: pd.DataFrame, date_col: str, yesterday, days: int = 3, threshold: float = 6) -> Dict[str, int]:
    """
    æ‰¹é‡è®¡ç®—å¤šå¤©çš„é«˜é…é€è´¹è®¢å•æ•°ï¼ˆV7.6æ€§èƒ½ä¼˜åŒ–ï¼‰
    
    Args:
        df: åŸå§‹æ•°æ®
        date_col: æ—¥æœŸåˆ—å
        yesterday: æ˜¨æ—¥æ—¥æœŸ
        days: æŸ¥è¯¢å¤©æ•°
        threshold: é…é€è´¹é˜ˆå€¼
    
    Returns:
        {date: high_delivery_count} æ¯å¤©çš„é«˜é…é€è´¹è®¢å•æ•°
    """
    order_id_col = 'è®¢å•ID' if 'è®¢å•ID' in df.columns else None
    if not order_id_col or 'ç‰©æµé…é€è´¹' not in df.columns:
        return {}
    
    # ä¸€æ¬¡æ€§ç­›é€‰å‰Nå¤©çš„æ•°æ®
    start_date = yesterday - timedelta(days=days)
    recent_df = df[df[date_col].dt.normalize() >= start_date].copy()
    
    if recent_df.empty:
        return {}
    
    # å‡†å¤‡èšåˆå­—æ®µ
    agg_dict = {
        'ç‰©æµé…é€è´¹': pd.NamedAgg(column='ç‰©æµé…é€è´¹', aggfunc='first'),
        'æ—¥æœŸ': pd.NamedAgg(column=date_col, aggfunc='first')
    }
    
    if 'ç”¨æˆ·æ”¯ä»˜é…é€è´¹' in recent_df.columns:
        agg_dict['ç”¨æˆ·æ”¯ä»˜é…é€è´¹'] = pd.NamedAgg(column='ç”¨æˆ·æ”¯ä»˜é…é€è´¹', aggfunc='first')
    
    delivery_discount_col = next((c for c in ['é…é€è´¹å‡å…é‡‘é¢', 'é…é€è´¹å‡å…'] if c in recent_df.columns), None)
    if delivery_discount_col:
        agg_dict['é…é€è´¹å‡å…é‡‘é¢'] = pd.NamedAgg(column=delivery_discount_col, aggfunc='first')
    
    if 'ä¼å®¢åè¿”' in recent_df.columns:
        agg_dict['ä¼å®¢åè¿”'] = pd.NamedAgg(column='ä¼å®¢åè¿”', aggfunc='sum')
    
    # æŒ‰è®¢å•IDèšåˆ
    order_data = recent_df.groupby(order_id_col).agg(**agg_dict).reset_index()
    
    # è®¡ç®—é…é€å‡€æˆæœ¬
    delivery_net = order_data['ç‰©æµé…é€è´¹'].fillna(0)
    if 'ç”¨æˆ·æ”¯ä»˜é…é€è´¹' in order_data.columns:
        delivery_net = delivery_net - order_data['ç”¨æˆ·æ”¯ä»˜é…é€è´¹'].fillna(0)
    if 'é…é€è´¹å‡å…é‡‘é¢' in order_data.columns:
        delivery_net = delivery_net + order_data['é…é€è´¹å‡å…é‡‘é¢'].fillna(0)
    if 'ä¼å®¢åè¿”' in order_data.columns:
        delivery_net = delivery_net - order_data['ä¼å®¢åè¿”'].fillna(0)
    
    # æ ‡è®°é«˜é…é€è´¹è®¢å•
    high_delivery_mask = delivery_net > threshold
    
    # æŒ‰æ—¥æœŸåˆ†ç»„ç»Ÿè®¡
    order_data['æ—¥æœŸ_norm'] = pd.to_datetime(order_data['æ—¥æœŸ']).dt.normalize()
    daily_counts = order_data[high_delivery_mask].groupby('æ—¥æœŸ_norm').size().to_dict()
    
    return daily_counts


# ============ V8.6 æ€§èƒ½ä¼˜åŒ–ï¼šç»Ÿä¸€è®¢å•èšåˆå‡½æ•° ============

def calculate_order_aggregation(df: pd.DataFrame) -> pd.DataFrame:
    """
    ç»Ÿä¸€çš„è®¢å•èšåˆå‡½æ•°ï¼ˆV8.6æ€§èƒ½ä¼˜åŒ–ï¼‰
    
    ä¸€æ¬¡æ€§è®¡ç®—æ‰€æœ‰è¯Šæ–­åˆ†æéœ€è¦çš„è®¢å•çº§æŒ‡æ ‡ï¼Œé¿å…é‡å¤èšåˆ
    
    Args:
        df: åŸå§‹è®¢å•æ•°æ®
    
    Returns:
        è®¢å•èšåˆåçš„DataFrameï¼ŒåŒ…å«ï¼š
        - è®¢å•å®é™…åˆ©æ¶¦
        - é…é€å‡€æˆæœ¬
        - é”€å”®é¢
        - æˆæœ¬
        - æ´»åŠ¨æˆæœ¬
        - æ¸ é“ã€é—¨åº—ã€æ—¥æœŸç­‰ç»´åº¦å­—æ®µ
    
    æ€§èƒ½æå‡ï¼š
        - ä¼˜åŒ–å‰ï¼šæ¯ä¸ªåˆ†æå‡½æ•°ç‹¬ç«‹èšåˆï¼Œé‡å¤3æ¬¡ï¼Œè€—æ—¶60-90ç§’
        - ä¼˜åŒ–åï¼šç»Ÿä¸€èšåˆä¸€æ¬¡ï¼Œè€—æ—¶20-30ç§’
        - æå‡ï¼š3å€æ€§èƒ½æå‡
    """
    if df is None or df.empty:
        return pd.DataFrame()
    
    order_id_col = 'è®¢å•ID' if 'è®¢å•ID' in df.columns else None
    if not order_id_col:
        return pd.DataFrame()
    
    # å‡†å¤‡é”€é‡å­—æ®µ
    sales_field = 'æœˆå”®' if 'æœˆå”®' in df.columns else 'é”€é‡'
    if 'å®æ”¶ä»·æ ¼' in df.columns and sales_field in df.columns:
        df = df.copy()
        df['_å®æ”¶ä»·æ ¼_é”€é‡'] = df['å®æ”¶ä»·æ ¼'].fillna(0) * df[sales_field].fillna(1)
    
    # æ„å»ºèšåˆå­—å…¸ - åŒ…å«æ‰€æœ‰åˆ†æéœ€è¦çš„å­—æ®µ
    agg_dict = {}
    
    # ===== å•†å“çº§å­—æ®µ (sum) =====
    if 'åˆ©æ¶¦é¢' in df.columns:
        agg_dict['åˆ©æ¶¦é¢'] = pd.NamedAgg(column='åˆ©æ¶¦é¢', aggfunc='sum')
    if 'å¹³å°æœåŠ¡è´¹' in df.columns:
        agg_dict['å¹³å°æœåŠ¡è´¹'] = pd.NamedAgg(column='å¹³å°æœåŠ¡è´¹', aggfunc='sum')
    if 'ä¼å®¢åè¿”' in df.columns:
        agg_dict['ä¼å®¢åè¿”'] = pd.NamedAgg(column='ä¼å®¢åè¿”', aggfunc='sum')
    if '_å®æ”¶ä»·æ ¼_é”€é‡' in df.columns:
        agg_dict['é”€å”®é¢'] = pd.NamedAgg(column='_å®æ”¶ä»·æ ¼_é”€é‡', aggfunc='sum')
    elif 'å•†å“å®å”®ä»·' in df.columns:
        agg_dict['é”€å”®é¢'] = pd.NamedAgg(column='å•†å“å®å”®ä»·', aggfunc='sum')
    
    cost_col = 'å•†å“é‡‡è´­æˆæœ¬' if 'å•†å“é‡‡è´­æˆæœ¬' in df.columns else 'æˆæœ¬'
    if cost_col in df.columns:
        agg_dict['æˆæœ¬'] = pd.NamedAgg(column=cost_col, aggfunc='sum')
    
    # ===== è®¢å•çº§å­—æ®µ (first) =====
    if 'ç‰©æµé…é€è´¹' in df.columns:
        agg_dict['ç‰©æµé…é€è´¹'] = pd.NamedAgg(column='ç‰©æµé…é€è´¹', aggfunc='first')
    if 'ç”¨æˆ·æ”¯ä»˜é…é€è´¹' in df.columns:
        agg_dict['ç”¨æˆ·æ”¯ä»˜é…é€è´¹'] = pd.NamedAgg(column='ç”¨æˆ·æ”¯ä»˜é…é€è´¹', aggfunc='first')
    
    delivery_discount_col = next((c for c in ['é…é€è´¹å‡å…é‡‘é¢', 'é…é€è´¹å‡å…'] if c in df.columns), None)
    if delivery_discount_col:
        agg_dict['é…é€è´¹å‡å…é‡‘é¢'] = pd.NamedAgg(column=delivery_discount_col, aggfunc='first')
    
    # æ¸ é“
    channel_col = next((c for c in ['å¹³å°', 'æ¸ é“', 'platform'] if c in df.columns), None)
    if channel_col:
        agg_dict['æ¸ é“'] = pd.NamedAgg(column=channel_col, aggfunc='first')
    
    # é—¨åº—
    if 'é—¨åº—' in df.columns:
        agg_dict['é—¨åº—'] = pd.NamedAgg(column='é—¨åº—', aggfunc='first')
    elif 'é—¨åº—åç§°' in df.columns:
        agg_dict['é—¨åº—'] = pd.NamedAgg(column='é—¨åº—åç§°', aggfunc='first')
    
    # æ—¥æœŸ
    date_col = 'æ—¥æœŸ' if 'æ—¥æœŸ' in df.columns else 'ä¸‹å•æ—¶é—´'
    if date_col in df.columns:
        agg_dict['æ—¥æœŸ'] = pd.NamedAgg(column=date_col, aggfunc='first')
    
    # è®¢å•ç¼–å·
    if 'è®¢å•ç¼–å·' in df.columns:
        agg_dict['è®¢å•ç¼–å·'] = pd.NamedAgg(column='è®¢å•ç¼–å·', aggfunc='first')
    
    # æ´»åŠ¨å­—æ®µï¼ˆè®¢å•çº§ï¼‰
    for name, field in ACTIVITY_FIELDS.items():
        if field in df.columns:
            agg_dict[name] = pd.NamedAgg(column=field, aggfunc='first')
    
    if not agg_dict:
        return pd.DataFrame()
    
    # æ‰§è¡Œèšåˆ
    order_agg = df.groupby(order_id_col).agg(**agg_dict).reset_index()
    
    # è®¡ç®—è¡ç”ŸæŒ‡æ ‡
    # 1. è®¢å•å®é™…åˆ©æ¶¦
    order_agg['è®¢å•å®é™…åˆ©æ¶¦'] = calculate_order_profit(order_agg)
    
    # 2. é…é€å‡€æˆæœ¬
    delivery_net = order_agg.get('ç‰©æµé…é€è´¹', pd.Series(0, index=order_agg.index)).fillna(0)
    if 'ç”¨æˆ·æ”¯ä»˜é…é€è´¹' in order_agg.columns:
        delivery_net = delivery_net - order_agg['ç”¨æˆ·æ”¯ä»˜é…é€è´¹'].fillna(0)
    if 'é…é€è´¹å‡å…é‡‘é¢' in order_agg.columns:
        delivery_net = delivery_net + order_agg['é…é€è´¹å‡å…é‡‘é¢'].fillna(0)
    if 'ä¼å®¢åè¿”' in order_agg.columns:
        delivery_net = delivery_net - order_agg['ä¼å®¢åè¿”'].fillna(0)
    order_agg['é…é€å‡€æˆæœ¬'] = delivery_net
    
    # 3. æ´»åŠ¨æˆæœ¬
    activity_cost = 0
    for name in ACTIVITY_FIELDS.keys():
        if name in order_agg.columns:
            activity_cost += order_agg[name].fillna(0)
    order_agg['æ´»åŠ¨æˆæœ¬'] = activity_cost
    
    return order_agg


def analyze_urgent_issues(df: pd.DataFrame, order_agg: pd.DataFrame = None) -> Dict[str, Any]:
    """
    åˆ†æç´§æ€¥é—®é¢˜ï¼ˆä»Šæ—¥å¿…é¡»å¤„ç†ï¼‰
    
    åŒ…å«:
    - ç©¿åº•æ­¢è¡€ï¼šè®¢å•å®é™…åˆ©æ¶¦ < 0 (ä½¿ç”¨ä¸»çœ‹æ¿ç»Ÿä¸€å…¬å¼)
    - é«˜é…é€è´¹é¢„è­¦ï¼šé…é€è´¹ > 6å…ƒ ä¸” åˆ©æ¶¦ < é…é€è´¹
    - çƒ­é”€ç¼ºè´§ï¼šæ˜¨æ—¥çƒ­é”€å“ä»Šæ—¥é›¶é”€é‡
    - ä»·æ ¼å¼‚å¸¸ï¼šå”®ä»·ä½äºæˆæœ¬ï¼Œå–ä¸€å•äºä¸€å•
    
    Args:
        df: åŸå§‹è®¢å•æ•°æ®
        order_agg: é¢„è®¡ç®—çš„è®¢å•èšåˆæ•°æ®ï¼ˆV8.6æ€§èƒ½ä¼˜åŒ–ï¼‰
    
    Returns:
        Dict with keys: overflow, delivery, stockout, price_abnormal
    """
    result = {
        'overflow': {'count': 0, 'loss': 0, 'channels': {}, 'error': None},
        'delivery': {'count': 0, 'extra_cost': 0, 'distance_distribution': {}, 'error': None},
        'stockout': {'count': 0, 'loss': 0, 'channels': {}, 'error': None},
        'price_abnormal': {'count': 0, 'loss': 0, 'severe_count': 0, 'mild_count': 0, 'products': [], 'error': None}
    }
    
    if df is None or df.empty:
        return result
    
    # âš¡ V8.6æ€§èƒ½ä¼˜åŒ–ï¼šå¦‚æœæ²¡æœ‰ä¼ å…¥order_aggï¼Œåˆ™è®¡ç®—ï¼ˆå‘åå…¼å®¹ï¼‰
    if order_agg is None:
        order_agg = calculate_order_aggregation(df)
    
    if order_agg.empty:
        return result
    
    try:
        date_col = 'æ—¥æœŸ' if 'æ—¥æœŸ' in order_agg.columns else ('æ—¥æœŸ' if 'æ—¥æœŸ' in df.columns else 'ä¸‹å•æ—¶é—´')
        
        # âš¡ V8.6æ€§èƒ½ä¼˜åŒ–ï¼šç›´æ¥ä½¿ç”¨order_aggï¼Œæ— éœ€é‡æ–°èšåˆ
        # ç¡®ä¿order_aggæœ‰æ—¥æœŸåˆ—
        if date_col not in order_agg.columns and date_col in df.columns:
            # å¦‚æœorder_aggç¼ºå°‘æ—¥æœŸï¼Œä»dfè¡¥å……
            df_copy = df.copy()
            df_copy[date_col] = pd.to_datetime(df_copy[date_col])
            order_id_col = 'è®¢å•ID' if 'è®¢å•ID' in df_copy.columns else None
            if order_id_col:
                date_map = df_copy.groupby(order_id_col)[date_col].first()
                order_agg = order_agg.copy()
                order_agg['æ—¥æœŸ'] = order_agg[order_id_col].map(date_map)
                date_col = 'æ—¥æœŸ'
        
        # æ ‡å‡†åŒ–æ—¥æœŸåˆ—
        order_agg = order_agg.copy()
        order_agg[date_col] = pd.to_datetime(order_agg[date_col])
        yesterday = order_agg[date_col].max().normalize()
        day_before = yesterday - timedelta(days=1)
        
        # ç­›é€‰æ˜¨æ—¥è®¢å•
        yesterday_orders = order_agg[order_agg[date_col].dt.normalize() == yesterday]
        
        if yesterday_orders.empty:
            return result
        
        # ================== 1. ç©¿åº•æ­¢è¡€åˆ†æï¼ˆä½¿ç”¨é¢„è®¡ç®—çš„order_aggï¼‰==================
        # ç©¿åº•åˆ¤æ–­æ ‡å‡†ï¼šè®¢å•å®é™…åˆ©æ¶¦ < 0
        # order_aggä¸­å·²ç»åŒ…å«'è®¢å•å®é™…åˆ©æ¶¦'å­—æ®µ
        
        if 'è®¢å•å®é™…åˆ©æ¶¦' in yesterday_orders.columns:
            # ç©¿åº•è®¢å•ï¼šè®¢å•å®é™…åˆ©æ¶¦ < 0 ä¸” åˆ©æ¶¦é¢ != 0ï¼ˆæ’é™¤å¼‚å¸¸æ•°æ®ï¼‰
            overflow_mask = yesterday_orders['è®¢å•å®é™…åˆ©æ¶¦'] < 0
            if 'åˆ©æ¶¦é¢' in yesterday_orders.columns:
                overflow_mask = overflow_mask & (yesterday_orders['åˆ©æ¶¦é¢'] != 0)
            overflow_orders = yesterday_orders[overflow_mask]
            
            if len(overflow_orders) > 0:
                result['overflow']['count'] = len(overflow_orders)
                # ç©¿åº•æŸå¤± = è´Ÿåˆ©æ¶¦è®¢å•çš„åˆ©æ¶¦ç»å¯¹å€¼ä¹‹å’Œ
                result['overflow']['loss'] = round(abs(overflow_orders['è®¢å•å®é™…åˆ©æ¶¦'].sum()), 2)
                if 'æ¸ é“' in overflow_orders.columns:
                    result['overflow']['channels'] = overflow_orders['æ¸ é“'].value_counts().to_dict()
            
            # ===== V7.6ä¼˜åŒ–ï¼šç©¿åº•è¶‹åŠ¿åˆ†æï¼ˆæ‰¹é‡è®¡ç®—ï¼‰=====
            try:
                # æ‰¹é‡è®¡ç®—å‰3å¤©çš„ç©¿åº•è®¢å•æ•°
                daily_overflow = calculate_daily_overflow_batch(df, date_col, yesterday, days=3)
                
                # æå–å‰3å¤©çš„æ•°æ®ï¼ˆæ’é™¤æ˜¨æ—¥ï¼‰
                overflow_3d_counts = []
                for day_offset in range(1, 4):
                    check_date = (yesterday - timedelta(days=day_offset)).normalize()
                    count = daily_overflow.get(check_date, 0)
                    overflow_3d_counts.append(count)
                
                avg_3d = sum(overflow_3d_counts) / len(overflow_3d_counts) if overflow_3d_counts else 0
                result['overflow']['trend'] = calculate_trend_indicator(result['overflow']['count'], avg_3d)
                result['overflow']['avg_3d'] = round(avg_3d, 1)
            except Exception as e:
                print(f"[ç©¿åº•è¶‹åŠ¿åˆ†æ] å¤±è´¥: {e}")
                result['overflow']['trend'] = {'trend': 'stable', 'icon': 'â†’', 'label': 'æŒå¹³', 'color': 'gray', 'description': ''}
                result['overflow']['avg_3d'] = 0
        
        # ================== 2. é«˜é…é€è´¹é¢„è­¦ï¼ˆä½¿ç”¨é¢„è®¡ç®—çš„é…é€å‡€æˆæœ¬ï¼‰==================
        if 'é…é€å‡€æˆæœ¬' in yesterday_orders.columns:
            # åˆ¤æ–­æ ‡å‡†ï¼šé…é€å‡€æˆæœ¬ > 6å…ƒ
            high_delivery_mask = yesterday_orders['é…é€å‡€æˆæœ¬'] > DELIVERY_FEE_THRESHOLD
            high_delivery_orders = yesterday_orders[high_delivery_mask]
            
            if len(high_delivery_orders) > 0:
                result['delivery']['count'] = len(high_delivery_orders)
                # é…é€æº¢ä»· = é…é€å‡€æˆæœ¬ - æ ‡å‡†å€¼(6å…ƒ)
                result['delivery']['extra_cost'] = round((high_delivery_orders['é…é€å‡€æˆæœ¬'] - DELIVERY_FEE_THRESHOLD).sum(), 2)
                
                # æ¸ é“åˆ†å¸ƒç»Ÿè®¡
                if 'æ¸ é“' in high_delivery_orders.columns:
                    result['delivery']['channels'] = high_delivery_orders['æ¸ é“'].value_counts().to_dict()
                
                # è·ç¦»åˆ†å¸ƒåˆ†æï¼ˆéœ€è¦ä»åŸå§‹dfè·å–ï¼‰
                order_id_col = 'è®¢å•ID' if 'è®¢å•ID' in df.columns else None
                if order_id_col:
                    distance_col = next((c for c in ['é…é€è·ç¦»', 'é€è¾¾è·ç¦»'] if c in df.columns), None)
                    if distance_col:
                        # è·å–è¿™äº›è®¢å•çš„è·ç¦»
                        problem_order_ids = high_delivery_orders[order_id_col].tolist()
                        yesterday_df = df[df[date_col].dt.normalize() == yesterday]
                        distance_df = yesterday_df[yesterday_df[order_id_col].isin(problem_order_ids)]
                        distances = distance_df.groupby(order_id_col)[distance_col].first()
                        
                        # åŸå§‹æ•°æ®æ˜¯ç±³ï¼Œè½¬æ¢ä¸ºkm
                        distances_km = distances / 1000
                        
                        # åˆ†æ®µç»Ÿè®¡ï¼ˆå•ä½ï¼škmï¼‰
                        bins = [0, 3, 5, 8, float('inf')]
                        labels = ['0-3km', '3-5km', '5-8km', '8km+']
                        distance_cut = pd.cut(distances_km, bins=bins, labels=labels)
                        result['delivery']['distance_distribution'] = distance_cut.value_counts().to_dict()
            
            # ===== V7.6ä¼˜åŒ–ï¼šé«˜é…é€è´¹è¶‹åŠ¿åˆ†æï¼ˆæ‰¹é‡è®¡ç®—ï¼‰=====
            try:
                # æ‰¹é‡è®¡ç®—å‰3å¤©çš„é«˜é…é€è´¹è®¢å•æ•°
                daily_delivery = calculate_daily_delivery_batch(df, date_col, yesterday, days=3, threshold=DELIVERY_FEE_THRESHOLD)
                
                # æå–å‰3å¤©çš„æ•°æ®ï¼ˆæ’é™¤æ˜¨æ—¥ï¼‰
                delivery_3d_counts = []
                for day_offset in range(1, 4):
                    check_date = (yesterday - timedelta(days=day_offset)).normalize()
                    count = daily_delivery.get(check_date, 0)
                    delivery_3d_counts.append(count)
                
                avg_3d_delivery = sum(delivery_3d_counts) / len(delivery_3d_counts) if delivery_3d_counts else 0
                result['delivery']['trend'] = calculate_trend_indicator(result['delivery']['count'], avg_3d_delivery)
                result['delivery']['avg_3d'] = round(avg_3d_delivery, 1)
            except Exception as e:
                print(f"[é…é€è´¹è¶‹åŠ¿åˆ†æ] å¤±è´¥: {e}")
                result['delivery']['trend'] = {'trend': 'stable', 'icon': 'â†’', 'label': 'æŒå¹³', 'color': 'gray', 'description': ''}
                result['delivery']['avg_3d'] = 0
            overflow_orders = order_data[overflow_mask]
            
            if len(overflow_orders) > 0:
                result['overflow']['count'] = len(overflow_orders)
                # ç©¿åº•æŸå¤± = è´Ÿåˆ©æ¶¦è®¢å•çš„åˆ©æ¶¦ç»å¯¹å€¼ä¹‹å’Œ
                result['overflow']['loss'] = round(abs(overflow_orders['è®¢å•å®é™…åˆ©æ¶¦'].sum()), 2)
                if 'æ¸ é“' in overflow_orders.columns:
                    result['overflow']['channels'] = overflow_orders['æ¸ é“'].value_counts().to_dict()
            
            # ===== V7.6ä¼˜åŒ–ï¼šç©¿åº•è¶‹åŠ¿åˆ†æï¼ˆæ‰¹é‡è®¡ç®—ï¼‰=====
            try:
                # æ‰¹é‡è®¡ç®—å‰3å¤©çš„ç©¿åº•è®¢å•æ•°
                daily_overflow = calculate_daily_overflow_batch(df, date_col, yesterday, days=3)
                
                # æå–å‰3å¤©çš„æ•°æ®ï¼ˆæ’é™¤æ˜¨æ—¥ï¼‰
                overflow_3d_counts = []
                for day_offset in range(1, 4):
                    check_date = (yesterday - timedelta(days=day_offset)).normalize()
                    count = daily_overflow.get(check_date, 0)
                    overflow_3d_counts.append(count)
                
                avg_3d = sum(overflow_3d_counts) / len(overflow_3d_counts) if overflow_3d_counts else 0
                result['overflow']['trend'] = calculate_trend_indicator(result['overflow']['count'], avg_3d)
                result['overflow']['avg_3d'] = round(avg_3d, 1)
            except Exception as e:
                print(f"[ç©¿åº•è¶‹åŠ¿åˆ†æ] å¤±è´¥: {e}")
                result['overflow']['trend'] = {'trend': 'stable', 'icon': 'â†’', 'label': 'æŒå¹³', 'color': 'gray', 'description': ''}
                result['overflow']['avg_3d'] = 0
            
            # ================== 2. é«˜é…é€è´¹é¢„è­¦ ==================
            # ä½¿ç”¨é…é€å‡€æˆæœ¬å…¬å¼ï¼šç‰©æµé…é€è´¹ - (ç”¨æˆ·æ”¯ä»˜é…é€è´¹ - é…é€è´¹å‡å…) - ä¼å®¢åè¿”
            if 'ç‰©æµé…é€è´¹' in order_data.columns:
                # è®¡ç®—é…é€å‡€æˆæœ¬
                delivery_net_cost = order_data['ç‰©æµé…é€è´¹'].fillna(0).copy()
                
                # å‡å»ç”¨æˆ·æ”¯ä»˜é…é€è´¹
                if 'ç”¨æˆ·æ”¯ä»˜é…é€è´¹' in order_data.columns:
                    delivery_net_cost = delivery_net_cost - order_data['ç”¨æˆ·æ”¯ä»˜é…é€è´¹'].fillna(0)
                
                # åŠ å›é…é€è´¹å‡å…ï¼ˆå› ä¸ºç”¨æˆ·æ”¯ä»˜é…é€è´¹å·²ç»å‡æ‰äº†å‡å…éƒ¨åˆ†ï¼‰
                delivery_discount_col = next((c for c in ['é…é€è´¹å‡å…é‡‘é¢', 'é…é€è´¹å‡å…'] if c in order_data.columns), None)
                if delivery_discount_col:
                    delivery_net_cost = delivery_net_cost + order_data[delivery_discount_col].fillna(0)
                
                # å‡å»ä¼å®¢åè¿”
                if 'ä¼å®¢åè¿”' in order_data.columns:
                    delivery_net_cost = delivery_net_cost - order_data['ä¼å®¢åè¿”'].fillna(0)
                
                # åˆ¤æ–­æ ‡å‡†ï¼šé…é€å‡€æˆæœ¬ > 6å…ƒ
                high_delivery_mask = delivery_net_cost > DELIVERY_FEE_THRESHOLD
                high_delivery_orders = order_data[high_delivery_mask]
                
                if len(high_delivery_orders) > 0:
                    result['delivery']['count'] = len(high_delivery_orders)
                    # é…é€æº¢ä»· = é…é€å‡€æˆæœ¬ - æ ‡å‡†å€¼(6å…ƒ)
                    high_delivery_net_costs = delivery_net_cost[high_delivery_mask]
                    result['delivery']['extra_cost'] = round((high_delivery_net_costs - DELIVERY_FEE_THRESHOLD).sum(), 2)
                    
                    # æ¸ é“åˆ†å¸ƒç»Ÿè®¡
                    if 'æ¸ é“' in high_delivery_orders.columns:
                        result['delivery']['channels'] = high_delivery_orders['æ¸ é“'].value_counts().to_dict()
                    
                    # è·ç¦»åˆ†å¸ƒåˆ†æ
                    distance_col = next((c for c in ['é…é€è·ç¦»', 'é€è¾¾è·ç¦»'] if c in yesterday_df.columns), None)
                    if distance_col:
                        # è·å–è¿™äº›è®¢å•çš„è·ç¦»
                        problem_order_ids = high_delivery_orders[order_id_col].tolist()
                        distance_df = yesterday_df[yesterday_df[order_id_col].isin(problem_order_ids)]
                        distances = distance_df.groupby(order_id_col)[distance_col].first()
                        
                        # åŸå§‹æ•°æ®æ˜¯ç±³ï¼Œè½¬æ¢ä¸ºkm
                        distances_km = distances / 1000
                        
                        # åˆ†æ®µç»Ÿè®¡ï¼ˆå•ä½ï¼škmï¼‰
                        bins = [0, 3, 5, 8, float('inf')]
                        labels = ['0-3km', '3-5km', '5-8km', '8km+']
                        distance_cut = pd.cut(distances_km, bins=bins, labels=labels)
                        result['delivery']['distance_distribution'] = distance_cut.value_counts().to_dict()
            
            # ===== V7.6ä¼˜åŒ–ï¼šé«˜é…é€è´¹è¶‹åŠ¿åˆ†æï¼ˆæ‰¹é‡è®¡ç®—ï¼‰=====
            try:
                # æ‰¹é‡è®¡ç®—å‰3å¤©çš„é«˜é…é€è´¹è®¢å•æ•°
                daily_delivery = calculate_daily_delivery_batch(df, date_col, yesterday, days=3, threshold=DELIVERY_FEE_THRESHOLD)
                
                # æå–å‰3å¤©çš„æ•°æ®ï¼ˆæ’é™¤æ˜¨æ—¥ï¼‰
                delivery_3d_counts = []
                for day_offset in range(1, 4):
                    check_date = (yesterday - timedelta(days=day_offset)).normalize()
                    count = daily_delivery.get(check_date, 0)
                    delivery_3d_counts.append(count)
                
                avg_3d_delivery = sum(delivery_3d_counts) / len(delivery_3d_counts) if delivery_3d_counts else 0
                result['delivery']['trend'] = calculate_trend_indicator(result['delivery']['count'], avg_3d_delivery)
                result['delivery']['avg_3d'] = round(avg_3d_delivery, 1)
            except Exception as e:
                print(f"[é…é€è´¹è¶‹åŠ¿åˆ†æ] å¤±è´¥: {e}")
                result['delivery']['trend'] = {'trend': 'stable', 'icon': 'â†’', 'label': 'æŒå¹³', 'color': 'gray', 'description': ''}
                result['delivery']['avg_3d'] = 0
        
        # ================== 3. çƒ­é”€ç¼ºè´§åˆ†æ ==================
        # å®šä¹‰ï¼šè¿‘Nå¤©æœ‰é”€é‡ ä¸” æ˜¨æ—¥å‰©ä½™åº“å­˜=0ï¼ˆè‡ªé€‚åº”æ•°æ®å¤©æ•°ï¼‰
        # æ³¨æ„ï¼šéœ€è¦å‰”é™¤ä¸€çº§åˆ†ç±»ä¸º"è€—æ"çš„å•†å“
        sales_col = 'æœˆå”®' if 'æœˆå”®' in df.columns else 'é”€é‡'
        stock_col = next((c for c in ['å‰©ä½™åº“å­˜', 'åº“å­˜'] if c in df.columns), None)
        category_col_stockout = next((c for c in ['ä¸€çº§åˆ†ç±»å', 'ä¸€çº§åˆ†ç±»'] if c in df.columns), None)
        
        if sales_col in df.columns:
            # è®¡ç®—æ•°æ®å¤©æ•°
            min_date = df[date_col].min().normalize()
            data_days = (yesterday - min_date).days + 1
            
            # è‡ªé€‚åº”ç»Ÿè®¡å¤©æ•°
            if data_days >= 7:
                stat_days = 7
                start_date = yesterday - timedelta(days=6)
            elif data_days >= 2:
                stat_days = data_days
                start_date = min_date
            else:
                # åªæœ‰1å¤©æ•°æ®ï¼Œæ— æ³•åˆ¤æ–­ç¼ºè´§
                stat_days = 0
                start_date = None
            
            if stat_days >= 2:
                period_df = df[(df[date_col].dt.normalize() >= start_date) & (df[date_col].dt.normalize() <= yesterday)]
                
                if not period_df.empty:
                    # ç»Ÿè®¡æœŸé—´å•†å“é”€é‡
                    period_sales = period_df.groupby('å•†å“åç§°')[sales_col].sum().reset_index()
                    period_sales.columns = ['å•†å“åç§°', f'{stat_days}å¤©é”€é‡']
                    
                    # æ˜¨æ—¥åº“å­˜æƒ…å†µ
                    if stock_col:
                        yesterday_stock = yesterday_df.groupby('å•†å“åç§°')[stock_col].first().reset_index()
                        yesterday_stock.columns = ['å•†å“åç§°', 'æ˜¨æ—¥åº“å­˜']
                        
                        # åˆå¹¶
                        comparison = period_sales.merge(yesterday_stock, on='å•†å“åç§°', how='left')
                        comparison['æ˜¨æ—¥åº“å­˜'] = comparison['æ˜¨æ—¥åº“å­˜'].fillna(-1)
                        
                        # ç­›é€‰ï¼šæœ‰é”€é‡ ä¸” æ˜¨æ—¥åº“å­˜=0
                        stockout_mask = (comparison[f'{stat_days}å¤©é”€é‡'] > 0) & (comparison['æ˜¨æ—¥åº“å­˜'] == 0)
                        stockout_products = comparison[stockout_mask]
                    else:
                        # æ²¡æœ‰åº“å­˜å­—æ®µæ—¶ï¼Œå›é€€åˆ°æ—§é€»è¾‘ï¼šå‰æ—¥é”€é‡>=3 ä¸” æ˜¨æ—¥é”€é‡=0
                        if not day_before_df.empty:
                            day_before_sales = day_before_df.groupby('å•†å“åç§°')[sales_col].sum().reset_index()
                            day_before_sales.columns = ['å•†å“åç§°', 'å‰æ—¥é”€é‡']
                            yesterday_sales = yesterday_df.groupby('å•†å“åç§°')[sales_col].sum().reset_index()
                            yesterday_sales.columns = ['å•†å“åç§°', 'æ˜¨æ—¥é”€é‡']
                            comparison = day_before_sales.merge(yesterday_sales, on='å•†å“åç§°', how='left')
                            comparison['æ˜¨æ—¥é”€é‡'] = comparison['æ˜¨æ—¥é”€é‡'].fillna(0)
                            stockout_mask = (comparison['å‰æ—¥é”€é‡'] >= 3) & (comparison['æ˜¨æ—¥é”€é‡'] == 0)
                            stockout_products = comparison[stockout_mask]
                        else:
                            stockout_products = pd.DataFrame()
                    
                    # ===== è¿‡æ»¤è€—æåˆ†ç±» =====
                    if category_col_stockout and not stockout_products.empty:
                        # è·å–å•†å“çš„ä¸€çº§åˆ†ç±»
                        product_category = period_df.groupby('å•†å“åç§°')[category_col_stockout].first().reset_index()
                        product_category.columns = ['å•†å“åç§°', '_category']
                        stockout_products = stockout_products.merge(product_category, on='å•†å“åç§°', how='left')
                        stockout_products = stockout_products[stockout_products['_category'] != 'è€—æ'].copy()
                        stockout_products = stockout_products.drop(columns=['_category'], errors='ignore')
                    
                    if len(stockout_products) > 0:
                        result['stockout']['count'] = len(stockout_products)
                        
                        # ä¼°ç®—æŸå¤±ï¼ˆæŒ‰æ—¥å‡åˆ©æ¶¦ï¼‰
                        profit_col = next((c for c in ['åˆ©æ¶¦é¢'] if c in period_df.columns), None)
                        if profit_col:
                            stockout_names = stockout_products['å•†å“åç§°'].tolist()
                            stockout_profit = period_df[period_df['å•†å“åç§°'].isin(stockout_names)].groupby('å•†å“åç§°')[profit_col].sum()
                            result['stockout']['loss'] = round(stockout_profit.sum() / stat_days, 2)
                        
                        # æ¸ é“åˆ†å¸ƒï¼ˆæŒ‰å•†å“æ•°ç»Ÿè®¡ï¼Œä¸æ˜¯è®¢å•è¡Œæ•°ï¼‰
                        channel_col = next((c for c in ['å¹³å°', 'æ¸ é“', 'platform'] if c in period_df.columns), None)
                        if channel_col:
                            stockout_names = stockout_products['å•†å“åç§°'].tolist()
                            # è·å–æ¯ä¸ªå•†å“çš„ä¸»æ¸ é“ï¼ˆé”€é‡æœ€é«˜çš„æ¸ é“ï¼‰
                            stockout_channel = period_df[period_df['å•†å“åç§°'].isin(stockout_names)]
                            product_main_channel = stockout_channel.groupby(['å•†å“åç§°', channel_col])[sales_col].sum().reset_index()
                            idx = product_main_channel.groupby('å•†å“åç§°')[sales_col].idxmax()
                            main_channels = product_main_channel.loc[idx][channel_col]
                            result['stockout']['channels'] = main_channels.value_counts().to_dict()
                        
                        # ===== ç¼ºè´§è¿ç»­å¤©æ•°åˆ†æ =====
                        # ç»Ÿè®¡æ¯ä¸ªç¼ºè´§å•†å“è¿ç»­ç¼ºè´§äº†å¤šå°‘å¤©
                        try:
                            stockout_names = stockout_products['å•†å“åç§°'].tolist()
                            consecutive_days = {}
                            for product_name in stockout_names:
                                # æ£€æŸ¥æœ€è¿‘å‡ å¤©è¯¥å•†å“åº“å­˜æƒ…å†µ
                                days_count = 1  # æ˜¨æ—¥å·²ç¼ºè´§
                                for day_offset in range(1, 8):  # æœ€å¤šå¾€å‰æŸ¥7å¤©
                                    check_date = yesterday - timedelta(days=day_offset)
                                    check_df = df[(df[date_col].dt.normalize() == check_date) & (df['å•†å“åç§°'] == product_name)]
                                    if not check_df.empty and stock_col:
                                        stock_val = check_df[stock_col].iloc[0] if len(check_df) > 0 else -1
                                        if stock_val == 0:
                                            days_count += 1
                                        else:
                                            break
                                    else:
                                        break
                                consecutive_days[product_name] = days_count
                            
                            # æŒ‰è¿ç»­å¤©æ•°åˆ†çº§
                            persistent_count = sum(1 for d in consecutive_days.values() if d >= 3)  # â‰¥3å¤©
                            new_count = sum(1 for d in consecutive_days.values() if d == 1)  # ä»…æ˜¨æ—¥
                            result['stockout']['persistent_count'] = persistent_count  # æŒç»­ç¼ºè´§(â‰¥3å¤©)
                            result['stockout']['new_count'] = new_count  # æ–°å¢ç¼ºè´§(æ˜¨æ—¥)
                            result['stockout']['consecutive_days'] = consecutive_days
                        except Exception as e:
                            result['stockout']['persistent_count'] = 0
                            result['stockout']['new_count'] = result['stockout']['count']
                            result['stockout']['consecutive_days'] = {}
        
        # ================== 4. ä»·æ ¼å¼‚å¸¸é¢„è­¦ ==================
        # å®šä¹‰ï¼šå®æ”¶ä»·æ ¼ < å•å“é‡‡è´­æˆæœ¬ï¼ˆå•†å“é‡‡è´­æˆæœ¬/æœˆå”®ï¼‰ï¼Œå–ä¸€å•äºä¸€å•
        # æ³¨æ„ï¼šåŸå§‹æ•°æ®ä¸­çš„å•†å“é‡‡è´­æˆæœ¬ = å•å“æˆæœ¬ Ã— æœˆå”®
        sales_field = 'æœˆå”®' if 'æœˆå”®' in yesterday_df.columns else 'é”€é‡'
        cost_col = 'å•†å“é‡‡è´­æˆæœ¬' if 'å•†å“é‡‡è´­æˆæœ¬' in yesterday_df.columns else 'æˆæœ¬'
        
        if 'å®æ”¶ä»·æ ¼' in yesterday_df.columns and cost_col in yesterday_df.columns and sales_field in yesterday_df.columns:
            price_df = yesterday_df[['å•†å“åç§°', 'å®æ”¶ä»·æ ¼', cost_col, sales_field]].copy()
            price_df = price_df.dropna(subset=['å®æ”¶ä»·æ ¼', cost_col])
            
            # è®¡ç®—å•å“æˆæœ¬ = å•†å“é‡‡è´­æˆæœ¬ / æœˆå”®
            price_df[sales_field] = pd.to_numeric(price_df[sales_field], errors='coerce').fillna(1)
            price_df[sales_field] = price_df[sales_field].replace(0, 1)  # é¿å…é™¤é›¶
            price_df['_å•å“æˆæœ¬'] = price_df[cost_col] / price_df[sales_field]
            
            # ç­›é€‰å”®ä»·ä½äºå•å“æˆæœ¬çš„è®°å½•
            price_df['_äºæŸ'] = price_df['_å•å“æˆæœ¬'] - price_df['å®æ”¶ä»·æ ¼']
            abnormal_mask = price_df['å®æ”¶ä»·æ ¼'] < price_df['_å•å“æˆæœ¬']
            abnormal_df = price_df[abnormal_mask].copy()
            
            if len(abnormal_df) > 0:
                # è®¡ç®—æ€»äºæŸé‡‘é¢ï¼ˆå•ä½äºæŸ Ã— é”€é‡ï¼‰
                abnormal_df['_æ€»äºæŸ'] = abnormal_df['_äºæŸ'] * abnormal_df[sales_field]
                
                result['price_abnormal']['count'] = len(abnormal_df)
                result['price_abnormal']['loss'] = round(abnormal_df['_æ€»äºæŸ'].sum(), 2)
                
                # åˆ†çº§ï¼šä¸¥é‡äºæŸï¼ˆå”®ä»·<å•å“æˆæœ¬Ã—0.8ï¼‰vs è½»åº¦äºæŸ
                severe_mask = abnormal_df['å®æ”¶ä»·æ ¼'] < abnormal_df['_å•å“æˆæœ¬'] * 0.8
                result['price_abnormal']['severe_count'] = int(severe_mask.sum())
                result['price_abnormal']['mild_count'] = int((~severe_mask).sum())
                
                # TOPå•†å“åˆ—è¡¨
                top_products = abnormal_df.nlargest(5, '_æ€»äºæŸ')['å•†å“åç§°'].tolist()
                result['price_abnormal']['products'] = top_products
    
    except Exception as e:
        for key in result:
            result[key]['error'] = str(e)
    
    return result


def analyze_watch_issues(df: pd.DataFrame, order_agg: pd.DataFrame = None) -> Dict[str, Any]:
    """
    åˆ†æå…³æ³¨é—®é¢˜ï¼ˆæœ¬å‘¨å†…å¤„ç†ï¼‰
    
    åŒ…å«:
    - æµé‡å¼‚å¸¸ï¼šé”€é‡ç¯æ¯”ä¸‹è·Œ >50%ï¼ˆä½†æœªå½’é›¶ï¼‰
    - æ–°å¢æ»é”€é£é™©ï¼šå‰7å¤©æœ‰é”€é‡ + æœ€è¿‘3å¤©é›¶é”€é‡ï¼ˆé¦–æ¬¡è¿›å…¥è§‚å¯ŸæœŸï¼‰
    - æŒç»­æ»é”€ï¼šè¿ç»­7-14å¤©é›¶é”€é‡
    - ä¸¥é‡æ»é”€ï¼šè¿ç»­15å¤©+é›¶é”€é‡
    - æ–°å“è¡¨ç°ï¼šæ˜¨æ—¥é¦–æ¬¡äº§ç”Ÿé”€é‡
    - åˆ©æ¶¦ç‡ä¸‹æ»‘ï¼šè¿‘7å¤©vså‰7å¤©åˆ©æ¶¦ç‡ä¸‹æ»‘>10%
    
    Args:
        df: åŸå§‹è®¢å•æ•°æ®
        order_agg: é¢„è®¡ç®—çš„è®¢å•èšåˆæ•°æ®ï¼ˆV8.6æ€§èƒ½ä¼˜åŒ–ï¼Œå¯é€‰ï¼‰
    
    Returns:
        Dict with keys: traffic_drop, new_slow, ongoing_slow, severe_slow, new_products, profit_rate_drop
    """
    result = {
        'traffic_drop': {'count': 0, 'channels': {}, 'error': None},
        'new_slow': {'count': 0, 'cost': 0, 'products': [], 'error': None},
        'ongoing_slow': {'count': 0, 'cost': 0, 'error': None},
        'severe_slow': {'count': 0, 'cost': 0, 'error': None},
        'new_products': {'count': 0, 'sales': 0, 'error': None},
        'profit_rate_drop': {'count': 0, 'loss': 0, 'drop_5': 0, 'drop_10': 0, 'drop_15': 0, 'drop_20': 0, 'error': None}
    }
    
    if df is None or df.empty:
        return result
    
    # âš¡ V8.6æ€§èƒ½ä¼˜åŒ–ï¼šorder_aggå‚æ•°æš‚æ—¶æœªä½¿ç”¨ï¼Œä½†ä¿ç•™æ¥å£ä»¥ä¾¿åç»­ä¼˜åŒ–
    # å½“å‰å‡½æ•°ä¸»è¦åˆ†æå•†å“çº§æ•°æ®ï¼Œä¸éœ€è¦è®¢å•èšåˆ
    
    try:
        date_col = 'æ—¥æœŸ' if 'æ—¥æœŸ' in df.columns else 'ä¸‹å•æ—¶é—´'
        sales_col = 'æœˆå”®' if 'æœˆå”®' in df.columns else 'é”€é‡'
        
        df = df.copy()  # ä¿æŒåŸæœ‰é€»è¾‘ï¼Œé¿å…å¼•å…¥bug
        df[date_col] = pd.to_datetime(df[date_col])
        yesterday = df[date_col].max().normalize()
        
        # ================== 1. æµé‡å¼‚å¸¸åˆ†æï¼ˆ7æ—¥ vs 7æ—¥ï¼‰ ==================
        # æ–°é€»è¾‘ï¼šæœ€è¿‘7å¤©æ—¥å‡ vs å‰7å¤©æ—¥å‡ï¼Œè·Œå¹…>30%
        min_date = df[date_col].min().normalize()
        data_days = (yesterday - min_date).days + 1
        
        # éœ€è¦è‡³å°‘14å¤©æ•°æ®
        if data_days >= 14 and sales_col in df.columns:
            # å®šä¹‰æ—¶é—´çª—å£
            recent_7d_start = yesterday - timedelta(days=6)  # æœ€è¿‘7å¤©ï¼ˆå«æ˜¨æ—¥ï¼‰
            prev_7d_start = yesterday - timedelta(days=13)   # å‰7å¤©
            prev_7d_end = yesterday - timedelta(days=7)      # å‰7å¤©ç»“æŸ
            
            recent_7d_df = df[(df[date_col].dt.normalize() >= recent_7d_start) & (df[date_col].dt.normalize() <= yesterday)]
            prev_7d_df = df[(df[date_col].dt.normalize() >= prev_7d_start) & (df[date_col].dt.normalize() <= prev_7d_end)]
            
            if not prev_7d_df.empty:
                # å‰7å¤©æ—¥å‡é”€é‡
                prev_sales = prev_7d_df.groupby('å•†å“åç§°')[sales_col].sum().reset_index()
                prev_sales.columns = ['å•†å“åç§°', 'å‰7å¤©æ€»é”€é‡']
                prev_sales['å‰7å¤©æ—¥å‡'] = (prev_sales['å‰7å¤©æ€»é”€é‡'] / 7).round(1)
                
                # æœ€è¿‘7å¤©æ—¥å‡é”€é‡
                recent_sales = recent_7d_df.groupby('å•†å“åç§°')[sales_col].sum().reset_index()
                recent_sales.columns = ['å•†å“åç§°', 'è¿‘7å¤©æ€»é”€é‡']
                recent_sales['è¿‘7å¤©æ—¥å‡'] = (recent_sales['è¿‘7å¤©æ€»é”€é‡'] / 7).round(1)
                
                # åˆå¹¶
                comparison = prev_sales.merge(recent_sales, on='å•†å“åç§°', how='left')
                comparison['è¿‘7å¤©æ—¥å‡'] = comparison['è¿‘7å¤©æ—¥å‡'].fillna(0)
                
                # ç­›é€‰ï¼šå‰7å¤©æ—¥å‡>=2 ä¸” è·Œå¹…>30%
                comparison['è·Œå¹…'] = (comparison['å‰7å¤©æ—¥å‡'] - comparison['è¿‘7å¤©æ—¥å‡']) / comparison['å‰7å¤©æ—¥å‡']
                drop_mask = (comparison['å‰7å¤©æ—¥å‡'] >= 2) & (comparison['è·Œå¹…'] > 0.3)
                drop_products = comparison[drop_mask]
                
                # è¿‡æ»¤è€—æ
                category_col = next((c for c in ['ä¸€çº§åˆ†ç±»å', 'ä¸€çº§åˆ†ç±»'] if c in df.columns), None)
                if category_col and not drop_products.empty:
                    product_category = df.groupby('å•†å“åç§°')[category_col].first().reset_index()
                    product_category.columns = ['å•†å“åç§°', '_category']
                    drop_products = drop_products.merge(product_category, on='å•†å“åç§°', how='left')
                    drop_products = drop_products[drop_products['_category'] != 'è€—æ'].copy()
                    drop_products = drop_products.drop(columns=['_category'], errors='ignore')
                
                if len(drop_products) > 0:
                    result['traffic_drop']['count'] = len(drop_products)
                    
                    # æ¸ é“åˆ†å¸ƒï¼ˆæŒ‰å•†å“æ•°ç»Ÿè®¡ï¼Œå–æ¯ä¸ªå•†å“çš„ä¸»æ¸ é“ï¼‰
                    channel_col = next((c for c in ['æ¸ é“', 'å¹³å°', 'channel'] if c in prev_7d_df.columns), None)
                    if channel_col:
                        drop_names = drop_products['å•†å“åç§°'].tolist()
                        # è·å–æ¯ä¸ªå•†å“çš„ä¸»æ¸ é“ï¼ˆå‰7å¤©é”€é‡æœ€é«˜çš„æ¸ é“ï¼‰
                        drop_channel = prev_7d_df[prev_7d_df['å•†å“åç§°'].isin(drop_names)]
                        product_main_channel = drop_channel.groupby(['å•†å“åç§°', channel_col])[sales_col].sum().reset_index()
                        idx = product_main_channel.groupby('å•†å“åç§°')[sales_col].idxmax()
                        main_channels = product_main_channel.loc[idx][channel_col]
                        result['traffic_drop']['channels'] = main_channels.value_counts().to_dict()
        
        # ================== 2. æ»é”€åˆ†æï¼ˆç²¾ç¡®åŒ¹é… - çŠ¶æ€å˜åŒ–ç‚¹ï¼‰ ==================
        # åªåœ¨å•†å“"åˆšè¿›å…¥"æŸä¸ªæ»é”€çŠ¶æ€æ—¶æé†’ï¼Œé¿å…æ¯å¤©é‡å¤
        # ğŸ†• æ–°å¢é£é™©ï¼šåˆšæ»¡3å¤©æ— é”€é‡ï¼ˆä»Šå¤©åˆšè¿›å…¥é£é™©æœŸï¼‰
        # âš ï¸ æŒç»­æ»é”€ï¼šåˆšæ»¡7å¤©æ— é”€é‡ï¼ˆä»Šå¤©å‡çº§ä¸ºæŒç»­æ»é”€ï¼‰
        # ğŸ”´ ä¸¥é‡æ»é”€ï¼šåˆšæ»¡15å¤©æ— é”€é‡ï¼ˆä»Šå¤©å‡çº§ä¸ºä¸¥é‡æ»é”€ï¼‰
        # æ³¨ï¼šåº“å­˜=0çš„ä¸ç®—æ»é”€ï¼ˆå¯èƒ½æ˜¯ç¼ºè´§/ä¸‹æ¶ï¼‰
        
        if sales_col in df.columns:
            stock_col = next((c for c in ['å‰©ä½™åº“å­˜', 'åº“å­˜'] if c in df.columns), None)
            cost_col = next((c for c in ['å•†å“é‡‡è´­æˆæœ¬', 'æˆæœ¬'] if c in df.columns), None)
            
            # è®¡ç®—æ¯ä¸ªå•†å“çš„æœ€åé”€å”®æ—¥æœŸå’Œæœ€æ–°åº“å­˜
            product_last_sale = df.groupby('å•†å“åç§°')[date_col].max().reset_index()
            product_last_sale.columns = ['å•†å“åç§°', 'æœ€åé”€å”®æ—¥']
            product_last_sale['æ— é”€é‡å¤©æ•°'] = (yesterday - product_last_sale['æœ€åé”€å”®æ—¥'].dt.normalize()).dt.days
            
            # ğŸ”§ è·å–æ¯ä¸ªå•†å“çš„æœ€æ–°åº“å­˜ - é‡‡ç”¨åŒé‡åˆ¤æ–­é€»è¾‘ï¼ˆä¸ä¸»çœ‹æ¿ä¸€è‡´ï¼‰
            if stock_col:
                last_date = df[date_col].max()
                
                # æ­¥éª¤1: è·å–æœ€åä¸€å¤©æœ‰é”€å”®çš„å•†å“åº“å­˜
                last_day_data = df[df[date_col] == last_date]
                if len(last_day_data) > 0:
                    last_day_stock_map = last_day_data.groupby('å•†å“åç§°')[stock_col].last().to_dict()
                else:
                    last_day_stock_map = {}
                
                # æ­¥éª¤2: è·å–æ¯ä¸ªå•†å“æœ€åä¸€æ¬¡å”®å–è®°å½•çš„åº“å­˜ï¼ˆå›é€€æ–¹æ¡ˆï¼‰
                last_sale_stock_map = df.sort_values(date_col).groupby('å•†å“åç§°')[stock_col].last().to_dict()
                
                # æ­¥éª¤3: åŒé‡åˆ¤æ–­ - ä¼˜å…ˆä½¿ç”¨æœ€åä¸€å¤©çš„åº“å­˜ï¼Œå¦åˆ™ä½¿ç”¨æœ€åå”®å–æ—¶çš„åº“å­˜
                def get_final_stock(product_name):
                    if product_name in last_day_stock_map:
                        return last_day_stock_map[product_name]
                    elif product_name in last_sale_stock_map:
                        return last_sale_stock_map[product_name]
                    else:
                        return 0
                
                product_last_sale['åº“å­˜'] = product_last_sale['å•†å“åç§°'].apply(get_final_stock)
                
                # æ ¸å¿ƒæ¡ä»¶ï¼šåº“å­˜>0 æ‰ç®—æ»é”€
                has_stock_mask = product_last_sale['åº“å­˜'] > 0
            else:
                # æ²¡æœ‰åº“å­˜å­—æ®µæ—¶ï¼Œæ— æ³•åˆ¤æ–­æ»é”€
                has_stock_mask = pd.Series([True] * len(product_last_sale))
            
            # === æ–°å¢æ»é”€é£é™© ===
            # æ¡ä»¶ï¼šåº“å­˜>0 ä¸” åˆšæ»¡3å¤©æ— é”€é‡
            new_slow_mask = has_stock_mask & (product_last_sale['æ— é”€é‡å¤©æ•°'] == 3)
            new_slow_products = product_last_sale[new_slow_mask]
            
            if len(new_slow_products) > 0:
                result['new_slow']['count'] = len(new_slow_products)
                result['new_slow']['products'] = new_slow_products['å•†å“åç§°'].tolist()[:10]
                
                if cost_col and stock_col:
                    # âš ï¸ ä¿®å¤ï¼šä½¿ç”¨åº—å†…ç è·å–å•å“æˆæœ¬ï¼Œé¿å…åŒåä¸åŒè§„æ ¼æ··æ·†
                    # å•†å“é‡‡è´­æˆæœ¬æ˜¯æ€»æˆæœ¬(=å•å“æˆæœ¬Ã—é”€é‡)ï¼Œéœ€è¦é™¤ä»¥é”€é‡å¾—åˆ°å•å“æˆæœ¬
                    slow_names = new_slow_products['å•†å“åç§°'].tolist()
                    slow_df = df[df['å•†å“åç§°'].isin(slow_names)].copy()
                    
                    # æŒ‰åº—å†…ç èšåˆè®¡ç®—å•å“æˆæœ¬ï¼ˆå¦‚æœæœ‰åº—å†…ç ï¼‰
                    group_key = 'åº—å†…ç ' if 'åº—å†…ç ' in slow_df.columns else 'å•†å“åç§°'
                    sales_col_local = 'æœˆå”®' if 'æœˆå”®' in slow_df.columns else ('é”€é‡' if 'é”€é‡' in slow_df.columns else None)
                    
                    if sales_col_local:
                        slow_df['_é”€é‡'] = pd.to_numeric(slow_df[sales_col_local], errors='coerce').fillna(1).replace(0, 1)
                        slow_df['_æ€»æˆæœ¬'] = pd.to_numeric(slow_df[cost_col], errors='coerce').fillna(0)
                        cost_agg = slow_df.groupby(group_key).agg({
                            '_æ€»æˆæœ¬': 'sum',
                            '_é”€é‡': 'sum',
                            'å•†å“åç§°': 'first'
                        }).reset_index()
                        cost_agg['å•å“æˆæœ¬'] = cost_agg['_æ€»æˆæœ¬'] / cost_agg['_é”€é‡']
                        cost_info = cost_agg.set_index('å•†å“åç§°')['å•å“æˆæœ¬'].to_dict()
                    else:
                        cost_info = slow_df.sort_values(date_col).groupby('å•†å“åç§°')[cost_col].last().to_dict()
                    
                    # ä½¿ç”¨å·²æœ‰çš„åº“å­˜æ•°æ®å’Œè·å–çš„æˆæœ¬è®¡ç®—æ€»å€¼
                    total_cost = 0
                    for _, row in new_slow_products.iterrows():
                        product_stock = row['åº“å­˜']
                        product_cost = cost_info.get(row['å•†å“åç§°'], 0)
                        total_cost += product_stock * product_cost
                    result['new_slow']['cost'] = round(total_cost, 2)
            
            # === æŒç»­æ»é”€ ===
            # æ¡ä»¶ï¼šåº“å­˜>0 ä¸” åˆšæ»¡7å¤©æ— é”€é‡
            ongoing_slow_mask = has_stock_mask & (product_last_sale['æ— é”€é‡å¤©æ•°'] == 7)
            ongoing_slow_products = product_last_sale[ongoing_slow_mask]
            
            if len(ongoing_slow_products) > 0:
                result['ongoing_slow']['count'] = len(ongoing_slow_products)
                
                if cost_col and stock_col:
                    # âš ï¸ ä¿®å¤ï¼šä½¿ç”¨åº—å†…ç è·å–å•å“æˆæœ¬
                    slow_names = ongoing_slow_products['å•†å“åç§°'].tolist()
                    slow_df = df[df['å•†å“åç§°'].isin(slow_names)].copy()
                    
                    group_key = 'åº—å†…ç ' if 'åº—å†…ç ' in slow_df.columns else 'å•†å“åç§°'
                    sales_col_local = 'æœˆå”®' if 'æœˆå”®' in slow_df.columns else ('é”€é‡' if 'é”€é‡' in slow_df.columns else None)
                    
                    if sales_col_local:
                        slow_df['_é”€é‡'] = pd.to_numeric(slow_df[sales_col_local], errors='coerce').fillna(1).replace(0, 1)
                        slow_df['_æ€»æˆæœ¬'] = pd.to_numeric(slow_df[cost_col], errors='coerce').fillna(0)
                        cost_agg = slow_df.groupby(group_key).agg({
                            '_æ€»æˆæœ¬': 'sum',
                            '_é”€é‡': 'sum',
                            'å•†å“åç§°': 'first'
                        }).reset_index()
                        cost_agg['å•å“æˆæœ¬'] = cost_agg['_æ€»æˆæœ¬'] / cost_agg['_é”€é‡']
                        cost_info = cost_agg.set_index('å•†å“åç§°')['å•å“æˆæœ¬'].to_dict()
                    else:
                        cost_info = slow_df.sort_values(date_col).groupby('å•†å“åç§°')[cost_col].last().to_dict()
                    
                    total_cost = 0
                    for _, row in ongoing_slow_products.iterrows():
                        product_stock = row['åº“å­˜']
                        product_cost = cost_info.get(row['å•†å“åç§°'], 0)
                        total_cost += product_stock * product_cost
                    result['ongoing_slow']['cost'] = round(total_cost, 2)
            
            # === ä¸¥é‡æ»é”€ ===
            # æ¡ä»¶ï¼šåº“å­˜>0 ä¸” åˆšæ»¡15å¤©æ— é”€é‡
            severe_slow_mask = has_stock_mask & (product_last_sale['æ— é”€é‡å¤©æ•°'] == 15)
            severe_slow_products = product_last_sale[severe_slow_mask]
            
            if len(severe_slow_products) > 0:
                result['severe_slow']['count'] = len(severe_slow_products)
                
                if cost_col and stock_col:
                    # âš ï¸ ä¿®å¤ï¼šä½¿ç”¨åº—å†…ç è·å–å•å“æˆæœ¬
                    slow_names = severe_slow_products['å•†å“åç§°'].tolist()
                    slow_df = df[df['å•†å“åç§°'].isin(slow_names)].copy()
                    
                    group_key = 'åº—å†…ç ' if 'åº—å†…ç ' in slow_df.columns else 'å•†å“åç§°'
                    sales_col_local = 'æœˆå”®' if 'æœˆå”®' in slow_df.columns else ('é”€é‡' if 'é”€é‡' in slow_df.columns else None)
                    
                    if sales_col_local:
                        slow_df['_é”€é‡'] = pd.to_numeric(slow_df[sales_col_local], errors='coerce').fillna(1).replace(0, 1)
                        slow_df['_æ€»æˆæœ¬'] = pd.to_numeric(slow_df[cost_col], errors='coerce').fillna(0)
                        cost_agg = slow_df.groupby(group_key).agg({
                            '_æ€»æˆæœ¬': 'sum',
                            '_é”€é‡': 'sum',
                            'å•†å“åç§°': 'first'
                        }).reset_index()
                        cost_agg['å•å“æˆæœ¬'] = cost_agg['_æ€»æˆæœ¬'] / cost_agg['_é”€é‡']
                        cost_info = cost_agg.set_index('å•†å“åç§°')['å•å“æˆæœ¬'].to_dict()
                    else:
                        cost_info = slow_df.sort_values(date_col).groupby('å•†å“åç§°')[cost_col].last().to_dict()
                    
                    total_cost = 0
                    for _, row in severe_slow_products.iterrows():
                        product_stock = row['åº“å­˜']
                        product_cost = cost_info.get(row['å•†å“åç§°'], 0)
                        total_cost += product_stock * product_cost
                    result['severe_slow']['cost'] = round(total_cost, 2)
        
        # ================== 3. æ–°å“è¡¨ç° ==================
        # å®šä¹‰ï¼šè¿‡å»7å¤©æ— é”€é‡ + æ˜¨æ—¥æœ‰é”€é‡ï¼ˆé¦–æ¬¡åŠ¨é”€ï¼‰
        start_check_date = yesterday - timedelta(days=7)
        
        # è·å–æ˜¨æ—¥æ•°æ®
        yesterday_df = df[df[date_col].dt.normalize() == yesterday]
        
        # æ˜¨æ—¥æœ‰é”€é‡çš„å•†å“
        yesterday_products = set(yesterday_df['å•†å“åç§°'].unique())
        
        # è¿‡å»7å¤©ï¼ˆä¸å«æ˜¨æ—¥ï¼‰æœ‰é”€é‡çš„å•†å“
        past_df = df[(df[date_col].dt.normalize() >= start_check_date) & (df[date_col].dt.normalize() < yesterday)]
        past_products = set(past_df['å•†å“åç§°'].unique()) if not past_df.empty else set()
        
        # æ–°å“ = æ˜¨æ—¥æœ‰é”€é‡ ä½† è¿‡å»7å¤©æ²¡é”€é‡
        new_products = yesterday_products - past_products
        
        if len(new_products) > 0:
            result['new_products']['count'] = len(new_products)
            
            # è·å–é¦–é”€å•†å“æ•°æ®
            new_df = yesterday_df[yesterday_df['å•†å“åç§°'].isin(new_products)].copy()
            
            # è®¡ç®—é”€å”®é¢ = å®æ”¶ä»·æ ¼ Ã— é”€é‡
            sales_field = 'æœˆå”®' if 'æœˆå”®' in new_df.columns else 'é”€é‡'
            if 'å®æ”¶ä»·æ ¼' in new_df.columns and sales_field in new_df.columns:
                new_df['_é”€å”®é¢'] = new_df['å®æ”¶ä»·æ ¼'].fillna(0) * new_df[sales_field].fillna(1)
                result['new_products']['sales'] = round(new_df['_é”€å”®é¢'].sum(), 2)
            elif 'å•†å“å®å”®ä»·' in new_df.columns:
                result['new_products']['sales'] = round(new_df['å•†å“å®å”®ä»·'].sum(), 2)
            
            # è®¡ç®—åˆ©æ¶¦é¢
            if 'åˆ©æ¶¦é¢' in new_df.columns:
                result['new_products']['profit'] = round(new_df['åˆ©æ¶¦é¢'].sum(), 2)
            
            # æŒ‰ä¸€çº§åˆ†ç±»æ±‡æ€»ï¼Œè®¡ç®—åˆ©æ¶¦TOPåˆ†ç±»
            if 'ä¸€çº§åˆ†ç±»å' in new_df.columns and 'åˆ©æ¶¦é¢' in new_df.columns:
                # è®¡ç®—åˆ†ç±»é”€å”®é¢å’Œåˆ©æ¶¦é¢
                if '_é”€å”®é¢' in new_df.columns:
                    category_stats = new_df.groupby('ä¸€çº§åˆ†ç±»å').agg({
                        '_é”€å”®é¢': 'sum',
                        'åˆ©æ¶¦é¢': 'sum'
                    }).reset_index()
                    category_stats.columns = ['åˆ†ç±»', 'é”€å”®é¢', 'åˆ©æ¶¦é¢']
                else:
                    category_stats = new_df.groupby('ä¸€çº§åˆ†ç±»å').agg({
                        'åˆ©æ¶¦é¢': 'sum'
                    }).reset_index()
                    category_stats.columns = ['åˆ†ç±»', 'åˆ©æ¶¦é¢']
                    category_stats['é”€å”®é¢'] = 0
                
                # è®¡ç®—åˆ©æ¶¦ç‡
                category_stats['åˆ©æ¶¦ç‡'] = category_stats.apply(
                    lambda x: round(x['åˆ©æ¶¦é¢'] / x['é”€å”®é¢'] * 100, 1) if x['é”€å”®é¢'] > 0 else 0, axis=1
                )
                
                # åˆ©æ¶¦é¢TOPåˆ†ç±»
                if len(category_stats) > 0:
                    top_profit = category_stats.nlargest(1, 'åˆ©æ¶¦é¢').iloc[0]
                    result['new_products']['top_profit_category'] = top_profit['åˆ†ç±»']
                    result['new_products']['top_profit_amount'] = round(top_profit['åˆ©æ¶¦é¢'], 2)
                    
                    # åˆ©æ¶¦ç‡TOPåˆ†ç±»ï¼ˆæ’é™¤é”€å”®é¢è¿‡ä½çš„ï¼‰
                    valid_categories = category_stats[category_stats['é”€å”®é¢'] >= 10]  # é”€å”®é¢>=10æ‰å‚ä¸åˆ©æ¶¦ç‡æ’å
                    if len(valid_categories) > 0:
                        top_rate = valid_categories.nlargest(1, 'åˆ©æ¶¦ç‡').iloc[0]
                        result['new_products']['top_rate_category'] = top_rate['åˆ†ç±»']
                        result['new_products']['top_rate_value'] = round(top_rate['åˆ©æ¶¦ç‡'], 1)
        
        # ================== 4. åˆ©æ¶¦ç‡ä¸‹æ»‘ ==================
        # å®šä¹‰ï¼šè¿‘7å¤©åˆ©æ¶¦ç‡ vs å‰7å¤©åˆ©æ¶¦ç‡ï¼Œä¸‹æ»‘>10ä¸ªç™¾åˆ†ç‚¹
        sales_field = 'æœˆå”®' if 'æœˆå”®' in df.columns else 'é”€é‡'
        
        if 'åˆ©æ¶¦é¢' in df.columns and 'å®æ”¶ä»·æ ¼' in df.columns and sales_field in df.columns:
            # è®¡ç®—æ—¶é—´èŒƒå›´
            recent_start = yesterday - timedelta(days=6)  # è¿‘7å¤©
            prev_start = yesterday - timedelta(days=13)   # å‰7å¤©
            prev_end = yesterday - timedelta(days=7)
            
            recent_df = df[(df[date_col].dt.normalize() >= recent_start) & (df[date_col].dt.normalize() <= yesterday)].copy()
            prev_df = df[(df[date_col].dt.normalize() >= prev_start) & (df[date_col].dt.normalize() <= prev_end)].copy()
            
            if not recent_df.empty and not prev_df.empty:
                # è®¡ç®—é”€å”®é¢ = å®æ”¶ä»·æ ¼ Ã— é”€é‡
                recent_df['_é”€å”®é¢'] = recent_df['å®æ”¶ä»·æ ¼'].fillna(0) * recent_df[sales_field].fillna(1)
                prev_df['_é”€å”®é¢'] = prev_df['å®æ”¶ä»·æ ¼'].fillna(0) * prev_df[sales_field].fillna(1)
                
                # æŒ‰å•†å“æ±‡æ€»
                recent_stats = recent_df.groupby('å•†å“åç§°').agg({
                    '_é”€å”®é¢': 'sum',
                    'åˆ©æ¶¦é¢': 'sum',
                    sales_field: 'sum'
                }).reset_index()
                recent_stats.columns = ['å•†å“åç§°', 'è¿‘7å¤©é”€å”®é¢', 'è¿‘7å¤©åˆ©æ¶¦', 'è¿‘7å¤©é”€é‡']
                
                prev_stats = prev_df.groupby('å•†å“åç§°').agg({
                    '_é”€å”®é¢': 'sum',
                    'åˆ©æ¶¦é¢': 'sum',
                    sales_field: 'sum'
                }).reset_index()
                prev_stats.columns = ['å•†å“åç§°', 'å‰7å¤©é”€å”®é¢', 'å‰7å¤©åˆ©æ¶¦', 'å‰7å¤©é”€é‡']
                
                # åˆå¹¶å¯¹æ¯”
                comparison = recent_stats.merge(prev_stats, on='å•†å“åç§°', how='inner')
                
                # è®¡ç®—åˆ©æ¶¦ç‡
                comparison['è¿‘7å¤©åˆ©æ¶¦ç‡'] = comparison.apply(
                    lambda x: round(x['è¿‘7å¤©åˆ©æ¶¦'] / x['è¿‘7å¤©é”€å”®é¢'] * 100, 1) if x['è¿‘7å¤©é”€å”®é¢'] > 0 else 0, axis=1
                )
                comparison['å‰7å¤©åˆ©æ¶¦ç‡'] = comparison.apply(
                    lambda x: round(x['å‰7å¤©åˆ©æ¶¦'] / x['å‰7å¤©é”€å”®é¢'] * 100, 1) if x['å‰7å¤©é”€å”®é¢'] > 0 else 0, axis=1
                )
                comparison['åˆ©æ¶¦ç‡å˜åŒ–'] = comparison['è¿‘7å¤©åˆ©æ¶¦ç‡'] - comparison['å‰7å¤©åˆ©æ¶¦ç‡']
                
                # ç­›é€‰ï¼šåˆ©æ¶¦ç‡ä¸‹æ»‘>5%ï¼Œä¸”è¿‘7å¤©é”€é‡>=5
                drop_mask = (comparison['åˆ©æ¶¦ç‡å˜åŒ–'] < -5) & (comparison['è¿‘7å¤©é”€é‡'] >= 5) & (comparison['å‰7å¤©åˆ©æ¶¦ç‡'] > 0)
                drop_products = comparison[drop_mask]
                
                if len(drop_products) > 0:
                    result['profit_rate_drop']['count'] = len(drop_products)
                    
                    # ä¼°ç®—åˆ©æ¶¦æŸå¤±ï¼ˆå‰7å¤©åˆ©æ¶¦ç‡ Ã— è¿‘7å¤©é”€å”®é¢ - è¿‘7å¤©åˆ©æ¶¦ï¼‰
                    drop_products = drop_products.copy()
                    drop_products['_é¢„æœŸåˆ©æ¶¦'] = drop_products['å‰7å¤©åˆ©æ¶¦ç‡'] / 100 * drop_products['è¿‘7å¤©é”€å”®é¢']
                    drop_products['_åˆ©æ¶¦æŸå¤±'] = drop_products['_é¢„æœŸåˆ©æ¶¦'] - drop_products['è¿‘7å¤©åˆ©æ¶¦']
                    result['profit_rate_drop']['loss'] = round(drop_products['_åˆ©æ¶¦æŸå¤±'].sum(), 2)
                    
                    # æ–°åˆ†çº§ï¼š5%ã€10%ã€15%ã€20%å››æ¡£
                    # ä¸‹æ»‘5-10%
                    drop_5_mask = (drop_products['åˆ©æ¶¦ç‡å˜åŒ–'] >= -10) & (drop_products['åˆ©æ¶¦ç‡å˜åŒ–'] < -5)
                    # ä¸‹æ»‘10-15%
                    drop_10_mask = (drop_products['åˆ©æ¶¦ç‡å˜åŒ–'] >= -15) & (drop_products['åˆ©æ¶¦ç‡å˜åŒ–'] < -10)
                    # ä¸‹æ»‘15-20%
                    drop_15_mask = (drop_products['åˆ©æ¶¦ç‡å˜åŒ–'] >= -20) & (drop_products['åˆ©æ¶¦ç‡å˜åŒ–'] < -15)
                    # ä¸‹æ»‘>20%
                    drop_20_mask = drop_products['åˆ©æ¶¦ç‡å˜åŒ–'] < -20
                    
                    result['profit_rate_drop']['drop_5'] = int(drop_5_mask.sum())
                    result['profit_rate_drop']['drop_10'] = int(drop_10_mask.sum())
                    result['profit_rate_drop']['drop_15'] = int(drop_15_mask.sum())
                    result['profit_rate_drop']['drop_20'] = int(drop_20_mask.sum())
    
    except Exception as e:
        for key in result:
            result[key]['error'] = str(e)
    
    return result


def analyze_highlights(df: pd.DataFrame, order_agg: pd.DataFrame = None) -> Dict[str, Any]:
    """
    åˆ†ææ­£å‘æ¿€åŠ±ï¼ˆä»Šæ—¥äº®ç‚¹ï¼‰
    
    åŒ…å«:
    - çˆ†æ¬¾å•†å“ï¼šæ˜¨æ—¥é”€é‡çªå¢çš„å•†å“ï¼ˆç¯æ¯”å¢é•¿>50%ä¸”é”€é‡>=10ï¼‰
    - é«˜åˆ©æ¶¦å•†å“ï¼šæ˜¨æ—¥åˆ©æ¶¦è´¡çŒ®TOPå•†å“
    
    Args:
        df: åŸå§‹è®¢å•æ•°æ®
        order_agg: é¢„è®¡ç®—çš„è®¢å•èšåˆæ•°æ®ï¼ˆV8.6æ€§èƒ½ä¼˜åŒ–ï¼Œå¯é€‰ï¼‰
    
    Returns:
        Dict with keys: hot_products, high_profit_products
    """
    result = {
        'hot_products': {'count': 0, 'total_sales': 0, 'total_qty': 0, 'top_products': [], 'error': None},
        'high_profit_products': {'count': 0, 'total_profit': 0, 'top_products': [], 'error': None}
    }
    
    if df is None or df.empty:
        return result
    
    # âš¡ V8.6æ€§èƒ½ä¼˜åŒ–ï¼šorder_aggå‚æ•°æš‚æ—¶æœªä½¿ç”¨ï¼Œä½†ä¿ç•™æ¥å£ä»¥ä¾¿åç»­ä¼˜åŒ–
    # å½“å‰å‡½æ•°ä¸»è¦åˆ†æå•†å“çº§æ•°æ®ï¼Œä¸éœ€è¦è®¢å•èšåˆ
    
    try:
        date_col = 'æ—¥æœŸ' if 'æ—¥æœŸ' in df.columns else 'ä¸‹å•æ—¶é—´'
        sales_col = 'æœˆå”®' if 'æœˆå”®' in df.columns else 'é”€é‡'
        
        df = df.copy()
        df[date_col] = pd.to_datetime(df[date_col])
        yesterday = df[date_col].max().normalize()
        day_before = yesterday - pd.Timedelta(days=1)
        
        # è·å–æ˜¨æ—¥å’Œå‰æ—¥æ•°æ®
        yesterday_df = df[df[date_col].dt.normalize() == yesterday]
        day_before_df = df[df[date_col].dt.normalize() == day_before]
        
        if yesterday_df.empty:
            return result
        
        # ================== 1. çˆ†æ¬¾å•†å“åˆ†æ ==================
        # å®šä¹‰ï¼šæ˜¨æ—¥é”€é‡ç¯æ¯”å¢é•¿>50% ä¸” æ˜¨æ—¥é”€é‡>=10
        if sales_col in yesterday_df.columns and not day_before_df.empty:
            # æ˜¨æ—¥é”€é‡æ±‡æ€»
            yesterday_sales = yesterday_df.groupby('å•†å“åç§°').agg({
                sales_col: 'sum',
                'åˆ©æ¶¦é¢': 'sum' if 'åˆ©æ¶¦é¢' in yesterday_df.columns else 'count'
            }).reset_index()
            yesterday_sales.columns = ['å•†å“åç§°', 'æ˜¨æ—¥é”€é‡', 'æ˜¨æ—¥åˆ©æ¶¦']
            
            # å‰æ—¥é”€é‡æ±‡æ€»
            day_before_sales = day_before_df.groupby('å•†å“åç§°')[sales_col].sum().reset_index()
            day_before_sales.columns = ['å•†å“åç§°', 'å‰æ—¥é”€é‡']
            
            # åˆå¹¶å¯¹æ¯”
            comparison = yesterday_sales.merge(day_before_sales, on='å•†å“åç§°', how='left')
            comparison['å‰æ—¥é”€é‡'] = comparison['å‰æ—¥é”€é‡'].fillna(0)
            
            # è®¡ç®—å¢é•¿ç‡
            comparison['å¢é•¿ç‡'] = comparison.apply(
                lambda x: ((x['æ˜¨æ—¥é”€é‡'] - x['å‰æ—¥é”€é‡']) / x['å‰æ—¥é”€é‡'] * 100) if x['å‰æ—¥é”€é‡'] > 0 else (100 if x['æ˜¨æ—¥é”€é‡'] > 0 else 0),
                axis=1
            )
            
            # ç­›é€‰çˆ†æ¬¾ï¼šå¢é•¿ç‡>50% ä¸” æ˜¨æ—¥é”€é‡>=10
            hot_mask = (comparison['å¢é•¿ç‡'] > 50) & (comparison['æ˜¨æ—¥é”€é‡'] >= 10)
            hot_products = comparison[hot_mask].copy()
            
            # è¿‡æ»¤è€—æ
            category_col = next((c for c in ['ä¸€çº§åˆ†ç±»å', 'ä¸€çº§åˆ†ç±»'] if c in df.columns), None)
            if category_col and not hot_products.empty:
                product_category = df.groupby('å•†å“åç§°')[category_col].first().reset_index()
                product_category.columns = ['å•†å“åç§°', '_category']
                hot_products = hot_products.merge(product_category, on='å•†å“åç§°', how='left')
                hot_products = hot_products[hot_products['_category'] != 'è€—æ'].copy()
            
            if len(hot_products) > 0:
                # æŒ‰å¢é•¿ç‡æ’åº
                hot_products = hot_products.sort_values('å¢é•¿ç‡', ascending=False)
                
                result['hot_products']['count'] = len(hot_products)
                result['hot_products']['total_qty'] = int(hot_products['æ˜¨æ—¥é”€é‡'].sum())
                result['hot_products']['total_sales'] = round(hot_products['æ˜¨æ—¥åˆ©æ¶¦'].sum(), 2) if 'æ˜¨æ—¥åˆ©æ¶¦' in hot_products.columns else 0
                
                # ===== è®¡ç®—è¿ç»­å¢é•¿å¤©æ•° =====
                # å¯¹TOP5å•†å“è®¡ç®—è¿ç»­å¢é•¿äº†å¤šå°‘å¤©
                top5_names = hot_products.head(5)['å•†å“åç§°'].tolist()
                consecutive_growth = {}
                for product_name in top5_names:
                    days_count = 1  # æ˜¨æ—¥å·²å¢é•¿
                    for day_offset in range(1, 8):  # æœ€å¤šå¾€å‰æŸ¥7å¤©
                        check_date_curr = yesterday - timedelta(days=day_offset)
                        check_date_prev = yesterday - timedelta(days=day_offset + 1)
                        
                        curr_df = df[(df[date_col].dt.normalize() == check_date_curr) & (df['å•†å“åç§°'] == product_name)]
                        prev_df_check = df[(df[date_col].dt.normalize() == check_date_prev) & (df['å•†å“åç§°'] == product_name)]
                        
                        if not curr_df.empty and not prev_df_check.empty:
                            curr_qty = curr_df[sales_col].sum()
                            prev_qty = prev_df_check[sales_col].sum()
                            if prev_qty > 0 and curr_qty > prev_qty:
                                days_count += 1
                            else:
                                break
                        else:
                            break
                    consecutive_growth[product_name] = days_count
                
                result['hot_products']['consecutive_growth'] = consecutive_growth
                
                # TOP5å•†å“ï¼ˆå¸¦è¿ç»­å¢é•¿å¤©æ•°ï¼‰
                top5 = hot_products.head(5)
                result['hot_products']['top_products'] = [
                    {
                        'name': row['å•†å“åç§°'],
                        'qty': int(row['æ˜¨æ—¥é”€é‡']),
                        'growth': round(row['å¢é•¿ç‡'], 1),
                        'consecutive_days': consecutive_growth.get(row['å•†å“åç§°'], 1)
                    }
                    for _, row in top5.iterrows()
                ]
                
                # ç»Ÿè®¡è¿ç»­å¢é•¿â‰¥3å¤©çš„å•†å“æ•°
                sustained_hot_count = sum(1 for d in consecutive_growth.values() if d >= 3)
                result['hot_products']['sustained_count'] = sustained_hot_count
        
        # ================== 2. é«˜åˆ©æ¶¦å•†å“åˆ†æ ==================
        # å®šä¹‰ï¼šæ˜¨æ—¥åˆ©æ¶¦é¢TOPå•†å“ï¼ˆåˆ©æ¶¦é¢>0ï¼‰
        if 'åˆ©æ¶¦é¢' in yesterday_df.columns and sales_col in yesterday_df.columns:
            # è®¡ç®—é”€å”®é¢
            if 'å®æ”¶ä»·æ ¼' in yesterday_df.columns:
                yesterday_df = yesterday_df.copy()
                yesterday_df['_é”€å”®é¢'] = yesterday_df['å®æ”¶ä»·æ ¼'].fillna(0) * yesterday_df[sales_col].fillna(1)
            else:
                yesterday_df['_é”€å”®é¢'] = 0
            
            # æŒ‰å•†å“æ±‡æ€»
            profit_stats = yesterday_df.groupby('å•†å“åç§°').agg({
                'åˆ©æ¶¦é¢': 'sum',
                '_é”€å”®é¢': 'sum',
                sales_col: 'sum'
            }).reset_index()
            profit_stats.columns = ['å•†å“åç§°', 'åˆ©æ¶¦é¢', 'é”€å”®é¢', 'é”€é‡']
            
            # è®¡ç®—åˆ©æ¶¦ç‡
            profit_stats['åˆ©æ¶¦ç‡'] = profit_stats.apply(
                lambda x: round(x['åˆ©æ¶¦é¢'] / x['é”€å”®é¢'] * 100, 1) if x['é”€å”®é¢'] > 0 else 0,
                axis=1
            )
            
            # ç­›é€‰ï¼šåˆ©æ¶¦é¢>0 ä¸” é”€é‡>=3
            high_profit_mask = (profit_stats['åˆ©æ¶¦é¢'] > 0) & (profit_stats['é”€é‡'] >= 3)
            high_profit = profit_stats[high_profit_mask].copy()
            
            # è¿‡æ»¤è€—æ
            if category_col and not high_profit.empty:
                product_category = df.groupby('å•†å“åç§°')[category_col].first().reset_index()
                product_category.columns = ['å•†å“åç§°', '_category']
                high_profit = high_profit.merge(product_category, on='å•†å“åç§°', how='left')
                high_profit = high_profit[high_profit['_category'] != 'è€—æ'].copy()
            
            if len(high_profit) > 0:
                # æŒ‰åˆ©æ¶¦é¢æ’åºå–TOP
                high_profit = high_profit.sort_values('åˆ©æ¶¦é¢', ascending=False)
                
                # åªç»Ÿè®¡TOP10çš„å•†å“
                top10 = high_profit.head(10)
                
                result['high_profit_products']['count'] = len(top10)
                result['high_profit_products']['total_profit'] = round(top10['åˆ©æ¶¦é¢'].sum(), 2)
                
                # TOP5å•†å“
                top5 = high_profit.head(5)
                result['high_profit_products']['top_products'] = [
                    {
                        'name': row['å•†å“åç§°'],
                        'profit': round(row['åˆ©æ¶¦é¢'], 2),
                        'rate': row['åˆ©æ¶¦ç‡'],
                        'qty': int(row['é”€é‡'])
                    }
                    for _, row in top5.iterrows()
                ]
    
    except Exception as e:
        for key in result:
            result[key]['error'] = str(e)
        import traceback
        traceback.print_exc()
    
    return result


def get_diagnosis_summary(df: pd.DataFrame) -> Dict[str, Any]:
    """
    è·å–å®Œæ•´çš„ç»è¥è¯Šæ–­æ‘˜è¦ï¼ˆV8.6æ€§èƒ½ä¼˜åŒ–ï¼‰
    
    æ€§èƒ½ä¼˜åŒ–ï¼š
        - è®¢å•èšåˆå‰ç½®ï¼Œåªè®¡ç®—ä¸€æ¬¡
        - ä¼˜åŒ–å‰ï¼šé‡å¤èšåˆ3æ¬¡ï¼Œè€—æ—¶60-90ç§’
        - ä¼˜åŒ–åï¼šç»Ÿä¸€èšåˆ1æ¬¡ï¼Œè€—æ—¶20-30ç§’
        - æå‡ï¼š3å€æ€§èƒ½æå‡
    
    Returns:
        {
            'date': '2025-11-26',
            'urgent': {...},  # ç´§æ€¥é—®é¢˜
            'watch': {...},   # å…³æ³¨é—®é¢˜
            'highlights': {...},  # æ­£å‘æ¿€åŠ±
            'has_urgent_issues': bool,
            'has_watch_issues': bool,
            'has_highlights': bool
        }
    """
    result = {
        'date': None,
        'urgent': {},
        'watch': {},
        'highlights': {},
        'has_urgent_issues': False,
        'has_watch_issues': False,
        'has_highlights': False
    }
    
    if df is None or df.empty:
        return result
    
    # è·å–åŸºå‡†æ—¥æœŸ
    base_date = get_base_date(df)
    if base_date:
        result['date'] = base_date.strftime('%Y-%m-%d')
    
    # âš¡ V8.6æ€§èƒ½ä¼˜åŒ–ï¼šè®¢å•èšåˆå‰ç½®ï¼ˆåªè®¡ç®—ä¸€æ¬¡ï¼‰
    import time
    agg_start = time.time()
    order_agg = calculate_order_aggregation(df)
    agg_time = time.time() - agg_start
    print(f"âš¡ [V8.6ä¼˜åŒ–] è®¢å•èšåˆå®Œæˆ: {len(order_agg)}æ¡è®¢å•, è€—æ—¶: {agg_time:.2f}ç§’")
    
    # åˆ†æç´§æ€¥é—®é¢˜ï¼ˆä¼ å…¥order_aggï¼Œé¿å…é‡å¤èšåˆï¼‰
    urgent_start = time.time()
    result['urgent'] = analyze_urgent_issues(df, order_agg=order_agg)
    urgent_time = time.time() - urgent_start
    print(f"  â”œâ”€ ç´§æ€¥é—®é¢˜åˆ†æ: {urgent_time:.2f}ç§’")
    
    # åˆ†ææ­£å‘æ¿€åŠ±ï¼ˆä¼ å…¥order_aggï¼Œé¿å…é‡å¤èšåˆï¼‰
    highlights_start = time.time()
    result['highlights'] = analyze_highlights(df, order_agg=order_agg)
    highlights_time = time.time() - highlights_start
    print(f"  â”œâ”€ æ­£å‘æ¿€åŠ±åˆ†æ: {highlights_time:.2f}ç§’")
    
    # åˆ†æå…³æ³¨é—®é¢˜ï¼ˆä¼ å…¥order_aggï¼Œé¿å…é‡å¤èšåˆï¼‰
    watch_start = time.time()
    result['watch'] = analyze_watch_issues(df, order_agg=order_agg)
    watch_time = time.time() - watch_start
    print(f"  â””â”€ å…³æ³¨é—®é¢˜åˆ†æ: {watch_time:.2f}ç§’")
    
    total_time = agg_time + urgent_time + highlights_time + watch_time
    print(f"âš¡ [V8.6ä¼˜åŒ–] æ€»è€—æ—¶: {total_time:.2f}ç§’ (ä¼˜åŒ–å‰çº¦70-100ç§’)")

    
    # åˆ¤æ–­æ˜¯å¦æœ‰é—®é¢˜
    urgent = result['urgent']
    result['has_urgent_issues'] = (
        urgent['overflow']['count'] > 0 or
        urgent['delivery']['count'] > 0 or
        urgent['stockout']['count'] > 0
    )
    
    watch = result['watch']
    result['has_watch_issues'] = (
        watch['traffic_drop']['count'] > 0 or
        watch['new_slow']['count'] > 0 or
        watch['ongoing_slow']['count'] > 0 or
        watch['severe_slow']['count'] > 0 or
        watch['new_products']['count'] > 0
    )
    
    # åˆ¤æ–­æ˜¯å¦æœ‰äº®ç‚¹
    highlights = result['highlights']
    result['has_highlights'] = (
        highlights.get('hot_products', {}).get('count', 0) > 0 or
        highlights.get('high_profit_products', {}).get('count', 0) > 0
    )
    
    return result


# ==================== è¯¦æƒ…æ•°æ®è·å–å‡½æ•° ====================

def get_overflow_orders(df: pd.DataFrame, days: int = 1) -> pd.DataFrame:
    """
    è·å–ç©¿åº•è®¢å•è¯¦æƒ…ï¼ˆä½¿ç”¨ä¸»çœ‹æ¿ç»Ÿä¸€å…¬å¼ï¼‰
    
    ç©¿åº•åˆ¤æ–­æ ‡å‡†ï¼šè®¢å•å®é™…åˆ©æ¶¦ < 0
    å…¬å¼ï¼šè®¢å•å®é™…åˆ©æ¶¦ = åˆ©æ¶¦é¢ - å¹³å°æœåŠ¡è´¹ - ç‰©æµé…é€è´¹ + ä¼å®¢åè¿”
    
    å‚æ•°:
        df: åŸå§‹æ•°æ®
        days: æŸ¥è¯¢å¤©æ•°ï¼Œ1=æ˜¨æ—¥ï¼Œ3=è¿‘3å¤©ï¼Œ7=è¿‘7å¤©ï¼Œ15=è¿‘15å¤©ï¼Œ0=å…¨éƒ¨
    """
    if df is None or df.empty:
        return pd.DataFrame()
    
    try:
        date_col = 'æ—¥æœŸ' if 'æ—¥æœŸ' in df.columns else 'ä¸‹å•æ—¶é—´'
        df = df.copy()
        df[date_col] = pd.to_datetime(df[date_col])
        latest_date = df[date_col].max().normalize()
        
        # æ ¹æ®dayså‚æ•°ç­›é€‰æ—¥æœŸèŒƒå›´
        if days == 0:
            # å…¨éƒ¨æ•°æ®
            filtered_df = df.copy()
        else:
            start_date = latest_date - timedelta(days=days-1)
            filtered_df = df[df[date_col].dt.normalize() >= start_date]
        
        if filtered_df.empty:
            return pd.DataFrame()
        
        order_id_col = 'è®¢å•ID' if 'è®¢å•ID' in filtered_df.columns else None
        if not order_id_col:
            return pd.DataFrame()
        
        # æ„å»ºèšåˆå­—å…¸ - ä¸¥æ ¼åŒºåˆ†å­—æ®µçº§åˆ«
        agg_dict = {}
        
        # ===== å•†å“çº§å­—æ®µ (sum) =====
        # åˆ©æ¶¦é¢
        if 'åˆ©æ¶¦é¢' in filtered_df.columns:
            agg_dict['åˆ©æ¶¦é¢'] = pd.NamedAgg(column='åˆ©æ¶¦é¢', aggfunc='sum')
        
        # å¹³å°æœåŠ¡è´¹
        if 'å¹³å°æœåŠ¡è´¹' in filtered_df.columns:
            agg_dict['å¹³å°æœåŠ¡è´¹'] = pd.NamedAgg(column='å¹³å°æœåŠ¡è´¹', aggfunc='sum')
        
        # ä¼å®¢åè¿”
        if 'ä¼å®¢åè¿”' in filtered_df.columns:
            agg_dict['ä¼å®¢åè¿”'] = pd.NamedAgg(column='ä¼å®¢åè¿”', aggfunc='sum')
        
        # å®æ”¶ä»·æ ¼ (éœ€è¦å…ˆä¹˜ä»¥é”€é‡å†sum)
        sales_field = 'æœˆå”®' if 'æœˆå”®' in filtered_df.columns else 'é”€é‡'
        if 'å®æ”¶ä»·æ ¼' in filtered_df.columns and sales_field in filtered_df.columns:
            # åˆ›å»ºä¸´æ—¶åˆ—ï¼šå®æ”¶ä»·æ ¼ Ã— é”€é‡
            filtered_df['_å®æ”¶ä»·æ ¼_é”€é‡'] = filtered_df['å®æ”¶ä»·æ ¼'].fillna(0) * filtered_df[sales_field].fillna(1)
            agg_dict['é”€å”®é¢'] = pd.NamedAgg(column='_å®æ”¶ä»·æ ¼_é”€é‡', aggfunc='sum')
        elif 'å•†å“å®å”®ä»·' in filtered_df.columns:
            agg_dict['é”€å”®é¢'] = pd.NamedAgg(column='å•†å“å®å”®ä»·', aggfunc='sum')
        
        # å•†å“é‡‡è´­æˆæœ¬
        cost_col = 'å•†å“é‡‡è´­æˆæœ¬' if 'å•†å“é‡‡è´­æˆæœ¬' in filtered_df.columns else 'æˆæœ¬'
        if cost_col in filtered_df.columns:
            agg_dict['æˆæœ¬'] = pd.NamedAgg(column=cost_col, aggfunc='sum')
        
        # ===== è®¢å•çº§å­—æ®µ (first) =====
        # ç‰©æµé…é€è´¹
        if 'ç‰©æµé…é€è´¹' in filtered_df.columns:
            agg_dict['ç‰©æµé…é€è´¹'] = pd.NamedAgg(column='ç‰©æµé…é€è´¹', aggfunc='first')
        
        # è®¢å•ç¼–å· - ç”¨äºè¯†åˆ«æ¸ é“å¹³å°
        if 'è®¢å•ç¼–å·' in filtered_df.columns:
            agg_dict['è®¢å•ç¼–å·'] = pd.NamedAgg(column='è®¢å•ç¼–å·', aggfunc='first')
        
        # æ¸ é“
        channel_col = next((c for c in ['å¹³å°', 'æ¸ é“', 'platform'] if c in filtered_df.columns), None)
        if channel_col:
            agg_dict['æ¸ é“'] = pd.NamedAgg(column=channel_col, aggfunc='first')
        
        # é—¨åº—
        if 'é—¨åº—' in filtered_df.columns:
            agg_dict['é—¨åº—'] = pd.NamedAgg(column='é—¨åº—', aggfunc='first')
        
        # æ—¥æœŸ - ç”¨äºå±•ç¤º
        agg_dict['æ—¥æœŸ'] = pd.NamedAgg(column=date_col, aggfunc='first')
        
        # æ´»åŠ¨å­—æ®µï¼ˆè®¢å•çº§ï¼‰
        for name, field in ACTIVITY_FIELDS.items():
            if field in filtered_df.columns:
                agg_dict[name] = pd.NamedAgg(column=field, aggfunc='first')
        
        if not agg_dict:
            return pd.DataFrame()
        
        order_data = filtered_df.groupby(order_id_col).agg(**agg_dict).reset_index()
        
        # ä½¿ç”¨ç»Ÿä¸€å‡½æ•°è®¡ç®—è®¢å•å®é™…åˆ©æ¶¦
        order_data['è®¢å•å®é™…åˆ©æ¶¦'] = calculate_order_profit(order_data)
        
        # è®¡ç®—å•†å®¶æ´»åŠ¨æˆæœ¬ï¼ˆç”¨äºå±•ç¤ºï¼‰
        order_data['æ´»åŠ¨æˆæœ¬'] = 0
        for name in ACTIVITY_FIELDS.keys():
            if name in order_data.columns:
                order_data['æ´»åŠ¨æˆæœ¬'] += order_data[name].fillna(0)
        
        # ç­›é€‰ç©¿åº•è®¢å•ï¼šè®¢å•å®é™…åˆ©æ¶¦ < 0 ä¸” åˆ©æ¶¦é¢ != 0ï¼ˆæ’é™¤å¼‚å¸¸æ•°æ®ï¼‰
        # åˆ©æ¶¦é¢=0é€šå¸¸æ˜¯æˆæœ¬æ•°æ®ç¼ºå¤±çš„å¼‚å¸¸è®¢å•ï¼Œä¸å‚ä¸åˆ†æ
        overflow_mask = (order_data['è®¢å•å®é™…åˆ©æ¶¦'] < 0)
        if 'åˆ©æ¶¦é¢' in order_data.columns:
            overflow_mask = overflow_mask & (order_data['åˆ©æ¶¦é¢'] != 0)
        
        overflow_orders = order_data[overflow_mask].copy()
        overflow_orders = overflow_orders.sort_values('è®¢å•å®é™…åˆ©æ¶¦', ascending=True)
        
        # æ ¼å¼åŒ–æ—¥æœŸåˆ—
        if 'æ—¥æœŸ' in overflow_orders.columns:
            overflow_orders['æ—¥æœŸ'] = pd.to_datetime(overflow_orders['æ—¥æœŸ']).dt.strftime('%m-%d')
        
        # é€‰æ‹©å±•ç¤ºåˆ—ï¼ˆåŠ å…¥è®¢å•ç¼–å·å’Œæ—¥æœŸï¼‰
        display_cols = [order_id_col, 'è®¢å•ç¼–å·', 'æ—¥æœŸ', 'æ¸ é“', 'é—¨åº—', 'é”€å”®é¢', 'æˆæœ¬', 'æ´»åŠ¨æˆæœ¬', 'åˆ©æ¶¦é¢', 'è®¢å•å®é™…åˆ©æ¶¦']
        display_cols = [c for c in display_cols if c in overflow_orders.columns]
        
        return overflow_orders[display_cols]
    except Exception as e:
        print(f"get_overflow_orders é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return pd.DataFrame()


def get_overflow_products(df: pd.DataFrame, days: int = 1) -> pd.DataFrame:
    """
    è·å–ç©¿åº•å•†å“åˆ†æï¼ˆå•†å“çº§å®šä½ï¼‰
    
    åˆ†æç»´åº¦ï¼š
    1. ç©¿åº•è´¡çŒ®é‡‘é¢ - è¯¥å•†å“åœ¨ç©¿åº•è®¢å•ä¸­è´¡çŒ®çš„è´Ÿåˆ©æ¶¦
    2. ç©¿åº•è®¢å•æ•° - åŒ…å«è¯¥å•†å“çš„ç©¿åº•è®¢å•æ•°é‡
    3. å•†å“æ¯›åˆ©ç‡ - (å®æ”¶ä»·æ ¼-æˆæœ¬)/å®æ”¶ä»·æ ¼
    4. æ´»åŠ¨å‚ä¸æƒ…å†µ - è¯¥å•†å“çš„å¹³å‡æ´»åŠ¨æŠ˜æ‰£
    5. æ˜¨æ—¥é”€é‡ - åˆ¤æ–­å½±å“èŒƒå›´
    
    å‚æ•°:
        df: åŸå§‹æ•°æ®
        days: æŸ¥è¯¢å¤©æ•°ï¼Œ1=æ˜¨æ—¥ï¼Œ3=è¿‘3å¤©ï¼Œ7=è¿‘7å¤©ï¼Œ15=è¿‘15å¤©ï¼Œ0=å…¨éƒ¨
    
    ä¸šåŠ¡ä»·å€¼ï¼š
    - ä½æ¯›åˆ©+é«˜æ´»åŠ¨ â†’ å»ºè®®é™ä½æ´»åŠ¨åŠ›åº¦æˆ–é€€å‡ºæ´»åŠ¨
    - é«˜é”€é‡+ç©¿åº• â†’ ä¼˜å…ˆå¤„ç†
    """
    if df is None or df.empty:
        return pd.DataFrame()
    
    try:
        date_col = 'æ—¥æœŸ' if 'æ—¥æœŸ' in df.columns else 'ä¸‹å•æ—¶é—´'
        df = df.copy()
        df[date_col] = pd.to_datetime(df[date_col])
        latest_date = df[date_col].max().normalize()
        
        # æ ¹æ®dayså‚æ•°ç­›é€‰æ—¥æœŸèŒƒå›´
        if days == 0:
            filtered_df = df.copy()
        else:
            start_date = latest_date - timedelta(days=days-1)
            filtered_df = df[df[date_col].dt.normalize() >= start_date]
        
        if filtered_df.empty:
            return pd.DataFrame()
        
        order_id_col = 'è®¢å•ID' if 'è®¢å•ID' in filtered_df.columns else None
        if not order_id_col or 'å•†å“åç§°' not in filtered_df.columns:
            return pd.DataFrame()
        
        # ===== Step 1: å…ˆæŒ‰è®¢å•èšåˆï¼Œè®¡ç®—è®¢å•å®é™…åˆ©æ¶¦ =====
        order_agg_dict = {}
        
        # å•†å“çº§å­—æ®µ (sum)
        if 'åˆ©æ¶¦é¢' in filtered_df.columns:
            order_agg_dict['åˆ©æ¶¦é¢'] = pd.NamedAgg(column='åˆ©æ¶¦é¢', aggfunc='sum')
        if 'å¹³å°æœåŠ¡è´¹' in filtered_df.columns:
            order_agg_dict['å¹³å°æœåŠ¡è´¹'] = pd.NamedAgg(column='å¹³å°æœåŠ¡è´¹', aggfunc='sum')
        if 'ä¼å®¢åè¿”' in filtered_df.columns:
            order_agg_dict['ä¼å®¢åè¿”'] = pd.NamedAgg(column='ä¼å®¢åè¿”', aggfunc='sum')
        
        # è®¢å•çº§å­—æ®µ (first)
        if 'ç‰©æµé…é€è´¹' in filtered_df.columns:
            order_agg_dict['ç‰©æµé…é€è´¹'] = pd.NamedAgg(column='ç‰©æµé…é€è´¹', aggfunc='first')
        
        if not order_agg_dict:
            return pd.DataFrame()
        
        order_data = filtered_df.groupby(order_id_col).agg(**order_agg_dict).reset_index()
        order_data['è®¢å•å®é™…åˆ©æ¶¦'] = calculate_order_profit(order_data)
        
        # ç­›é€‰ç©¿åº•è®¢å•IDï¼šè®¢å•å®é™…åˆ©æ¶¦ < 0 ä¸” åˆ©æ¶¦é¢ != 0ï¼ˆæ’é™¤å¼‚å¸¸æ•°æ®ï¼‰
        # ä¸è®¢å•è§†å›¾ä¿æŒä¸€è‡´çš„è¿‡æ»¤é€»è¾‘
        overflow_mask = (order_data['è®¢å•å®é™…åˆ©æ¶¦'] < 0)
        if 'åˆ©æ¶¦é¢' in order_data.columns:
            overflow_mask = overflow_mask & (order_data['åˆ©æ¶¦é¢'] != 0)
        
        overflow_order_ids = order_data[overflow_mask][order_id_col].tolist()
        
        if not overflow_order_ids:
            return pd.DataFrame()
        
        # ===== Step 2: è·å–ç©¿åº•è®¢å•ä¸­çš„å•†å“æ˜ç»† =====
        overflow_items = filtered_df[filtered_df[order_id_col].isin(overflow_order_ids)].copy()
        
        # è®¡ç®—é”€é‡å­—æ®µ
        sales_field = 'æœˆå”®' if 'æœˆå”®' in overflow_items.columns else 'é”€é‡'
        if sales_field not in overflow_items.columns:
            overflow_items[sales_field] = 1
        
        # å•†å“åŸä»·ï¼ˆåŸå§‹æ•°æ®æ¯è¡Œå°±æ˜¯å•ä»·ï¼Œä¸éœ€è¦é™¤ä»¥é”€é‡ï¼‰
        if 'å•†å“åŸä»·' in overflow_items.columns:
            overflow_items['_å•†å“åŸä»·'] = overflow_items['å•†å“åŸä»·'].fillna(0)
        else:
            overflow_items['_å•†å“åŸä»·'] = 0
        
        # å•†å“å®å”®ä»·ï¼ˆåŸå§‹æ•°æ®æ¯è¡Œå°±æ˜¯å•ä»·ï¼Œä¸éœ€è¦é™¤ä»¥é”€é‡ï¼‰
        if 'å•†å“å®å”®ä»·' in overflow_items.columns:
            overflow_items['_å•†å“å®å”®ä»·'] = overflow_items['å•†å“å®å”®ä»·'].fillna(0)
        else:
            overflow_items['_å•†å“å®å”®ä»·'] = 0
        
        # å®æ”¶ä»·æ ¼ï¼ˆå•å“ï¼‰
        if 'å®æ”¶ä»·æ ¼' in overflow_items.columns:
            overflow_items['_å®æ”¶ä»·æ ¼'] = overflow_items['å®æ”¶ä»·æ ¼'].fillna(0)
            overflow_items['å•†å“é”€å”®é¢'] = overflow_items['å®æ”¶ä»·æ ¼'].fillna(0) * overflow_items[sales_field].fillna(1)
        elif 'å•†å“å®å”®ä»·' in overflow_items.columns:
            overflow_items['_å®æ”¶ä»·æ ¼'] = overflow_items['å•†å“å®å”®ä»·'].fillna(0)
            overflow_items['å•†å“é”€å”®é¢'] = overflow_items['å•†å“å®å”®ä»·'].fillna(0)
        else:
            overflow_items['_å®æ”¶ä»·æ ¼'] = 0
            overflow_items['å•†å“é”€å”®é¢'] = 0
        
        # å•†å“æˆæœ¬ï¼ˆåŒºåˆ†å•å“æˆæœ¬å’Œæ€»æˆæœ¬ï¼‰
        # æ³¨æ„ï¼šåŸå§‹æ•°æ®ä¸­ å•†å“é‡‡è´­æˆæœ¬ = å•å“æˆæœ¬ Ã— æœˆå”®ï¼ˆå·²ç»æ˜¯æ€»æˆæœ¬ï¼‰
        cost_col = 'å•†å“é‡‡è´­æˆæœ¬' if 'å•†å“é‡‡è´­æˆæœ¬' in overflow_items.columns else 'æˆæœ¬'
        if cost_col in overflow_items.columns:
            # æ€»æˆæœ¬ï¼šç›´æ¥ä½¿ç”¨åŸå§‹å­—æ®µï¼ˆå·²ä¹˜ä»¥é”€é‡ï¼‰
            overflow_items['å•†å“æˆæœ¬'] = overflow_items[cost_col].fillna(0)
            # å•å“æˆæœ¬ï¼šæ€»æˆæœ¬ / é”€é‡
            overflow_items['å•å“æˆæœ¬'] = overflow_items[cost_col].fillna(0) / overflow_items[sales_field].replace(0, 1).fillna(1)
        else:
            overflow_items['å•å“æˆæœ¬'] = 0
            overflow_items['å•†å“æˆæœ¬'] = 0
        
        # å•†å“æ¯›åˆ©ï¼ˆæ€»é”€å”®é¢ - æ€»æˆæœ¬ï¼‰
        overflow_items['å•†å“æ¯›åˆ©'] = overflow_items['å•†å“é”€å”®é¢'] - overflow_items['å•†å“æˆæœ¬']
        
        # ===== Step 3: æŒ‰å•†å“èšåˆåˆ†æ =====
        # å…ˆè·å–å•†å“çš„ä¸€çº§åˆ†ç±»ï¼ˆç”¨äºåç»­è¿‡æ»¤è€—æï¼‰
        category_col = 'ä¸€çº§åˆ†ç±»å' if 'ä¸€çº§åˆ†ç±»å' in overflow_items.columns else 'ä¸€çº§åˆ†ç±»'
        
        # èšåˆé€»è¾‘ï¼š
        # - å•†å“åŸä»·ï¼šç”¨maxå–æœ€é«˜ä»·ï¼ˆå•†å“å®šä»·/æ ‡ä»·ï¼‰
        # - å•†å“å®å”®ä»·ï¼šç”¨meanå–å¹³å‡ï¼ˆæŠ˜æ‰£åçš„å”®ä»·ï¼‰
        # - å®æ”¶ä»·æ ¼ï¼šç”¨meanå–å¹³å‡ï¼ˆç©¿åº•æ—¶çš„å®é™…æˆäº¤ä»·ï¼‰
        agg_dict = {
            'ç©¿åº•è®¢å•æ•°': pd.NamedAgg(column=order_id_col, aggfunc='nunique'),
            'è®¢å•ID': pd.NamedAgg(column=order_id_col, aggfunc=lambda x: '\n'.join(x.astype(str).unique())),
            'ç©¿åº•é”€é‡': pd.NamedAgg(column=sales_field, aggfunc='sum'),
            'å•†å“åŸä»·': pd.NamedAgg(column='_å•†å“åŸä»·', aggfunc='max'),      # å•†å“å®šä»·/æ ‡ä»·
            'å•†å“å®å”®ä»·': pd.NamedAgg(column='_å•†å“å®å”®ä»·', aggfunc='mean'),  # æŠ˜æ‰£åå”®ä»·
            'å®æ”¶ä»·æ ¼': pd.NamedAgg(column='_å®æ”¶ä»·æ ¼', aggfunc='mean'),     # å®é™…æˆäº¤ä»·
            'å•å“æˆæœ¬': pd.NamedAgg(column='å•å“æˆæœ¬', aggfunc='first'),
            'æ€»é”€å”®é¢': pd.NamedAgg(column='å•†å“é”€å”®é¢', aggfunc='sum'),
            'æ€»æˆæœ¬': pd.NamedAgg(column='å•†å“æˆæœ¬', aggfunc='sum'),
            'å•†å“æ¯›åˆ©': pd.NamedAgg(column='å•†å“æ¯›åˆ©', aggfunc='sum'),
        }
        
        if 'åˆ©æ¶¦é¢' in overflow_items.columns:
            agg_dict['åˆ©æ¶¦é¢'] = pd.NamedAgg(column='åˆ©æ¶¦é¢', aggfunc='sum')
        
        # æ·»åŠ åˆ†ç±»å­—æ®µ
        if category_col in overflow_items.columns:
            agg_dict['ä¸€çº§åˆ†ç±»'] = pd.NamedAgg(column=category_col, aggfunc='first')
        
        # ä¸‰çº§åˆ†ç±»
        category3_col = 'ä¸‰çº§åˆ†ç±»å' if 'ä¸‰çº§åˆ†ç±»å' in overflow_items.columns else 'ä¸‰çº§åˆ†ç±»'
        if category3_col in overflow_items.columns:
            agg_dict['ä¸‰çº§åˆ†ç±»'] = pd.NamedAgg(column=category3_col, aggfunc='first')
        
        # å•†å“åç§°ï¼ˆç”¨äºå±•ç¤ºï¼‰
        agg_dict['å•†å“åç§°'] = pd.NamedAgg(column='å•†å“åç§°', aggfunc='first')
        
        # â­ ä½¿ç”¨åº—å†…ç ä½œä¸ºèšåˆkeyï¼ŒåŒºåˆ†åŒåä¸åŒè§„æ ¼å•†å“
        group_key = get_product_group_key(overflow_items)
        product_agg = overflow_items.groupby(group_key).agg(**agg_dict).reset_index()
        
        # å¦‚æœç”¨åº—å†…ç èšåˆï¼Œé‡å‘½ååˆ—
        if group_key != 'å•†å“åç§°':
            product_agg = product_agg.rename(columns={group_key: 'åº—å†…ç '})
        
        # è®¡ç®—å®šä»·æ¯›åˆ©ç‡ï¼ˆåŸºäºå•†å“åŸä»·å’Œå•å“æˆæœ¬ï¼Œåæ˜ å®šä»·ç­–ç•¥ï¼‰
        product_agg['å®šä»·æ¯›åˆ©ç‡'] = np.where(
            product_agg['å•†å“åŸä»·'] > 0,
            ((product_agg['å•†å“åŸä»·'] - product_agg['å•å“æˆæœ¬']) / product_agg['å•†å“åŸä»·'] * 100).round(1),
            0
        )
        
        # è®¡ç®—å®æ”¶æ¯›åˆ©ç‡ï¼ˆåŸºäºå®æ”¶ä»·æ ¼å’Œå•å“æˆæœ¬ï¼Œåæ˜ å®é™…æˆäº¤æ¯›åˆ©ï¼‰
        product_agg['å®æ”¶æ¯›åˆ©ç‡'] = np.where(
            product_agg['å®æ”¶ä»·æ ¼'] > 0,
            ((product_agg['å®æ”¶ä»·æ ¼'] - product_agg['å•å“æˆæœ¬']) / product_agg['å®æ”¶ä»·æ ¼'] * 100).round(1),
            0
        )
        
        # ç©¿åº•è´¡çŒ® = å•†å“æ¯›åˆ©ï¼ˆè´Ÿå€¼è¡¨ç¤ºè´¡çŒ®ç©¿åº•ï¼‰
        product_agg['ç©¿åº•è´¡çŒ®'] = product_agg['å•†å“æ¯›åˆ©']
        
        # ===== Step 4: è·å–è¯¥å•†å“åœ¨ç­›é€‰å‘¨æœŸå†…çš„æ€»é”€é‡ï¼ˆç”¨äºå¯¹æ¯”ï¼‰=====
        # ä½¿ç”¨ç›¸åŒçš„èšåˆkey
        group_key = get_product_group_key(filtered_df)
        all_product_sales = filtered_df.groupby(group_key)[sales_field].sum().reset_index()
        all_product_sales.columns = [group_key, 'å‘¨æœŸæ€»é”€é‡']
        
        # ç¡®ä¿mergeçš„keyä¸€è‡´
        merge_key = 'åº—å†…ç ' if 'åº—å†…ç ' in product_agg.columns else 'å•†å“åç§°'
        if group_key != merge_key:
            all_product_sales = all_product_sales.rename(columns={group_key: merge_key})
        product_agg = product_agg.merge(all_product_sales, on=merge_key, how='left')
        
        # ===== Step 5: ç”Ÿæˆå¤„ç†å»ºè®® =====
        product_agg['å¤„ç†å»ºè®®'] = "å…³æ³¨ä¸´æœŸå•†å“ã€çˆ†å“ã€ç¥ä»·å“ã€é‡é‡åŠ ä»·é…ç½®"
        
        # æŒ‰ç©¿åº•è´¡çŒ®æ’åºï¼ˆè´Ÿå€¼è¶Šå°=è´¡çŒ®ç©¿åº•è¶Šå¤šï¼‰
        product_agg = product_agg.sort_values('ç©¿åº•è´¡çŒ®', ascending=True)
        
        # ===== Step 6: è¿‡æ»¤è€—æåˆ†ç±»ï¼ˆå¦‚è´­ç‰©è¢‹ï¼‰ï¼Œåªå½±å“å±•ç¤ºä¸å½±å“è®¡ç®— =====
        if 'ä¸€çº§åˆ†ç±»' in product_agg.columns:
            product_agg = product_agg[product_agg['ä¸€çº§åˆ†ç±»'] != 'è€—æ'].copy()
        
        # é€‰æ‹©å±•ç¤ºåˆ—ï¼ˆä¸šåŠ¡è§†è§’ï¼šåˆ†ç±» + å•å“ä¿¡æ¯ + ç©¿åº•å½±å“ï¼‰
        display_cols = ['ä¸€çº§åˆ†ç±»', 'ä¸‰çº§åˆ†ç±»', 'åº—å†…ç ', 'å•†å“åç§°', 'ç©¿åº•è®¢å•æ•°', 'è®¢å•ID', 'ç©¿åº•é”€é‡', 'å‘¨æœŸæ€»é”€é‡',
                        'å•†å“åŸä»·', 'å•†å“å®å”®ä»·', 'å®æ”¶ä»·æ ¼', 'å•å“æˆæœ¬', 'å®šä»·æ¯›åˆ©ç‡', 'å®æ”¶æ¯›åˆ©ç‡', 'ç©¿åº•è´¡çŒ®', 'å¤„ç†å»ºè®®']
        display_cols = [c for c in display_cols if c in product_agg.columns]
        
        return product_agg[display_cols]
        
    except Exception as e:
        print(f"get_overflow_products é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return pd.DataFrame()


def get_high_delivery_orders(df: pd.DataFrame, days: int = 1) -> pd.DataFrame:
    """
    è·å–é«˜é…é€è´¹è®¢å•è¯¦æƒ…ï¼ˆä¼˜åŒ–ç‰ˆï¼‰
    
    é«˜é…é€è´¹åˆ¤æ–­æ ‡å‡†ï¼šé…é€å‡€æˆæœ¬ > 6å…ƒ
    é…é€å‡€æˆæœ¬å…¬å¼ï¼šç‰©æµé…é€è´¹ - (ç”¨æˆ·æ”¯ä»˜é…é€è´¹ - é…é€è´¹å‡å…) - ä¼å®¢åè¿”
    
    å‚æ•°:
        df: åŸå§‹æ•°æ®
        days: æ—¥æœŸèŒƒå›´ï¼ˆ1=æ˜¨æ—¥ï¼Œ3=è¿‘3å¤©ï¼Œ7=è¿‘7å¤©ï¼Œ15=è¿‘15å¤©ï¼Œ0=å…¨éƒ¨ï¼‰
    
    åŠŸèƒ½ï¼š
    1. é…é€è·ç¦»å±•ç¤ºä¸ºkmï¼ˆåŸå§‹æ•°æ®ä¸ºç±³ï¼‰
    2. å¢åŠ æ—¶æ®µå­—æ®µï¼ˆæ—©é¤ã€åˆé¤ã€æ™šé¤ç­‰ï¼‰
    3. æ™ºèƒ½åˆ¤æ–­æç¤ºï¼ˆå¤§è§„æ ¼å•†å“ã€å¤œé—´åŠ ä»·ã€è¿œè·ç¦»é…é€ç­‰ï¼‰
    4. é…é€æº¢ä»· = é…é€å‡€æˆæœ¬ - 6å…ƒ
    """
    if df is None or df.empty:
        return pd.DataFrame()
    
    try:
        date_col = 'æ—¥æœŸ' if 'æ—¥æœŸ' in df.columns else 'ä¸‹å•æ—¶é—´'
        df = df.copy()
        df[date_col] = pd.to_datetime(df[date_col])
        
        # æ ¹æ®dayså‚æ•°ç­›é€‰æ—¥æœŸèŒƒå›´
        latest_date = df[date_col].max().normalize()
        if days == 0:
            # å…¨éƒ¨æ•°æ®
            filtered_df = df.copy()
        elif days == 1:
            # æ˜¨æ—¥
            filtered_df = df[df[date_col].dt.normalize() == latest_date]
        else:
            # è¿‘Nå¤©
            start_date = latest_date - pd.Timedelta(days=days-1)
            filtered_df = df[(df[date_col].dt.normalize() >= start_date) & 
                            (df[date_col].dt.normalize() <= latest_date)]
        
        if filtered_df.empty:
            return pd.DataFrame()
        
        order_id_col = 'è®¢å•ID' if 'è®¢å•ID' in filtered_df.columns else None
        if not order_id_col or 'ç‰©æµé…é€è´¹' not in filtered_df.columns:
            return pd.DataFrame()
        
        # æå–å°æ—¶ç”¨äºæ—¶æ®µåˆ†æ
        filtered_df['_å°æ—¶'] = filtered_df[date_col].apply(lambda x: pd.to_datetime(x).hour if pd.notna(x) else -1)
        
        # æ„å»ºèšåˆå­—å…¸ - ä¸¥æ ¼åŒºåˆ†å­—æ®µçº§åˆ«
        agg_dict = {}
        
        # ===== å•†å“çº§å­—æ®µ (sum) =====
        if 'åˆ©æ¶¦é¢' in filtered_df.columns:
            agg_dict['åˆ©æ¶¦é¢'] = pd.NamedAgg(column='åˆ©æ¶¦é¢', aggfunc='sum')
        
        if 'å¹³å°æœåŠ¡è´¹' in filtered_df.columns:
            agg_dict['å¹³å°æœåŠ¡è´¹'] = pd.NamedAgg(column='å¹³å°æœåŠ¡è´¹', aggfunc='sum')
        
        if 'ä¼å®¢åè¿”' in filtered_df.columns:
            agg_dict['ä¼å®¢åè¿”'] = pd.NamedAgg(column='ä¼å®¢åè¿”', aggfunc='sum')
        
        # å®æ”¶ä»·æ ¼ (éœ€è¦å…ˆä¹˜ä»¥é”€é‡å†sum)
        sales_field = 'æœˆå”®' if 'æœˆå”®' in filtered_df.columns else 'é”€é‡'
        if 'å®æ”¶ä»·æ ¼' in filtered_df.columns and sales_field in filtered_df.columns:
            filtered_df['_å®æ”¶ä»·æ ¼_é”€é‡'] = filtered_df['å®æ”¶ä»·æ ¼'].fillna(0) * filtered_df[sales_field].fillna(1)
            agg_dict['é”€å”®é¢'] = pd.NamedAgg(column='_å®æ”¶ä»·æ ¼_é”€é‡', aggfunc='sum')
        elif 'å•†å“å®å”®ä»·' in filtered_df.columns:
            agg_dict['é”€å”®é¢'] = pd.NamedAgg(column='å•†å“å®å”®ä»·', aggfunc='sum')
        
        # å•†å“æˆæœ¬
        cost_col = 'å•†å“é‡‡è´­æˆæœ¬' if 'å•†å“é‡‡è´­æˆæœ¬' in filtered_df.columns else 'æˆæœ¬'
        if cost_col in filtered_df.columns:
            filtered_df['_æˆæœ¬_é”€é‡'] = filtered_df[cost_col].fillna(0) * filtered_df[sales_field].fillna(1)
            agg_dict['æˆæœ¬'] = pd.NamedAgg(column='_æˆæœ¬_é”€é‡', aggfunc='sum')
        
        # ===== è®¢å•çº§å­—æ®µ (first) =====
        agg_dict['ç‰©æµé…é€è´¹'] = pd.NamedAgg(column='ç‰©æµé…é€è´¹', aggfunc='first')
        agg_dict['å°æ—¶'] = pd.NamedAgg(column='_å°æ—¶', aggfunc='first')
        
        # ç”¨æˆ·æ”¯ä»˜é…é€è´¹ï¼ˆç”¨äºè®¡ç®—é…é€å‡€æˆæœ¬ï¼‰
        if 'ç”¨æˆ·æ”¯ä»˜é…é€è´¹' in filtered_df.columns:
            agg_dict['ç”¨æˆ·æ”¯ä»˜é…é€è´¹'] = pd.NamedAgg(column='ç”¨æˆ·æ”¯ä»˜é…é€è´¹', aggfunc='first')
        
        # é…é€è´¹å‡å…é‡‘é¢ï¼ˆç”¨äºè®¡ç®—é…é€å‡€æˆæœ¬ï¼‰
        if 'é…é€è´¹å‡å…é‡‘é¢' in filtered_df.columns:
            agg_dict['é…é€è´¹å‡å…é‡‘é¢'] = pd.NamedAgg(column='é…é€è´¹å‡å…é‡‘é¢', aggfunc='first')
        elif 'é…é€è´¹å‡å…' in filtered_df.columns:
            agg_dict['é…é€è´¹å‡å…é‡‘é¢'] = pd.NamedAgg(column='é…é€è´¹å‡å…', aggfunc='first')
        
        # æ¸ é“
        channel_col = next((c for c in ['å¹³å°', 'æ¸ é“', 'platform'] if c in filtered_df.columns), None)
        if channel_col:
            agg_dict['æ¸ é“'] = pd.NamedAgg(column=channel_col, aggfunc='first')
        
        # é—¨åº—
        if 'é—¨åº—' in filtered_df.columns:
            agg_dict['é—¨åº—'] = pd.NamedAgg(column='é—¨åº—', aggfunc='first')
        
        # è·ç¦»
        distance_col = next((c for c in ['é…é€è·ç¦»', 'é€è¾¾è·ç¦»'] if c in filtered_df.columns), None)
        if distance_col:
            agg_dict['_é…é€è·ç¦»'] = pd.NamedAgg(column=distance_col, aggfunc='first')
        
        # æ”¶è´§åœ°å€
        if 'æ”¶è´§åœ°å€' in filtered_df.columns:
            agg_dict['æ”¶è´§åœ°å€'] = pd.NamedAgg(column='æ”¶è´§åœ°å€', aggfunc='first')
        
        # æ”¶é›†å•†å“åç§°ç”¨äºå¤§è§„æ ¼åˆ¤æ–­
        if 'å•†å“åç§°' in filtered_df.columns:
            agg_dict['_å•†å“åˆ—è¡¨'] = pd.NamedAgg(column='å•†å“åç§°', aggfunc=lambda x: '|'.join(x.astype(str).unique()))
        
        order_data = filtered_df.groupby(order_id_col).agg(**agg_dict).reset_index()
        
        # ä½¿ç”¨ç»Ÿä¸€å‡½æ•°è®¡ç®—è®¢å•å®é™…åˆ©æ¶¦
        order_data['è®¢å•å®é™…åˆ©æ¶¦'] = calculate_order_profit(order_data)
        
        # ===== è®¡ç®—é…é€å‡€æˆæœ¬ =====
        # å…¬å¼ï¼šé…é€å‡€æˆæœ¬ = ç‰©æµé…é€è´¹ - (ç”¨æˆ·æ”¯ä»˜é…é€è´¹ - é…é€è´¹å‡å…) - ä¼å®¢åè¿”
        delivery_fee = order_data['ç‰©æµé…é€è´¹'].fillna(0)
        user_paid = order_data.get('ç”¨æˆ·æ”¯ä»˜é…é€è´¹', pd.Series(0, index=order_data.index)).fillna(0)
        delivery_discount = order_data.get('é…é€è´¹å‡å…é‡‘é¢', pd.Series(0, index=order_data.index)).fillna(0)
        enterprise_rebate = order_data.get('ä¼å®¢åè¿”', pd.Series(0, index=order_data.index)).fillna(0)
        
        order_data['é…é€å‡€æˆæœ¬'] = delivery_fee - (user_paid - delivery_discount) - enterprise_rebate
        
        # ç­›é€‰é«˜é…é€è´¹è®¢å•ï¼šé…é€å‡€æˆæœ¬ > 6å…ƒ
        # æ³¨ï¼šä¹‹å‰è¿˜æœ‰æ¡ä»¶"è®¢å•å®é™…åˆ©æ¶¦ < é…é€å‡€æˆæœ¬"ï¼Œä½†ä¸šåŠ¡ä¸Šåªéœ€è¦å…³æ³¨é…é€å‡€æˆæœ¬>6å…ƒçš„è®¢å•
        mask = (order_data['é…é€å‡€æˆæœ¬'] > DELIVERY_FEE_THRESHOLD)
        high_delivery = order_data[mask].copy()
        
        if len(high_delivery) > 0:
            # é…é€æº¢ä»· = é…é€å‡€æˆæœ¬ - åŸºå‡†é…é€è´¹(6å…ƒ)
            high_delivery['é…é€æº¢ä»·'] = high_delivery['é…é€å‡€æˆæœ¬'] - DELIVERY_FEE_THRESHOLD
            
            # é…é€è·ç¦»æ ¼å¼åŒ–ä¸ºkmï¼ˆæºæ•°æ®å•ä½ä¸ºç±³ï¼Œéœ€è¦é™¤ä»¥1000ï¼‰
            if '_é…é€è·ç¦»' in high_delivery.columns:
                high_delivery['é…é€è·ç¦»'] = high_delivery['_é…é€è·ç¦»'].apply(
                    lambda x: f"{x/1000:.2f}km" if pd.notna(x) and x > 0 else "æœªçŸ¥"
                )
                # ä¿å­˜kmå€¼ç”¨äºé£é™©åˆ¤æ–­
                high_delivery['_é…é€è·ç¦»km'] = high_delivery['_é…é€è·ç¦»'].apply(
                    lambda x: x/1000 if pd.notna(x) and x > 0 else 0
                )
            
            # æ—¶æ®µåˆ¤æ–­
            high_delivery['æ—¶æ®µ'] = high_delivery['å°æ—¶'].apply(_get_scene_period)
            
            # æ™ºèƒ½åˆ¤æ–­æç¤º
            high_delivery['é£é™©æç¤º'] = high_delivery.apply(_generate_delivery_risk_tips, axis=1)
            
            high_delivery = high_delivery.sort_values('é…é€å‡€æˆæœ¬', ascending=False)
        
        # é€‰æ‹©å±•ç¤ºåˆ—ï¼ˆç”¨é…é€å‡€æˆæœ¬æ›¿ä»£ç‰©æµé…é€è´¹ï¼‰
        display_cols = [order_id_col, 'æ¸ é“', 'é—¨åº—', 'é”€å”®é¢', 'æˆæœ¬', 'é…é€å‡€æˆæœ¬', 'è®¢å•å®é™…åˆ©æ¶¦', 
                       'é…é€æº¢ä»·', 'é…é€è·ç¦»', 'æ”¶è´§åœ°å€', 'æ—¶æ®µ', 'é£é™©æç¤º']
        display_cols = [c for c in display_cols if c in high_delivery.columns]
        
        return high_delivery[display_cols] if not high_delivery.empty else pd.DataFrame()
    except Exception as e:
        print(f"get_high_delivery_orders é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return pd.DataFrame()


def _get_scene_period(hour: int) -> str:
    """æ ¹æ®å°æ—¶è·å–åœºæ™¯æ—¶æ®µ"""
    if pd.isna(hour) or hour < 0:
        return 'æœªçŸ¥'
    
    hour = int(hour)
    if 6 <= hour < 9:
        return 'æ—©é¤(6-9ç‚¹)'
    elif 9 <= hour < 11:
        return 'ä¸Šåˆ(9-11ç‚¹)'
    elif 11 <= hour < 14:
        return 'åˆé¤(11-14ç‚¹)'
    elif 14 <= hour < 17:
        return 'ä¸‹åˆèŒ¶(14-17ç‚¹)'
    elif 17 <= hour < 21:
        return 'æ™šé¤(17-21ç‚¹)'
    elif 21 <= hour <= 23:
        return 'å¤œå®µ(21-24ç‚¹)'
    elif 0 <= hour < 6:
        return 'å‡Œæ™¨(0-6ç‚¹)'
    else:
        return 'å…¶ä»–'


def _generate_delivery_risk_tips(row) -> str:
    """
    ç”Ÿæˆé…é€æº¢ä»·é£é™©æç¤º
    
    åˆ¤æ–­é€»è¾‘ï¼š
    1. å‡Œæ™¨æ—¶æ®µ(0-6ç‚¹) â†’ å¤œé—´åŠ ä»·æç¤º
    2. å¤œå®µæ—¶æ®µ(21-24ç‚¹) â†’ å¤œé—´åŠ ä»·æç¤º
    3. å¤§è§„æ ¼å•†å“åˆ¤æ–­ â†’ é‡é‡åŠ ä»·æç¤º
    4. é…é€è·ç¦»è¿‡è¿œ â†’ è·ç¦»åŠ ä»·æç¤º
    """
    tips = []
    
    hour = row.get('å°æ—¶', -1)
    products = row.get('_å•†å“åˆ—è¡¨', '')
    # ä¼˜å…ˆä½¿ç”¨è½¬æ¢åçš„kmå€¼ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨åŸå§‹å€¼é™¤ä»¥1000
    distance_km = row.get('_é…é€è·ç¦»km', 0)
    if distance_km == 0:
        raw_distance = row.get('_é…é€è·ç¦»', 0)
        distance_km = raw_distance / 1000 if pd.notna(raw_distance) and raw_distance > 0 else 0
    
    # 1. å¤œé—´æ—¶æ®µæ£€æµ‹
    if pd.notna(hour):
        hour = int(hour)
        if 0 <= hour < 6:
            tips.append("â°å‡Œæ™¨è®¢å•ï¼Œè¯·æ£€æŸ¥å¤œé—´åŠ ä»·é…ç½®")
        elif 21 <= hour <= 23:
            tips.append("ğŸŒ™å¤œå®µæ—¶æ®µï¼Œæ³¨æ„å¤œé—´é…é€æº¢ä»·")
    
    # 2. å¤§è§„æ ¼å•†å“æ£€æµ‹
    if products:
        large_item_keywords = [
            # å®¹é‡è§„æ ¼
            '5L', '4L', '3L', '2.5L', '10L', '12L', '15L', '20L',
            # å¤šç“¶è£…
            '12ç“¶', '24ç“¶', '6ç“¶', '12ç½', '24ç½', '6ç½',
            # æ•´ç®±
            'æ•´ç®±', 'ä¸€ç®±', 'ç®±è£…', '/ç®±',
            # å¤šåŒ…è£…
            '12åŒ…', '24åŒ…', '6åŒ…', '10åŒ…',
            # å¤§æ¡¶
            'å¤§æ¡¶', 'æ¡¶è£…',
            # é‡é‡
            '5kg', '10kg', '5å…¬æ–¤', '10å…¬æ–¤', '5KG', '10KG',
            # è§„æ ¼æ•°é‡
            'Ã—12', '*12', 'x12', 'Ã—24', '*24', 'x24', 'Ã—6', '*6', 'x6',
        ]
        
        products_upper = products.upper()
        for keyword in large_item_keywords:
            if keyword.upper() in products_upper:
                tips.append("ğŸ“¦è®¢å•å«å¤§è§„æ ¼å•†å“ï¼Œè¯·æ£€æŸ¥é‡é‡åŠ ä»·é…ç½®")
                break
    
    # 3. è¿œè·ç¦»æ£€æµ‹ï¼ˆå•ä½å·²è½¬æ¢ä¸ºkmï¼Œé˜ˆå€¼5kmï¼‰
    if distance_km > 5:
        tips.append(f"ğŸš—é…é€è·ç¦»è¾ƒè¿œ({distance_km:.2f}km)ï¼Œæ£€æŸ¥è¿œè·ç¦»é…é€è´¹")
    
    # 4. é»˜è®¤æç¤º
    if not tips:
        tips.append("ğŸ“‹è¯·æ£€æŸ¥é…é€è´¹è®¾ç½®")
    
    return 'ï¼›'.join(tips)


def get_stockout_products(df: pd.DataFrame) -> pd.DataFrame:
    """
    è·å–çƒ­é”€ç¼ºè´§å•†å“è¯¦æƒ…
    
    åˆ¤æ–­æ ‡å‡†ï¼š
    - æœ‰åº“å­˜å­—æ®µï¼šè¿‘Nå¤©æœ‰é”€é‡ ä¸” æ˜¨æ—¥å‰©ä½™åº“å­˜=0
    - æ— åº“å­˜å­—æ®µï¼šå‰æ—¥é”€é‡>=3 ä¸” æ˜¨æ—¥é”€é‡=0
    
    è‡ªé€‚åº”æ•°æ®å¤©æ•°ï¼š
    - å¦‚æœæ•°æ®>=7å¤©ï¼Œä½¿ç”¨7å¤©ç»Ÿè®¡
    - å¦‚æœæ•°æ®<7å¤©ï¼Œä½¿ç”¨æ‰€æœ‰å¯ç”¨å¤©æ•°
    - å¦‚æœæ•°æ®åªæœ‰1å¤©ï¼Œä½¿ç”¨å•æ—¥æ•°æ®
    
    æ–°å¢å­—æ®µï¼š
    - ä¸€çº§åˆ†ç±»åã€ä¸‰çº§åˆ†ç±»åã€åº—å†…ç 
    - æ€»åˆ©æ¶¦é¢ã€æ€»åˆ©æ¶¦ç‡ï¼ˆä»å…¨é‡æ•°æ®è®¡ç®—ï¼‰
    """
    if df is None or df.empty:
        return pd.DataFrame()
    
    try:
        date_col = 'æ—¥æœŸ' if 'æ—¥æœŸ' in df.columns else 'ä¸‹å•æ—¶é—´'
        sales_col = 'æœˆå”®' if 'æœˆå”®' in df.columns else 'é”€é‡'
        stock_col = next((c for c in ['å‰©ä½™åº“å­˜', 'åº“å­˜'] if c in df.columns), None)
        
        df = df.copy()
        df[date_col] = pd.to_datetime(df[date_col])
        
        # è·å–æ•°æ®çš„æ—¥æœŸèŒƒå›´
        max_date = df[date_col].max().normalize()
        min_date = df[date_col].min().normalize()
        data_days = (max_date - min_date).days + 1
        
        # è‡ªé€‚åº”ç»Ÿè®¡å¤©æ•°
        if data_days >= 7:
            stat_days = 7
            start_date = max_date - timedelta(days=6)
        elif data_days >= 2:
            stat_days = data_days
            start_date = min_date
        else:
            # åªæœ‰1å¤©æ•°æ®ï¼Œæ— æ³•åˆ¤æ–­ç¼ºè´§
            return pd.DataFrame()
        
        yesterday = max_date
        yesterday_df = df[df[date_col].dt.normalize() == yesterday]
        period_df = df[(df[date_col].dt.normalize() >= start_date) & (df[date_col].dt.normalize() <= yesterday)]
        
        if period_df.empty or sales_col not in df.columns:
            return pd.DataFrame()
        
        # ç»Ÿè®¡æœŸé—´é”€é‡ - ä½¿ç”¨åº—å†…ç ä½œä¸ºèšåˆkey
        group_key = get_product_group_key(period_df)
        
        agg_dict = {sales_col: 'sum', 'å•†å“åç§°': 'first'}  # ä¿ç•™å•†å“åç§°ç”¨äºå±•ç¤º
        
        # æ·»åŠ åˆ†ç±»å­—æ®µ
        if 'ä¸€çº§åˆ†ç±»å' in period_df.columns:
            agg_dict['ä¸€çº§åˆ†ç±»å'] = 'first'
        if 'ä¸‰çº§åˆ†ç±»å' in period_df.columns:
            agg_dict['ä¸‰çº§åˆ†ç±»å'] = 'first'
        
        period_sales = period_df.groupby(group_key).agg(agg_dict).reset_index()
        if group_key != 'å•†å“åç§°':
            period_sales = period_sales.rename(columns={group_key: 'åº—å†…ç '})
        period_sales.rename(columns={sales_col: f'{stat_days}å¤©é”€é‡'}, inplace=True)
        
        # ç¡®å®šåç»­mergeç”¨çš„key
        merge_key = 'åº—å†…ç ' if 'åº—å†…ç ' in period_sales.columns else 'å•†å“åç§°'
        
        # ========== è®¡ç®—ä¸»æ¸ é“ï¼ˆé”€é‡æœ€é«˜çš„æ¸ é“ï¼‰ ==========
        channel_col = next((c for c in ['æ¸ é“', 'å¹³å°', 'channel'] if c in period_df.columns), None)
        if channel_col:
            # æŒ‰å•†å“+æ¸ é“ç»Ÿè®¡é”€é‡
            product_channel_sales = period_df.groupby([group_key, channel_col])[sales_col].sum().reset_index()
            # å–æ¯ä¸ªå•†å“é”€é‡æœ€é«˜çš„æ¸ é“
            idx = product_channel_sales.groupby(group_key)[sales_col].idxmax()
            main_channel = product_channel_sales.loc[idx][[group_key, channel_col]].copy()
            main_channel.columns = [merge_key, 'ä¸»æ¸ é“']
            period_sales = period_sales.merge(main_channel, on=merge_key, how='left')
        
        # ========== è®¡ç®—å»ºè®®è¡¥è´§æ•°é‡ï¼ˆæ—¥å‡é”€é‡ Ã— 3å¤©å®‰å…¨åº“å­˜ï¼Œå‘ä¸Šå–æ•´ç¡®ä¿è‡³å°‘è¡¥1ï¼‰ ==========
        import math
        daily_avg = period_sales[f'{stat_days}å¤©é”€é‡'] / stat_days
        period_sales['å»ºè®®è¡¥è´§'] = daily_avg.apply(lambda x: max(1, math.ceil(x * 3)))
        
        # ========== è®¡ç®—å…¨é‡æ•°æ®çš„æ€»åˆ©æ¶¦é¢å’Œæ€»åˆ©æ¶¦ç‡ ==========
        profit_col = 'åˆ©æ¶¦é¢' if 'åˆ©æ¶¦é¢' in df.columns else None
        cost_col = next((c for c in ['å•†å“é‡‡è´­æˆæœ¬', 'æˆæœ¬'] if c in df.columns), None)
        price_col = next((c for c in ['å®æ”¶ä»·æ ¼', 'å•†å“å®å”®ä»·'] if c in df.columns), None)
        
        if profit_col:
            # è®¡ç®—æ¯ä¸ªå•†å“çš„æ€»åˆ©æ¶¦ï¼ˆä½¿ç”¨ç›¸åŒçš„èšåˆkeyï¼‰
            product_profit = df.groupby(group_key).agg({
                profit_col: 'sum'
            }).reset_index()
            product_profit.columns = [merge_key, 'æ€»åˆ©æ¶¦é¢']
            product_profit['æ€»åˆ©æ¶¦é¢'] = product_profit['æ€»åˆ©æ¶¦é¢'].round(2)
            
            # åˆå¹¶æ€»åˆ©æ¶¦é¢
            period_sales = period_sales.merge(product_profit, on=merge_key, how='left')
            
            # è®¡ç®—æ€»åˆ©æ¶¦ç‡
            if cost_col and price_col and sales_col in df.columns:
                # è®¡ç®—æ€»é”€å”®é¢å’Œæ€»æˆæœ¬
                product_financials = df.groupby(group_key).agg({
                    price_col: lambda x: (x * df.loc[x.index, sales_col]).sum(),
                    cost_col: lambda x: (x * df.loc[x.index, sales_col]).sum()
                }).reset_index()
                product_financials.columns = [merge_key, '_æ€»é”€å”®é¢', '_æ€»æˆæœ¬']
                
                # åˆ©æ¶¦ç‡ = æ€»åˆ©æ¶¦é¢ / æ€»é”€å”®é¢
                period_sales = period_sales.merge(product_financials, on=merge_key, how='left')
                period_sales['æ€»åˆ©æ¶¦ç‡'] = period_sales.apply(
                    lambda row: f"{(row['æ€»åˆ©æ¶¦é¢'] / row['_æ€»é”€å”®é¢'] * 100):.1f}%" 
                    if row.get('_æ€»é”€å”®é¢', 0) > 0 else "0%", axis=1
                )
                # åˆ é™¤ä¸´æ—¶åˆ—
                period_sales = period_sales.drop(columns=['_æ€»é”€å”®é¢', '_æ€»æˆæœ¬'], errors='ignore')
        
        # ========== ç­›é€‰ç¼ºè´§å•†å“ ==========
        if stock_col and not yesterday_df.empty:
            # æœ‰åº“å­˜å­—æ®µï¼šä½¿ç”¨åº“å­˜é€»è¾‘
            yesterday_stock = yesterday_df.groupby(group_key)[stock_col].first().reset_index()
            yesterday_stock.columns = [merge_key, 'æ˜¨æ—¥åº“å­˜']
            
            # åˆå¹¶
            comparison = period_sales.merge(yesterday_stock, on=merge_key, how='left')
            comparison['æ˜¨æ—¥åº“å­˜'] = comparison['æ˜¨æ—¥åº“å­˜'].fillna(-1)
            
            # ç­›é€‰ï¼šæœ‰é”€é‡ ä¸” æ˜¨æ—¥åº“å­˜=0
            stockout = comparison[(comparison[f'{stat_days}å¤©é”€é‡'] > 0) & (comparison['æ˜¨æ—¥åº“å­˜'] == 0)].copy()
        else:
            # æ²¡æœ‰åº“å­˜å­—æ®µï¼šå›é€€åˆ°é”€é‡é€»è¾‘
            if stat_days >= 2:
                day_before = yesterday - timedelta(days=1)
                day_before_df = df[df[date_col].dt.normalize() == day_before]
                
                if day_before_df.empty:
                    return pd.DataFrame()
                
                day_before_sales = day_before_df.groupby('å•†å“åç§°')[sales_col].sum().reset_index()
                day_before_sales.columns = ['å•†å“åç§°', 'å‰æ—¥é”€é‡']
                
                yesterday_sales = yesterday_df.groupby('å•†å“åç§°')[sales_col].sum().reset_index()
                yesterday_sales.columns = ['å•†å“åç§°', 'æ˜¨æ—¥é”€é‡']
                
                comparison = period_sales.merge(day_before_sales, on='å•†å“åç§°', how='left')
                comparison = comparison.merge(yesterday_sales, on='å•†å“åç§°', how='left')
                comparison['å‰æ—¥é”€é‡'] = comparison['å‰æ—¥é”€é‡'].fillna(0)
                comparison['æ˜¨æ—¥é”€é‡'] = comparison['æ˜¨æ—¥é”€é‡'].fillna(0)
                
                stockout = comparison[(comparison['å‰æ—¥é”€é‡'] >= 3) & (comparison['æ˜¨æ—¥é”€é‡'] == 0)].copy()
            else:
                return pd.DataFrame()
        
        if stockout.empty:
            return pd.DataFrame()
        
        # ===== è¿‡æ»¤è€—æåˆ†ç±» =====
        if 'ä¸€çº§åˆ†ç±»å' in stockout.columns:
            stockout = stockout[stockout['ä¸€çº§åˆ†ç±»å'] != 'è€—æ'].copy()
        
        if stockout.empty:
            return pd.DataFrame()
        
        # æ’åº
        sort_col = f'{stat_days}å¤©é”€é‡' if f'{stat_days}å¤©é”€é‡' in stockout.columns else 'å‰æ—¥é”€é‡'
        if sort_col in stockout.columns:
            stockout = stockout.sort_values(sort_col, ascending=False)
        
        # æ•´ç†åˆ—é¡ºåºï¼ˆç§»é™¤æ—¥å‡é”€é‡ï¼‰
        priority_cols = ['å•†å“åç§°', 'ä¸€çº§åˆ†ç±»å', 'ä¸‰çº§åˆ†ç±»å', 'åº—å†…ç ', 'ä¸»æ¸ é“',
                        f'{stat_days}å¤©é”€é‡', 'å»ºè®®è¡¥è´§', 'æ˜¨æ—¥åº“å­˜',
                        'æ€»åˆ©æ¶¦é¢', 'æ€»åˆ©æ¶¦ç‡']
        final_cols = [c for c in priority_cols if c in stockout.columns]
        # æ·»åŠ å…¶ä»–åˆ—
        other_cols = [c for c in stockout.columns if c not in final_cols]
        final_cols.extend(other_cols)
        
        return stockout[final_cols]
    except Exception as e:
        print(f"get_stockout_products é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return pd.DataFrame()


def get_traffic_drop_products(df: pd.DataFrame) -> pd.DataFrame:
    """
    è·å–æµé‡ä¸‹è·Œå•†å“è¯¦æƒ…ï¼ˆ7æ—¥ vs 7æ—¥å¯¹æ¯”ï¼‰
    
    åˆ¤æ–­æ ‡å‡†ï¼š
    - å‰7å¤©æ—¥å‡é”€é‡ >= 2ï¼ˆç¡®ä¿æœ‰ç¨³å®šé”€é‡ï¼‰
    - è·Œå¹… > 20%ï¼ˆ(å‰7å¤©æ—¥å‡ - è¿‘7å¤©æ—¥å‡) / å‰7å¤©æ—¥å‡ï¼‰
    
    æ–°å¢å­—æ®µï¼ˆå¯¹é½çƒ­é”€ç¼ºè´§ï¼‰ï¼š
    - ä¸€çº§åˆ†ç±»åã€ä¸‰çº§åˆ†ç±»åã€åº—å†…ç 
    - ä¸»æ¸ é“ï¼ˆå‰7å¤©é”€é‡æœ€é«˜çš„æ¸ é“ï¼‰
    - æ€»åˆ©æ¶¦é¢ã€æ€»åˆ©æ¶¦ç‡
    """
    if df is None or df.empty:
        return pd.DataFrame()
    
    try:
        date_col = 'æ—¥æœŸ' if 'æ—¥æœŸ' in df.columns else 'ä¸‹å•æ—¶é—´'
        sales_col = 'æœˆå”®' if 'æœˆå”®' in df.columns else 'é”€é‡'
        
        df = df.copy()
        df[date_col] = pd.to_datetime(df[date_col])
        
        # è·å–æ•°æ®èŒƒå›´
        max_date = df[date_col].max().normalize()
        min_date = df[date_col].min().normalize()
        data_days = (max_date - min_date).days + 1
        
        # éœ€è¦è‡³å°‘14å¤©æ•°æ®
        if data_days < 14:
            return pd.DataFrame()
        
        yesterday = max_date
        
        # å®šä¹‰æ—¶é—´çª—å£
        recent_7d_start = yesterday - timedelta(days=6)  # æœ€è¿‘7å¤©ï¼ˆå«æ˜¨æ—¥ï¼‰
        prev_7d_start = yesterday - timedelta(days=13)   # å‰7å¤©å¼€å§‹
        prev_7d_end = yesterday - timedelta(days=7)      # å‰7å¤©ç»“æŸ
        
        recent_7d_df = df[(df[date_col].dt.normalize() >= recent_7d_start) & (df[date_col].dt.normalize() <= yesterday)]
        prev_7d_df = df[(df[date_col].dt.normalize() >= prev_7d_start) & (df[date_col].dt.normalize() <= prev_7d_end)]
        
        if prev_7d_df.empty or sales_col not in df.columns:
            return pd.DataFrame()
        
        # ========== ç¡®å®šèšåˆkeyï¼ˆä¼˜å…ˆä½¿ç”¨åº—å†…ç ï¼‰ ==========
        group_key = get_product_group_key(prev_7d_df)
        
        # ========== å‰7å¤©ç»Ÿè®¡ ==========
        agg_dict = {sales_col: 'sum'}
        
        # æ·»åŠ å•†å“åç§°ä½œä¸ºæ˜¾ç¤ºå­—æ®µ
        if 'å•†å“åç§°' in prev_7d_df.columns and group_key != 'å•†å“åç§°':
            agg_dict['å•†å“åç§°'] = 'first'
        
        # æ·»åŠ åˆ†ç±»å­—æ®µ
        if 'ä¸€çº§åˆ†ç±»å' in prev_7d_df.columns:
            agg_dict['ä¸€çº§åˆ†ç±»å'] = 'first'
        if 'ä¸‰çº§åˆ†ç±»å' in prev_7d_df.columns:
            agg_dict['ä¸‰çº§åˆ†ç±»å'] = 'first'
        if 'åº—å†…ç ' in prev_7d_df.columns and group_key != 'åº—å†…ç ':
            agg_dict['åº—å†…ç '] = 'first'
        
        prev_sales = prev_7d_df.groupby(group_key).agg(agg_dict).reset_index()
        prev_sales.rename(columns={sales_col: 'å‰7å¤©é”€é‡'}, inplace=True)
        prev_sales['å‰7å¤©æ—¥å‡'] = (prev_sales['å‰7å¤©é”€é‡'] / 7).round(1)
        
        # ========== æœ€è¿‘7å¤©ç»Ÿè®¡ ==========
        recent_agg = {sales_col: 'sum'}
        recent_sales = recent_7d_df.groupby(group_key).agg(recent_agg).reset_index()
        recent_sales.columns = [group_key, 'è¿‘7å¤©é”€é‡']
        recent_sales['è¿‘7å¤©æ—¥å‡'] = (recent_sales['è¿‘7å¤©é”€é‡'] / 7).round(1)
        
        # ========== è®¡ç®—ä¸»æ¸ é“ï¼ˆå‰7å¤©é”€é‡æœ€é«˜çš„æ¸ é“ï¼‰ ==========
        channel_col = next((c for c in ['æ¸ é“', 'å¹³å°', 'channel'] if c in prev_7d_df.columns), None)
        if channel_col:
            product_channel_sales = prev_7d_df.groupby([group_key, channel_col])[sales_col].sum().reset_index()
            idx = product_channel_sales.groupby(group_key)[sales_col].idxmax()
            main_channel = product_channel_sales.loc[idx][[group_key, channel_col]].copy()
            main_channel.columns = [group_key, 'ä¸»æ¸ é“']
            prev_sales = prev_sales.merge(main_channel, on=group_key, how='left')
        
        # ========== è®¡ç®—å…¨é‡æ•°æ®çš„æ€»åˆ©æ¶¦é¢å’Œæ€»åˆ©æ¶¦ç‡ ==========
        profit_col = 'åˆ©æ¶¦é¢' if 'åˆ©æ¶¦é¢' in df.columns else None
        price_col = next((c for c in ['å®æ”¶ä»·æ ¼', 'å•†å“å®å”®ä»·'] if c in df.columns), None)
        
        if profit_col:
            product_profit = df.groupby(group_key)[profit_col].sum().reset_index()
            product_profit.columns = [group_key, 'æ€»åˆ©æ¶¦é¢']
            product_profit['æ€»åˆ©æ¶¦é¢'] = product_profit['æ€»åˆ©æ¶¦é¢'].round(2)
            prev_sales = prev_sales.merge(product_profit, on=group_key, how='left')
            
            # è®¡ç®—æ€»åˆ©æ¶¦ç‡
            if price_col and sales_col in df.columns:
                product_revenue = df.groupby(group_key).apply(
                    lambda x: (x[price_col] * x[sales_col]).sum()
                ).reset_index()
                product_revenue.columns = [group_key, '_æ€»é”€å”®é¢']
                prev_sales = prev_sales.merge(product_revenue, on=group_key, how='left')
                prev_sales['æ€»åˆ©æ¶¦ç‡'] = prev_sales.apply(
                    lambda row: f"{(row['æ€»åˆ©æ¶¦é¢'] / row['_æ€»é”€å”®é¢'] * 100):.1f}%" 
                    if row.get('_æ€»é”€å”®é¢', 0) > 0 else "0%", axis=1
                )
                prev_sales = prev_sales.drop(columns=['_æ€»é”€å”®é¢'], errors='ignore')
        
        # ========== åˆå¹¶å¹¶è®¡ç®—è·Œå¹… ==========
        comparison = prev_sales.merge(recent_sales, on=group_key, how='left')
        comparison['è¿‘7å¤©æ—¥å‡'] = comparison['è¿‘7å¤©æ—¥å‡'].fillna(0)
        comparison['è¿‘7å¤©é”€é‡'] = comparison['è¿‘7å¤©é”€é‡'].fillna(0)
        
        # è®¡ç®—è·Œå¹…ï¼ˆæ­£æ•°è¡¨ç¤ºä¸‹è·Œï¼Œè´Ÿæ•°è¡¨ç¤ºä¸Šæ¶¨ï¼Œä¸ä¼ ç»Ÿç†è§£ä¸€è‡´ï¼‰
        # ä½†ä¸ºäº†å›è°ƒå‡½æ•°ä¸­æ­£ç¡®æ˜¾ç¤ºï¼Œè¿™é‡Œæ”¹ä¸ºï¼šè¿‘æœŸ-å‰æœŸï¼ˆè´Ÿæ•°=ä¸‹è·Œï¼‰
        comparison['è·Œå¹…'] = ((comparison['è¿‘7å¤©æ—¥å‡'] - comparison['å‰7å¤©æ—¥å‡']) / comparison['å‰7å¤©æ—¥å‡'] * 100).round(1)
        
        # ========== ç­›é€‰ï¼šå‰7å¤©æ—¥å‡>=2 ä¸” è·Œå¹…<-20%ï¼ˆè´Ÿæ•°=ä¸‹è·Œï¼‰ ==========
        drop_products = comparison[(comparison['å‰7å¤©æ—¥å‡'] >= 2) & (comparison['è·Œå¹…'] < -20)].copy()
        
        if drop_products.empty:
            return pd.DataFrame()
        
        # ===== è¿‡æ»¤è€—æåˆ†ç±» =====
        if 'ä¸€çº§åˆ†ç±»å' in drop_products.columns:
            drop_products = drop_products[drop_products['ä¸€çº§åˆ†ç±»å'] != 'è€—æ'].copy()
        
        if drop_products.empty:
            return pd.DataFrame()
        
        # æŒ‰è·Œå¹…æ’åº
        drop_products = drop_products.sort_values('è·Œå¹…', ascending=False)
        
        # æ•´ç†åˆ—é¡ºåºï¼ˆå¯¹é½çƒ­é”€ç¼ºè´§ï¼‰
        priority_cols = ['å•†å“åç§°', 'ä¸€çº§åˆ†ç±»å', 'ä¸‰çº§åˆ†ç±»å', 'åº—å†…ç ', 'ä¸»æ¸ é“',
                        'å‰7å¤©æ—¥å‡', 'è¿‘7å¤©æ—¥å‡', 'è·Œå¹…',
                        'æ€»åˆ©æ¶¦é¢', 'æ€»åˆ©æ¶¦ç‡']
        final_cols = [c for c in priority_cols if c in drop_products.columns]
        other_cols = [c for c in drop_products.columns if c not in final_cols]
        final_cols.extend(other_cols)
        
        return drop_products[final_cols]
        
    except Exception as e:
        print(f"get_traffic_drop_products é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return pd.DataFrame()


def get_slow_moving_products(df: pd.DataFrame) -> pd.DataFrame:
    """è·å–æ»é”€å•†å“è¯¦æƒ…ï¼ˆç²¾ç¡®åŒ¹é… - çŠ¶æ€å˜åŒ–ç‚¹ï¼‰
    
    åªåœ¨å•†å“"åˆšè¿›å…¥"æŸä¸ªæ»é”€çŠ¶æ€æ—¶æ˜¾ç¤ºï¼Œé¿å…æ¯å¤©é‡å¤
    - ğŸ†• æ–°å¢é£é™©ï¼šåˆšæ»¡3å¤©æ— é”€é‡ï¼ˆä»Šå¤©åˆšè¿›å…¥é£é™©æœŸï¼‰
    - âš ï¸ æŒç»­æ»é”€ï¼šåˆšæ»¡7å¤©æ— é”€é‡ï¼ˆä»Šå¤©å‡çº§ä¸ºæŒç»­æ»é”€ï¼‰
    - ğŸ”´ ä¸¥é‡æ»é”€ï¼šåˆšæ»¡15å¤©æ— é”€é‡ï¼ˆä»Šå¤©å‡çº§ä¸ºä¸¥é‡æ»é”€ï¼‰
    
    æ³¨ï¼šåº“å­˜=0çš„ä¸ç®—æ»é”€ï¼ˆå¯èƒ½æ˜¯ç¼ºè´§/ä¸‹æ¶ï¼‰
    """
    if df is None or df.empty:
        return pd.DataFrame()
    
    try:
        date_col = 'æ—¥æœŸ' if 'æ—¥æœŸ' in df.columns else 'ä¸‹å•æ—¶é—´'
        sales_col = 'æœˆå”®' if 'æœˆå”®' in df.columns else 'é”€é‡'
        stock_col = next((c for c in ['å‰©ä½™åº“å­˜', 'åº“å­˜'] if c in df.columns), None)
        
        df = df.copy()
        df[date_col] = pd.to_datetime(df[date_col])
        yesterday = df[date_col].max().normalize()
        
        # æ„å»ºèšåˆå­—å…¸
        agg_dict = {date_col: 'max', sales_col: 'sum'}
        if 'å•†å“åç§°' in df.columns:
            agg_dict['å•†å“åç§°'] = 'first'
        if 'ä¸€çº§åˆ†ç±»å' in df.columns:
            agg_dict['ä¸€çº§åˆ†ç±»å'] = 'first'
        if 'ä¸‰çº§åˆ†ç±»å' in df.columns:
            agg_dict['ä¸‰çº§åˆ†ç±»å'] = 'first'
        if 'å•†å“é‡‡è´­æˆæœ¬' in df.columns:
            agg_dict['å•†å“é‡‡è´­æˆæœ¬'] = 'mean'
        if stock_col:
            agg_dict[stock_col] = 'last'
        
        # ç¡®å®šèšåˆkeyï¼ˆä¼˜å…ˆä½¿ç”¨åº—å†…ç ï¼‰
        group_key = get_product_group_key(df)
        
        # è®¡ç®—æ¯ä¸ªå•†å“çš„æœ€åé”€å”®æ—¥æœŸå’Œæœ€æ–°åº“å­˜
        product_stats = df.sort_values(date_col).groupby(group_key).agg(agg_dict).reset_index()
        product_stats['æ— é”€é‡å¤©æ•°'] = (yesterday - product_stats[date_col].dt.normalize()).dt.days
        
        # è·å–åº“å­˜
        if stock_col:
            product_stats['åº“å­˜'] = product_stats[stock_col].fillna(0)
        else:
            product_stats['åº“å­˜'] = 1  # æ²¡æœ‰åº“å­˜å­—æ®µæ—¶å‡å®šæœ‰è´§
        
        results = []
        
        for _, row in product_stats.iterrows():
            days_no_sales = row['æ— é”€é‡å¤©æ•°']
            stock = row['åº“å­˜']
            
            # æ ¸å¿ƒæ¡ä»¶ï¼šåº“å­˜>0 æ‰ç®—æ»é”€
            if stock <= 0:
                continue
            
            level = None
            # ç²¾ç¡®åŒ¹é…çŠ¶æ€å˜åŒ–ç‚¹
            if days_no_sales == 3:
                level = 'ğŸ†• æ–°å¢é£é™©'
            elif days_no_sales == 7:
                level = 'âš ï¸ æŒç»­æ»é”€'
            elif days_no_sales == 15:
                level = 'ğŸ”´ ä¸¥é‡æ»é”€'
            
            if level:
                # ä»rowä¸­è·å–å­—æ®µï¼ˆä½¿ç”¨group_keyç¡®å®šå•†å“æ ‡è¯†ï¼‰
                product_name = row.get('å•†å“åç§°', '') if 'å•†å“åç§°' in row.index else ''
                if not product_name and group_key == 'å•†å“åç§°':
                    product_name = row.name if hasattr(row, 'name') else ''
                
                category1 = row.get('ä¸€çº§åˆ†ç±»å', '') if 'ä¸€çº§åˆ†ç±»å' in row.index else ''
                category3 = row.get('ä¸‰çº§åˆ†ç±»å', '') if 'ä¸‰çº§åˆ†ç±»å' in row.index else ''
                cost = row.get('å•†å“é‡‡è´­æˆæœ¬', 0) if 'å•†å“é‡‡è´­æˆæœ¬' in row.index else 0
                
                # è·å–åº—å†…ç 
                store_code = ''
                if group_key == 'åº—å†…ç ':
                    store_code = str(row[group_key]) if pd.notna(row[group_key]) else ''
                elif 'åº—å†…ç ' in row.index and pd.notna(row.get('åº—å†…ç ')):
                    store_code = str(row['åº—å†…ç '])
                
                # è®¡ç®—æœ€åé”€å”®æ—¥æœŸ
                last_sale_date = row[date_col].strftime('%Y-%m-%d') if pd.notna(row[date_col]) else ''
                
                results.append({
                    'åº—å†…ç ': store_code,
                    'å•†å“åç§°': row['å•†å“åç§°'],
                    'ä¸€çº§åˆ†ç±»': category1 if pd.notna(category1) else '',
                    'ä¸‰çº§åˆ†ç±»': category3 if pd.notna(category3) else '',
                    'æ»é”€ç­‰çº§': level,
                    'æœ€åé”€å”®æ—¥': last_sale_date,
                    'æ— é”€é‡å¤©æ•°': int(days_no_sales),
                    'åº“å­˜': int(stock),
                    'ç§¯å‹æˆæœ¬': round(cost * stock, 2) if pd.notna(cost) else 0
                })
        
        result_df = pd.DataFrame(results)
        if not result_df.empty:
            level_order = {'ğŸ”´ ä¸¥é‡æ»é”€': 0, 'âš ï¸ æŒç»­æ»é”€': 1, 'ğŸ†• æ–°å¢é£é™©': 2}
            result_df['æ’åº'] = result_df['æ»é”€ç­‰çº§'].map(level_order)
            result_df = result_df.sort_values(['æ’åº', 'æ— é”€é‡å¤©æ•°'], ascending=[True, False]).drop(columns=['æ’åº'])
        
        return result_df
    except Exception as e:
        print(f"get_slow_moving_products é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return pd.DataFrame()


def get_new_products(df: pd.DataFrame) -> pd.DataFrame:
    """è·å–æ˜¨æ—¥é¦–é”€å•†å“è¯¦æƒ…
    
    é¦–é”€å®šä¹‰ï¼šæ˜¨æ—¥æœ‰é”€é‡ + è¿‡å»7å¤©æ— é”€é‡ï¼ˆæ²‰å¯‚åå¤æ´»ï¼‰
    æŒ‰æ²‰å¯‚å¤©æ•°åˆ†çº§ï¼š
    - ğŸŸ¢ çŸ­æœŸæ²‰å¯‚ï¼š7-14å¤©æ— é”€é‡åå¤æ´»
    - ğŸŸ¡ ä¸­æœŸæ²‰å¯‚ï¼š15-30å¤©æ— é”€é‡åå¤æ´»
    - ğŸ”´ é•¿æœŸæ²‰å¯‚ï¼š30å¤©ä»¥ä¸Šæ— é”€é‡åå¤æ´»
    """
    if df is None or df.empty:
        return pd.DataFrame()
    
    try:
        date_col = 'æ—¥æœŸ' if 'æ—¥æœŸ' in df.columns else 'ä¸‹å•æ—¶é—´'
        sales_col = 'æœˆå”®' if 'æœˆå”®' in df.columns else 'é”€é‡'
        
        df = df.copy()
        df[date_col] = pd.to_datetime(df[date_col])
        yesterday = df[date_col].max().normalize()
        check_start = yesterday - timedelta(days=7)
        
        yesterday_df = df[df[date_col].dt.normalize() == yesterday]
        
        if yesterday_df.empty:
            return pd.DataFrame()
        
        # ç¡®å®šèšåˆkeyï¼ˆä¼˜å…ˆä½¿ç”¨åº—å†…ç ï¼‰
        group_key = get_product_group_key(df)
        
        # æ˜¨æ—¥æœ‰é”€å”®çš„å•†å“
        yesterday_products = set(yesterday_df[group_key].unique())
        
        # è¿‡å»7å¤©ï¼ˆä¸å«æ˜¨æ—¥ï¼‰æœ‰é”€é‡çš„å•†å“
        past_7d_df = df[(df[date_col].dt.normalize() >= check_start) & (df[date_col].dt.normalize() < yesterday)]
        past_7d_products = set(past_7d_df[group_key].unique()) if not past_7d_df.empty else set()
        
        # æ˜¨æ—¥é¦–é”€ = æ˜¨æ—¥æœ‰é”€é‡ ä¸” è¿‡å»7å¤©æ— é”€é‡
        first_sale_products = yesterday_products - past_7d_products
        
        if not first_sale_products:
            return pd.DataFrame()
        
        # è®¡ç®—æ¯ä¸ªå•†å“çš„ä¸Šæ¬¡é”€å”®æ—¥æœŸï¼ˆç”¨äºè®¡ç®—æ²‰å¯‚å¤©æ•°ï¼‰
        before_yesterday_df = df[df[date_col].dt.normalize() < yesterday]
        if not before_yesterday_df.empty:
            product_last_sale = before_yesterday_df.groupby(group_key)[date_col].max().reset_index()
            product_last_sale.columns = [group_key, 'ä¸Šæ¬¡é”€å”®æ—¥']
            product_last_sale['æ²‰å¯‚å¤©æ•°'] = (yesterday - product_last_sale['ä¸Šæ¬¡é”€å”®æ—¥'].dt.normalize()).dt.days
        else:
            product_last_sale = pd.DataFrame(columns=[group_key, 'ä¸Šæ¬¡é”€å”®æ—¥', 'æ²‰å¯‚å¤©æ•°'])
        
        # è·å–é¦–é”€å•†å“æ•°æ®
        new_df = yesterday_df[yesterday_df[group_key].isin(first_sale_products)].copy()
        
        # è®¡ç®—é”€å”®é¢ = å®æ”¶ä»·æ ¼ Ã— é”€é‡
        if 'å®æ”¶ä»·æ ¼' in new_df.columns and sales_col in new_df.columns:
            new_df['_å®æ”¶ä»·æ ¼_é”€é‡'] = new_df['å®æ”¶ä»·æ ¼'].fillna(0) * new_df[sales_col].fillna(1)
            sales_amount_col = '_å®æ”¶ä»·æ ¼_é”€é‡'
        elif 'å•†å“å®å”®ä»·' in new_df.columns:
            sales_amount_col = 'å•†å“å®å”®ä»·'
        else:
            sales_amount_col = None
        
        # æ„å»ºèšåˆå­—å…¸
        agg_dict = {sales_col: 'sum'}
        if sales_amount_col:
            agg_dict[sales_amount_col] = 'sum'
        if 'åˆ©æ¶¦é¢' in new_df.columns:
            agg_dict['åˆ©æ¶¦é¢'] = 'sum'
        # æ·»åŠ å•†å“åç§°ä½œä¸ºæ˜¾ç¤ºå­—æ®µ
        if 'å•†å“åç§°' in new_df.columns and group_key != 'å•†å“åç§°':
            agg_dict['å•†å“åç§°'] = 'first'
        if 'ä¸€çº§åˆ†ç±»å' in new_df.columns:
            agg_dict['ä¸€çº§åˆ†ç±»å'] = 'first'
        if 'ä¸‰çº§åˆ†ç±»å' in new_df.columns:
            agg_dict['ä¸‰çº§åˆ†ç±»å'] = 'first'
        if 'åº—å†…ç ' in new_df.columns and group_key != 'åº—å†…ç ':
            agg_dict['åº—å†…ç '] = 'first'
        
        # è®¡ç®—ä¸»è¦é”€å”®æ¸ é“
        channel_col = next((c for c in ['å¹³å°åç§°', 'å¹³å°', 'æ¸ é“'] if c in new_df.columns), None)
        if channel_col:
            agg_dict[channel_col] = lambda x: x.value_counts().index[0] if len(x) > 0 else ''
        
        product_stats = new_df.groupby(group_key).agg(agg_dict).reset_index()
        
        # æ„å»ºç»“æœ
        results = []
        for _, row in product_stats.iterrows():
            product_key = row[group_key]
            product_name = row.get('å•†å“åç§°', product_key) if 'å•†å“åç§°' in row.index else str(product_key)
            
            # è·å–åº—å†…ç 
            store_code = ''
            if group_key == 'åº—å†…ç ':
                store_code = str(product_key) if pd.notna(product_key) else ''
            elif 'åº—å†…ç ' in row.index and pd.notna(row.get('åº—å†…ç ')):
                store_code = str(row['åº—å†…ç '])
            
            # è·å–æ²‰å¯‚å¤©æ•°å¹¶åˆ†çº§
            silent_info = product_last_sale[product_last_sale[group_key] == product_key]
            if not silent_info.empty:
                silent_days = int(silent_info['æ²‰å¯‚å¤©æ•°'].values[0])
            else:
                silent_days = 999  # æ²¡æœ‰å†å²è®°å½•ï¼Œè§†ä¸ºé•¿æœŸæ²‰å¯‚
            
            # æŒ‰æ²‰å¯‚å¤©æ•°åˆ†çº§
            if silent_days <= 14:
                silent_level = 'ğŸŸ¢ çŸ­æœŸæ²‰å¯‚'
            elif silent_days <= 30:
                silent_level = 'ğŸŸ¡ ä¸­æœŸæ²‰å¯‚'
            else:
                silent_level = 'ğŸ”´ é•¿æœŸæ²‰å¯‚'
            
            # è®¡ç®—å®¢å•ä»·
            qty = int(row[sales_col]) if pd.notna(row[sales_col]) else 0
            # é”€å”®é¢ï¼šä¼˜å…ˆç”¨ å®æ”¶ä»·æ ¼Ã—é”€é‡ï¼Œå¤‡é€‰ç”¨å•†å“å®å”®ä»·
            if sales_amount_col and sales_amount_col in row.index:
                sales_amount = round(row.get(sales_amount_col, 0), 2) if pd.notna(row.get(sales_amount_col)) else 0
            else:
                sales_amount = 0
            avg_price = round(sales_amount / qty, 2) if qty > 0 else 0
            
            # åˆ©æ¶¦é¢
            profit = round(row.get('åˆ©æ¶¦é¢', 0), 2) if 'åˆ©æ¶¦é¢' in row.index and pd.notna(row.get('åˆ©æ¶¦é¢')) else 0
            
            result_row = {
                'åº—å†…ç ': store_code,
                'å•†å“åç§°': product_name,
                'æ²‰å¯‚ç­‰çº§': silent_level,
                'æ²‰å¯‚å¤©æ•°': silent_days if silent_days < 999 else '-',
                'ä¸€çº§åˆ†ç±»': row.get('ä¸€çº§åˆ†ç±»å', '') if 'ä¸€çº§åˆ†ç±»å' in row.index and pd.notna(row.get('ä¸€çº§åˆ†ç±»å')) else '',
                'ä¸‰çº§åˆ†ç±»': row.get('ä¸‰çº§åˆ†ç±»å', '') if 'ä¸‰çº§åˆ†ç±»å' in row.index and pd.notna(row.get('ä¸‰çº§åˆ†ç±»å')) else '',
                'é¦–æ—¥é”€é‡': qty,
                'é¦–æ—¥é”€å”®é¢': sales_amount,
                'é¦–æ—¥åˆ©æ¶¦': profit,
                'å®¢å•ä»·': avg_price,
                'ä¸»æ¸ é“': row.get(channel_col, '') if channel_col and channel_col in row.index else ''
            }
            results.append(result_row)
        
        result_df = pd.DataFrame(results)
        if not result_df.empty:
            result_df = result_df.sort_values('é¦–æ—¥é”€é‡', ascending=False)
        
        return result_df
    except Exception as e:
        print(f"get_new_products é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return pd.DataFrame()


def get_price_abnormal_products(df: pd.DataFrame, store_name: str = None) -> pd.DataFrame:
    """
    è·å–ä»·æ ¼å¼‚å¸¸å•†å“è¯¦æƒ…ï¼ˆæ˜¨æ—¥å”®ä»·ä½äºæˆæœ¬çš„è®¢å•è¡Œï¼‰
    
    å¼‚å¸¸ç­‰çº§åˆ†ç±»ï¼š
    - ğŸ”´ä¸¥é‡äºæŸ: å®æ”¶ä»·æ ¼ < æˆæœ¬Ã—0.8
    - ğŸŸ è½»åº¦äºæŸ: æˆæœ¬Ã—0.8 â‰¤ å®æ”¶ä»·æ ¼ < æˆæœ¬
    
    ä¸å¡ç‰‡ç»Ÿè®¡é€»è¾‘ä¿æŒä¸€è‡´ï¼šç­›é€‰æ˜¨æ—¥æ•°æ®ä¸­ å®æ”¶ä»·æ ¼ < å•†å“é‡‡è´­æˆæœ¬ çš„è®°å½•
    
    Args:
        df: è®¢å•æ•°æ®DataFrame
        store_name: é—¨åº—åç§°ç­›é€‰ï¼ˆå¯é€‰ï¼‰
    
    Returns:
        ä»·æ ¼å¼‚å¸¸å•†å“DataFrame
    """
    try:
        if df is None or df.empty:
            return pd.DataFrame()
        
        df_copy = df.copy()
        
        # é—¨åº—ç­›é€‰
        if store_name and store_name != 'å…¨éƒ¨é—¨åº—':
            store_col = next((c for c in ['é—¨åº—åç§°', 'é—¨åº—', 'store_name'] if c in df_copy.columns), None)
            if store_col:
                df_copy = df_copy[df_copy[store_col] == store_name]
        
        # æŸ¥æ‰¾æ—¥æœŸåˆ—å¹¶ç­›é€‰æ˜¨æ—¥æ•°æ®ï¼ˆä¸å¡ç‰‡ç»Ÿè®¡é€»è¾‘ä¸€è‡´ï¼‰
        date_col = next((c for c in ['æ—¥æœŸ', 'date', 'è®¢å•æ—¥æœŸ'] if c in df_copy.columns), None)
        if date_col:
            df_copy[date_col] = pd.to_datetime(df_copy[date_col], errors='coerce')
            max_date = df_copy[date_col].max()
            if pd.notna(max_date):
                # å…³é”®ï¼šä½¿ç”¨ normalize() å½’ä¸€åŒ–åˆ°æ—¥æœŸï¼Œä¸å¡ç‰‡ç»Ÿè®¡é€»è¾‘ä¿æŒä¸€è‡´
                yesterday = max_date.normalize()
                df_copy = df_copy[df_copy[date_col].dt.normalize() == yesterday]
        
        if df_copy.empty:
            print(f"get_price_abnormal_products: æ˜¨æ—¥æ•°æ®ä¸ºç©º")
            return pd.DataFrame()
        
        # æŸ¥æ‰¾å¿…è¦åˆ—
        price_col = next((c for c in ['å®æ”¶ä»·æ ¼', 'å•†å“å®å”®ä»·', 'å”®ä»·', 'price'] if c in df_copy.columns), None)
        cost_col = next((c for c in ['å•†å“é‡‡è´­æˆæœ¬', 'é‡‡è´­æˆæœ¬', 'æˆæœ¬', 'cost'] if c in df_copy.columns), None)
        product_col = next((c for c in ['å•†å“åç§°', 'å•†å“', 'product_name'] if c in df_copy.columns), None)
        code_col = next((c for c in ['åº—å†…ç ', 'å•†å“ç¼–ç ', 'sku'] if c in df_copy.columns), None)
        channel_col = next((c for c in ['è®¢å•æ¸ é“åç§°', 'æ¸ é“', 'channel'] if c in df_copy.columns), None)
        sales_col = next((c for c in ['æœˆå”®', 'é”€é‡', 'æ•°é‡', 'quantity'] if c in df_copy.columns), None)
        original_price_col = next((c for c in ['å•†å“åŸä»·', 'åŸä»·', 'original_price'] if c in df_copy.columns), None)
        
        if not price_col or not cost_col or not product_col:
            print(f"get_price_abnormal_products: ç¼ºå°‘å¿…è¦åˆ— price_col={price_col}, cost_col={cost_col}, product_col={product_col}")
            return pd.DataFrame()
        
        # æ¸…æ´—æ•°æ®
        df_copy[price_col] = pd.to_numeric(df_copy[price_col], errors='coerce').fillna(0)
        df_copy[cost_col] = pd.to_numeric(df_copy[cost_col], errors='coerce').fillna(0)
        if original_price_col:
            df_copy[original_price_col] = pd.to_numeric(df_copy[original_price_col], errors='coerce').fillna(0)
        if sales_col:
            df_copy[sales_col] = pd.to_numeric(df_copy[sales_col], errors='coerce').fillna(1)
            df_copy[sales_col] = df_copy[sales_col].replace(0, 1)  # é¿å…é™¤é›¶
        
        # å…³é”®ï¼šè®¡ç®—å•å“æˆæœ¬ = å•†å“é‡‡è´­æˆæœ¬ / æœˆå”®
        # å› ä¸ºåŸå§‹æ•°æ®ä¸­çš„å•†å“é‡‡è´­æˆæœ¬ = å•å“æˆæœ¬ Ã— æœˆå”®
        if sales_col:
            df_copy['_å•å“æˆæœ¬'] = df_copy[cost_col] / df_copy[sales_col]
        else:
            df_copy['_å•å“æˆæœ¬'] = df_copy[cost_col]
        
        # ç­›é€‰ï¼šå•å“æˆæœ¬>0 ä¸” ä»·æ ¼>0ï¼ˆæœ‰æ•ˆæ•°æ®ï¼‰ä¸” ä»·æ ¼<å•å“æˆæœ¬ï¼ˆäºæŸï¼‰
        valid_df = df_copy[(df_copy['_å•å“æˆæœ¬'] > 0) & (df_copy[price_col] > 0)].copy()
        abnormal_df = valid_df[valid_df[price_col] < valid_df['_å•å“æˆæœ¬']].copy()
        
        if abnormal_df.empty:
            return pd.DataFrame()
        
        # è®¡ç®—äºæŸé‡‘é¢ï¼ˆåŸºäºå•å“æˆæœ¬ï¼‰
        abnormal_df['å•ä½äºæŸ'] = abnormal_df['_å•å“æˆæœ¬'] - abnormal_df[price_col]
        if sales_col:
            abnormal_df['æ€»äºæŸ'] = abnormal_df['å•ä½äºæŸ'] * abnormal_df[sales_col]
        else:
            abnormal_df['æ€»äºæŸ'] = abnormal_df['å•ä½äºæŸ']
        
        # ç¡®å®šèšåˆkeyï¼ˆä¼˜å…ˆä½¿ç”¨åº—å†…ç ï¼‰
        group_key = get_product_group_key(abnormal_df)
        
        # æŒ‰å•†å“æ±‡æ€»ï¼ˆä½¿ç”¨åº—å†…ç èšåˆï¼‰
        agg_dict = {
            price_col: 'mean',
            '_å•å“æˆæœ¬': 'mean',  # ä½¿ç”¨å•å“æˆæœ¬è€ŒéåŸå§‹æˆæœ¬
            'å•ä½äºæŸ': 'mean',
            'æ€»äºæŸ': 'sum'
        }
        # æ·»åŠ å•†å“åç§°ä½œä¸ºæ˜¾ç¤ºå­—æ®µ
        if 'å•†å“åç§°' in abnormal_df.columns and group_key != 'å•†å“åç§°':
            agg_dict['å•†å“åç§°'] = 'first'
        if sales_col:
            agg_dict[sales_col] = 'sum'
        if original_price_col and original_price_col in abnormal_df.columns:
            agg_dict[original_price_col] = 'max'  # å•†å“åŸä»·å–æœ€é«˜å€¼
        if code_col and code_col in abnormal_df.columns and group_key != code_col:
            agg_dict[code_col] = 'first'
        if 'ä¸€çº§åˆ†ç±»å' in abnormal_df.columns:
            agg_dict['ä¸€çº§åˆ†ç±»å'] = 'first'
        if 'ä¸‰çº§åˆ†ç±»å' in abnormal_df.columns:
            agg_dict['ä¸‰çº§åˆ†ç±»å'] = 'first'
        if channel_col:
            agg_dict[channel_col] = 'first'
        
        product_stats = abnormal_df.groupby(group_key, as_index=False).agg(agg_dict)
        
        # åˆ†çº§ï¼šä¸¥é‡äºæŸï¼ˆå”®ä»·<å•å“æˆæœ¬Ã—0.8ï¼‰vs è½»åº¦äºæŸ
        def get_abnormal_level(row):
            if row[price_col] < row['_å•å“æˆæœ¬'] * 0.8:
                return 'ğŸ”´ä¸¥é‡äºæŸ'
            else:
                return 'ğŸŸ è½»åº¦äºæŸ'
        
        product_stats['å¼‚å¸¸ç­‰çº§'] = product_stats.apply(get_abnormal_level, axis=1)
        
        # è®¡ç®—æ¯›åˆ©ç‡
        # å®šä»·æ¯›åˆ©ç‡ = (å•†å“åŸä»· - å•å“æˆæœ¬) / å•†å“åŸä»· * 100%
        # å®æ”¶æ¯›åˆ©ç‡ = (å®æ”¶ä»·æ ¼ - å•å“æˆæœ¬) / å®æ”¶ä»·æ ¼ * 100%
        if original_price_col and original_price_col in product_stats.columns:
            product_stats['å®šä»·æ¯›åˆ©ç‡'] = np.where(
                product_stats[original_price_col] > 0,
                ((product_stats[original_price_col] - product_stats['_å•å“æˆæœ¬']) / product_stats[original_price_col] * 100).round(1),
                0
            )
        else:
            product_stats['å®šä»·æ¯›åˆ©ç‡'] = 0
        
        product_stats['å®æ”¶æ¯›åˆ©ç‡'] = np.where(
            product_stats[price_col] > 0,
            ((product_stats[price_col] - product_stats['_å•å“æˆæœ¬']) / product_stats[price_col] * 100).round(1),
            0
        )
        
        # æ•´ç†è¾“å‡º
        results = []
        for _, row in product_stats.iterrows():
            # è·å–åº—å†…ç 
            store_code = ''
            if group_key == 'åº—å†…ç ':
                store_code = str(row[group_key]) if pd.notna(row[group_key]) else ''
            elif code_col and code_col in row.index:
                store_code = str(row[code_col]) if pd.notna(row.get(code_col)) else ''
            
            # è·å–å•†å“åç§°
            product_name = row.get('å•†å“åç§°', '') if 'å•†å“åç§°' in row.index else ''
            if not product_name and group_key == 'å•†å“åç§°':
                product_name = str(row[group_key])
            
            result_row = {
                'åº—å†…ç ': store_code,
                'å•†å“åç§°': product_name,
                'å¼‚å¸¸ç­‰çº§': row['å¼‚å¸¸ç­‰çº§'],
                'å•†å“åŸä»·': round(row.get(original_price_col, 0), 2) if original_price_col and original_price_col in row.index else 0,
                'å®æ”¶ä»·æ ¼': round(row[price_col], 2),
                'å•å“æˆæœ¬': round(row['_å•å“æˆæœ¬'], 2),
                'å®šä»·æ¯›åˆ©ç‡': f"{row['å®šä»·æ¯›åˆ©ç‡']}%",
                'å®æ”¶æ¯›åˆ©ç‡': f"{row['å®æ”¶æ¯›åˆ©ç‡']}%",
                'å•ä½äºæŸ': round(row['å•ä½äºæŸ'], 2),
                'é¢„ä¼°æ€»äºæŸ': round(row['æ€»äºæŸ'], 2),
                'ä¸€çº§åˆ†ç±»': row.get('ä¸€çº§åˆ†ç±»å', '') if 'ä¸€çº§åˆ†ç±»å' in row.index else '',
                'ä¸‰çº§åˆ†ç±»': row.get('ä¸‰çº§åˆ†ç±»å', '') if 'ä¸‰çº§åˆ†ç±»å' in row.index else '',
            }
            if sales_col and sales_col in row.index:
                result_row['é”€é‡'] = int(row[sales_col])
            if channel_col and channel_col in row.index:
                result_row['ä¸»æ¸ é“'] = row[channel_col]
            results.append(result_row)
        
        result_df = pd.DataFrame(results)
        if not result_df.empty:
            # æŒ‰äºæŸé‡‘é¢æ’åº
            result_df = result_df.sort_values('é¢„ä¼°æ€»äºæŸ', ascending=False)
        
        return result_df
        
    except Exception as e:
        print(f"get_price_abnormal_products é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return pd.DataFrame()


def get_profit_rate_drop_products(df: pd.DataFrame, store_name: str = None) -> pd.DataFrame:
    """
    è·å–åˆ©æ¶¦ç‡ä¸‹æ»‘å•†å“è¯¦æƒ…ï¼ˆè¿‘7å¤©vså‰7å¤©ï¼Œä¸‹æ»‘>10ä¸ªç™¾åˆ†ç‚¹ï¼‰
    
    ä¸‹æ»‘ç­‰çº§åˆ†ç±»ï¼š
    - ğŸ”´æš´è·Œ: ä¸‹æ»‘>20ä¸ªç™¾åˆ†ç‚¹
    - ğŸŸ å¤§å¹…ä¸‹æ»‘: ä¸‹æ»‘10-20ä¸ªç™¾åˆ†ç‚¹
    
    ä¸å¡ç‰‡ç»Ÿè®¡é€»è¾‘ä¿æŒä¸€è‡´ï¼šé˜ˆå€¼ä¸ºä¸‹æ»‘è¶…è¿‡10ä¸ªç™¾åˆ†ç‚¹
    
    Args:
        df: è®¢å•æ•°æ®DataFrame
        store_name: é—¨åº—åç§°ç­›é€‰ï¼ˆå¯é€‰ï¼‰
    
    Returns:
        åˆ©æ¶¦ç‡ä¸‹æ»‘å•†å“DataFrame
    """
    try:
        if df is None or df.empty:
            return pd.DataFrame()
        
        df_copy = df.copy()
        
        # é—¨åº—ç­›é€‰
        if store_name and store_name != 'å…¨éƒ¨é—¨åº—':
            store_col = next((c for c in ['é—¨åº—åç§°', 'é—¨åº—', 'store_name'] if c in df_copy.columns), None)
            if store_col:
                df_copy = df_copy[df_copy[store_col] == store_name]
        
        # æŸ¥æ‰¾å¿…è¦åˆ—
        date_col = next((c for c in ['æ—¥æœŸ', 'date', 'è®¢å•æ—¥æœŸ'] if c in df_copy.columns), None)
        product_col = next((c for c in ['å•†å“åç§°', 'å•†å“', 'product_name'] if c in df_copy.columns), None)
        code_col = next((c for c in ['åº—å†…ç ', 'å•†å“ç¼–ç ', 'sku'] if c in df_copy.columns), None)
        price_col = next((c for c in ['å®æ”¶ä»·æ ¼', 'å•†å“å®å”®ä»·', 'å”®ä»·', 'price'] if c in df_copy.columns), None)
        sales_col = next((c for c in ['æœˆå”®', 'é”€é‡', 'æ•°é‡', 'quantity'] if c in df_copy.columns), None)
        channel_col = next((c for c in ['è®¢å•æ¸ é“åç§°', 'æ¸ é“', 'channel'] if c in df_copy.columns), None)
        cost_col = next((c for c in ['å•†å“é‡‡è´­æˆæœ¬', 'é‡‡è´­æˆæœ¬', 'æˆæœ¬', 'cost'] if c in df_copy.columns), None)
        original_price_col = next((c for c in ['å•†å“åŸä»·', 'åŸä»·', 'original_price'] if c in df_copy.columns), None)
        
        if not date_col or not product_col:
            print(f"get_profit_rate_drop_products: ç¼ºå°‘å¿…è¦åˆ— date_col={date_col}, product_col={product_col}")
            return pd.DataFrame()
        
        if 'åˆ©æ¶¦é¢' not in df_copy.columns:
            print("get_profit_rate_drop_products: ç¼ºå°‘åˆ©æ¶¦é¢åˆ—")
            return pd.DataFrame()
        
        # è½¬æ¢æ—¥æœŸ
        df_copy[date_col] = pd.to_datetime(df_copy[date_col], errors='coerce')
        df_copy = df_copy.dropna(subset=[date_col])
        
        if df_copy.empty:
            return pd.DataFrame()
        
        # è®¡ç®—æ—¶é—´æ®µï¼ˆä¸å¡ç‰‡ç»Ÿè®¡ä¸€è‡´ï¼‰- ä½¿ç”¨å½’ä¸€åŒ–æ—¥æœŸ
        max_date = df_copy[date_col].max().normalize()
        recent_start = max_date - pd.Timedelta(days=6)  # è¿‘7å¤©
        prev_start = recent_start - pd.Timedelta(days=7)  # å‰7å¤©å¼€å§‹
        prev_end = recent_start - pd.Timedelta(days=1)    # å‰7å¤©ç»“æŸ
        
        # åˆ’åˆ†æ•°æ® - ä½¿ç”¨å½’ä¸€åŒ–æ—¥æœŸæ¯”è¾ƒ
        df_copy['_date_norm'] = df_copy[date_col].dt.normalize()
        recent_df = df_copy[(df_copy['_date_norm'] >= recent_start) & (df_copy['_date_norm'] <= max_date)].copy()
        prev_df = df_copy[(df_copy['_date_norm'] >= prev_start) & (df_copy['_date_norm'] <= prev_end)].copy()
        
        if recent_df.empty or prev_df.empty:
            print(f"get_profit_rate_drop_products: æ—¶é—´æ®µæ•°æ®ä¸ºç©º recent={len(recent_df)}, prev={len(prev_df)}")
            return pd.DataFrame()
        
        # è®¡ç®—é”€å”®é¢ï¼ˆå®æ”¶ä»·æ ¼ Ã— é”€é‡ï¼‰
        if price_col and sales_col:
            recent_df[price_col] = pd.to_numeric(recent_df[price_col], errors='coerce').fillna(0)
            recent_df[sales_col] = pd.to_numeric(recent_df[sales_col], errors='coerce').fillna(0)
            recent_df['é”€å”®é¢'] = recent_df[price_col] * recent_df[sales_col]
            
            prev_df[price_col] = pd.to_numeric(prev_df[price_col], errors='coerce').fillna(0)
            prev_df[sales_col] = pd.to_numeric(prev_df[sales_col], errors='coerce').fillna(0)
            prev_df['é”€å”®é¢'] = prev_df[price_col] * prev_df[sales_col]
        else:
            print("get_profit_rate_drop_products: ç¼ºå°‘ä»·æ ¼æˆ–é”€é‡åˆ—")
            return pd.DataFrame()
        
        # è®¡ç®—å•å“æˆæœ¬ï¼ˆç”¨äºæ¯›åˆ©ç‡è®¡ç®—ï¼‰
        if cost_col and cost_col in recent_df.columns:
            recent_df[cost_col] = pd.to_numeric(recent_df[cost_col], errors='coerce').fillna(0)
            recent_df['_å•å“æˆæœ¬'] = recent_df[cost_col] / recent_df[sales_col].replace(0, 1)
        if original_price_col and original_price_col in recent_df.columns:
            recent_df[original_price_col] = pd.to_numeric(recent_df[original_price_col], errors='coerce').fillna(0)
        
        # ç¡®å®šèšåˆkeyï¼ˆä¼˜å…ˆä½¿ç”¨åº—å†…ç ï¼‰
        group_key = get_product_group_key(recent_df)
        
        # æŒ‰å•†å“æ±‡æ€»ï¼ˆä½¿ç”¨åº—å†…ç èšåˆï¼‰
        agg_dict = {'åˆ©æ¶¦é¢': 'sum', 'é”€å”®é¢': 'sum', price_col: 'mean'}
        # æ·»åŠ å•†å“åç§°ä½œä¸ºæ˜¾ç¤ºå­—æ®µ
        if 'å•†å“åç§°' in recent_df.columns and group_key != 'å•†å“åç§°':
            agg_dict['å•†å“åç§°'] = 'first'
        if sales_col:
            agg_dict[sales_col] = 'sum'
        if cost_col and '_å•å“æˆæœ¬' in recent_df.columns:
            agg_dict['_å•å“æˆæœ¬'] = 'mean'
        if original_price_col and original_price_col in recent_df.columns:
            agg_dict[original_price_col] = 'max'
        if code_col and code_col in recent_df.columns and group_key != code_col:
            agg_dict[code_col] = 'first'
        if 'ä¸€çº§åˆ†ç±»å' in df_copy.columns:
            agg_dict['ä¸€çº§åˆ†ç±»å'] = 'first'
        if 'ä¸‰çº§åˆ†ç±»å' in df_copy.columns:
            agg_dict['ä¸‰çº§åˆ†ç±»å'] = 'first'
        if channel_col:
            agg_dict[channel_col] = 'first'
        
        recent_stats = recent_df.groupby(group_key, as_index=False).agg(agg_dict)
        
        # å‰7å¤©åªéœ€è¦åˆ©æ¶¦ç‡ç›¸å…³å­—æ®µ
        prev_agg_dict = {'åˆ©æ¶¦é¢': 'sum', 'é”€å”®é¢': 'sum'}
        if sales_col:
            prev_agg_dict[sales_col] = 'sum'
        prev_stats = prev_df.groupby(group_key, as_index=False).agg(prev_agg_dict)
        
        # è®¡ç®—åˆ©æ¶¦ç‡ï¼ˆé¿å…é™¤é›¶ï¼Œå¹¶é™åˆ¶åœ¨åˆç†èŒƒå›´ -100% ~ 100%ï¼‰
        raw_recent_rate = np.where(
            recent_stats['é”€å”®é¢'] > 0,
            recent_stats['åˆ©æ¶¦é¢'] / recent_stats['é”€å”®é¢'] * 100,
            0
        )
        recent_stats['è¿‘7å¤©åˆ©æ¶¦ç‡'] = np.clip(raw_recent_rate, -100, 100)
        
        raw_prev_rate = np.where(
            prev_stats['é”€å”®é¢'] > 0,
            prev_stats['åˆ©æ¶¦é¢'] / prev_stats['é”€å”®é¢'] * 100,
            0
        )
        prev_stats['å‰7å¤©åˆ©æ¶¦ç‡'] = np.clip(raw_prev_rate, -100, 100)
        
        # åˆå¹¶å¯¹æ¯”
        # æ„å»ºåˆå¹¶åˆ—ï¼ˆåŒ…å«å‰7å¤©é”€é‡å’Œåˆ©æ¶¦é¢ï¼‰
        prev_merge_cols = [group_key, 'å‰7å¤©åˆ©æ¶¦ç‡', 'é”€å”®é¢', 'åˆ©æ¶¦é¢']
        if sales_col and sales_col in prev_stats.columns:
            prev_merge_cols.append(sales_col)
        merged = pd.merge(
            recent_stats, 
            prev_stats[prev_merge_cols], 
            on=group_key, 
            how='inner', 
            suffixes=('', '_prev')
        )
        
        # è®¡ç®—å˜åŒ–ï¼ˆä¸‹æ»‘å¹…åº¦ï¼‰
        merged['åˆ©æ¶¦ç‡å˜åŒ–'] = merged['è¿‘7å¤©åˆ©æ¶¦ç‡'] - merged['å‰7å¤©åˆ©æ¶¦ç‡']
        
        # ç­›é€‰ä¸‹æ»‘å•†å“ï¼ˆä¸‹æ»‘è¶…è¿‡5ä¸ªç™¾åˆ†ç‚¹ï¼Œä¼˜åŒ–åçš„é˜ˆå€¼ï¼‰
        drop_df = merged[merged['åˆ©æ¶¦ç‡å˜åŒ–'] < -5].copy()
        
        if drop_df.empty:
            return pd.DataFrame()
        
        # åˆ†çº§ï¼ˆä¼˜åŒ–åçš„4æ¡£é˜ˆå€¼ï¼‰
        def get_drop_level(change):
            if change < -20:
                return 'ğŸ”´ä¸¥é‡ä¸‹æ»‘'
            elif change < -15:
                return 'ğŸŸ å¤§å¹…ä¸‹æ»‘'
            elif change < -10:
                return 'ğŸŸ¡ä¸­åº¦ä¸‹æ»‘'
            else:
                return 'ğŸŸ¢è½»å¾®ä¸‹æ»‘'
        
        drop_df['ä¸‹æ»‘ç­‰çº§'] = drop_df['åˆ©æ¶¦ç‡å˜åŒ–'].apply(get_drop_level)
        
        # æ•´ç†è¾“å‡ºï¼ˆç²¾ç®€å­—æ®µï¼‰
        results = []
        for _, row in drop_df.iterrows():
            # è·å–åº—å†…ç 
            store_code = ''
            if group_key == 'åº—å†…ç ':
                store_code = str(row[group_key]) if pd.notna(row[group_key]) else ''
            elif code_col and code_col in row.index:
                store_code = str(row[code_col]) if pd.notna(row.get(code_col)) else ''
            
            # è·å–å•†å“åç§°
            product_name = row.get('å•†å“åç§°', '') if 'å•†å“åç§°' in row.index else ''
            if not product_name and group_key == 'å•†å“åç§°':
                product_name = str(row[group_key])
            
            result_row = {
                'åº—å†…ç ': store_code,
                'å•†å“åç§°': product_name,
                'ä¸‹æ»‘ç­‰çº§': row['ä¸‹æ»‘ç­‰çº§'],
                'å‰7å¤©åˆ©æ¶¦ç‡': f"{round(row['å‰7å¤©åˆ©æ¶¦ç‡'], 1)}%",
                'è¿‘7å¤©åˆ©æ¶¦ç‡': f"{round(row['è¿‘7å¤©åˆ©æ¶¦ç‡'], 1)}%",
                'ä¸‹æ»‘å¹…åº¦': f"{round(row['åˆ©æ¶¦ç‡å˜åŒ–'], 1)}%",
                'å‰7å¤©åˆ©æ¶¦é¢': round(row.get('åˆ©æ¶¦é¢_prev', 0), 2),
                'è¿‘7å¤©åˆ©æ¶¦é¢': round(row['åˆ©æ¶¦é¢'], 2),
                'å‰7å¤©é”€å”®é¢': round(row.get('é”€å”®é¢_prev', 0), 2),
                'è¿‘7å¤©é”€å”®é¢': round(row['é”€å”®é¢'], 2),
            }
            # æ·»åŠ é”€é‡å­—æ®µ
            if sales_col and f'{sales_col}_prev' in row.index:
                result_row['å‰7å¤©é”€é‡'] = int(row[f'{sales_col}_prev'])
            if sales_col and sales_col in row.index:
                result_row['è¿‘7å¤©é”€é‡'] = int(row[sales_col])
            if channel_col and channel_col in row.index:
                result_row['ä¸»æ¸ é“'] = row[channel_col]
            if 'ä¸€çº§åˆ†ç±»å' in row.index:
                result_row['ä¸€çº§åˆ†ç±»'] = row.get('ä¸€çº§åˆ†ç±»å', '')
            results.append(result_row)
        
        result_df = pd.DataFrame(results)
        if not result_df.empty:
            # æŒ‰ä¸‹æ»‘ç¨‹åº¦æ’åºï¼ˆå˜åŒ–å€¼è¶Šå°æ’è¶Šå‰ï¼‰
            result_df = result_df.sort_values('ä¸‹æ»‘å¹…åº¦', key=lambda x: x.str.rstrip('%').astype(float), ascending=True)
        
        return result_df
        
    except Exception as e:
        print(f"get_profit_rate_drop_products é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return pd.DataFrame()


def get_hot_products(df: pd.DataFrame, store_name: str = None) -> pd.DataFrame:
    """
    è·å–çˆ†æ¬¾å•†å“è¯¦æƒ…ï¼ˆæ˜¨æ—¥é”€é‡çªå¢çš„å•†å“ï¼‰
    
    çˆ†æ¬¾åˆ¤æ–­æ ‡å‡†ï¼š
    - æ˜¨æ—¥é”€é‡ç¯æ¯”å¢é•¿>50%
    - æ˜¨æ—¥é”€é‡>=10
    
    Args:
        df: è®¢å•æ•°æ®DataFrame
        store_name: é—¨åº—åç§°ç­›é€‰ï¼ˆå¯é€‰ï¼‰
    
    Returns:
        çˆ†æ¬¾å•†å“DataFrame
    """
    try:
        if df is None or df.empty:
            return pd.DataFrame()
        
        df_copy = df.copy()
        
        # é—¨åº—ç­›é€‰
        if store_name and store_name != 'å…¨éƒ¨é—¨åº—':
            store_col = next((c for c in ['é—¨åº—åç§°', 'é—¨åº—', 'store_name'] if c in df_copy.columns), None)
            if store_col:
                df_copy = df_copy[df_copy[store_col] == store_name]
        
        # æŸ¥æ‰¾å¿…è¦åˆ—
        date_col = next((c for c in ['æ—¥æœŸ', 'date', 'è®¢å•æ—¥æœŸ'] if c in df_copy.columns), None)
        product_col = next((c for c in ['å•†å“åç§°', 'å•†å“', 'product_name'] if c in df_copy.columns), None)
        code_col = next((c for c in ['åº—å†…ç ', 'å•†å“ç¼–ç ', 'sku'] if c in df_copy.columns), None)
        price_col = next((c for c in ['å®æ”¶ä»·æ ¼', 'å•†å“å®å”®ä»·', 'å”®ä»·', 'price'] if c in df_copy.columns), None)
        sales_col = next((c for c in ['æœˆå”®', 'é”€é‡', 'æ•°é‡', 'quantity'] if c in df_copy.columns), None)
        channel_col = next((c for c in ['è®¢å•æ¸ é“åç§°', 'æ¸ é“', 'channel'] if c in df_copy.columns), None)
        category_col = next((c for c in ['ä¸€çº§åˆ†ç±»å', 'ä¸€çº§åˆ†ç±»'] if c in df_copy.columns), None)
        
        if not date_col or not product_col:
            return pd.DataFrame()
        
        # è½¬æ¢æ—¥æœŸ
        df_copy[date_col] = pd.to_datetime(df_copy[date_col], errors='coerce')
        df_copy = df_copy.dropna(subset=[date_col])
        
        if df_copy.empty:
            return pd.DataFrame()
        
        # è®¡ç®—æ—¶é—´æ®µ
        yesterday = df_copy[date_col].max().normalize()
        day_before = yesterday - pd.Timedelta(days=1)
        
        # åˆ’åˆ†æ•°æ®
        yesterday_df = df_copy[df_copy[date_col].dt.normalize() == yesterday].copy()
        day_before_df = df_copy[df_copy[date_col].dt.normalize() == day_before].copy()
        
        if yesterday_df.empty or day_before_df.empty:
            return pd.DataFrame()
        
        # æ¸…æ´—æ•°æ®
        if sales_col:
            yesterday_df[sales_col] = pd.to_numeric(yesterday_df[sales_col], errors='coerce').fillna(0)
            day_before_df[sales_col] = pd.to_numeric(day_before_df[sales_col], errors='coerce').fillna(0)
        if price_col:
            yesterday_df[price_col] = pd.to_numeric(yesterday_df[price_col], errors='coerce').fillna(0)
        
        # è®¡ç®—é”€å”®é¢
        if price_col and sales_col:
            yesterday_df['_é”€å”®é¢'] = yesterday_df[price_col] * yesterday_df[sales_col]
        else:
            yesterday_df['_é”€å”®é¢'] = 0
        
        # ç¡®å®šèšåˆkeyï¼ˆä¼˜å…ˆä½¿ç”¨åº—å†…ç ï¼‰
        group_key = get_product_group_key(yesterday_df)
        
        # æŒ‰å•†å“æ±‡æ€»æ˜¨æ—¥æ•°æ®
        agg_dict = {}
        if sales_col:
            agg_dict[sales_col] = 'sum'
        agg_dict['_é”€å”®é¢'] = 'sum'
        if 'åˆ©æ¶¦é¢' in yesterday_df.columns:
            agg_dict['åˆ©æ¶¦é¢'] = 'sum'
        if price_col:
            agg_dict[price_col] = 'mean'
        # æ·»åŠ å•†å“åç§°ä½œä¸ºæ˜¾ç¤ºå­—æ®µ
        if 'å•†å“åç§°' in yesterday_df.columns and group_key != 'å•†å“åç§°':
            agg_dict['å•†å“åç§°'] = 'first'
        if code_col and code_col in yesterday_df.columns and group_key != code_col:
            agg_dict[code_col] = 'first'
        if category_col and category_col in yesterday_df.columns:
            agg_dict[category_col] = 'first'
        if channel_col and channel_col in yesterday_df.columns:
            agg_dict[channel_col] = 'first'
        
        yesterday_stats = yesterday_df.groupby(group_key, as_index=False).agg(agg_dict)
        
        # å‰æ—¥é”€é‡
        prev_agg = {sales_col: 'sum'} if sales_col else {}
        day_before_stats = day_before_df.groupby(group_key, as_index=False).agg(prev_agg) if sales_col else pd.DataFrame()
        if not day_before_stats.empty:
            day_before_stats = day_before_stats.rename(columns={sales_col: 'å‰æ—¥é”€é‡'})
        
        # åˆå¹¶
        merged = yesterday_stats.merge(day_before_stats, on=group_key, how='left')
        merged['å‰æ—¥é”€é‡'] = merged['å‰æ—¥é”€é‡'].fillna(0)
        
        # è®¡ç®—å¢é•¿ç‡
        merged['å¢é•¿ç‡'] = merged.apply(
            lambda x: round(((x[sales_col] - x['å‰æ—¥é”€é‡']) / x['å‰æ—¥é”€é‡'] * 100), 1) if x['å‰æ—¥é”€é‡'] > 0 else (999.9 if x[sales_col] > 0 else 0),
            axis=1
        )
        
        # ç­›é€‰çˆ†æ¬¾ï¼šå¢é•¿ç‡>50% ä¸” æ˜¨æ—¥é”€é‡>=10
        hot_mask = (merged['å¢é•¿ç‡'] > 50) & (merged[sales_col] >= 10)
        
        # è¿‡æ»¤è€—æ
        if category_col and category_col in merged.columns:
            hot_mask = hot_mask & (merged[category_col] != 'è€—æ')
        
        hot_df = merged[hot_mask].copy()
        
        if hot_df.empty:
            return pd.DataFrame()
        
        # æŒ‰å¢é•¿ç‡æ’åº
        hot_df = hot_df.sort_values('å¢é•¿ç‡', ascending=False)
        
        # æ•´ç†è¾“å‡º
        results = []
        for _, row in hot_df.iterrows():
            growth_display = f"+{row['å¢é•¿ç‡']}%" if row['å¢é•¿ç‡'] < 999 else "æ–°çˆ†å‘"
            
            # è·å–åº—å†…ç 
            store_code = ''
            if group_key == 'åº—å†…ç ':
                store_code = str(row[group_key]) if pd.notna(row[group_key]) else ''
            elif code_col and code_col in row.index:
                store_code = str(row[code_col]) if pd.notna(row.get(code_col)) else ''
            
            # è·å–å•†å“åç§°
            product_name = row.get('å•†å“åç§°', '') if 'å•†å“åç§°' in row.index else ''
            if not product_name and group_key == 'å•†å“åç§°':
                product_name = str(row[group_key])
            
            result_row = {
                'åº—å†…ç ': store_code,
                'å•†å“åç§°': product_name,
                'çˆ†æ¬¾ç­‰çº§': 'è¶…çº§çˆ†æ¬¾' if row['å¢é•¿ç‡'] > 200 else ('çƒ­é”€' if row['å¢é•¿ç‡'] > 100 else 'å¢é•¿'),
                'æ˜¨æ—¥é”€é‡': int(row[sales_col]),
                'å‰æ—¥é”€é‡': int(row['å‰æ—¥é”€é‡']),
                'å¢é•¿ç‡': growth_display,
                'æ˜¨æ—¥é”€å”®é¢': round(row['_é”€å”®é¢'], 2),
                'æ˜¨æ—¥åˆ©æ¶¦': round(row.get('åˆ©æ¶¦é¢', 0), 2) if 'åˆ©æ¶¦é¢' in row.index else 0,
                'ä¸€çº§åˆ†ç±»': row.get(category_col, '') if category_col and category_col in row.index else '',
            }
            if channel_col and channel_col in row.index:
                result_row['ä¸»æ¸ é“'] = row[channel_col]
            results.append(result_row)
        
        return pd.DataFrame(results)
        
    except Exception as e:
        print(f"get_hot_products é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return pd.DataFrame()


# ==================== ä»·æ ¼å˜åŠ¨æ£€æµ‹ä¸å¼¹æ€§åˆ†æ ====================

def detect_price_changes_from_orders(df: pd.DataFrame, price_threshold: float = 0.05) -> pd.DataFrame:
    """
    ä»é€æ—¥è®¢å•æ•°æ®ä¸­æ£€æµ‹ä»·æ ¼å˜åŠ¨ï¼ˆåŸä»·+å”®ä»·äº¤å‰åˆ¤æ–­ï¼‰
    
    æ ¸å¿ƒé€»è¾‘ï¼š
    1. æŒ‰ åº—å†…ç +æ¸ é“+æ—¥æœŸ èšåˆï¼Œè·å–æ¯æ—¥åŸä»·å’Œå”®ä»·å¿«ç…§
    2. æ£€æµ‹åŸä»·æˆ–å”®ä»·çš„å˜åŠ¨ï¼ˆè¶…è¿‡é˜ˆå€¼ï¼‰
    3. åˆ¤æ–­è°ƒä»·ç±»å‹ï¼šä¸»åŠ¨è°ƒä»· vs ä¿ƒé”€æ´»åŠ¨
    4. è®¡ç®—è°ƒä»·å‰å7å¤©çš„é”€é‡ã€é”€å”®é¢ã€åˆ©æ¶¦å˜åŒ–
    
    âš ï¸ é‡è¦ï¼šä½¿ç”¨åº—å†…ç ï¼ˆè€Œéå•†å“åç§°ï¼‰åŒºåˆ†å•†å“ï¼Œé¿å…åŒåä¸åŒè§„æ ¼æ··æ·†
    âš ï¸ é‡è¦ï¼šæŒ‰æ¸ é“åˆ†åˆ«åˆ†æï¼Œå› ä¸ºä¸åŒå¹³å°å®šä»·ç­–ç•¥ä¸åŒ
    
    äº¤å‰åˆ¤æ–­é€»è¾‘ï¼š
    - åŸä»·+å”®ä»·éƒ½å˜ â†’ "ä¸»åŠ¨è°ƒä»·"ï¼ˆé—¨åº—è°ƒæ•´äº†å•†å“å®šä»·ï¼‰
    - ä»…å”®ä»·å˜ â†’ "ä¿ƒé”€/æ´»åŠ¨"ï¼ˆä¸´æ—¶æŠ˜æ‰£æˆ–ä¿ƒé”€ç»“æŸï¼‰
    - ä»…åŸä»·å˜ â†’ "æ ‡ä»·è°ƒæ•´"ï¼ˆå°‘è§ï¼Œå¯å¿½ç•¥ï¼‰
    
    Args:
        df: è®¢å•æ•°æ®DataFrame
        price_threshold: ä»·æ ¼å˜åŠ¨é˜ˆå€¼ï¼Œé»˜è®¤5%
    
    Returns:
        ä»·æ ¼å˜åŠ¨è®°å½•DataFrame
    """
    if df is None or df.empty:
        return pd.DataFrame()
    
    try:
        # 1. è¯†åˆ«å­—æ®µ
        date_col = 'æ—¥æœŸ' if 'æ—¥æœŸ' in df.columns else 'ä¸‹å•æ—¶é—´'
        # åŸä»·å­—æ®µ
        original_price_col = next((c for c in ['å•†å“åŸä»·', 'åŸä»·'] if c in df.columns), None)
        # å”®ä»·å­—æ®µï¼ˆå®å”®ä»·ï¼‰
        selling_price_col = next((c for c in ['å•†å“å®å”®ä»·', 'å”®ä»·'] if c in df.columns), None)
        # å®æ”¶ä»·æ ¼ï¼ˆç”¨äºè®¡ç®—é”€å”®é¢ï¼‰
        received_price_col = 'å®æ”¶ä»·æ ¼' if 'å®æ”¶ä»·æ ¼' in df.columns else selling_price_col
        # åˆ©æ¶¦å­—æ®µ
        profit_col = 'åˆ©æ¶¦é¢' if 'åˆ©æ¶¦é¢' in df.columns else None
        sales_col = 'æœˆå”®' if 'æœˆå”®' in df.columns else 'é”€é‡'
        
        # åˆ†ç±»å­—æ®µ
        category1_col = next((c for c in ['ä¸€çº§åˆ†ç±»å', 'ä¸€çº§åˆ†ç±»'] if c in df.columns), None)
        category3_col = next((c for c in ['ä¸‰çº§åˆ†ç±»å', 'ä¸‰çº§åˆ†ç±»'] if c in df.columns), None)
        
        # â­ å•†å“å”¯ä¸€æ ‡è¯†ï¼šä¼˜å…ˆç”¨åº—å†…ç ï¼Œå…¶æ¬¡æ¡ç 
        code_col = next((c for c in ['åº—å†…ç ', 'æ¡ç ', 'å•†å“ç¼–ç ', 'SKU'] if c in df.columns), None)
        
        # â­ æ¸ é“å­—æ®µ
        channel_col = next((c for c in ['æ¸ é“', 'å¹³å°', 'é…é€å¹³å°'] if c in df.columns), None)
        
        # åº“å­˜å­—æ®µ
        stock_col = next((c for c in ['å‰©ä½™åº“å­˜', 'åº“å­˜', 'å½“å‰åº“å­˜'] if c in df.columns), None)
        
        # è‡³å°‘éœ€è¦ä¸€ä¸ªä»·æ ¼å­—æ®µ
        if not original_price_col and not selling_price_col:
            print("detect_price_changes: ç¼ºå°‘ä»·æ ¼å­—æ®µï¼ˆéœ€è¦å•†å“åŸä»·æˆ–å•†å“å®å”®ä»·ï¼‰")
            return pd.DataFrame()
        if date_col not in df.columns:
            print("detect_price_changes: ç¼ºå°‘æ—¥æœŸå­—æ®µ")
            return pd.DataFrame()
        
        # éœ€è¦å•†å“æ ‡è¯†å­—æ®µ
        if not code_col:
            print("detect_price_changes: ç¼ºå°‘å•†å“æ ‡è¯†å­—æ®µï¼ˆåº—å†…ç /æ¡ç ï¼‰ï¼Œå°†ä½¿ç”¨å•†å“åç§°")
            code_col = 'å•†å“åç§°'
        
        df = df.copy()
        df[date_col] = pd.to_datetime(df[date_col])
        df['_æ—¥æœŸ'] = df[date_col].dt.date
        
        # å¡«å……æ¸ é“ç©ºå€¼
        if channel_col and channel_col in df.columns:
            df[channel_col] = df[channel_col].fillna('æœªçŸ¥æ¸ é“')
        else:
            df['_æ¸ é“'] = 'å…¨æ¸ é“'
            channel_col = '_æ¸ é“'
        
        # è®¡ç®—é”€å”®é¢ï¼ˆå®æ”¶ä»·æ ¼ Ã— é”€é‡ï¼‰
        if received_price_col and received_price_col in df.columns:
            df['_é”€å”®é¢'] = df[received_price_col].fillna(0) * df[sales_col].fillna(1)
        elif selling_price_col:
            df['_é”€å”®é¢'] = df[selling_price_col].fillna(0) * df[sales_col].fillna(1)
        else:
            df['_é”€å”®é¢'] = 0
        
        # 2. æŒ‰ åº—å†…ç +æ¸ é“+æ—¥æœŸ èšåˆï¼ˆæ ¸å¿ƒæ”¹åŠ¨ï¼ï¼‰
        group_cols = [code_col, channel_col, '_æ—¥æœŸ']
        
        agg_dict = {
            sales_col: 'sum',
            '_é”€å”®é¢': 'sum',
            'å•†å“åç§°': 'first',  # ä¿ç•™å•†å“åç§°ç”¨äºå±•ç¤º
        }
        if original_price_col:
            agg_dict[original_price_col] = 'mean'
        if selling_price_col:
            agg_dict[selling_price_col] = 'mean'
        if profit_col:
            agg_dict[profit_col] = 'sum'
        if category1_col:
            agg_dict[category1_col] = 'first'
        if category3_col:
            agg_dict[category3_col] = 'first'
        if stock_col:
            agg_dict[stock_col] = 'last'
        
        daily_data = df.groupby(group_cols).agg(agg_dict).reset_index()
        daily_data = daily_data.rename(columns={
            code_col: 'åº—å†…ç ',
            channel_col: 'æ¸ é“',
            '_æ—¥æœŸ': 'æ—¥æœŸ',
            sales_col: 'é”€é‡',
            '_é”€å”®é¢': 'é”€å”®é¢',
            original_price_col: 'åŸä»·' if original_price_col else None,
            selling_price_col: 'å”®ä»·' if selling_price_col else None,
            profit_col: 'åˆ©æ¶¦é¢' if profit_col else None,
            category1_col: 'ä¸€çº§åˆ†ç±»' if category1_col else None,
            category3_col: 'ä¸‰çº§åˆ†ç±»' if category3_col else None,
            stock_col: 'åº“å­˜' if stock_col else None
        })
        # ç§»é™¤Noneé”®
        daily_data = daily_data.loc[:, daily_data.columns.notna()]
        daily_data = daily_data.sort_values(['åº—å†…ç ', 'æ¸ é“', 'æ—¥æœŸ'])
        
        # 3. æ£€æµ‹ä»·æ ¼å˜åŠ¨ï¼ˆæŒ‰ åº—å†…ç +æ¸ é“ åˆ†ç»„ï¼‰
        price_changes = []
        
        for (code, channel), group_data in daily_data.groupby(['åº—å†…ç ', 'æ¸ é“']):
            product_data = group_data.copy()
            
            if len(product_data) < 2:
                continue
            
            # è®¡ç®—åŸä»·å’Œå”®ä»·çš„å˜åŒ–ç‡
            if 'åŸä»·' in product_data.columns:
                product_data['åŸä»·_å‰'] = product_data['åŸä»·'].shift(1)
                product_data['åŸä»·å˜åŒ–ç‡'] = (product_data['åŸä»·'] - product_data['åŸä»·_å‰']) / product_data['åŸä»·_å‰']
            else:
                product_data['åŸä»·å˜åŒ–ç‡'] = 0
                
            if 'å”®ä»·' in product_data.columns:
                product_data['å”®ä»·_å‰'] = product_data['å”®ä»·'].shift(1)
                product_data['å”®ä»·å˜åŒ–ç‡'] = (product_data['å”®ä»·'] - product_data['å”®ä»·_å‰']) / product_data['å”®ä»·_å‰']
            else:
                product_data['å”®ä»·å˜åŒ–ç‡'] = 0
            
            # æ‰¾åˆ°ä»·æ ¼è·³å˜ç‚¹ï¼ˆåŸä»·æˆ–å”®ä»·å˜åŠ¨è¶…è¿‡é˜ˆå€¼ï¼‰
            changes = product_data[
                (abs(product_data['åŸä»·å˜åŒ–ç‡']) > price_threshold) |
                (abs(product_data['å”®ä»·å˜åŒ–ç‡']) > price_threshold)
            ]
            
            for idx, row in changes.iterrows():
                change_date = row['æ—¥æœŸ']
                
                # è·å–å˜åŠ¨å‰å7å¤©çš„æ•°æ®
                prev_data = product_data[product_data['æ—¥æœŸ'] < change_date].tail(7)
                post_data = product_data[product_data['æ—¥æœŸ'] >= change_date].head(7)
                
                if len(prev_data) < 3 or len(post_data) < 3:
                    continue
                
                # ===== é”€é‡è®¡ç®— =====
                prev_avg_qty = prev_data['é”€é‡'].mean()
                post_avg_qty = post_data['é”€é‡'].mean()
                
                if prev_avg_qty == 0:
                    continue
                
                qty_change_rate = (post_avg_qty - prev_avg_qty) / prev_avg_qty
                
                # ===== é”€å”®é¢è®¡ç®— =====
                prev_total_revenue = prev_data['é”€å”®é¢'].sum() if 'é”€å”®é¢' in prev_data.columns else 0
                post_total_revenue = post_data['é”€å”®é¢'].sum() if 'é”€å”®é¢' in post_data.columns else 0
                revenue_change_rate = (post_total_revenue - prev_total_revenue) / prev_total_revenue if prev_total_revenue > 0 else 0
                
                # ===== åˆ©æ¶¦é¢è®¡ç®— =====
                prev_total_profit = prev_data['åˆ©æ¶¦é¢'].sum() if 'åˆ©æ¶¦é¢' in prev_data.columns else 0
                post_total_profit = post_data['åˆ©æ¶¦é¢'].sum() if 'åˆ©æ¶¦é¢' in post_data.columns else 0
                profit_change_rate = (post_total_profit - prev_total_profit) / abs(prev_total_profit) if prev_total_profit != 0 else 0
                
                # ===== æ¯›åˆ©ç‡è®¡ç®— =====
                prev_margin_rate = (prev_total_profit / prev_total_revenue * 100) if prev_total_revenue > 0 else 0
                post_margin_rate = (post_total_profit / post_total_revenue * 100) if post_total_revenue > 0 else 0
                margin_change = post_margin_rate - prev_margin_rate  # æ¯›åˆ©ç‡å˜åŒ–ï¼ˆç™¾åˆ†ç‚¹ï¼‰
                
                # ===== åº“å­˜çŠ¶æ€åˆ¤æ–­ =====
                # è·å–è°ƒä»·åæœŸé—´çš„æœ€ååº“å­˜
                last_stock = post_data['åº“å­˜'].iloc[-1] if 'åº“å­˜' in post_data.columns else None
                # åˆ¤æ–­æ˜¯å¦å”®ç½„ï¼ˆåº“å­˜=0ï¼‰
                is_stockout = last_stock is not None and last_stock == 0
                
                # åˆ¤æ–­è°ƒä»·ç±»å‹
                orig_changed = abs(row.get('åŸä»·å˜åŒ–ç‡', 0)) > price_threshold
                sell_changed = abs(row.get('å”®ä»·å˜åŒ–ç‡', 0)) > price_threshold
                
                if orig_changed and sell_changed:
                    change_type = "ä¸»åŠ¨è°ƒä»·"
                elif sell_changed:
                    change_type = "ä¿ƒé”€/æ´»åŠ¨"
                elif orig_changed:
                    change_type = "æ ‡ä»·è°ƒæ•´"
                else:
                    change_type = "æœªçŸ¥"
                
                # å–ä¸»è¦çš„ä»·æ ¼å˜åŒ–ç‡ï¼ˆä¼˜å…ˆå”®ä»·ï¼Œå› ä¸ºå®ƒåæ˜ å®é™…é”€å”®ä»·æ ¼ï¼‰
                main_price_change = row.get('å”®ä»·å˜åŒ–ç‡', 0) if sell_changed else row.get('åŸä»·å˜åŒ–ç‡', 0)
                
                # è·å–å•†å“åç§°ï¼ˆä»èšåˆæ•°æ®ä¸­ï¼‰
                product_name = row.get('å•†å“åç§°', '') if 'å•†å“åç§°' in row.index else str(code)
                
                record = {
                    'ä¸€çº§åˆ†ç±»': row.get('ä¸€çº§åˆ†ç±»', '') if row.get('ä¸€çº§åˆ†ç±»') else '',
                    'åº—å†…ç ': code,  # ä½¿ç”¨åˆ†ç»„çš„åº—å†…ç 
                    'å•†å“åç§°': product_name,
                    'æ¸ é“': channel,  # â­ æ–°å¢æ¸ é“å­—æ®µ
                    'å˜åŠ¨æ—¥æœŸ': change_date,
                    'è°ƒä»·ç±»å‹': change_type,
                    'åŸä»·å˜åŠ¨': f"{row.get('åŸä»·_å‰', 0):.1f}â†’{row.get('åŸä»·', 0):.1f}" if 'åŸä»·' in row.index else '-',
                    'å”®ä»·å˜åŠ¨': f"{row.get('å”®ä»·_å‰', 0):.1f}â†’{row.get('å”®ä»·', 0):.1f}" if 'å”®ä»·' in row.index else '-',
                    'ä»·æ ¼å˜åŒ–ç‡': round(main_price_change * 100, 1),
                    # é”€é‡ï¼ˆæ—¥å‡ï¼‰
                    'è°ƒä»·å‰7æ—¥å‡é”€é‡': round(prev_avg_qty, 1),
                    'è°ƒä»·å7æ—¥å‡é”€é‡': round(post_avg_qty, 1),
                    'é”€é‡å˜åŒ–ç‡': round(qty_change_rate * 100, 1),
                    # é”€å”®é¢ï¼ˆ7æ—¥æ€»è®¡ï¼‰
                    'è°ƒä»·å‰7æ—¥é”€å”®é¢': round(prev_total_revenue, 1),
                    'è°ƒä»·å7æ—¥é”€å”®é¢': round(post_total_revenue, 1),
                    'é”€å”®é¢å˜åŒ–ç‡': round(revenue_change_rate * 100, 1),
                    # åˆ©æ¶¦é¢ï¼ˆ7æ—¥æ€»è®¡ï¼‰
                    'è°ƒä»·å‰7æ—¥åˆ©æ¶¦é¢': round(prev_total_profit, 1),
                    'è°ƒä»·å7æ—¥åˆ©æ¶¦é¢': round(post_total_profit, 1),
                    'åˆ©æ¶¦é¢å˜åŒ–ç‡': round(profit_change_rate * 100, 1),
                    # æ¯›åˆ©ç‡ = åˆ©æ¶¦é¢ / é”€å”®é¢ Ã— 100%
                    'è°ƒä»·å‰æ¯›åˆ©ç‡': round(prev_margin_rate, 1),
                    'è°ƒä»·åæ¯›åˆ©ç‡': round(post_margin_rate, 1),
                    'æ¯›åˆ©ç‡å˜åŒ–': round(margin_change, 1),
                    # å†…éƒ¨è®¡ç®—ç”¨
                    '_ä»·æ ¼å˜åŒ–ç‡': main_price_change * 100,
                    '_é”€é‡å˜åŒ–ç‡': qty_change_rate * 100,
                    '_é”€å”®é¢å˜åŒ–ç‡': revenue_change_rate * 100,
                    '_åˆ©æ¶¦å˜åŒ–ç‡': profit_change_rate * 100,
                    # åº“å­˜çŠ¶æ€
                    'å½“å‰åº“å­˜': last_stock if last_stock is not None else '-',
                    'æ˜¯å¦å”®ç½„': is_stockout,
                }
                price_changes.append(record)
        
        result_df = pd.DataFrame(price_changes)
        
        if not result_df.empty:
            result_df = calculate_price_elasticity(result_df)
            result_df = result_df.sort_values('å˜åŠ¨æ—¥æœŸ', ascending=False)
        
        return result_df
        
    except Exception as e:
        print(f"detect_price_changes_from_orders é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return pd.DataFrame()


def calculate_price_elasticity(price_changes_df: pd.DataFrame) -> pd.DataFrame:
    """
    è®¡ç®—ä»·æ ¼å¼¹æ€§ç³»æ•°ã€è°ƒä»·æ•ˆæœå¹¶æ·»åŠ ç»¼åˆè§£è¯»
    
    ä»·æ ¼å¼¹æ€§å…¬å¼ï¼šE = é”€é‡å˜åŒ–ç‡ / ä»·æ ¼å˜åŒ–ç‡
    
    è°ƒä»·æ•ˆæœè¯„ä¼°ï¼š
    - ç»¼åˆè€ƒè™‘é”€é‡ã€é”€å”®é¢ã€åˆ©æ¶¦é¢ã€æ¯›åˆ©ç‡çš„å˜åŒ–
    - ç»™å‡º"è°ƒä»·æˆåŠŸ/è°ƒä»·ä¸­æ€§/è°ƒä»·å¤±è´¥"çš„ç»¼åˆåˆ¤æ–­
    """
    if price_changes_df.empty:
        return price_changes_df
    
    df = price_changes_df.copy()
    
    # ä½¿ç”¨å†…éƒ¨è®¡ç®—åˆ—
    price_col = '_ä»·æ ¼å˜åŒ–ç‡' if '_ä»·æ ¼å˜åŒ–ç‡' in df.columns else 'ä»·å˜%'
    qty_col = '_é”€é‡å˜åŒ–ç‡' if '_é”€é‡å˜åŒ–ç‡' in df.columns else 'é‡å˜%'
    revenue_col = '_é”€å”®é¢å˜åŒ–ç‡' if '_é”€å”®é¢å˜åŒ–ç‡' in df.columns else 'é¢å˜%'
    profit_col = '_åˆ©æ¶¦å˜åŒ–ç‡' if '_åˆ©æ¶¦å˜åŒ–ç‡' in df.columns else 'æ¶¦å˜%'
    
    # è¿‡æ»¤æœ‰æ•ˆæ•°æ®
    valid_mask = df[price_col] != 0
    
    # è®¡ç®—å¼¹æ€§ç³»æ•°
    df['å¼¹æ€§'] = np.where(
        valid_mask,
        (df[qty_col] / df[price_col]).round(2),
        np.nan
    )
    
    # ===== å¼¹æ€§æ•æ„Ÿåº¦è§£è¯» =====
    def interpret_elasticity(row):
        e = row['å¼¹æ€§']
        price_change = row[price_col]
        qty_change = row[qty_col]
        
        if pd.isna(e):
            return 'âšª æ•°æ®ä¸è¶³'
        
        is_price_up = price_change > 0
        is_qty_down = qty_change < 0
        
        # å¼‚å¸¸æƒ…å†µï¼šæ¶¨ä»·é”€é‡æ¶¨ æˆ– é™ä»·é”€é‡é™
        if (is_price_up and not is_qty_down) or (not is_price_up and is_qty_down):
            return 'ğŸŸ£ å¼‚å¸¸'
        
        abs_e = abs(e)
        if abs_e > 1.5:
            return 'ğŸ”´ é«˜æ•æ„Ÿ'
        elif abs_e > 0.5:
            return 'ğŸŸ¡ ä¸­æ•æ„Ÿ'
        else:
            return 'ğŸŸ¢ ä½æ•æ„Ÿ'
    
    df['æ•æ„Ÿåº¦'] = df.apply(interpret_elasticity, axis=1)
    
    # ===== è°ƒä»·æ•ˆæœç»¼åˆè¯„ä¼° =====
    def evaluate_pricing_effect(row):
        """
        ç»¼åˆè¯„ä¼°è°ƒä»·æ•ˆæœ
        
        è¯„ä¼°ç»´åº¦ï¼š
        1. åˆ©æ¶¦å˜åŒ–ï¼ˆæ ¸å¿ƒæŒ‡æ ‡ï¼‰
        2. é”€å”®é¢å˜åŒ–
        3. æ¯›åˆ©ç‡å˜åŒ–
        
        è¯„ä¼°é€»è¾‘ï¼š
        - æˆåŠŸï¼šåˆ©æ¶¦â†‘ æˆ– (åˆ©æ¶¦æŒå¹³ ä¸” é”€å”®é¢â†‘)
        - ä¸­æ€§ï¼šåˆ©æ¶¦æŒå¹³ ä¸” é”€å”®é¢æŒå¹³
        - å¤±è´¥ï¼šåˆ©æ¶¦â†“
        """
        price_change = row.get(price_col, 0)
        profit_change = row.get(profit_col, 0) if profit_col in row.index else 0
        revenue_change = row.get(revenue_col, 0) if revenue_col in row.index else 0
        margin_change = row.get('æ¯›åˆ©ç‡å˜åŒ–', 0) if 'æ¯›åˆ©ç‡å˜åŒ–' in row.index else 0
        
        is_price_up = price_change > 0
        
        # åˆ©æ¶¦å˜åŒ–é˜ˆå€¼ï¼šÂ±10%
        profit_up = profit_change > 10
        profit_down = profit_change < -10
        profit_stable = not profit_up and not profit_down
        
        # é”€å”®é¢å˜åŒ–é˜ˆå€¼ï¼šÂ±10%
        revenue_up = revenue_change > 10
        revenue_down = revenue_change < -10
        
        # æ¯›åˆ©ç‡å˜åŒ–é˜ˆå€¼ï¼šÂ±3ä¸ªç™¾åˆ†ç‚¹
        margin_up = margin_change > 3
        margin_down = margin_change < -3
        
        if is_price_up:
            # æ¶¨ä»·åœºæ™¯
            if profit_up:
                return 'âœ… è°ƒä»·æˆåŠŸ'  # æ¶¨ä»·ä¸”åˆ©æ¶¦å¢åŠ 
            elif profit_down:
                if revenue_down:
                    return 'âŒ è°ƒä»·å¤±è´¥'  # æ¶¨ä»·å¯¼è‡´åˆ©æ¶¦å’Œé”€å”®é¢éƒ½ä¸‹é™
                else:
                    return 'âš ï¸ è°ƒä»·ä¸­æ€§'  # æ¶¨ä»·åˆ©æ¶¦é™ä½†é”€å”®é¢æŒå¹³
            else:
                # åˆ©æ¶¦æŒå¹³
                if margin_up:
                    return 'âœ… è°ƒä»·æˆåŠŸ'  # æ¯›åˆ©ç‡æå‡
                elif revenue_down:
                    return 'âš ï¸ è°ƒä»·ä¸­æ€§'  # é”€å”®é¢ä¸‹é™ä½†åˆ©æ¶¦æŒå¹³
                else:
                    return 'âœ… è°ƒä»·æˆåŠŸ'  # æ¶¨ä»·ååˆ©æ¶¦æŒå¹³ï¼Œè¯´æ˜æ¶¨å¾—åˆç†
        else:
            # é™ä»·åœºæ™¯
            if profit_up:
                return 'âœ… è°ƒä»·æˆåŠŸ'  # è–„åˆ©å¤šé”€æˆåŠŸ
            elif profit_down:
                if revenue_up:
                    return 'âš ï¸ è°ƒä»·ä¸­æ€§'  # é”€å”®é¢æ¶¨ä½†åˆ©æ¶¦é™
                else:
                    return 'âŒ è°ƒä»·å¤±è´¥'  # é™ä»·ä½†åˆ©æ¶¦é”€å”®é¢éƒ½æ²¡æå‡
            else:
                # åˆ©æ¶¦æŒå¹³
                if revenue_up:
                    return 'âœ… è°ƒä»·æˆåŠŸ'  # é”€å”®é¢æå‡ï¼Œå¸‚åœºä»½é¢æ‰©å¤§
                else:
                    return 'âš ï¸ è°ƒä»·ä¸­æ€§'  # é™ä»·æ•ˆæœä¸æ˜æ˜¾
    
    # æ£€æŸ¥æ˜¯å¦æœ‰åˆ©æ¶¦æ•°æ®
    has_profit_data = profit_col in df.columns and df[profit_col].notna().any()
    if has_profit_data:
        df['è°ƒä»·æ•ˆæœ'] = df.apply(evaluate_pricing_effect, axis=1)
    else:
        df['è°ƒä»·æ•ˆæœ'] = 'ğŸ“Š ç¼ºå°‘åˆ©æ¶¦æ•°æ®'
    
    # ===== ç»¼åˆå»ºè®® =====
    def generate_advice(row):
        """åŸºäºæ•æ„Ÿåº¦å’Œè°ƒä»·æ•ˆæœç”Ÿæˆç»¼åˆå»ºè®®"""
        e = row['å¼¹æ€§']
        sensitivity = str(row.get('æ•æ„Ÿåº¦', ''))
        effect = str(row.get('è°ƒä»·æ•ˆæœ', ''))
        price_change = row.get(price_col, 0)
        qty_change = row.get(qty_col, 0)
        is_price_up = price_change > 0
        is_qty_up = qty_change > 0
        
        if pd.isna(e):
            return 'æ•°æ®ä¸è¶³ï¼Œç»§ç»­è§‚å¯Ÿ'
        
        # æ£€æŸ¥æ˜¯å¦å”®ç½„
        is_stockout = row.get('æ˜¯å¦å”®ç½„', False)
        current_stock = row.get('å½“å‰åº“å­˜', '-')
        
        # ===== ä¼˜å…ˆçº§1ï¼šå”®ç½„åˆ¤æ–­ =====
        if is_stockout:
            if is_qty_up:
                return 'âš ï¸å·²å”®ç½„ï¼Œé”€é‡ä»æ¶¨è¯´æ˜éœ€æ±‚å¼ºåŠ²ï¼Œä¼˜å…ˆè¡¥è´§'
            else:
                return 'âš ï¸å·²å”®ç½„ï¼Œé”€é‡ä¸‹é™éä»·æ ¼å› ç´ ï¼Œå»ºè®®åŠæ—¶è¡¥è´§'
        
        # ===== ä¼˜å…ˆçº§2ï¼šæ ¹æ®è°ƒä»·æ•ˆæœ+å¼‚å¸¸æƒ…å†µç»¼åˆåˆ¤æ–­ =====
        if 'æˆåŠŸ' in effect:
            # è°ƒä»·æˆåŠŸ
            if is_price_up:
                if is_qty_up:
                    # æ¶¨ä»·+é”€é‡æ¶¨+åˆ©æ¶¦æ¶¨ â†’ çœŸæ­£çš„å¥½å•†å“
                    return 'âœ…æ¶¨ä»·é”€é‡åŒæ¶¨(åˆšéœ€/ç«å“å¼±)ï¼Œå¯ç»§ç»­å°å¹…æµ‹è¯•ä¸Šé™'
                else:
                    # æ¶¨ä»·+é”€é‡é™+åˆ©æ¶¦æ¶¨ â†’ æ­£å¸¸çš„æ¶¨ä»·æˆåŠŸ
                    return 'æ¶¨ä»·æˆåŠŸï¼Œå¯è€ƒè™‘ç±»ä¼¼å•†å“è·Ÿè¿›'
            else:
                # é™ä»·+åˆ©æ¶¦æ¶¨ â†’ è–„åˆ©å¤šé”€æˆåŠŸ
                if current_stock != '-' and isinstance(current_stock, (int, float)) and current_stock < 10:
                    return f'âœ…ä¿ƒé”€æœ‰æ•ˆï¼Œåº“å­˜ä»…{int(current_stock)}ï¼Œæ³¨æ„è¡¥è´§'
                return 'âœ…ä¿ƒé”€æœ‰æ•ˆï¼Œå¯è¯„ä¼°å¸¸æ€åŒ–æˆ–æ‰©å“'
        
        elif 'å¤±è´¥' in effect:
            # è°ƒä»·å¤±è´¥
            if is_price_up:
                return 'âŒæ¶¨ä»·è¿‡åº¦ï¼Œå»ºè®®å›è°ƒæˆ–å¢åŠ ä¿ƒé”€'
            else:
                if is_qty_up:
                    # é™ä»·+é”€é‡æ¶¨+åˆ©æ¶¦é™ â†’ è®©åˆ©è¿‡å¤š
                    return 'âŒé™ä»·å¹…åº¦è¿‡å¤§ï¼Œé”€é‡æ¶¨ä½†åˆ©æ¶¦é™ï¼Œå»ºè®®æ”¶çª„æŠ˜æ‰£'
                else:
                    # é™ä»·+é”€é‡é™+åˆ©æ¶¦é™ â†’ å®Œå…¨å¤±è´¥
                    if current_stock != '-' and isinstance(current_stock, (int, float)) and current_stock < 5:
                        return f'âŒä¿ƒé”€æ•ˆæœå·®ï¼Œåº“å­˜ä½({int(current_stock)})ï¼Œå…ˆè¡¥è´§å†è¯„ä¼°'
                    return 'âŒé™ä»·åé™é‡ï¼Œå¯èƒ½å“è´¨ç–‘è™‘æˆ–ä¿ƒé”€ç–²åŠ³ï¼Œå»ºè®®æ¢å¤åŸä»·'
        
        elif 'ä¸­æ€§' in effect:
            # è°ƒä»·æ•ˆæœä¸­æ€§
            if is_price_up:
                if is_qty_up:
                    return 'æ¶¨ä»·åé”€é‡åæ¶¨(å¯èƒ½åˆšéœ€)ï¼Œä½†åˆ©æ¶¦å˜åŒ–ä¸å¤§ï¼Œç»§ç»­è§‚å¯Ÿ'
                else:
                    return 'æ¶¨ä»·å½±å“æœ‰é™ï¼Œå¯ç»§ç»­è§‚å¯Ÿ'
            else:
                if is_qty_up:
                    return 'ä¿ƒé”€å¸¦åŠ¨é”€é‡ä½†åˆ©æ¶¦æŒå¹³ï¼Œè¯„ä¼°æŠ•å…¥äº§å‡ºæ¯”'
                else:
                    return 'ä¿ƒé”€æ•ˆæœä¸€èˆ¬ï¼Œè¯„ä¼°æ˜¯å¦ç»§ç»­'
        
        # ===== ä¼˜å…ˆçº§3ï¼šåŸºäºæ•æ„Ÿåº¦çš„å…œåº•å»ºè®® =====
        abs_e = abs(e) if not pd.isna(e) else 0
        if abs_e > 1.5:
            return 'é«˜æ•æ„Ÿå•†å“ï¼Œè°ƒä»·éœ€è°¨æ…æµ‹è¯•'
        elif abs_e > 0.5:
            return 'ä¸­æ•æ„Ÿå•†å“ï¼Œå¯å°å¹…è°ƒä»·'
        else:
            return 'ä½æ•æ„Ÿå•†å“ï¼Œè°ƒä»·ç©ºé—´è¾ƒå¤§'
    
    df['å»ºè®®'] = df.apply(generate_advice, axis=1)
    
    # ===== è”åŠ¨å¼¹æ€§å­¦ä¹ æœºåˆ¶ =====
    # å°†è®¡ç®—å‡ºçš„çœŸå®å¼¹æ€§åŒæ­¥åˆ°æ™ºèƒ½è°ƒä»·å™¨çš„å­¦ä¹ åº“
    if learn_elasticity_from_price_change is not None:
        learned_count = 0
        for _, row in df.iterrows():
            try:
                elasticity = row.get('å¼¹æ€§')
                if pd.isna(elasticity):
                    continue
                    
                # è§£æä»·æ ¼å˜åŠ¨å­—ç¬¦ä¸²ï¼ˆæ ¼å¼ï¼š"10.0â†’12.0"ï¼‰
                å”®ä»·å˜åŠ¨ = row.get('å”®ä»·å˜åŠ¨', '')
                if 'â†’' not in str(å”®ä»·å˜åŠ¨):
                    continue
                    
                parts = str(å”®ä»·å˜åŠ¨).split('â†’')
                if len(parts) != 2:
                    continue
                    
                old_price = float(parts[0].strip())
                new_price = float(parts[1].strip())
                
                # è·å–é”€é‡æ•°æ®
                old_sales = row.get('è°ƒä»·å‰7æ—¥å‡é”€é‡', 0)
                new_sales = row.get('è°ƒä»·å7æ—¥å‡é”€é‡', 0)
                
                # è·å–å•†å“æ ‡è¯†
                product_code = str(row.get('åº—å†…ç ', ''))
                channel = str(row.get('æ¸ é“', 'æœªçŸ¥'))
                
                if not product_code or old_price <= 0:
                    continue
                
                # è°ƒç”¨å­¦ä¹ å‡½æ•°
                result = learn_elasticity_from_price_change(
                    product_code=product_code,
                    channel=channel,
                    old_price=old_price,
                    new_price=new_price,
                    old_daily_sales=old_sales,
                    new_daily_sales=new_sales,
                    days_after_change=7
                )
                if result is not None:
                    learned_count += 1
            except Exception as e:
                pass  # å•æ¡æ•°æ®å­¦ä¹ å¤±è´¥ä¸å½±å“æ•´ä½“
        
        if learned_count > 0:
            print(f"ğŸ“š å·²å­¦ä¹  {learned_count} æ¡å•†å“å¼¹æ€§ç³»æ•°åˆ°æ™ºèƒ½è°ƒä»·å™¨")
    
    return df


def get_product_price_history(df: pd.DataFrame, product_name: str) -> pd.DataFrame:
    """
    è·å–æŒ‡å®šå•†å“çš„å†å²ä»·æ ¼å˜åŠ¨è®°å½•
    
    Args:
        df: è®¢å•æ•°æ®DataFrame
        product_name: å•†å“åç§°
    
    Returns:
        è¯¥å•†å“çš„ä»·æ ¼å˜åŠ¨å†å²
    """
    if df is None or df.empty or not product_name:
        return pd.DataFrame()
    
    # æ£€æµ‹æ‰€æœ‰ä»·æ ¼å˜åŠ¨
    all_changes = detect_price_changes_from_orders(df)
    
    if all_changes.empty:
        return pd.DataFrame()
    
    # ç­›é€‰æŒ‡å®šå•†å“
    product_changes = all_changes[all_changes['å•†å“åç§°'] == product_name].copy()
    
    return product_changes


def get_price_elasticity_summary(df: pd.DataFrame) -> Dict[str, Any]:
    """
    è·å–ä»·æ ¼å¼¹æ€§æ±‡æ€»ç»Ÿè®¡
    
    ç»Ÿè®¡å†…å®¹ï¼š
    1. æ£€æµ‹åˆ°çš„è°ƒä»·äº‹ä»¶æ•°
    2. é«˜/ä¸­/ä½æ•æ„Ÿå•†å“åˆ†å¸ƒ
    3. å¹³å‡ä»·æ ¼å¼¹æ€§
    4. å»ºè®®å…³æ³¨çš„å•†å“ï¼ˆé«˜æ•æ„Ÿ+è¿‘æœŸè°ƒä»·ï¼‰
    
    Args:
        df: è®¢å•æ•°æ®DataFrame
    
    Returns:
        å¼¹æ€§æ±‡æ€»ç»Ÿè®¡Dict
    """
    result = {
        'è°ƒä»·äº‹ä»¶æ•°': 0,
        'é«˜æ•æ„Ÿå•†å“æ•°': 0,
        'ä¸­æ•æ„Ÿå•†å“æ•°': 0,
        'ä½æ•æ„Ÿå•†å“æ•°': 0,
        'å¼‚å¸¸å•†å“æ•°': 0,
        'å¹³å‡å¼¹æ€§': None,
        'å»ºè®®å…³æ³¨å•†å“': [],
        'error': None
    }
    
    try:
        all_changes = detect_price_changes_from_orders(df)
        
        if all_changes.empty:
            result['error'] = 'æœªæ£€æµ‹åˆ°ä»·æ ¼å˜åŠ¨'
            return result
        
        result['è°ƒä»·äº‹ä»¶æ•°'] = len(all_changes)
        
        # ç»Ÿè®¡æ•æ„Ÿåº¦åˆ†å¸ƒï¼ˆä½¿ç”¨'æ•æ„Ÿåº¦'å­—æ®µï¼‰
        result['é«˜æ•æ„Ÿå•†å“æ•°'] = len(all_changes[all_changes['æ•æ„Ÿåº¦'].str.contains('é«˜æ•æ„Ÿ', na=False)])
        result['ä¸­æ•æ„Ÿå•†å“æ•°'] = len(all_changes[all_changes['æ•æ„Ÿåº¦'].str.contains('ä¸­æ•æ„Ÿ', na=False)])
        result['ä½æ•æ„Ÿå•†å“æ•°'] = len(all_changes[all_changes['æ•æ„Ÿåº¦'].str.contains('ä½æ•æ„Ÿ', na=False)])
        result['å¼‚å¸¸å•†å“æ•°'] = len(all_changes[all_changes['æ•æ„Ÿåº¦'].str.contains('å¼‚å¸¸', na=False)])
        
        # è®¡ç®—å¹³å‡å¼¹æ€§ï¼ˆæ’é™¤å¼‚å¸¸å€¼ï¼‰
        valid_elasticity = all_changes['å¼¹æ€§'].dropna() if 'å¼¹æ€§' in all_changes.columns else pd.Series()
        valid_elasticity = valid_elasticity[(valid_elasticity > -10) & (valid_elasticity < 10)]  # æ’é™¤æç«¯å€¼
        if len(valid_elasticity) > 0:
            result['å¹³å‡å¼¹æ€§'] = round(valid_elasticity.mean(), 2)
        
        # å»ºè®®å…³æ³¨å•†å“ï¼šé«˜æ•æ„Ÿ + æœ€è¿‘30å¤©å†…è°ƒä»·
        from datetime import datetime, timedelta
        recent_date = datetime.now().date() - timedelta(days=30)
        
        recent_sensitive = all_changes[
            (all_changes['æ•æ„Ÿåº¦'].str.contains('é«˜æ•æ„Ÿ', na=False)) &
            (all_changes['å˜åŠ¨æ—¥æœŸ'] >= recent_date)
        ]
        
        if not recent_sensitive.empty:
            result['å»ºè®®å…³æ³¨å•†å“'] = recent_sensitive.head(5)['å•†å“åç§°'].tolist()
    
    except Exception as e:
        result['error'] = str(e)
    
    return result


def get_high_profit_products(df: pd.DataFrame, store_name: str = None, days: int = 1) -> pd.DataFrame:
    """
    è·å–é«˜åˆ©æ¶¦å•†å“è¯¦æƒ…ï¼ˆçœŸæ­£çš„é«˜åˆ©æ¶¦å•†å“ï¼‰
    
    é«˜åˆ©æ¶¦åˆ¤æ–­æ ‡å‡†ï¼ˆä¼˜åŒ–åï¼‰ï¼š
    - æ¯›åˆ©ç‡ >= 25%ï¼ˆå®šä»·æœ‰è¶³å¤Ÿåˆ©æ¶¦ç©ºé—´ï¼‰
    - åˆ©æ¶¦é¢ >= 10å…ƒï¼ˆå®é™…èµšå¾—å¤šï¼‰
    - é”€é‡ >= 3ï¼ˆæœ‰ä¸€å®šé”€å”®é‡ï¼Œæ’é™¤å¶å‘ï¼‰
    
    Args:
        df: è®¢å•æ•°æ®DataFrame
        store_name: é—¨åº—åç§°ç­›é€‰ï¼ˆå¯é€‰ï¼‰
        days: æ—¥æœŸèŒƒå›´ï¼ˆ1=æ˜¨æ—¥ï¼Œ3=è¿‘3å¤©ï¼Œ7=è¿‘7å¤©ï¼Œ15=è¿‘15å¤©ï¼Œ0=å…¨éƒ¨ï¼‰
    
    Returns:
        é«˜åˆ©æ¶¦å•†å“DataFrame
    """
    try:
        if df is None or df.empty:
            return pd.DataFrame()
        
        df_copy = df.copy()
        
        # é—¨åº—ç­›é€‰
        if store_name and store_name != 'å…¨éƒ¨é—¨åº—':
            store_col = next((c for c in ['é—¨åº—åç§°', 'é—¨åº—', 'store_name'] if c in df_copy.columns), None)
            if store_col:
                df_copy = df_copy[df_copy[store_col] == store_name]
        
        # æŸ¥æ‰¾å¿…è¦åˆ—
        date_col = next((c for c in ['æ—¥æœŸ', 'date', 'è®¢å•æ—¥æœŸ'] if c in df_copy.columns), None)
        product_col = next((c for c in ['å•†å“åç§°', 'å•†å“', 'product_name'] if c in df_copy.columns), None)
        code_col = next((c for c in ['åº—å†…ç ', 'å•†å“ç¼–ç ', 'sku'] if c in df_copy.columns), None)
        price_col = next((c for c in ['å®æ”¶ä»·æ ¼', 'å•†å“å®å”®ä»·', 'å”®ä»·', 'price'] if c in df_copy.columns), None)
        sales_col = next((c for c in ['æœˆå”®', 'é”€é‡', 'æ•°é‡', 'quantity'] if c in df_copy.columns), None)
        cost_col = next((c for c in ['å•†å“é‡‡è´­æˆæœ¬', 'é‡‡è´­æˆæœ¬', 'æˆæœ¬', 'cost'] if c in df_copy.columns), None)
        channel_col = next((c for c in ['è®¢å•æ¸ é“åç§°', 'æ¸ é“', 'channel'] if c in df_copy.columns), None)
        category_col = next((c for c in ['ä¸€çº§åˆ†ç±»å', 'ä¸€çº§åˆ†ç±»'] if c in df_copy.columns), None)
        
        if not date_col or not product_col or 'åˆ©æ¶¦é¢' not in df_copy.columns:
            return pd.DataFrame()
        
        # è½¬æ¢æ—¥æœŸ
        df_copy[date_col] = pd.to_datetime(df_copy[date_col], errors='coerce')
        df_copy = df_copy.dropna(subset=[date_col])
        
        if df_copy.empty:
            return pd.DataFrame()
        
        # æ ¹æ®dayså‚æ•°ç­›é€‰æ—¥æœŸèŒƒå›´
        latest_date = df_copy[date_col].max().normalize()
        if days == 0:
            # å…¨éƒ¨æ•°æ®
            filtered_df = df_copy.copy()
        elif days == 1:
            # æ˜¨æ—¥
            filtered_df = df_copy[df_copy[date_col].dt.normalize() == latest_date].copy()
        else:
            # è¿‘Nå¤©
            start_date = latest_date - pd.Timedelta(days=days-1)
            filtered_df = df_copy[(df_copy[date_col].dt.normalize() >= start_date) & 
                                  (df_copy[date_col].dt.normalize() <= latest_date)].copy()
        
        if filtered_df.empty:
            return pd.DataFrame()
        
        # æ¸…æ´—æ•°æ®
        if sales_col:
            filtered_df[sales_col] = pd.to_numeric(filtered_df[sales_col], errors='coerce').fillna(0)
        if price_col:
            filtered_df[price_col] = pd.to_numeric(filtered_df[price_col], errors='coerce').fillna(0)
        if cost_col:
            filtered_df[cost_col] = pd.to_numeric(filtered_df[cost_col], errors='coerce').fillna(0)
        filtered_df['åˆ©æ¶¦é¢'] = pd.to_numeric(filtered_df['åˆ©æ¶¦é¢'], errors='coerce').fillna(0)
        
        # è®¡ç®—é”€å”®é¢å’Œå•å“æˆæœ¬
        if price_col and sales_col:
            filtered_df['_é”€å”®é¢'] = filtered_df[price_col] * filtered_df[sales_col]
        else:
            filtered_df['_é”€å”®é¢'] = 0
        
        if cost_col and sales_col:
            filtered_df['_å•å“æˆæœ¬'] = filtered_df[cost_col] / filtered_df[sales_col].replace(0, 1)
        else:
            filtered_df['_å•å“æˆæœ¬'] = 0
        
        # æŒ‰å•†å“æ±‡æ€»
        agg_dict = {
            'åˆ©æ¶¦é¢': 'sum',
            '_é”€å”®é¢': 'sum',
            '_å•å“æˆæœ¬': 'mean'
        }
        if sales_col:
            agg_dict[sales_col] = 'sum'
        if price_col:
            agg_dict[price_col] = 'mean'
        if category_col and category_col in filtered_df.columns:
            agg_dict[category_col] = 'first'
        if channel_col and channel_col in filtered_df.columns:
            agg_dict[channel_col] = 'first'
        
        group_cols = [product_col]
        if code_col and code_col in filtered_df.columns:
            group_cols.append(code_col)
        
        profit_stats = filtered_df.groupby(group_cols, as_index=False).agg(agg_dict)
        
        # è®¡ç®—åˆ©æ¶¦ç‡
        profit_stats['åˆ©æ¶¦ç‡'] = np.where(
            profit_stats['_é”€å”®é¢'] > 0,
            (profit_stats['åˆ©æ¶¦é¢'] / profit_stats['_é”€å”®é¢'] * 100).round(1),
            0
        )
        
        # é«˜åˆ©æ¶¦å•†å“ç­›é€‰ï¼ˆä¼˜åŒ–åçš„ä¸¥æ ¼æ ‡å‡†ï¼‰ï¼š
        # 1. æ¯›åˆ©ç‡ >= 25%ï¼ˆå®šä»·æœ‰è¶³å¤Ÿåˆ©æ¶¦ç©ºé—´ï¼‰
        # 2. åˆ©æ¶¦é¢ >= 10å…ƒï¼ˆå®é™…èµšå¾—å¤šï¼‰
        # 3. é”€é‡ >= 3ï¼ˆæœ‰ä¸€å®šé”€å”®é‡ï¼Œæ’é™¤å¶å‘ï¼‰
        if sales_col:
            high_mask = (profit_stats['åˆ©æ¶¦ç‡'] >= 25) & (profit_stats['åˆ©æ¶¦é¢'] >= 10) & (profit_stats[sales_col] >= 3)
        else:
            high_mask = (profit_stats['åˆ©æ¶¦ç‡'] >= 25) & (profit_stats['åˆ©æ¶¦é¢'] >= 10)
        
        # è¿‡æ»¤è€—æ
        if category_col and category_col in profit_stats.columns:
            high_mask = high_mask & (profit_stats[category_col] != 'è€—æ')
        
        high_df = profit_stats[high_mask].copy()
        
        if high_df.empty:
            return pd.DataFrame()
        
        # æŒ‰åˆ©æ¶¦é¢æ’åºï¼Œå–TOP30
        high_df = high_df.sort_values('åˆ©æ¶¦é¢', ascending=False).head(30)
        
        # æ ¹æ®dayså‚æ•°å†³å®šåˆ—åå‰ç¼€
        if days == 0:
            period_prefix = 'ç´¯è®¡'
        elif days == 1:
            period_prefix = 'å½“å¤©'
        else:
            period_prefix = f'{days}å¤©'
        
        # æ•´ç†è¾“å‡º
        results = []
        for rank, (_, row) in enumerate(high_df.iterrows(), 1):
            # åˆ©æ¶¦ç­‰çº§æ ‡è¯†
            if rank <= 3:
                level = 'ğŸ¥‡' if rank == 1 else ('ğŸ¥ˆ' if rank == 2 else 'ğŸ¥‰')
            elif rank <= 10:
                level = 'â­'
            else:
                level = ''
            
            result_row = {
                'æ’å': f"{level} TOP{rank}" if level else f"TOP{rank}",
                'åº—å†…ç ': row.get(code_col, '') if code_col and code_col in row.index else '',
                'å•†å“åç§°': row[product_col],
                f'{period_prefix}åˆ©æ¶¦': round(row['åˆ©æ¶¦é¢'], 2),
                f'{period_prefix}é”€å”®é¢': round(row['_é”€å”®é¢'], 2),
                f'{period_prefix}é”€é‡': int(row.get(sales_col, 0)) if sales_col and sales_col in row.index else 0,
                'åˆ©æ¶¦ç‡': f"{row['åˆ©æ¶¦ç‡']}%",
                'å®æ”¶ä»·æ ¼': round(row.get(price_col, 0), 2) if price_col and price_col in row.index else 0,
                'å•å“æˆæœ¬': round(row['_å•å“æˆæœ¬'], 2),
                'ä¸€çº§åˆ†ç±»': row.get(category_col, '') if category_col and category_col in row.index else '',
            }
            if channel_col and channel_col in row.index:
                result_row['ä¸»æ¸ é“'] = row[channel_col]
            results.append(result_row)
        
        return pd.DataFrame(results)
        
    except Exception as e:
        print(f"get_high_profit_products é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return pd.DataFrame()
