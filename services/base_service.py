# -*- coding: utf-8 -*-
"""
åŸºç¡€æœåŠ¡ç±»

æä¾›æ‰€æœ‰Serviceçš„å…¬å…±åŠŸèƒ½ï¼š
- ç¼“å­˜é›†æˆ
- æ—¥å¿—è®°å½•
- é”™è¯¯å¤„ç†
- æ•°æ®éªŒè¯

ç‰ˆæœ¬: v1.0
åˆ›å»ºæ—¥æœŸ: 2026-01-05
"""

import logging
import hashlib
import pandas as pd
import numpy as np
from typing import Any, Optional, Dict, List, Tuple, Callable
from datetime import datetime, date
from functools import wraps

from .cache.hierarchical_cache_adapter import OrderDashboardCacheManager, get_cache_manager
from .cache.cache_keys import CacheKeys

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


def cache_result(cache_key_func: Callable, ttl: int = 300, level: int = 4):
    """
    ç¼“å­˜è£…é¥°å™¨
    
    Args:
        cache_key_func: ç”Ÿæˆç¼“å­˜é”®çš„å‡½æ•°ï¼Œæ¥æ”¶ä¸è¢«è£…é¥°å‡½æ•°ç›¸åŒçš„å‚æ•°
        ttl: ç¼“å­˜è¿‡æœŸæ—¶é—´ï¼ˆç§’ï¼‰
        level: ç¼“å­˜å±‚çº§
    
    Usage:
        @cache_result(lambda self, df, top_n: f"hot_products:{top_n}", ttl=600)
        def get_hot_products(self, df, top_n=10):
            ...
    """
    def decorator(func):
        @wraps(func)
        def wrapper(self, *args, **kwargs):
            # æ£€æŸ¥ç¼“å­˜æ˜¯å¦å¯ç”¨
            if not hasattr(self, 'cache') or self.cache is None:
                return func(self, *args, **kwargs)
            
            # ç”Ÿæˆç¼“å­˜é”®
            try:
                cache_key = cache_key_func(self, *args, **kwargs)
            except Exception:
                return func(self, *args, **kwargs)
            
            # å°è¯•ä»ç¼“å­˜è·å–
            cached = self.cache.get(cache_key, level=level)
            if cached is not None:
                logger.debug(f"ğŸš€ ç¼“å­˜å‘½ä¸­: {cache_key}")
                return cached
            
            # æ‰§è¡Œå‡½æ•°
            result = func(self, *args, **kwargs)
            
            # å†™å…¥ç¼“å­˜
            if result is not None:
                self.cache.set(cache_key, result, level=level, ttl=ttl)
                logger.debug(f"ğŸ’¾ å†™å…¥ç¼“å­˜: {cache_key}")
            
            return result
        return wrapper
    return decorator


class BaseService:
    """
    åŸºç¡€æœåŠ¡ç±»
    
    æ‰€æœ‰Serviceçš„åŸºç±»ï¼Œæä¾›å…¬å…±åŠŸèƒ½
    """
    
    # ==================== å­—æ®µçº§åˆ«å®šä¹‰ï¼ˆä¸ä¸»çœ‹æ¿ä¿æŒä¸€è‡´ï¼‰====================
    # è®¢å•çº§å­—æ®µ - ä½¿ç”¨ first() èšåˆ
    ORDER_LEVEL_FIELDS = [
        'ç‰©æµé…é€è´¹',
        'æ»¡å‡é‡‘é¢',
        'å•†å“å‡å…é‡‘é¢',
        'å•†å®¶ä»£é‡‘åˆ¸',
        'å•†å®¶æ‰¿æ‹…éƒ¨åˆ†åˆ¸',
        'æ»¡èµ é‡‘é¢',
        'å•†å®¶å…¶ä»–ä¼˜æƒ ',
        'æ–°å®¢å‡å…é‡‘é¢',
        'ç”¨æˆ·æ”¯ä»˜é…é€è´¹',
        'é…é€è´¹å‡å…é‡‘é¢',
        'æ¸ é“',
        'å¹³å°',
        'é—¨åº—',
        'ä¸‹å•æ—¶é—´',
        'æ—¥æœŸ',
    ]
    
    # å•†å“çº§å­—æ®µ - ä½¿ç”¨ sum() èšåˆ
    ITEM_LEVEL_FIELDS = [
        'åˆ©æ¶¦é¢',
        'å¹³å°æœåŠ¡è´¹',
        'ä¼å®¢åè¿”',
        'å®æ”¶ä»·æ ¼',
        'å•†å“å®å”®ä»·',
        'å•†å“é‡‡è´­æˆæœ¬',
        'æˆæœ¬',
        'æœˆå”®',
        'é”€é‡',
    ]
    
    def __init__(self, cache_manager: Optional[OrderDashboardCacheManager] = None):
        """
        åˆå§‹åŒ–åŸºç¡€æœåŠ¡
        
        Args:
            cache_manager: ç¼“å­˜ç®¡ç†å™¨å®ä¾‹ï¼Œä¸ºNoneæ—¶ä½¿ç”¨å…¨å±€å®ä¾‹
        """
        self.cache = cache_manager or get_cache_manager()
        self.logger = logging.getLogger(self.__class__.__name__)
    
    # ==================== ç¼“å­˜ç›¸å…³æ–¹æ³• ====================
    
    def cache_get(self, key: str, level: int = 4) -> Optional[Any]:
        """è·å–ç¼“å­˜"""
        if self.cache:
            return self.cache.get(key, level=level)
        return None
    
    def cache_set(self, key: str, value: Any, level: int = 4, ttl: int = 300) -> bool:
        """è®¾ç½®ç¼“å­˜"""
        if self.cache:
            return self.cache.set(key, value, level=level, ttl=ttl)
        return False
    
    def cache_delete(self, key: str, level: int = 4) -> bool:
        """åˆ é™¤ç¼“å­˜"""
        if self.cache:
            return self.cache.delete(key, level=level)
        return False
    
    def _build_cache_key(self, prefix: str, df: pd.DataFrame = None, *args, **kwargs) -> str:
        """
        æ„å»ºç¼“å­˜é”®
        
        Args:
            prefix: é”®å‰ç¼€
            df: DataFrameï¼ˆç”¨äºè®¡ç®—æ•°æ®å“ˆå¸Œï¼‰
            *args, **kwargs: å…¶ä»–å‚æ•°
        
        Returns:
            ç¼“å­˜é”®å­—ç¬¦ä¸²
        """
        parts = [prefix]
        
        # æ·»åŠ DataFrameå“ˆå¸Œ
        if df is not None and len(df) > 0:
            data_hash = hashlib.md5(
                pd.util.hash_pandas_object(df.head(100)).values.tobytes()
            ).hexdigest()[:8]
            parts.append(f"data_{data_hash}")
            parts.append(f"rows_{len(df)}")
        
        # æ·»åŠ å…¶ä»–å‚æ•°
        for arg in args:
            if arg is not None:
                parts.append(str(arg))
        
        for key, value in sorted(kwargs.items()):
            if value is not None:
                parts.append(f"{key}_{value}")
        
        return ":".join(parts)
    
    # ==================== æ•°æ®å¤„ç†å·¥å…·æ–¹æ³• ====================
    
    def get_date_column(self, df: pd.DataFrame) -> Optional[str]:
        """è·å–æ—¥æœŸåˆ—å"""
        for col in ['æ—¥æœŸ', 'ä¸‹å•æ—¶é—´', 'date', 'order_date']:
            if col in df.columns:
                return col
        return None
    
    def get_base_date(self, df: pd.DataFrame) -> Optional[pd.Timestamp]:
        """è·å–åŸºå‡†æ—¥æœŸï¼ˆæ˜¨æ—¥ = æ•°æ®æœ€åä¸€å¤©ï¼‰"""
        date_col = self.get_date_column(df)
        if date_col is None:
            return None
        
        df = df.copy()
        df[date_col] = pd.to_datetime(df[date_col])
        return df[date_col].max().normalize()
    
    def get_sales_column(self, df: pd.DataFrame) -> str:
        """è·å–é”€é‡åˆ—å"""
        return 'æœˆå”®' if 'æœˆå”®' in df.columns else 'é”€é‡'
    
    def get_product_group_key(self, df: pd.DataFrame) -> str:
        """
        è·å–å•†å“èšåˆçš„keyå­—æ®µå
        
        ä¼˜å…ˆçº§ï¼šåº—å†…ç  > æ¡ç  > å•†å“åç§°
        ä½¿ç”¨åº—å†…ç å¯ä»¥åŒºåˆ†åŒåä½†ä¸åŒè§„æ ¼çš„å•†å“
        """
        if 'åº—å†…ç ' in df.columns and df['åº—å†…ç '].notna().any():
            return 'åº—å†…ç '
        elif 'æ¡ç ' in df.columns and df['æ¡ç '].notna().any():
            return 'æ¡ç '
        else:
            return 'å•†å“åç§°'
    
    def calculate_order_profit(self, order_agg: pd.DataFrame) -> pd.Series:
        """
        è®¡ç®—è®¢å•å®é™…åˆ©æ¶¦ï¼ˆä¸ä¸»çœ‹æ¿å…¬å¼å®Œå…¨ä¸€è‡´ï¼‰
        
        å…¬å¼: è®¢å•å®é™…åˆ©æ¶¦ = åˆ©æ¶¦é¢ - å¹³å°æœåŠ¡è´¹ - ç‰©æµé…é€è´¹ + ä¼å®¢åè¿”
        
        Args:
            order_agg: è®¢å•çº§èšåˆåçš„DataFrame
        
        Returns:
            Series: è®¢å•å®é™…åˆ©æ¶¦
        """
        # è·å–å¿…éœ€å­—æ®µ
        profit = order_agg.get('åˆ©æ¶¦é¢', pd.Series(0, index=order_agg.index))
        delivery_fee = order_agg.get('ç‰©æµé…é€è´¹', pd.Series(0, index=order_agg.index))
        
        # è·å–å¯é€‰å­—æ®µ
        service_fee = order_agg.get('å¹³å°æœåŠ¡è´¹', pd.Series(0, index=order_agg.index))
        enterprise_rebate = order_agg.get('ä¼å®¢åè¿”', pd.Series(0, index=order_agg.index))
        
        # å¤„ç†NaN
        profit = profit.fillna(0)
        delivery_fee = delivery_fee.fillna(0)
        service_fee = service_fee.fillna(0)
        enterprise_rebate = enterprise_rebate.fillna(0)
        
        # è®¡ç®—è®¢å•å®é™…åˆ©æ¶¦
        result = profit - service_fee - delivery_fee + enterprise_rebate
        
        return result
    
    def aggregate_to_order_level(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        å°†å•†å“çº§æ•°æ®èšåˆåˆ°è®¢å•çº§
        
        ä½¿ç”¨æ­£ç¡®çš„èšåˆæ–¹å¼ï¼š
        - è®¢å•çº§å­—æ®µç”¨ first()
        - å•†å“çº§å­—æ®µç”¨ sum()
        
        Args:
            df: å•†å“çº§æ˜ç»†æ•°æ®
        
        Returns:
            è®¢å•çº§èšåˆæ•°æ®
        """
        if 'è®¢å•ID' not in df.columns:
            self.logger.warning("ç¼ºå°‘è®¢å•IDå­—æ®µï¼Œæ— æ³•èšåˆ")
            return df
        
        agg_dict = {}
        
        # è®¢å•çº§å­—æ®µ
        for field in self.ORDER_LEVEL_FIELDS:
            if field in df.columns:
                agg_dict[field] = 'first'
        
        # å•†å“çº§å­—æ®µ
        for field in self.ITEM_LEVEL_FIELDS:
            if field in df.columns:
                agg_dict[field] = 'sum'
        
        # ä¿ç•™å•†å“åç§°ï¼ˆç”¨äºå±•ç¤ºï¼‰
        if 'å•†å“åç§°' in df.columns:
            agg_dict['å•†å“åç§°'] = lambda x: ', '.join(x.head(3).astype(str))
        
        # å•†å“æ•°é‡
        agg_dict['å•†å“æ•°é‡'] = ('å•†å“åç§°', 'count') if 'å•†å“åç§°' in df.columns else ('è®¢å•ID', 'count')
        
        # æ‰§è¡Œèšåˆ
        result = df.groupby('è®¢å•ID').agg(agg_dict).reset_index()
        
        # è®¡ç®—è®¢å•å®é™…åˆ©æ¶¦
        result['è®¢å•å®é™…åˆ©æ¶¦'] = self.calculate_order_profit(result)
        
        return result
    
    def get_channel_distribution(self, df: pd.DataFrame, mask: pd.Series = None) -> Dict[str, int]:
        """è·å–æ¸ é“åˆ†å¸ƒ"""
        channel_col = next((c for c in ['å¹³å°', 'æ¸ é“', 'platform', 'channel'] if c in df.columns), None)
        if channel_col is None:
            return {}
        
        if mask is not None:
            df = df[mask]
        
        return df[channel_col].value_counts().to_dict()
    
    def clean_for_json(self, obj: Any) -> Any:
        """
        æ¸…ç†æ•°æ®ä»¥ä¾¿JSONåºåˆ—åŒ–
        
        å¤„ç†NaNã€Infã€numpyç±»å‹ç­‰
        """
        if isinstance(obj, dict):
            return {k: self.clean_for_json(v) for k, v in obj.items()}
        elif isinstance(obj, list):
            return [self.clean_for_json(item) for item in obj]
        elif isinstance(obj, pd.DataFrame):
            return obj.replace([np.inf, -np.inf], np.nan).fillna(0).to_dict('records')
        elif isinstance(obj, pd.Series):
            return obj.replace([np.inf, -np.inf], np.nan).fillna(0).to_list()
        elif isinstance(obj, (np.integer, np.floating)):
            if np.isnan(obj) or np.isinf(obj):
                return 0
            return obj.item()
        elif isinstance(obj, np.ndarray):
            return self.clean_for_json(obj.tolist())
        elif pd.isna(obj):
            return None
        else:
            return obj
    
    # ==================== é”™è¯¯å¤„ç† ====================
    
    def handle_error(self, error: Exception, context: str = "") -> Dict[str, Any]:
        """
        ç»Ÿä¸€é”™è¯¯å¤„ç†
        
        Args:
            error: å¼‚å¸¸å¯¹è±¡
            context: é”™è¯¯ä¸Šä¸‹æ–‡æè¿°
        
        Returns:
            é”™è¯¯ä¿¡æ¯å­—å…¸
        """
        error_msg = f"{context}: {str(error)}" if context else str(error)
        self.logger.error(error_msg)
        
        return {
            'error': error_msg,
            'success': False,
            'data': None
        }
    
    def validate_dataframe(self, df: pd.DataFrame, required_columns: List[str]) -> Tuple[bool, str]:
        """
        éªŒè¯DataFrameæ˜¯å¦åŒ…å«å¿…éœ€åˆ—
        
        Args:
            df: å¾…éªŒè¯çš„DataFrame
            required_columns: å¿…éœ€åˆ—åˆ—è¡¨
        
        Returns:
            (æ˜¯å¦æœ‰æ•ˆ, é”™è¯¯æ¶ˆæ¯)
        """
        if df is None or df.empty:
            return False, "æ•°æ®ä¸ºç©º"
        
        missing = [col for col in required_columns if col not in df.columns]
        if missing:
            return False, f"ç¼ºå°‘å¿…éœ€åˆ—: {', '.join(missing)}"
        
        return True, ""

