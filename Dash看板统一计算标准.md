# ğŸ“Š Dashçœ‹æ¿ç»Ÿä¸€è®¡ç®—æ ‡å‡† v2.0

**åˆ¶å®šæ—¥æœŸ**: 2025-10-24  
**é€‚ç”¨èŒƒå›´**: æ‰€æœ‰Dashç‰ˆæœ¬çœ‹æ¿  
**çŠ¶æ€**: âœ… ç”Ÿäº§æ ‡å‡†

---

## ğŸ¯ æ ¸å¿ƒåŸåˆ™

**æ‰€æœ‰Dashçœ‹æ¿å¿…é¡»éµå¾ªç»Ÿä¸€çš„æ•°æ®å¤„ç†å’Œè®¡ç®—é€»è¾‘ï¼Œç¡®ä¿æŒ‡æ ‡å£å¾„ä¸€è‡´ï¼**

---

## ğŸ“ ç¬¬ä¸€å±‚ï¼šæ•°æ®é¢„å¤„ç†ï¼ˆå…¥å£å±‚ï¼‰

### 1.1 æ•°æ®åŠ è½½ä¸æ ‡å‡†åŒ–

**å¤„ç†å™¨**: `çœŸå®æ•°æ®å¤„ç†å™¨.py` â†’ `RealDataProcessor.standardize_sales_data()`

```python
from çœŸå®æ•°æ®å¤„ç†å™¨ import RealDataProcessor

# æ ‡å‡†åŠ è½½æµç¨‹
def load_and_standardize_data(df_raw):
    """ç»Ÿä¸€æ•°æ®åŠ è½½æµç¨‹"""
    # Step 1: å­—æ®µæ ‡å‡†åŒ–æ˜ å°„ï¼ˆ14ä¸ªæ ¸å¿ƒå­—æ®µï¼‰
    processor = RealDataProcessor()
    df_std = processor.standardize_sales_data(df_raw)
    
    # Step 2: ä¸šåŠ¡è§„åˆ™è¿‡æ»¤
    df_clean = apply_business_rules(df_std)
    
    # Step 3: åœºæ™¯æ—¶æ®µæ¨æ–­
    df_final = add_scene_and_timeslot_fields(df_clean)
    
    return df_final
```

#### ğŸ”‘ æ ¸å¿ƒå­—æ®µæ˜ å°„ï¼ˆ14ä¸ªï¼‰

| æ ‡å‡†å­—æ®µå | å¯èƒ½æ¥æºå­—æ®µ | æ•°æ®ç±»å‹ | è¯´æ˜ |
|-----------|------------|---------|------|
| **å•†å“åç§°** | å•†å“åç§°, product_name, åç§° | str | å¿…éœ€ |
| **å•†å“å®å”®ä»·** | å”®ä»·, å•†å“å®å”®ä»·, price, å®å”®ä»· | float | å¿…éœ€ï¼Œç”¨äºæ¯›åˆ©ç‡è®¡ç®— |
| **å•†å“é‡‡è´­æˆæœ¬** | æˆæœ¬, åŸä»·, cost, è¿›è´§ä»· | float | å¿…éœ€ï¼Œç”¨äºåˆ©æ¶¦è®¡ç®— |
| **æ—¥æœŸ** | æ—¥æœŸ, date, **ä¸‹å•æ—¶é—´**, é‡‡é›†æ—¶é—´ | datetime | â­å¿…éœ€ï¼Œæ—¶é—´åˆ†æåŸºç¡€ |
| **è®¢å•ID** | è®¢å•ID, order_id, è®¢å•å· | str | è®¢å•èšåˆå¿…éœ€ |
| **ä¸€çº§åˆ†ç±»å** | ç¾å›¢ä¸€çº§åˆ†ç±», ä¸€çº§åˆ†ç±»å, category | str | åˆ†ç±»åˆ†æ |
| **ä¸‰çº§åˆ†ç±»å** | ç¾å›¢ä¸‰çº§åˆ†ç±», ä¸‰çº§åˆ†ç±»å | str | ç»†åˆ†åˆ†æ |
| **æœˆå”®** | æœˆå”®, monthly_sales, é”€é‡ | int | é”€é‡æŒ‡æ ‡ |
| **åº“å­˜** | åº“å­˜, stock, å‰©ä½™åº“å­˜ | int | åº“å­˜åˆ†æ |
| **ç‰©æµé…é€è´¹** | ç‰©æµé…é€è´¹, é…é€è´¹ | float | æˆæœ¬è®¡ç®— |
| **å¹³å°ä½£é‡‘** | å¹³å°ä½£é‡‘, ä½£é‡‘, commission | float | æˆæœ¬è®¡ç®— |
| **åœºæ™¯** | åœºæ™¯, scene | str | åœºæ™¯åˆ†æï¼ˆè‡ªåŠ¨æ¨æ–­ï¼‰ |
| **æ—¶æ®µ** | æ—¶æ®µ, time_period | str | æ—¶æ®µåˆ†æï¼ˆè‡ªåŠ¨æ¨æ–­ï¼‰ |
| **æ¸ é“** | æ¸ é“, channel | str | æ¸ é“è¿‡æ»¤ |

---

### 1.2 ä¸šåŠ¡è§„åˆ™è¿‡æ»¤ â­å…³é”®

```python
def apply_business_rules(df):
    """åº”ç”¨ç»Ÿä¸€ä¸šåŠ¡è§„åˆ™"""
    original_rows = len(df)
    
    # è§„åˆ™1ï¼šå‰”é™¤è€—ææ•°æ®ï¼ˆè´­ç‰©è¢‹ç­‰éé”€å”®å•†å“ï¼‰
    category_col = None
    for col in ['ä¸€çº§åˆ†ç±»å', 'ç¾å›¢ä¸€çº§åˆ†ç±»', 'ä¸€çº§åˆ†ç±»']:
        if col in df.columns:
            category_col = col
            break
    
    if category_col:
        df = df[df[category_col] != 'è€—æ'].copy()
        removed = original_rows - len(df)
        print(f"ğŸ”´ å‰”é™¤è€—æ: {removed:,} è¡Œ")
    
    # è§„åˆ™2ï¼šå‰”é™¤å’–å•¡æ¸ é“ï¼ˆéO2Oé›¶å”®æ ¸å¿ƒå“ç±»ï¼‰
    CHANNELS_TO_REMOVE = ['é¥¿äº†ä¹ˆå’–å•¡', 'ç¾å›¢å’–å•¡']
    if 'æ¸ é“' in df.columns:
        before = len(df)
        df = df[~df['æ¸ é“'].isin(CHANNELS_TO_REMOVE)].copy()
        removed = before - len(df)
        print(f"â˜• å‰”é™¤å’–å•¡æ¸ é“: {removed:,} è¡Œ")
    
    print(f"ğŸ“Š æœ€ç»ˆæ•°æ®é‡: {len(df):,} è¡Œ")
    return df
```

**ä¸šåŠ¡è§„åˆ™è¯´æ˜**:
- **è€—æå‰”é™¤åŸå› **: è´­ç‰©è¢‹ç­‰è€—æä¸å±äºé”€å”®å•†å“ï¼Œéœ€å•ç‹¬æ ¸ç®—
- **å’–å•¡å‰”é™¤åŸå› **: å’–å•¡ä¸šåŠ¡æ¨¡å¼ä¸åŒäºO2Oé›¶å”®ï¼Œéœ€å•ç‹¬åˆ†æ
- **æ•°æ®å½±å“**: çº¦å‡å°‘5-10%æ•°æ®é‡ï¼ˆå…·ä½“çœ‹æ•°æ®æºï¼‰

---

### 1.3 åœºæ™¯ä¸æ—¶æ®µæ¨æ–­

```python
from scene_inference import add_scene_and_timeslot_fields

def add_scene_and_timeslot_fields(df):
    """è‡ªåŠ¨æ¨æ–­åœºæ™¯å’Œæ—¶æ®µ"""
    # åŸºäºå•†å“åç§°ã€åˆ†ç±»ã€ä¸‹å•æ—¶é—´æ™ºèƒ½æ¨æ–­
    # ç”Ÿæˆ2ä¸ªæ–°å­—æ®µï¼š'åœºæ™¯'ã€'æ—¶æ®µ'
    return df_with_scene_timeslot
```

**æ¨æ–­é€»è¾‘**:
- åŸºäºå•†å“å…³é”®è¯ï¼ˆå¦‚"è±†æµ†"â†’æ—©é¤åœºæ™¯ï¼‰
- åŸºäºä¸‹å•æ—¶é—´ï¼ˆå¦‚6-9ç‚¹â†’æ¸…æ™¨æ—¶æ®µï¼‰
- åŸºäºå•†å“åˆ†ç±»ï¼ˆå¦‚"é¥®æ–™"â†’ä¸‹åˆèŒ¶åœºæ™¯ï¼‰

---

## ğŸ“ ç¬¬äºŒå±‚ï¼šæ´¾ç”Ÿå­—æ®µè®¡ç®—ï¼ˆè®¡ç®—å±‚ï¼‰

### 2.1 å•å“çº§åˆ«è®¡ç®—

```python
# å•å“æ¯›åˆ©
df['å•å“æ¯›åˆ©'] = df['å•†å“å®å”®ä»·'] - df['å•†å“é‡‡è´­æˆæœ¬']

# å•å“æ¯›åˆ©ç‡ï¼ˆç™¾åˆ†æ¯”ï¼‰
df['å•å“æ¯›åˆ©ç‡'] = (
    df['å•å“æ¯›åˆ©'] / df['å•†å“å®å”®ä»·'].where(df['å•†å“å®å”®ä»·'] > 0) * 100
).fillna(0)

# åº“å­˜å‘¨è½¬ç‡
df['åº“å­˜å‘¨è½¬ç‡'] = (
    df['æœˆå”®'] / df['åº“å­˜'].where(df['åº“å­˜'] > 0)
).fillna(0)
```

**è®¡ç®—åŸåˆ™**:
- âœ… æ¯›åˆ©ç‡åŸºäº**å•†å“å®å”®ä»·**ï¼Œä¸æ˜¯é¢„ä¼°è®¢å•æ”¶å…¥
- âœ… é¿å…é™¤ä»¥0ï¼Œä½¿ç”¨`.where()`åˆ¤æ–­
- âœ… ç©ºå€¼å¡«å……ä¸º0ï¼Œä¸æ˜¯NaN

---

### 2.2 è®¢å•çº§åˆ«èšåˆ â­æ ¸å¿ƒ

**åŸåˆ™**: å…ˆæŒ‰è®¢å•èšåˆï¼Œé¿å…é‡å¤è®¡ç®—è®¢å•çº§å­—æ®µ

```python
def aggregate_to_order_level(df):
    """è®¢å•çº§èšåˆï¼ˆæ ‡å‡†æµç¨‹ï¼‰"""
    
    order_agg = df.groupby('è®¢å•ID').agg({
        # å•†å“é”€å”®é¢ï¼ˆæ±‚å’Œï¼‰
        'å•†å“å®å”®ä»·': 'sum',
        'å•†å“é‡‡è´­æˆæœ¬': 'sum',
        'å•å“æ¯›åˆ©': 'sum',
        'æœˆå”®': 'sum',
        
        # è®¢å•çº§å­—æ®µï¼ˆå–ç¬¬ä¸€ä¸ªå€¼ï¼Œé¿å…é‡å¤ï¼‰
        'ç‰©æµé…é€è´¹': 'first',
        'å¹³å°ä½£é‡‘': 'first',
        'ç”¨æˆ·æ”¯ä»˜é…é€è´¹': 'first',
        'é…é€è´¹å‡å…': 'first',
        'æ»¡å‡é‡‘é¢': 'first',
        'å•†å“å‡å…é‡‘é¢': 'first',
        'å•†å®¶ä»£é‡‘åˆ¸': 'first',
        'å•†å®¶æ‰¿æ‹…éƒ¨åˆ†åˆ¸': 'first',
        'æ‰“åŒ…è¢‹é‡‘é¢': 'first',
        
        # ä¿ç•™å…³é”®ä¿¡æ¯
        'æ—¥æœŸ': 'first',
        'æ¸ é“': 'first',
        'åœºæ™¯': 'first',
        'æ—¶æ®µ': 'first'
    }).reset_index()
    
    return order_agg
```

**å…³é”®ç‚¹**:
- âŒ **é”™è¯¯**: `df.groupby('è®¢å•ID')['ç‰©æµé…é€è´¹'].sum()` â†’ ä¸€ä¸ªè®¢å•çš„é…é€è´¹è¢«è®¡ç®—Næ¬¡
- âœ… **æ­£ç¡®**: `df.groupby('è®¢å•ID')['ç‰©æµé…é€è´¹'].first()` â†’ æ¯ä¸ªè®¢å•é…é€è´¹åªè®¡ç®—1æ¬¡

---

### 2.3 è®¢å•æˆæœ¬ä¸åˆ©æ¶¦è®¡ç®— â­æ ¸å¿ƒå…¬å¼

```python
def calculate_order_profit(order_agg):
    """è®¡ç®—è®¢å•å®é™…åˆ©æ¶¦ï¼ˆç»Ÿä¸€æ ‡å‡†ï¼‰"""
    
    # A. å•†å®¶æ´»åŠ¨æˆæœ¬
    order_agg['å•†å®¶æ´»åŠ¨æˆæœ¬'] = (
        order_agg['æ»¡å‡é‡‘é¢'].fillna(0) + 
        order_agg['å•†å“å‡å…é‡‘é¢'].fillna(0) + 
        order_agg['å•†å®¶ä»£é‡‘åˆ¸'].fillna(0) +
        order_agg['å•†å®¶æ‰¿æ‹…éƒ¨åˆ†åˆ¸'].fillna(0)  # â­é‡è¦ï¼šå•†å®¶æ‰¿æ‹…çš„å¹³å°åˆ¸
    )
    
    # B. è®¢å•æ€»æ”¶å…¥
    order_agg['è®¢å•æ€»æ”¶å…¥'] = (
        order_agg['å•†å“å®å”®ä»·'] +      # å•†å“é”€å”®é¢
        order_agg['æ‰“åŒ…è¢‹é‡‘é¢'].fillna(0) +      # æ‰“åŒ…è¢‹æ”¶å…¥
        order_agg['ç”¨æˆ·æ”¯ä»˜é…é€è´¹'].fillna(0)    # ç”¨æˆ·æ”¯ä»˜çš„é…é€è´¹
    )
    
    # C. è®¢å•å®é™…åˆ©æ¶¦ â­â­â­ æ ¸å¿ƒå…¬å¼
    order_agg['è®¢å•å®é™…åˆ©æ¶¦'] = (
        order_agg['å•å“æ¯›åˆ©'] -                    # å•†å“æ¯›åˆ©ï¼ˆå·²æ‰£é™¤æˆæœ¬å’Œæ´»åŠ¨ï¼‰
        order_agg['ç‰©æµé…é€è´¹'].fillna(0) -       # å•†å®¶å®é™…æ”¯ä»˜çš„é…é€æˆæœ¬
        order_agg['å¹³å°ä½£é‡‘'].fillna(0)           # å¹³å°ä½£é‡‘
    )
    
    return order_agg
```

**å…¬å¼è¯´æ˜**:
```
è®¢å•å®é™…åˆ©æ¶¦ = å•†å“æ¯›åˆ© - ç‰©æµé…é€è´¹ - å¹³å°ä½£é‡‘

å…¶ä¸­:
- å•†å“æ¯›åˆ© = å•†å“é”€å”®é¢ - å•†å“æˆæœ¬ - æ´»åŠ¨æˆæœ¬
- ç‰©æµé…é€è´¹ = å•†å®¶å®é™…æ”¯ä»˜ç»™éª‘æ‰‹çš„è´¹ç”¨ï¼ˆä¸æ˜¯ç”¨æˆ·æ”¯ä»˜çš„é…é€è´¹ï¼‰
- å¹³å°ä½£é‡‘ = å¹³å°æŠ½æˆ
```

---

## ğŸ“ ç¬¬ä¸‰å±‚ï¼šæ±‡æ€»æŒ‡æ ‡è®¡ç®—ï¼ˆå±•ç¤ºå±‚ï¼‰

### 3.1 åŸºç¡€æ±‡æ€»æŒ‡æ ‡

```python
def calculate_summary_metrics(order_agg):
    """è®¡ç®—æ±‡æ€»æŒ‡æ ‡"""
    
    metrics = {
        # è®¢å•æŒ‡æ ‡
        'è®¢å•æ€»æ•°': len(order_agg),
        
        # é”€å”®æŒ‡æ ‡ï¼ˆåŸºäºå•†å“é”€å”®é¢ï¼‰
        'å•†å“é”€å”®é¢': order_agg['å•†å“å®å”®ä»·'].sum(),
        'è®¢å•æ€»æ”¶å…¥': order_agg['è®¢å•æ€»æ”¶å…¥'].sum(),
        
        # åˆ©æ¶¦æŒ‡æ ‡
        'æ€»åˆ©æ¶¦': order_agg['è®¢å•å®é™…åˆ©æ¶¦'].sum(),
        'åˆ©æ¶¦ç‡': 0,  # åç»­è®¡ç®—
        
        # æˆæœ¬æŒ‡æ ‡
        'å•†å“æˆæœ¬': order_agg['å•†å“é‡‡è´­æˆæœ¬'].sum(),
        'é…é€æˆæœ¬': order_agg['ç‰©æµé…é€è´¹'].sum(),
        'ä½£é‡‘æˆæœ¬': order_agg['å¹³å°ä½£é‡‘'].sum(),
        'æ´»åŠ¨æˆæœ¬': order_agg['å•†å®¶æ´»åŠ¨æˆæœ¬'].sum(),
        
        # è®¢å•å‡å€¼
        'å¹³å‡å®¢å•ä»·': 0,  # åç»­è®¡ç®—
        'å¹³å‡åˆ©æ¶¦': 0     # åç»­è®¡ç®—
    }
    
    # è®¡ç®—ç‡ç±»æŒ‡æ ‡
    if metrics['å•†å“é”€å”®é¢'] > 0:
        metrics['åˆ©æ¶¦ç‡'] = metrics['æ€»åˆ©æ¶¦'] / metrics['å•†å“é”€å”®é¢'] * 100
    
    if metrics['è®¢å•æ€»æ•°'] > 0:
        metrics['å¹³å‡å®¢å•ä»·'] = metrics['å•†å“é”€å”®é¢'] / metrics['è®¢å•æ€»æ•°']
        metrics['å¹³å‡åˆ©æ¶¦'] = metrics['æ€»åˆ©æ¶¦'] / metrics['è®¢å•æ€»æ•°']
    
    # è®¡ç®—ç›ˆåˆ©è®¢å•å æ¯”
    profitable_orders = (order_agg['è®¢å•å®é™…åˆ©æ¶¦'] > 0).sum()
    metrics['ç›ˆåˆ©è®¢å•å æ¯”'] = profitable_orders / metrics['è®¢å•æ€»æ•°'] * 100 if metrics['è®¢å•æ€»æ•°'] > 0 else 0
    
    return metrics
```

**æŒ‡æ ‡è¯´æ˜**:
- **åˆ©æ¶¦ç‡**: åŸºäº**å•†å“é”€å”®é¢**è®¡ç®—ï¼Œä¸æ˜¯è®¢å•æ€»æ”¶å…¥
- **å¹³å‡å®¢å•ä»·**: å•†å“é”€å”®é¢ / è®¢å•æ•°
- **ç›ˆåˆ©è®¢å•å æ¯”**: åˆ©æ¶¦>0çš„è®¢å•æ•° / æ€»è®¢å•æ•°

---

### 3.2 æ—¶é—´ç»´åº¦èšåˆ

```python
def aggregate_by_time(order_agg, dimension='æ—¥æœŸ'):
    """æŒ‰æ—¶é—´ç»´åº¦èšåˆ"""
    
    # ç¡®ä¿æ—¥æœŸåˆ—æ˜¯datetimeç±»å‹
    order_agg['æ—¥æœŸ'] = pd.to_datetime(order_agg['æ—¥æœŸ'])
    
    if dimension == 'å‘¨':
        order_agg['å‘¨'] = order_agg['æ—¥æœŸ'].dt.isocalendar().week
        group_col = 'å‘¨'
    elif dimension == 'æœˆ':
        order_agg['æœˆ'] = order_agg['æ—¥æœŸ'].dt.to_period('M').astype(str)
        group_col = 'æœˆ'
    else:  # æ—¥
        group_col = 'æ—¥æœŸ'
    
    time_agg = order_agg.groupby(group_col).agg({
        'è®¢å•ID': 'count',
        'å•†å“å®å”®ä»·': 'sum',
        'è®¢å•å®é™…åˆ©æ¶¦': 'sum',
        'è®¢å•æ€»æ”¶å…¥': 'sum'
    }).reset_index()
    
    time_agg.columns = [group_col, 'è®¢å•æ•°', 'é”€å”®é¢', 'åˆ©æ¶¦', 'æ€»æ”¶å…¥']
    
    return time_agg
```

---

### 3.3 åˆ†ç±»ç»´åº¦èšåˆ

```python
def aggregate_by_category(df):
    """æŒ‰åˆ†ç±»èšåˆï¼ˆæ³¨æ„ï¼šä½¿ç”¨åŸå§‹æ•°æ®ï¼Œä¸æ˜¯è®¢å•èšåˆæ•°æ®ï¼‰"""
    
    # âš ï¸ åˆ†ç±»åˆ†æè¦ç”¨åŸå§‹å•†å“æ˜ç»†æ•°æ®
    # å› ä¸ºé…é€è´¹/ä½£é‡‘ä¸èƒ½åˆ†æ‘Šåˆ°æ¯ä¸ªå•†å“
    
    category_agg = df.groupby('ä¸€çº§åˆ†ç±»å').agg({
        'å•†å“å®å”®ä»·': 'sum',           # é”€å”®é¢
        'å•†å“é‡‡è´­æˆæœ¬': 'sum',         # æˆæœ¬
        'å•å“æ¯›åˆ©': 'sum',             # æ¯›åˆ©
        'æœˆå”®': 'sum',                 # é”€é‡
        'è®¢å•ID': 'nunique'            # è®¢å•æ•°ï¼ˆå»é‡ï¼‰
    }).reset_index()
    
    category_agg.columns = ['åˆ†ç±»', 'é”€å”®é¢', 'æˆæœ¬', 'æ¯›åˆ©', 'é”€é‡', 'è®¢å•æ•°']
    
    # è®¡ç®—æ¯›åˆ©ç‡
    category_agg['æ¯›åˆ©ç‡'] = (
        category_agg['æ¯›åˆ©'] / category_agg['é”€å”®é¢'] * 100
    ).fillna(0)
    
    return category_agg
```

**å…³é”®ç‚¹**:
- âœ… åˆ†ç±»åˆ†æç”¨**åŸå§‹æ˜ç»†æ•°æ®**ï¼ˆdfï¼‰ï¼Œä¸æ˜¯è®¢å•èšåˆæ•°æ®ï¼ˆorder_aggï¼‰
- âœ… è®¢å•æ•°ä½¿ç”¨`nunique()`å»é‡
- âŒ ä¸è¦åœ¨åˆ†ç±»ç»´åº¦è®¡ç®—é…é€è´¹/ä½£é‡‘ï¼ˆè¿™æ˜¯è®¢å•çº§æˆæœ¬ï¼Œæ— æ³•åˆ†æ‘Šåˆ°å•†å“ï¼‰

---

## ğŸ“ ç¬¬å››å±‚ï¼šå‘¨æœŸå¯¹æ¯”è®¡ç®—ï¼ˆè¯Šæ–­å±‚ï¼‰

### 4.1 é”€é‡ä¸‹æ»‘è¯Šæ–­

```python
def diagnose_sales_decline(df, current_period, compare_period, time_period='week'):
    """é”€é‡ä¸‹æ»‘è¯Šæ–­ï¼ˆç»Ÿä¸€æ ‡å‡†ï¼‰"""
    
    # Step 1: è¿‡æ»¤å½“å‰å‘¨æœŸå’Œå¯¹æ¯”å‘¨æœŸæ•°æ®
    df_current = filter_by_period(df, current_period, time_period)
    df_compare = filter_by_period(df, compare_period, time_period)
    
    # Step 2: æŒ‰å•†å“èšåˆé”€é‡
    current_sales = df_current.groupby('å•†å“åç§°').agg({
        'æœˆå”®': 'sum',
        'å•†å“å®å”®ä»·': 'mean',
        'å•å“æ¯›åˆ©ç‡': 'mean'
    }).reset_index()
    
    compare_sales = df_compare.groupby('å•†å“åç§°').agg({
        'æœˆå”®': 'sum'
    }).reset_index()
    
    # Step 3: åˆå¹¶å¯¹æ¯”
    result = current_sales.merge(
        compare_sales, 
        on='å•†å“åç§°', 
        how='outer', 
        suffixes=('_å½“å‰', '_å¯¹æ¯”')
    ).fillna(0)
    
    # Step 4: è®¡ç®—å˜åŒ–
    result['é”€é‡å˜åŒ–'] = result['æœˆå”®_å½“å‰'] - result['æœˆå”®_å¯¹æ¯”']
    result['å˜åŒ–å¹…åº¦%'] = (
        result['é”€é‡å˜åŒ–'] / result['æœˆå”®_å¯¹æ¯”'].where(result['æœˆå”®_å¯¹æ¯”'] > 0) * 100
    ).fillna(0)
    
    # Step 5: ç­›é€‰ä¸‹æ»‘å•†å“
    decline_products = result[result['é”€é‡å˜åŒ–'] < 0].copy()
    
    # Step 6: è®¡ç®—æŸå¤±
    decline_products['æ”¶å…¥æŸå¤±'] = (
        decline_products['é”€é‡å˜åŒ–'].abs() * 
        decline_products['å•†å“å®å”®ä»·_å½“å‰']
    )
    
    decline_products['åˆ©æ¶¦æŸå¤±'] = (
        decline_products['æ”¶å…¥æŸå¤±'] * 
        decline_products['å•å“æ¯›åˆ©ç‡_å½“å‰'] / 100
    )
    
    return decline_products
```

---

### 4.2 å®¢å•ä»·å½’å› åˆ†æ

```python
def analyze_aov_attribution(df, current_period, compare_period):
    """å®¢å•ä»·å½’å› åˆ†æ"""
    
    # Step 1: è®¡ç®—è®¢å•çº§å®¢å•ä»·
    df_current = filter_by_period(df, current_period)
    df_compare = filter_by_period(df, compare_period)
    
    # è®¢å•èšåˆ
    current_orders = aggregate_to_order_level(df_current)
    compare_orders = aggregate_to_order_level(df_compare)
    
    # è®¡ç®—å¹³å‡å®¢å•ä»·
    current_aov = current_orders['å•†å“å®å”®ä»·'].mean()
    compare_aov = compare_orders['å•†å“å®å”®ä»·'].mean()
    
    # Step 2: å½’å› åˆ†è§£
    # å•†å“æ•°é‡å˜åŒ–è´¡çŒ®
    current_items_per_order = df_current.groupby('è®¢å•ID').size().mean()
    compare_items_per_order = df_compare.groupby('è®¢å•ID').size().mean()
    quantity_effect = (current_items_per_order - compare_items_per_order) * compare_aov
    
    # å•†å“å•ä»·å˜åŒ–è´¡çŒ®
    current_avg_price = df_current['å•†å“å®å”®ä»·'].mean()
    compare_avg_price = df_compare['å•†å“å®å”®ä»·'].mean()
    price_effect = (current_avg_price - compare_avg_price) * current_items_per_order
    
    # äº¤äº’æ•ˆåº”
    interaction_effect = (
        (current_items_per_order - compare_items_per_order) * 
        (current_avg_price - compare_avg_price)
    )
    
    attribution = {
        'å®¢å•ä»·å˜åŒ–': current_aov - compare_aov,
        'æ•°é‡æ•ˆåº”': quantity_effect,
        'ä»·æ ¼æ•ˆåº”': price_effect,
        'äº¤äº’æ•ˆåº”': interaction_effect
    }
    
    return attribution
```

---

## ğŸ”§ ç¬¬äº”å±‚ï¼šé—®é¢˜è¯Šæ–­å¼•æ“ï¼ˆæ™ºèƒ½å±‚ï¼‰

### 5.1 è¯Šæ–­å¼•æ“åˆå§‹åŒ–

```python
from é—®é¢˜è¯Šæ–­å¼•æ“ import ProblemDiagnosticEngine

# åˆå§‹åŒ–è¯Šæ–­å¼•æ“
engine = ProblemDiagnosticEngine(df_processed)

# ä½¿ç”¨è¯Šæ–­åŠŸèƒ½
decline_result = engine.diagnose_sales_decline(
    current_period_idx=0,
    compare_period_idx=1,
    time_period='week',
    threshold=-100  # æ˜¾ç¤ºæ‰€æœ‰ä¸‹æ»‘å•†å“
)
```

**è¯Šæ–­å¼•æ“æä¾›çš„åŠŸèƒ½**:
1. âœ… é”€é‡ä¸‹æ»‘è¯Šæ–­
2. âœ… å®¢å•ä»·å½’å› åˆ†æ
3. âœ… è´Ÿæ¯›åˆ©é¢„è­¦
4. âœ… é«˜é…é€è´¹è¯Šæ–­
5. âœ… å•†å“è§’è‰²å¤±è¡¡
6. âœ… å¼‚å¸¸æ³¢åŠ¨æ£€æµ‹

---

## âš ï¸ å¸¸è§é”™è¯¯ä¸é¿å…æ–¹æ³•

### é”™è¯¯1: é‡å¤è®¡ç®—è®¢å•çº§å­—æ®µ

```python
# âŒ é”™è¯¯ç¤ºä¾‹
product_delivery = df.groupby('å•†å“åç§°')['ç‰©æµé…é€è´¹'].sum()
# é—®é¢˜ï¼šä¸€ä¸ªè®¢å•çš„é…é€è´¹è¢«è®¡ç®—äº†Næ¬¡ï¼ˆN=å•†å“æ•°é‡ï¼‰

# âœ… æ­£ç¡®åšæ³•
# å…ˆæŒ‰è®¢å•èšåˆ
order_agg = df.groupby('è®¢å•ID')['ç‰©æµé…é€è´¹'].first()
# å†æŒ‰å•†å“åˆ†æ
product_orders = df.groupby('å•†å“åç§°')['è®¢å•ID'].apply(list)
```

---

### é”™è¯¯2: åˆ©æ¶¦ç‡åŸºæ•°é”™è¯¯

```python
# âŒ é”™è¯¯ç¤ºä¾‹
profit_rate = total_profit / total_revenue * 100
# é—®é¢˜ï¼šåŸºæ•°åº”è¯¥æ˜¯å•†å“é”€å”®é¢ï¼Œä¸æ˜¯è®¢å•æ€»æ”¶å…¥

# âœ… æ­£ç¡®åšæ³•
profit_rate = total_profit / total_sales * 100
# total_sales = å•†å“é”€å”®é¢ï¼ˆä¸å«é…é€è´¹ï¼‰
```

---

### é”™è¯¯3: å¿½ç•¥å•†å®¶æ‰¿æ‹…éƒ¨åˆ†åˆ¸

```python
# âŒ é”™è¯¯ç¤ºä¾‹
activity_cost = æ»¡å‡é‡‘é¢ + å•†å“å‡å…é‡‘é¢ + å•†å®¶ä»£é‡‘åˆ¸

# âœ… æ­£ç¡®åšæ³•
activity_cost = (
    æ»¡å‡é‡‘é¢ + 
    å•†å“å‡å…é‡‘é¢ + 
    å•†å®¶ä»£é‡‘åˆ¸ + 
    å•†å®¶æ‰¿æ‹…éƒ¨åˆ†åˆ¸  # â­ é‡è¦ï¼šè¿™æ˜¯å•†å®¶æˆæœ¬
)
```

---

### é”™è¯¯4: æ•°æ®æœªå‰”é™¤è€—æå’Œå’–å•¡

```python
# âŒ é”™è¯¯ç¤ºä¾‹
df_std = processor.standardize_sales_data(df_raw)
# ç›´æ¥ä½¿ç”¨ï¼Œæœªè¿‡æ»¤

# âœ… æ­£ç¡®åšæ³•
df_std = processor.standardize_sales_data(df_raw)
df_clean = apply_business_rules(df_std)  # â­ å¿…é¡»è¿‡æ»¤
```

---

## ğŸ“‹ å„çœ‹æ¿åº”ç”¨æ£€æŸ¥æ¸…å•

### é”€é‡ä¸‹æ»‘è¯Šæ–­çœ‹æ¿ âœ…

- [x] ä½¿ç”¨`RealDataProcessor.standardize_sales_data()`
- [x] åº”ç”¨ä¸šåŠ¡è§„åˆ™è¿‡æ»¤ï¼ˆè€—æã€å’–å•¡ï¼‰
- [x] ä½¿ç”¨`ProblemDiagnosticEngine.diagnose_sales_decline()`
- [x] å‘¨æœŸå¯¹æ¯”é€»è¾‘æ­£ç¡®
- [x] è®¡ç®—æ”¶å…¥/åˆ©æ¶¦æŸå¤±

### å®¢å•ä»·åˆ†æçœ‹æ¿ â¸ï¸

- [ ] ä½¿ç”¨ç»Ÿä¸€çš„è®¢å•èšåˆé€»è¾‘
- [ ] å½’å› åˆ†è§£é€»è¾‘æ­£ç¡®
- [ ] å•†å“æ•°é‡æ•ˆåº”ã€ä»·æ ¼æ•ˆåº”åˆ†ç¦»

### è®¢å•åˆ†æçœ‹æ¿ â¸ï¸

- [ ] è®¢å•çº§èšåˆï¼ˆé¿å…é‡å¤ï¼‰
- [ ] åˆ©æ¶¦è®¡ç®—å…¬å¼æ­£ç¡®
- [ ] æˆæœ¬ç»“æ„åˆ†æå®Œæ•´

---

## ğŸ¯ æ•°æ®ä¸€è‡´æ€§éªŒè¯æ–¹æ³•

```python
def verify_data_consistency(df1, df2):
    """éªŒè¯ä¸¤ä¸ªçœ‹æ¿çš„æ•°æ®ä¸€è‡´æ€§"""
    
    # éªŒè¯1: æ€»é”€å”®é¢
    sales1 = df1['å•†å“å®å”®ä»·'].sum()
    sales2 = df2['å•†å“å®å”®ä»·'].sum()
    assert abs(sales1 - sales2) < 0.01, f"é”€å”®é¢ä¸ä¸€è‡´: {sales1} vs {sales2}"
    
    # éªŒè¯2: æ€»åˆ©æ¶¦
    profit1 = df1['è®¢å•å®é™…åˆ©æ¶¦'].sum()
    profit2 = df2['è®¢å•å®é™…åˆ©æ¶¦'].sum()
    assert abs(profit1 - profit2) < 0.01, f"åˆ©æ¶¦ä¸ä¸€è‡´: {profit1} vs {profit2}"
    
    # éªŒè¯3: è®¢å•æ•°
    orders1 = df1['è®¢å•ID'].nunique()
    orders2 = df2['è®¢å•ID'].nunique()
    assert orders1 == orders2, f"è®¢å•æ•°ä¸ä¸€è‡´: {orders1} vs {orders2}"
    
    print("âœ… æ•°æ®ä¸€è‡´æ€§éªŒè¯é€šè¿‡")
```

---

## ğŸ“š å‚è€ƒæ–‡æ¡£

1. **ä¸šåŠ¡é€»è¾‘æœ€ç»ˆç¡®è®¤.md** - ä¸šåŠ¡è§„åˆ™å®šä¹‰
2. **ç»Ÿä¸€è®¡ç®—æ ‡å‡†.md** - Streamlitç‰ˆæœ¬æ ‡å‡†ï¼ˆå·²åºŸå¼ƒï¼Œä»¥æœ¬æ–‡æ¡£ä¸ºå‡†ï¼‰
3. **æ•°æ®å¤„ç†é€»è¾‘ä¸€è‡´æ€§æŠ¥å‘Š.md** - å†å²é—®é¢˜è®°å½•

---

## ğŸ”„ ç‰ˆæœ¬å†å²

### v2.0 (2025-10-24) - Dashç‰ˆæœ¬ç»Ÿä¸€æ ‡å‡†
- âœ… åŸºäºDashç‰ˆæœ¬é‡æ–°æ¢³ç†
- âœ… æ˜ç¡®5å±‚è®¡ç®—æ¶æ„
- âœ… æ·»åŠ é”™è¯¯ç¤ºä¾‹å’Œé¿å…æ–¹æ³•
- âœ… å®Œå–„è¯Šæ–­å¼•æ“ä½¿ç”¨è§„èŒƒ

### v1.0 (2025-10-18) - Streamlitç‰ˆæœ¬æ ‡å‡†
- åˆå§‹ç‰ˆæœ¬ï¼ˆå·²åºŸå¼ƒï¼‰

---

**ç»´æŠ¤äºº**: GitHub Copilot  
**å®¡æ ¸çŠ¶æ€**: âœ… å·²ç¡®è®¤  
**ä¸‹æ¬¡æ›´æ–°**: æ ¹æ®å®é™…å¼€å‘æƒ…å†µè°ƒæ•´

---

## ğŸš€ å¿«é€Ÿå¼€å§‹æ¨¡æ¿

```python
# ===== Dashçœ‹æ¿æ ‡å‡†å¼€å‘æ¨¡æ¿ =====

# Step 1: å¯¼å…¥æ ‡å‡†æ¨¡å—
from çœŸå®æ•°æ®å¤„ç†å™¨ import RealDataProcessor
from é—®é¢˜è¯Šæ–­å¼•æ“ import ProblemDiagnosticEngine
from scene_inference import add_scene_and_timeslot_fields

# Step 2: æ•°æ®åŠ è½½ä¸æ ‡å‡†åŒ–
def load_data(df_raw):
    # 2.1 å­—æ®µæ˜ å°„
    processor = RealDataProcessor()
    df_std = processor.standardize_sales_data(df_raw)
    
    # 2.2 ä¸šåŠ¡è§„åˆ™è¿‡æ»¤
    df_clean = apply_business_rules(df_std)
    
    # 2.3 åœºæ™¯æ—¶æ®µæ¨æ–­
    df_final = add_scene_and_timeslot_fields(df_clean)
    
    return df_final

# Step 3: åˆå§‹åŒ–è¯Šæ–­å¼•æ“
GLOBAL_DATA = load_data(df_raw)
DIAGNOSTIC_ENGINE = ProblemDiagnosticEngine(GLOBAL_DATA)

# Step 4: ä½¿ç”¨è¯Šæ–­åŠŸèƒ½
result = DIAGNOSTIC_ENGINE.diagnose_sales_decline(
    current_period_idx=0,
    compare_period_idx=1,
    time_period='week',
    threshold=-100
)

# Step 5: æ•°æ®éªŒè¯
verify_data_consistency(result, expected_result)
```

---

**æœ¬æ–‡æ¡£æ˜¯æ‰€æœ‰Dashçœ‹æ¿çš„æ•°æ®è®¡ç®—åŸºå‡†ï¼Œä»»ä½•ä¿®æ”¹éœ€åŒæ­¥æ›´æ–°ï¼**
