# -*- coding: utf-8 -*-
"""
è®¢å•æ•°æ®æ¦‚è§ˆ API

å®Œå…¨å¯¹é½è€ç‰ˆæœ¬Dashçš„Tab1è®¢å•æ•°æ®æ¦‚è§ˆåŠŸèƒ½ï¼š
- å…­å¤§æ ¸å¿ƒå¡ç‰‡æŒ‡æ ‡
- æ¸ é“è¡¨ç°å¯¹æ¯”
- å®¢å•ä»·åŒºé—´åˆ†å¸ƒ
- ä¸€çº§åˆ†ç±»é”€å”®è¶‹åŠ¿
- è®¢å•è¶‹åŠ¿åˆ†æ
- ç¯æ¯”è®¡ç®—
- å¼‚å¸¸è¯Šæ–­

ä¸šåŠ¡é€»è¾‘æ¥æº: æ™ºèƒ½é—¨åº—çœ‹æ¿_Dashç‰ˆ.py ä¸­çš„ Tab 1 å›è°ƒ
"""

from fastapi import APIRouter, Depends, Query, HTTPException
from typing import Optional, List, Dict, Any
from datetime import date, datetime, timedelta
import pandas as pd
import numpy as np
import hashlib
import json
import time

import sys
from pathlib import Path
APP_DIR = Path(__file__).resolve().parent.parent.parent
if str(APP_DIR) not in sys.path:
    sys.path.insert(0, str(APP_DIR))

from database.connection import SessionLocal
from database.models import Order

# å°è¯•å¯¼å…¥Redisç¼“å­˜
try:
    import redis
    REDIS_AVAILABLE = True
    redis_client = redis.Redis(host='localhost', port=6379, db=0, decode_responses=True)
    # æµ‹è¯•è¿æ¥
    redis_client.ping()
    print("âœ… Redisç¼“å­˜å·²è¿æ¥")
except Exception as e:
    REDIS_AVAILABLE = False
    redis_client = None
    print(f"âš ï¸ Redisç¼“å­˜ä¸å¯ç”¨: {e}")

router = APIRouter()

# ==================== ç¼“å­˜é…ç½® ====================
CACHE_TTL = 300  # ç¼“å­˜æœ‰æ•ˆæœŸ5åˆ†é’Ÿ
ORDER_DATA_CACHE_KEY = "order_data_cache"
ORDER_DATA_TIMESTAMP_KEY = "order_data_timestamp"

# å†…å­˜ç¼“å­˜ï¼ˆå¤‡ç”¨ï¼‰
_memory_cache = {
    "order_data": None,
    "timestamp": 0
}

# ==================== æ”¶è´¹æ¸ é“åˆ—è¡¨ï¼ˆä¸è€ç‰ˆæœ¬ä¸€è‡´ï¼‰====================
PLATFORM_FEE_CHANNELS = [
    'é¥¿äº†ä¹ˆ',
    'äº¬ä¸œåˆ°å®¶',
    'ç¾å›¢å…±æ©™',
    'ç¾å›¢é—ªè´­',
    'æŠ–éŸ³',
    'æŠ–éŸ³ç›´æ’­',
    'æ·˜é²œè¾¾',
    'äº¬ä¸œç§’é€',
    'ç¾å›¢å’–å•¡åº—',
    'é¥¿äº†ä¹ˆå’–å•¡åº—'
]


def get_order_data() -> pd.DataFrame:
    """
    ä»æ•°æ®åº“åŠ è½½è®¢å•æ•°æ®ï¼ˆå¸¦ç¼“å­˜ï¼‰
    
    ç¼“å­˜ç­–ç•¥:
    1. ä¼˜å…ˆä½¿ç”¨Redisç¼“å­˜
    2. å¤‡ç”¨å†…å­˜ç¼“å­˜
    3. ç¼“å­˜æœ‰æ•ˆæœŸ5åˆ†é’Ÿ
    """
    global _memory_cache
    current_time = time.time()
    
    # 1. å°è¯•ä»Redisè·å–ç¼“å­˜
    if REDIS_AVAILABLE and redis_client:
        try:
            cached_timestamp = redis_client.get(ORDER_DATA_TIMESTAMP_KEY)
            if cached_timestamp:
                if current_time - float(cached_timestamp) < CACHE_TTL:
                    cached_data = redis_client.get(ORDER_DATA_CACHE_KEY)
                    if cached_data:
                        data = json.loads(cached_data)
                        print(f"ğŸ“¦ ä½¿ç”¨Redisç¼“å­˜æ•°æ® ({len(data)} æ¡)")
                        return pd.DataFrame(data)
        except Exception as e:
            print(f"âš ï¸ Redisè¯»å–å¤±è´¥: {e}")
    
    # 2. å°è¯•ä½¿ç”¨å†…å­˜ç¼“å­˜
    if _memory_cache["order_data"] is not None:
        if current_time - _memory_cache["timestamp"] < CACHE_TTL:
            print(f"ğŸ“¦ ä½¿ç”¨å†…å­˜ç¼“å­˜æ•°æ®")
            return _memory_cache["order_data"].copy()
    
    # 3. ä»æ•°æ®åº“åŠ è½½
    print("ğŸ”„ ä»æ•°æ®åº“åŠ è½½è®¢å•æ•°æ®...")
    session = SessionLocal()
    try:
        orders = session.query(Order).all()
        if not orders:
            return pd.DataFrame()
        
        # è½¬æ¢ä¸ºDataFrameï¼ˆå­—æ®µåä¸æ•°æ®åº“æ¨¡å‹ä¸€è‡´ï¼‰
        data = []
        for order in orders:
            data.append({
                'è®¢å•ID': order.order_id,
                'é—¨åº—åç§°': order.store_name,
                'æ—¥æœŸ': order.date,  # æ•°æ®åº“å­—æ®µæ˜¯date
                'æ¸ é“': order.channel,
                'å•†å“åç§°': order.product_name,
                'ä¸€çº§åˆ†ç±»å': order.category_level1,
                'ä¸‰çº§åˆ†ç±»å': order.category_level3,  # æ•°æ®åº“åªæœ‰ä¸‰çº§åˆ†ç±»
                'æœˆå”®': order.quantity,
                'å®æ”¶ä»·æ ¼': float(order.actual_price or 0),
                'å•†å“å®å”®ä»·': float(order.price or 0),  # æ•°æ®åº“å­—æ®µæ˜¯price
                'å•†å“é‡‡è´­æˆæœ¬': float(order.cost or 0),  # æ•°æ®åº“å­—æ®µæ˜¯cost
                'åˆ©æ¶¦é¢': float(order.profit or 0),
                'ç‰©æµé…é€è´¹': float(order.delivery_fee or 0),
                'å¹³å°æœåŠ¡è´¹': float(order.platform_service_fee or 0),
                'å¹³å°ä½£é‡‘': float(order.commission or 0),
                'é¢„è®¡è®¢å•æ”¶å…¥': float(order.amount or 0),  # ä½¿ç”¨amountä½œä¸ºé¢„è®¡è®¢å•æ”¶å…¥
                'ä¼å®¢åè¿”': float(order.corporate_rebate or 0),  # æ•°æ®åº“å­—æ®µæ˜¯corporate_rebate
                'ç”¨æˆ·æ”¯ä»˜é…é€è´¹': float(order.user_paid_delivery_fee or 0),
                'é…é€è´¹å‡å…é‡‘é¢': float(order.delivery_discount or 0),
                'æ»¡å‡é‡‘é¢': float(order.full_reduction or 0),
                'å•†å“å‡å…é‡‘é¢': float(order.product_discount or 0),
                'æ–°å®¢å‡å…é‡‘é¢': float(order.new_customer_discount or 0),
                'åº“å­˜': order.stock,
            })
        
        df = pd.DataFrame(data)
        print(f"âœ… æ•°æ®åº“åŠ è½½å®Œæˆ: {len(df)} æ¡è®°å½•")
        
        # 4. æ›´æ–°ç¼“å­˜
        # æ›´æ–°å†…å­˜ç¼“å­˜
        _memory_cache["order_data"] = df.copy()
        _memory_cache["timestamp"] = current_time
        
        # æ›´æ–°Redisç¼“å­˜
        if REDIS_AVAILABLE and redis_client:
            try:
                # å°†æ—¥æœŸè½¬æ¢ä¸ºå­—ç¬¦ä¸²ä»¥ä¾¿JSONåºåˆ—åŒ–
                cache_data = data.copy()
                for item in cache_data:
                    if item.get('æ—¥æœŸ'):
                        item['æ—¥æœŸ'] = str(item['æ—¥æœŸ'])
                
                redis_client.set(ORDER_DATA_CACHE_KEY, json.dumps(cache_data, ensure_ascii=False))
                redis_client.set(ORDER_DATA_TIMESTAMP_KEY, str(current_time))
                print("âœ… æ•°æ®å·²ç¼“å­˜åˆ°Redis")
            except Exception as e:
                print(f"âš ï¸ Redisç¼“å­˜å†™å…¥å¤±è´¥: {e}")
        
        return df
    finally:
        session.close()


def invalidate_cache():
    """æ¸…é™¤ç¼“å­˜ï¼ˆæ•°æ®æ›´æ–°æ—¶è°ƒç”¨ï¼‰"""
    global _memory_cache
    _memory_cache = {"order_data": None, "timestamp": 0}
    
    if REDIS_AVAILABLE and redis_client:
        try:
            redis_client.delete(ORDER_DATA_CACHE_KEY)
            redis_client.delete(ORDER_DATA_TIMESTAMP_KEY)
            print("âœ… ç¼“å­˜å·²æ¸…é™¤")
        except Exception as e:
            print(f"âš ï¸ Redisç¼“å­˜æ¸…é™¤å¤±è´¥: {e}")


def calculate_order_metrics(df: pd.DataFrame) -> pd.DataFrame:
    """
    ç»Ÿä¸€çš„è®¢å•æŒ‡æ ‡è®¡ç®—å‡½æ•°ï¼ˆä¸è€ç‰ˆæœ¬å®Œå…¨ä¸€è‡´ï¼‰
    
    æ ¸å¿ƒè®¡ç®—é€»è¾‘:
    1. è®¢å•çº§èšåˆï¼ˆè®¢å•çº§å­—æ®µç”¨firstï¼Œå•†å“çº§å­—æ®µç”¨sumï¼‰
    2. è®¡ç®—è®¢å•å®é™…åˆ©æ¶¦ = åˆ©æ¶¦é¢ - å¹³å°æœåŠ¡è´¹ - ç‰©æµé…é€è´¹ + ä¼å®¢åè¿”
    3. æŒ‰æ¸ é“ç±»å‹è¿‡æ»¤å¼‚å¸¸è®¢å•
    """
    if df.empty or 'è®¢å•ID' not in df.columns:
        return pd.DataFrame()
    
    df = df.copy()
    
    # ç»Ÿä¸€è®¢å•IDç±»å‹ä¸ºå­—ç¬¦ä¸²
    df['è®¢å•ID'] = df['è®¢å•ID'].astype(str)
    
    # å…¼å®¹ä¸åŒæˆæœ¬å­—æ®µå
    cost_field = 'å•†å“é‡‡è´­æˆæœ¬' if 'å•†å“é‡‡è´­æˆæœ¬' in df.columns else 'æˆæœ¬'
    sales_field = 'æœˆå”®' if 'æœˆå”®' in df.columns else 'é”€é‡'
    
    # ç©ºå€¼å¡«å……
    df['ç‰©æµé…é€è´¹'] = df['ç‰©æµé…é€è´¹'].fillna(0)
    df['é…é€è´¹å‡å…é‡‘é¢'] = df['é…é€è´¹å‡å…é‡‘é¢'].fillna(0)
    df['ç”¨æˆ·æ”¯ä»˜é…é€è´¹'] = df['ç”¨æˆ·æ”¯ä»˜é…é€è´¹'].fillna(0)
    
    # è®¡ç®—è®¢å•æ€»æ”¶å…¥ï¼ˆå®æ”¶ä»·æ ¼ Ã— é”€é‡ï¼‰
    if 'å®æ”¶ä»·æ ¼' in df.columns and sales_field in df.columns:
        df['è®¢å•æ€»æ”¶å…¥'] = df['å®æ”¶ä»·æ ¼'] * df[sales_field]
    
    # è®¢å•çº§èšåˆ
    agg_dict = {
        'å•†å“å®å”®ä»·': 'sum',
        'é¢„è®¡è®¢å•æ”¶å…¥': 'sum',
        'ç”¨æˆ·æ”¯ä»˜é…é€è´¹': 'first',
        'é…é€è´¹å‡å…é‡‘é¢': 'first',
        'ç‰©æµé…é€è´¹': 'first',
        'å¹³å°ä½£é‡‘': 'first',
    }
    
    if sales_field in df.columns:
        agg_dict[sales_field] = 'sum'
    if 'å¹³å°æœåŠ¡è´¹' in df.columns:
        agg_dict['å¹³å°æœåŠ¡è´¹'] = 'sum'
    if 'è®¢å•æ€»æ”¶å…¥' in df.columns:
        agg_dict['è®¢å•æ€»æ”¶å…¥'] = 'sum'
    if 'åˆ©æ¶¦é¢' in df.columns:
        agg_dict['åˆ©æ¶¦é¢'] = 'sum'
    if 'ä¼å®¢åè¿”' in df.columns:
        agg_dict['ä¼å®¢åè¿”'] = 'sum'
    if cost_field in df.columns:
        agg_dict[cost_field] = 'sum'
    
    # è®¢å•çº§å­—æ®µç”¨first
    for field in ['æ»¡å‡é‡‘é¢', 'å•†å“å‡å…é‡‘é¢', 'æ–°å®¢å‡å…é‡‘é¢', 'æ¸ é“', 'é—¨åº—åç§°', 'æ—¥æœŸ']:
        if field in df.columns:
            agg_dict[field] = 'first'
    
    order_agg = df.groupby('è®¢å•ID').agg(agg_dict).reset_index()
    
    # å°†è®¢å•æ€»æ”¶å…¥é‡å‘½åä¸ºå®æ”¶ä»·æ ¼
    if 'è®¢å•æ€»æ”¶å…¥' in order_agg.columns:
        order_agg['å®æ”¶ä»·æ ¼'] = order_agg['è®¢å•æ€»æ”¶å…¥']
    
    # ç»Ÿä¸€æˆæœ¬å­—æ®µå
    if cost_field == 'æˆæœ¬' and cost_field in order_agg.columns:
        order_agg['å•†å“é‡‡è´­æˆæœ¬'] = order_agg['æˆæœ¬']
    
    # å…³é”®å­—æ®µå…œåº•
    if 'å¹³å°æœåŠ¡è´¹' not in order_agg.columns:
        order_agg['å¹³å°æœåŠ¡è´¹'] = 0
    order_agg['å¹³å°æœåŠ¡è´¹'] = order_agg['å¹³å°æœåŠ¡è´¹'].fillna(0)
    
    if 'ä¼å®¢åè¿”' not in order_agg.columns:
        order_agg['ä¼å®¢åè¿”'] = 0
    order_agg['ä¼å®¢åè¿”'] = order_agg['ä¼å®¢åè¿”'].fillna(0)
    
    if 'å¹³å°ä½£é‡‘' not in order_agg.columns:
        order_agg['å¹³å°ä½£é‡‘'] = order_agg['å¹³å°æœåŠ¡è´¹']
    order_agg['å¹³å°ä½£é‡‘'] = order_agg['å¹³å°ä½£é‡‘'].fillna(0)
    
    if 'åˆ©æ¶¦é¢' not in order_agg.columns:
        order_agg['åˆ©æ¶¦é¢'] = 0
    order_agg['åˆ©æ¶¦é¢'] = order_agg['åˆ©æ¶¦é¢'].fillna(0)
    
    # è®¡ç®—è®¢å•å®é™…åˆ©æ¶¦ï¼ˆæ ¸å¿ƒå…¬å¼ï¼‰
    # å…¬å¼: è®¢å•å®é™…åˆ©æ¶¦ = åˆ©æ¶¦é¢ - å¹³å°æœåŠ¡è´¹ - ç‰©æµé…é€è´¹ + ä¼å®¢åè¿”
    order_agg['è®¢å•å®é™…åˆ©æ¶¦'] = (
        order_agg['åˆ©æ¶¦é¢'] -
        order_agg['å¹³å°æœåŠ¡è´¹'] -
        order_agg['ç‰©æµé…é€è´¹'] +
        order_agg['ä¼å®¢åè¿”']
    )
    
    # æŒ‰æ¸ é“ç±»å‹è¿‡æ»¤å¼‚å¸¸è®¢å•
    if 'æ¸ é“' in order_agg.columns:
        is_fee_channel = order_agg['æ¸ é“'].isin(PLATFORM_FEE_CHANNELS)
        is_zero_fee = order_agg['å¹³å°æœåŠ¡è´¹'] <= 0
        invalid_orders = is_fee_channel & is_zero_fee
        order_agg = order_agg[~invalid_orders].copy()
    
    return order_agg


@router.get("/overview")
async def get_order_overview(
    store_name: Optional[str] = Query(None, description="é—¨åº—åç§°ç­›é€‰"),
    start_date: Optional[date] = Query(None, description="å¼€å§‹æ—¥æœŸ"),
    end_date: Optional[date] = Query(None, description="ç»“æŸæ—¥æœŸ")
) -> Dict[str, Any]:
    """
    è·å–è®¢å•æ•°æ®æ¦‚è§ˆï¼ˆå…­å¤§æ ¸å¿ƒå¡ç‰‡ï¼‰
    
    ä¸è€ç‰ˆæœ¬Tab1å®Œå…¨ä¸€è‡´çš„æŒ‡æ ‡:
    - ğŸ“¦ è®¢å•æ€»æ•°
    - ğŸ’° å•†å“å®æ”¶é¢
    - ğŸ’ æ€»åˆ©æ¶¦
    - ğŸ›’ å¹³å‡å®¢å•ä»·
    - ğŸ“ˆ æ€»åˆ©æ¶¦ç‡
    - ğŸ·ï¸ åŠ¨é”€å•†å“æ•°
    """
    df = get_order_data()
    if df.empty:
        return {
            "success": True,
            "data": {
                "total_orders": 0,
                "total_actual_sales": 0,
                "total_profit": 0,
                "avg_order_value": 0,
                "profit_rate": 0,
                "active_products": 0,
            }
        }
    
    # é—¨åº—ç­›é€‰
    if store_name and 'é—¨åº—åç§°' in df.columns:
        df = df[df['é—¨åº—åç§°'] == store_name]
    
    # æ—¥æœŸç­›é€‰
    if 'æ—¥æœŸ' in df.columns:
        df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'], errors='coerce')
        if start_date:
            df = df[df['æ—¥æœŸ'].dt.date >= start_date]
        if end_date:
            df = df[df['æ—¥æœŸ'].dt.date <= end_date]
    
    if df.empty:
        return {
            "success": True,
            "data": {
                "total_orders": 0,
                "total_actual_sales": 0,
                "total_profit": 0,
                "avg_order_value": 0,
                "profit_rate": 0,
                "active_products": 0,
            }
        }
    
    # è®¡ç®—è®¢å•çº§æŒ‡æ ‡
    order_agg = calculate_order_metrics(df)
    
    # å…­å¤§æ ¸å¿ƒå¡ç‰‡
    total_orders = len(order_agg)
    total_actual_sales = order_agg['å®æ”¶ä»·æ ¼'].sum() if 'å®æ”¶ä»·æ ¼' in order_agg.columns else 0
    total_profit = order_agg['è®¢å•å®é™…åˆ©æ¶¦'].sum() if 'è®¢å•å®é™…åˆ©æ¶¦' in order_agg.columns else 0
    avg_order_value = total_actual_sales / total_orders if total_orders > 0 else 0
    profit_rate = (total_profit / total_actual_sales * 100) if total_actual_sales > 0 else 0
    
    # åŠ¨é”€å•†å“æ•°ï¼ˆæœ‰é”€é‡çš„SKUï¼‰
    sales_field = 'æœˆå”®' if 'æœˆå”®' in df.columns else 'é”€é‡'
    if 'å•†å“åç§°' in df.columns and sales_field in df.columns:
        active_products = df[df[sales_field] > 0]['å•†å“åç§°'].nunique()
    else:
        active_products = df['å•†å“åç§°'].nunique() if 'å•†å“åç§°' in df.columns else 0
    
    return {
        "success": True,
        "data": {
            "total_orders": int(total_orders),
            "total_actual_sales": round(float(total_actual_sales), 2),
            "total_profit": round(float(total_profit), 2),
            "avg_order_value": round(float(avg_order_value), 2),
            "profit_rate": round(float(profit_rate), 2),
            "active_products": int(active_products),
        }
    }


@router.get("/channels")
async def get_channel_stats(
    store_name: Optional[str] = Query(None, description="é—¨åº—åç§°ç­›é€‰"),
    start_date: Optional[date] = Query(None, description="å¼€å§‹æ—¥æœŸ"),
    end_date: Optional[date] = Query(None, description="ç»“æŸæ—¥æœŸ")
) -> Dict[str, Any]:
    """
    è·å–æ¸ é“è¡¨ç°å¯¹æ¯”æ•°æ®
    
    ä¸è€ç‰ˆæœ¬Tab1æ¸ é“å¡ç‰‡å®Œå…¨ä¸€è‡´
    """
    df = get_order_data()
    if df.empty:
        return {"success": True, "data": []}
    
    # é—¨åº—ç­›é€‰
    if store_name and 'é—¨åº—åç§°' in df.columns:
        df = df[df['é—¨åº—åç§°'] == store_name]
    
    # æ—¥æœŸç­›é€‰
    if 'æ—¥æœŸ' in df.columns:
        df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'], errors='coerce')
        if start_date:
            df = df[df['æ—¥æœŸ'].dt.date >= start_date]
        if end_date:
            df = df[df['æ—¥æœŸ'].dt.date <= end_date]
    
    if df.empty or 'æ¸ é“' not in df.columns:
        return {"success": True, "data": []}
    
    # è®¡ç®—è®¢å•çº§æŒ‡æ ‡
    order_agg = calculate_order_metrics(df)
    
    if order_agg.empty or 'æ¸ é“' not in order_agg.columns:
        return {"success": True, "data": []}
    
    # æŒ‰æ¸ é“èšåˆ
    channel_stats = order_agg.groupby('æ¸ é“').agg({
        'è®¢å•ID': 'count',
        'å®æ”¶ä»·æ ¼': 'sum',
        'è®¢å•å®é™…åˆ©æ¶¦': 'sum',
    }).reset_index()
    
    channel_stats.columns = ['channel', 'order_count', 'amount', 'profit']
    
    # è®¡ç®—æ´¾ç”ŸæŒ‡æ ‡
    total_orders = channel_stats['order_count'].sum()
    total_amount = channel_stats['amount'].sum()
    
    channel_stats['order_ratio'] = (channel_stats['order_count'] / total_orders * 100) if total_orders > 0 else 0
    channel_stats['amount_ratio'] = (channel_stats['amount'] / total_amount * 100) if total_amount > 0 else 0
    channel_stats['avg_value'] = channel_stats.apply(
        lambda r: r['amount'] / r['order_count'] if r['order_count'] > 0 else 0, axis=1
    )
    channel_stats['profit_rate'] = channel_stats.apply(
        lambda r: r['profit'] / r['amount'] * 100 if r['amount'] > 0 else 0, axis=1
    )
    
    # æŒ‰è®¢å•æ•°æ’åº
    channel_stats = channel_stats.sort_values('order_count', ascending=False)
    
    # è½¬æ¢ä¸ºåˆ—è¡¨
    result = []
    for _, row in channel_stats.iterrows():
        result.append({
            "channel": row['channel'],
            "order_count": int(row['order_count']),
            "amount": round(float(row['amount']), 2),
            "profit": round(float(row['profit']), 2),
            "order_ratio": round(float(row['order_ratio']), 2),
            "amount_ratio": round(float(row['amount_ratio']), 2),
            "avg_value": round(float(row['avg_value']), 2),
            "profit_rate": round(float(row['profit_rate']), 2),
        })
    
    return {"success": True, "data": result}


@router.get("/trend")
async def get_order_trend(
    days: int = Query(30, ge=1, le=365, description="ç»Ÿè®¡å¤©æ•°"),
    store_name: Optional[str] = Query(None, description="é—¨åº—åç§°ç­›é€‰"),
    granularity: str = Query("day", description="ç²’åº¦: day/week/month")
) -> Dict[str, Any]:
    """
    è·å–è®¢å•è¶‹åŠ¿æ•°æ®
    
    è¿”å›æ¯æ—¥/æ¯å‘¨/æ¯æœˆçš„è®¢å•æ•°ã€é”€å”®é¢ã€åˆ©æ¶¦ã€å®¢å•ä»·
    """
    df = get_order_data()
    if df.empty:
        return {"success": True, "data": {"dates": [], "order_counts": [], "amounts": [], "profits": [], "avg_values": []}}
    
    # é—¨åº—ç­›é€‰
    if store_name and 'é—¨åº—åç§°' in df.columns:
        df = df[df['é—¨åº—åç§°'] == store_name]
    
    if 'æ—¥æœŸ' not in df.columns:
        return {"success": False, "error": "ç¼ºå°‘æ—¥æœŸå­—æ®µ"}
    
    df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'], errors='coerce')
    df = df.dropna(subset=['æ—¥æœŸ'])
    
    if df.empty:
        return {"success": True, "data": {"dates": [], "order_counts": [], "amounts": [], "profits": [], "avg_values": []}}
    
    # ç­›é€‰æœ€è¿‘Nå¤©
    max_date = df['æ—¥æœŸ'].max()
    if pd.isna(max_date):
        return {"success": True, "data": {"dates": [], "order_counts": [], "amounts": [], "profits": [], "avg_values": []}}
    
    min_date = max_date - timedelta(days=days)
    df = df[df['æ—¥æœŸ'] >= min_date]
    
    if df.empty:
        return {"success": True, "data": {"dates": [], "order_counts": [], "amounts": [], "profits": [], "avg_values": []}}
    
    # æ ¹æ®ç²’åº¦åˆ†ç»„
    if granularity == 'week':
        df['period'] = df['æ—¥æœŸ'].dt.to_period('W').apply(lambda x: x.start_time)
    elif granularity == 'month':
        df['period'] = df['æ—¥æœŸ'].dt.to_period('M').apply(lambda x: x.start_time)
    else:
        df['period'] = df['æ—¥æœŸ'].dt.date
    
    # å…ˆèšåˆåˆ°è®¢å•çº§
    order_agg = calculate_order_metrics(df)
    
    if 'æ—¥æœŸ' in order_agg.columns:
        order_agg['æ—¥æœŸ'] = pd.to_datetime(order_agg['æ—¥æœŸ'])
        if granularity == 'week':
            order_agg['period'] = order_agg['æ—¥æœŸ'].dt.to_period('W').apply(lambda x: x.start_time)
        elif granularity == 'month':
            order_agg['period'] = order_agg['æ—¥æœŸ'].dt.to_period('M').apply(lambda x: x.start_time)
        else:
            order_agg['period'] = order_agg['æ—¥æœŸ'].dt.date
        
        # æŒ‰å‘¨æœŸèšåˆ
        daily = order_agg.groupby('period').agg({
            'è®¢å•ID': 'count',
            'å®æ”¶ä»·æ ¼': 'sum',
            'è®¢å•å®é™…åˆ©æ¶¦': 'sum',
        }).reset_index()
        
        daily.columns = ['date', 'order_count', 'amount', 'profit']
    else:
        # å¤‡ç”¨æ–¹æ¡ˆï¼šæŒ‰åŸå§‹æ•°æ®æ—¥æœŸèšåˆ
        daily = df.groupby('period').agg({
            'è®¢å•ID': 'nunique' if 'è®¢å•ID' in df.columns else 'count',
            'å®æ”¶ä»·æ ¼': 'sum' if 'å®æ”¶ä»·æ ¼' in df.columns else lambda x: 0,
            'åˆ©æ¶¦é¢': 'sum' if 'åˆ©æ¶¦é¢' in df.columns else lambda x: 0,
        }).reset_index()
        daily.columns = ['date', 'order_count', 'amount', 'profit']
    
    daily = daily.sort_values('date')
    
    # è®¡ç®—å®¢å•ä»·
    daily['avg_value'] = daily.apply(
        lambda r: r['amount'] / r['order_count'] if r['order_count'] > 0 else 0, axis=1
    )
    
    return {
        "success": True,
        "data": {
            "dates": [str(d) for d in daily['date'].tolist()],
            "order_counts": [int(x) for x in daily['order_count'].tolist()],
            "amounts": [round(float(x), 2) for x in daily['amount'].tolist()],
            "profits": [round(float(x), 2) for x in daily['profit'].tolist()],
            "avg_values": [round(float(x), 2) for x in daily['avg_value'].tolist()],
        }
    }


@router.get("/list")
async def get_order_list(
    page: int = Query(1, ge=1, description="é¡µç "),
    page_size: int = Query(20, ge=1, le=100, description="æ¯é¡µæ•°é‡"),
    store_name: Optional[str] = Query(None, description="é—¨åº—ç­›é€‰"),
    channel: Optional[str] = Query(None, description="æ¸ é“ç­›é€‰"),
    start_date: Optional[date] = Query(None, description="å¼€å§‹æ—¥æœŸ"),
    end_date: Optional[date] = Query(None, description="ç»“æŸæ—¥æœŸ"),
    sort_by: str = Query("date", description="æ’åºå­—æ®µ"),
    sort_order: str = Query("desc", description="æ’åºæ–¹å‘")
) -> Dict[str, Any]:
    """
    è·å–è®¢å•åˆ—è¡¨ï¼ˆæ”¯æŒåˆ†é¡µå’Œç­›é€‰ï¼‰
    """
    df = get_order_data()
    if df.empty:
        return {"success": True, "data": [], "total": 0, "page": page, "page_size": page_size, "total_pages": 0}
    
    # é—¨åº—ç­›é€‰
    if store_name and 'é—¨åº—åç§°' in df.columns:
        df = df[df['é—¨åº—åç§°'] == store_name]
    
    # æ¸ é“ç­›é€‰
    if channel and 'æ¸ é“' in df.columns:
        df = df[df['æ¸ é“'] == channel]
    
    # æ—¥æœŸç­›é€‰
    if 'æ—¥æœŸ' in df.columns:
        df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'], errors='coerce')
        if start_date:
            df = df[df['æ—¥æœŸ'].dt.date >= start_date]
        if end_date:
            df = df[df['æ—¥æœŸ'].dt.date <= end_date]
    
    if df.empty:
        return {"success": True, "data": [], "total": 0, "page": page, "page_size": page_size, "total_pages": 0}
    
    # è®¡ç®—è®¢å•çº§æŒ‡æ ‡
    order_agg = calculate_order_metrics(df)
    
    # æ’åº
    sort_col_map = {
        'date': 'æ—¥æœŸ',
        'amount': 'å®æ”¶ä»·æ ¼',
        'profit': 'è®¢å•å®é™…åˆ©æ¶¦',
    }
    sort_col = sort_col_map.get(sort_by, 'æ—¥æœŸ')
    if sort_col in order_agg.columns:
        order_agg = order_agg.sort_values(sort_col, ascending=(sort_order == 'asc'))
    
    # åˆ†é¡µ
    total = len(order_agg)
    start = (page - 1) * page_size
    end = start + page_size
    page_data = order_agg.iloc[start:end]
    
    # é€‰æ‹©å±•ç¤ºå­—æ®µ
    result = []
    for _, row in page_data.iterrows():
        item = {
            "order_id": row.get('è®¢å•ID', ''),
            "order_date": str(row.get('æ—¥æœŸ', ''))[:10] if pd.notna(row.get('æ—¥æœŸ')) else '',
            "store_name": row.get('é—¨åº—åç§°', ''),
            "channel": row.get('æ¸ é“', ''),
            "amount": round(float(row.get('å®æ”¶ä»·æ ¼', 0)), 2),
            "profit": round(float(row.get('è®¢å•å®é™…åˆ©æ¶¦', 0)), 2),
            "profit_rate": round(float(row.get('è®¢å•å®é™…åˆ©æ¶¦', 0)) / float(row.get('å®æ”¶ä»·æ ¼', 1)) * 100, 2) if row.get('å®æ”¶ä»·æ ¼', 0) > 0 else 0,
        }
        result.append(item)
    
    return {
        "success": True,
        "data": result,
        "total": total,
        "page": page,
        "page_size": page_size,
        "total_pages": (total + page_size - 1) // page_size
    }


@router.get("/stores")
async def get_store_list() -> Dict[str, Any]:
    """è·å–é—¨åº—åˆ—è¡¨"""
    df = get_order_data()
    if df.empty or 'é—¨åº—åç§°' not in df.columns:
        return {"success": True, "data": []}
    
    stores = sorted(df['é—¨åº—åç§°'].dropna().unique().tolist())
    return {"success": True, "data": stores}


@router.get("/channel-list")
async def get_channel_list() -> Dict[str, Any]:
    """è·å–æ¸ é“åˆ—è¡¨"""
    df = get_order_data()
    if df.empty or 'æ¸ é“' not in df.columns:
        return {"success": True, "data": []}
    
    channels = sorted(df['æ¸ é“'].dropna().unique().tolist())
    return {"success": True, "data": channels}


@router.get("/profit-distribution")
async def get_profit_distribution(
    store_name: Optional[str] = Query(None, description="é—¨åº—åç§°ç­›é€‰"),
    start_date: Optional[date] = Query(None, description="å¼€å§‹æ—¥æœŸ"),
    end_date: Optional[date] = Query(None, description="ç»“æŸæ—¥æœŸ")
) -> Dict[str, Any]:
    """
    è·å–åˆ©æ¶¦åŒºé—´åˆ†å¸ƒ
    
    ä¸è€ç‰ˆæœ¬çš„åˆ©æ¶¦åŒºé—´åˆ†å¸ƒå›¾ä¸€è‡´
    """
    df = get_order_data()
    if df.empty:
        return {"success": True, "data": {"labels": [], "counts": [], "colors": []}}
    
    # é—¨åº—ç­›é€‰
    if store_name and 'é—¨åº—åç§°' in df.columns:
        df = df[df['é—¨åº—åç§°'] == store_name]
    
    # æ—¥æœŸç­›é€‰
    if 'æ—¥æœŸ' in df.columns:
        df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'], errors='coerce')
        if start_date:
            df = df[df['æ—¥æœŸ'].dt.date >= start_date]
        if end_date:
            df = df[df['æ—¥æœŸ'].dt.date <= end_date]
    
    if df.empty:
        return {"success": True, "data": {"labels": [], "counts": [], "colors": []}}
    
    # è®¡ç®—è®¢å•çº§æŒ‡æ ‡
    order_agg = calculate_order_metrics(df)
    
    if order_agg.empty or 'è®¢å•å®é™…åˆ©æ¶¦' not in order_agg.columns:
        return {"success": True, "data": {"labels": [], "counts": [], "colors": []}}
    
    profit_values = order_agg['è®¢å•å®é™…åˆ©æ¶¦'].values
    
    # å®šä¹‰åˆ©æ¶¦åŒºé—´
    bins = [-np.inf, -100, -50, -20, 0, 20, 50, 100, np.inf]
    labels = ['é‡åº¦äºæŸ(<-100)', 'ä¸­åº¦äºæŸ(-100~-50)', 'è½»åº¦äºæŸ(-50~-20)', 
              'å¾®äºæŸ(-20~0)', 'å¾®ç›ˆåˆ©(0~20)', 'è‰¯å¥½ç›ˆåˆ©(20~50)', 
              'ä¼˜ç§€ç›ˆåˆ©(50~100)', 'è¶…çº§ç›ˆåˆ©(>100)']
    
    # ç»Ÿè®¡å„åŒºé—´è®¢å•æ•°
    counts, _ = np.histogram(profit_values, bins=bins)
    
    # é¢œè‰²ï¼ˆäºæŸçº¢è‰²ç³»ï¼Œç›ˆåˆ©ç»¿è‰²ç³»ï¼‰
    colors = ['#C0392B', '#E74C3C', '#FF6B6B', '#FFA07A',
              '#98FB98', '#2ECC71', '#27AE60', '#229954']
    
    return {
        "success": True,
        "data": {
            "labels": labels,
            "counts": [int(c) for c in counts.tolist()],
            "colors": colors,
            "total_orders": len(profit_values)
        }
    }


@router.get("/price-distribution")
async def get_price_distribution(
    store_name: Optional[str] = Query(None, description="é—¨åº—åç§°ç­›é€‰"),
    start_date: Optional[date] = Query(None, description="å¼€å§‹æ—¥æœŸ"),
    end_date: Optional[date] = Query(None, description="ç»“æŸæ—¥æœŸ")
) -> Dict[str, Any]:
    """
    è·å–å®¢å•ä»·åŒºé—´åˆ†å¸ƒï¼ˆä¸è€ç‰ˆæœ¬å®Œå…¨ä¸€è‡´ï¼‰
    
    8ä¸ªæ ‡å‡†ä»·æ ¼åŒºé—´:
    - Â¥0-10, Â¥10-20, Â¥20-30, Â¥30-40, Â¥40-50, Â¥50-100, Â¥100-200, Â¥200+
    
    4å¤§ä¸šåŠ¡ä»·æ ¼ç»„:
    - æµé‡åŒº (< Â¥15): å¼•æµä½ä»·å•†å“
    - ä¸»æµåŒº (Â¥15-30): æ—¥å¸¸é«˜é¢‘å•†å“
    - åˆ©æ¶¦åŒº (Â¥30-50): æ¯›åˆ©è´¡çŒ®ä¸»åŠ›
    - é«˜ä»·åŒº (â‰¥ Â¥50): é«˜ç«¯/å¤§å•å•†å“
    """
    df = get_order_data()
    if df.empty:
        return {"success": True, "data": {"price_ranges": [], "business_zones": {}, "avg_basket_depth": 0}}
    
    # é—¨åº—ç­›é€‰
    if store_name and 'é—¨åº—åç§°' in df.columns:
        df = df[df['é—¨åº—åç§°'] == store_name]
    
    # æ—¥æœŸç­›é€‰
    if 'æ—¥æœŸ' in df.columns:
        df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'], errors='coerce')
        if start_date:
            df = df[df['æ—¥æœŸ'].dt.date >= start_date]
        if end_date:
            df = df[df['æ—¥æœŸ'].dt.date <= end_date]
    
    if df.empty:
        return {"success": True, "data": {"price_ranges": [], "business_zones": {}, "avg_basket_depth": 0}}
    
    # è®¡ç®—è®¢å•çº§æŒ‡æ ‡
    order_agg = calculate_order_metrics(df)
    
    if order_agg.empty or 'å®æ”¶ä»·æ ¼' not in order_agg.columns:
        return {"success": True, "data": {"price_ranges": [], "business_zones": {}, "avg_basket_depth": 0}}
    
    prices = order_agg['å®æ”¶ä»·æ ¼'].values
    total_orders = len(prices)
    
    # 8ä¸ªæ ‡å‡†ä»·æ ¼åŒºé—´
    price_ranges = [
        (0, 10, 'Â¥0-10'),
        (10, 20, 'Â¥10-20'),
        (20, 30, 'Â¥20-30'),
        (30, 40, 'Â¥30-40'),
        (40, 50, 'Â¥40-50'),
        (50, 100, 'Â¥50-100'),
        (100, 200, 'Â¥100-200'),
        (200, float('inf'), 'Â¥200+')
    ]
    
    range_data = []
    for low, high, label in price_ranges:
        if high == float('inf'):
            count = int(np.sum(prices >= low))
        else:
            count = int(np.sum((prices >= low) & (prices < high)))
        
        ratio = round(count / total_orders * 100, 2) if total_orders > 0 else 0
        range_data.append({
            "label": label,
            "count": count,
            "ratio": ratio,
            "color": get_price_range_color(low)
        })
    
    # 4å¤§ä¸šåŠ¡ä»·æ ¼ç»„
    flow_zone = int(np.sum(prices < 15))  # æµé‡åŒº
    main_zone = int(np.sum((prices >= 15) & (prices < 30)))  # ä¸»æµåŒº
    profit_zone = int(np.sum((prices >= 30) & (prices < 50)))  # åˆ©æ¶¦åŒº
    high_zone = int(np.sum(prices >= 50))  # é«˜ä»·åŒº
    
    business_zones = {
        "flow_zone": {"label": "æµé‡åŒº(<Â¥15)", "count": flow_zone, "ratio": round(flow_zone / total_orders * 100, 2) if total_orders > 0 else 0},
        "main_zone": {"label": "ä¸»æµåŒº(Â¥15-30)", "count": main_zone, "ratio": round(main_zone / total_orders * 100, 2) if total_orders > 0 else 0},
        "profit_zone": {"label": "åˆ©æ¶¦åŒº(Â¥30-50)", "count": profit_zone, "ratio": round(profit_zone / total_orders * 100, 2) if total_orders > 0 else 0},
        "high_zone": {"label": "é«˜ä»·åŒº(â‰¥Â¥50)", "count": high_zone, "ratio": round(high_zone / total_orders * 100, 2) if total_orders > 0 else 0},
    }
    
    # è´­ç‰©ç¯®æ·±åº¦ï¼ˆå¹³å‡SKUæ•°ï¼‰
    if 'è®¢å•ID' in df.columns:
        basket_depth = df.groupby('è®¢å•ID').size().mean()
    else:
        basket_depth = 1.0
    
    return {
        "success": True,
        "data": {
            "price_ranges": range_data,
            "business_zones": business_zones,
            "avg_basket_depth": round(float(basket_depth), 2),
            "total_orders": total_orders,
            "avg_order_value": round(float(np.mean(prices)), 2) if len(prices) > 0 else 0
        }
    }


def get_price_range_color(price: float) -> str:
    """æ ¹æ®ä»·æ ¼è¿”å›é¢œè‰²"""
    if price < 15:
        return "#3498DB"  # è“è‰² - æµé‡åŒº
    elif price < 30:
        return "#27AE60"  # ç»¿è‰² - ä¸»æµåŒº
    elif price < 50:
        return "#F39C12"  # æ©™è‰² - åˆ©æ¶¦åŒº
    else:
        return "#9B59B6"  # ç´«è‰² - é«˜ä»·åŒº


@router.get("/category-trend")
async def get_category_trend(
    store_name: Optional[str] = Query(None, description="é—¨åº—åç§°ç­›é€‰"),
    channel: Optional[str] = Query(None, description="æ¸ é“ç­›é€‰"),
    weeks: int = Query(4, ge=1, le=12, description="ç»Ÿè®¡å‘¨æ•°")
) -> Dict[str, Any]:
    """
    è·å–ä¸€çº§åˆ†ç±»é”€å”®è¶‹åŠ¿ï¼ˆä¸è€ç‰ˆæœ¬å®Œå…¨ä¸€è‡´ï¼‰
    
    è¿”å›å„ä¸€çº§åˆ†ç±»çš„å‘¨é”€å”®è¶‹åŠ¿æ•°æ®
    """
    df = get_order_data()
    if df.empty:
        return {"success": True, "data": {"categories": [], "weeks": [], "series": []}}
    
    # é—¨åº—ç­›é€‰
    if store_name and 'é—¨åº—åç§°' in df.columns:
        df = df[df['é—¨åº—åç§°'] == store_name]
    
    # æ¸ é“ç­›é€‰
    if channel and 'æ¸ é“' in df.columns:
        df = df[df['æ¸ é“'] == channel]
    
    if 'æ—¥æœŸ' not in df.columns or 'ä¸€çº§åˆ†ç±»å' not in df.columns:
        return {"success": True, "data": {"categories": [], "weeks": [], "series": []}}
    
    df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'], errors='coerce')
    df = df.dropna(subset=['æ—¥æœŸ'])
    
    if df.empty:
        return {"success": True, "data": {"categories": [], "weeks": [], "series": []}}
    
    # ç­›é€‰æœ€è¿‘Nå‘¨
    max_date = df['æ—¥æœŸ'].max()
    if pd.isna(max_date):
        return {"success": True, "data": {"categories": [], "weeks": [], "series": []}}
    
    min_date = max_date - timedelta(weeks=weeks)
    df = df[df['æ—¥æœŸ'] >= min_date]
    
    if df.empty:
        return {"success": True, "data": {"categories": [], "weeks": [], "series": []}}
    
    # æ·»åŠ å‘¨æ ‡è¯†
    df['å‘¨'] = df['æ—¥æœŸ'].dt.to_period('W').apply(lambda x: x.start_time.strftime('%Y-%m-%d'))
    
    # æŒ‰ä¸€çº§åˆ†ç±»å’Œå‘¨èšåˆ
    sales_field = 'å®æ”¶ä»·æ ¼' if 'å®æ”¶ä»·æ ¼' in df.columns else 'å•†å“å®å”®ä»·'
    if sales_field not in df.columns:
        return {"success": True, "data": {"categories": [], "weeks": [], "series": []}}
    
    category_weekly = df.groupby(['ä¸€çº§åˆ†ç±»å', 'å‘¨'])[sales_field].sum().reset_index()
    category_weekly.columns = ['category', 'week', 'sales']
    
    # è·å–æ‰€æœ‰åˆ†ç±»å’Œå‘¨
    categories = sorted(category_weekly['category'].unique().tolist())
    weeks_list = sorted(category_weekly['week'].unique().tolist())
    
    # æ„å»ºç³»åˆ—æ•°æ®
    series = []
    colors = ['#5470c6', '#91cc75', '#fac858', '#ee6666', '#73c0de', '#3ba272', '#fc8452', '#9a60b4']
    
    for i, cat in enumerate(categories):
        cat_data = category_weekly[category_weekly['category'] == cat]
        values = []
        for week in weeks_list:
            week_val = cat_data[cat_data['week'] == week]['sales'].values
            values.append(round(float(week_val[0]), 2) if len(week_val) > 0 else 0)
        
        series.append({
            "name": cat,
            "data": values,
            "color": colors[i % len(colors)]
        })
    
    return {
        "success": True,
        "data": {
            "categories": categories,
            "weeks": weeks_list,
            "series": series
        }
    }


@router.get("/comparison")
async def get_order_comparison(
    store_name: Optional[str] = Query(None, description="é—¨åº—åç§°ç­›é€‰"),
    start_date: Optional[date] = Query(None, description="å¼€å§‹æ—¥æœŸ"),
    end_date: Optional[date] = Query(None, description="ç»“æŸæ—¥æœŸ")
) -> Dict[str, Any]:
    """
    è·å–è®¢å•ç¯æ¯”æ•°æ®ï¼ˆä¸è€ç‰ˆæœ¬å®Œå…¨ä¸€è‡´ï¼‰
    
    è®¡ç®—å½“å‰å‘¨æœŸä¸ä¸Šä¸€å‘¨æœŸçš„ç¯æ¯”å˜åŒ–:
    - è®¢å•æ•°ç¯æ¯”
    - é”€å”®é¢ç¯æ¯”
    - åˆ©æ¶¦ç¯æ¯”
    - å®¢å•ä»·ç¯æ¯”
    - åˆ©æ¶¦ç‡ç¯æ¯”ï¼ˆä½¿ç”¨å·®å€¼ï¼‰
    - åŠ¨é”€å•†å“æ•°ç¯æ¯”
    """
    df = get_order_data()
    if df.empty:
        return {"success": True, "data": {"current": {}, "previous": {}, "changes": {}}}
    
    # é—¨åº—ç­›é€‰
    if store_name and 'é—¨åº—åç§°' in df.columns:
        df = df[df['é—¨åº—åç§°'] == store_name]
    
    if 'æ—¥æœŸ' not in df.columns:
        return {"success": True, "data": {"current": {}, "previous": {}, "changes": {}}}
    
    df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'], errors='coerce')
    df = df.dropna(subset=['æ—¥æœŸ'])  # ç§»é™¤æ— æ•ˆæ—¥æœŸ
    
    if df.empty:
        return {"success": True, "data": {"current": {}, "previous": {}, "changes": {}}}
    
    # ç¡®å®šæ—¥æœŸèŒƒå›´
    max_date = df['æ—¥æœŸ'].max()
    if pd.isna(max_date):
        return {"success": True, "data": {"current": {}, "previous": {}, "changes": {}}}
    
    if start_date is None:
        end_date = max_date.date()
        start_date = end_date - timedelta(days=6)  # é»˜è®¤æœ€è¿‘7å¤©
    elif end_date is None:
        end_date = start_date + timedelta(days=6)
    
    # è®¡ç®—å‘¨æœŸé•¿åº¦
    period_days = (end_date - start_date).days + 1
    if period_days <= 0:
        period_days = 7  # é»˜è®¤7å¤©
    
    # è®¡ç®—ä¸Šä¸€å‘¨æœŸæ—¥æœŸèŒƒå›´
    prev_end_date = start_date - timedelta(days=1)
    prev_start_date = prev_end_date - timedelta(days=period_days - 1)
    
    # å½“å‰å‘¨æœŸæ•°æ®
    current_df = df[(df['æ—¥æœŸ'].dt.date >= start_date) & (df['æ—¥æœŸ'].dt.date <= end_date)]
    # ä¸Šä¸€å‘¨æœŸæ•°æ®
    prev_df = df[(df['æ—¥æœŸ'].dt.date >= prev_start_date) & (df['æ—¥æœŸ'].dt.date <= prev_end_date)]
    
    # è®¡ç®—å½“å‰å‘¨æœŸæŒ‡æ ‡
    current_metrics = calculate_period_metrics(current_df)
    # è®¡ç®—ä¸Šä¸€å‘¨æœŸæŒ‡æ ‡
    prev_metrics = calculate_period_metrics(prev_df)
    
    # è®¡ç®—ç¯æ¯”å˜åŒ–
    changes = {}
    for key in ['order_count', 'total_sales', 'total_profit', 'avg_order_value', 'active_products']:
        curr_val = current_metrics.get(key, 0)
        prev_val = prev_metrics.get(key, 0)
        if prev_val > 0:
            change_rate = round((curr_val - prev_val) / prev_val * 100, 2)
        elif curr_val > 0:
            change_rate = 100.0
        else:
            change_rate = 0.0
        changes[key] = change_rate
    
    # åˆ©æ¶¦ç‡ä½¿ç”¨å·®å€¼ï¼ˆä¸æ˜¯ç™¾åˆ†æ¯”å˜åŒ–ï¼‰
    changes['profit_rate'] = round(current_metrics.get('profit_rate', 0) - prev_metrics.get('profit_rate', 0), 2)
    
    return {
        "success": True,
        "data": {
            "current": current_metrics,
            "previous": prev_metrics,
            "changes": changes,
            "period": {
                "current_start": str(start_date),
                "current_end": str(end_date),
                "previous_start": str(prev_start_date),
                "previous_end": str(prev_end_date),
                "period_days": period_days
            }
        }
    }


def calculate_period_metrics(df: pd.DataFrame) -> Dict[str, Any]:
    """è®¡ç®—å•ä¸ªå‘¨æœŸçš„æŒ‡æ ‡"""
    if df.empty:
        return {
            "order_count": 0,
            "total_sales": 0,
            "total_profit": 0,
            "avg_order_value": 0,
            "profit_rate": 0,
            "active_products": 0
        }
    
    order_agg = calculate_order_metrics(df)
    
    order_count = len(order_agg)
    total_sales = order_agg['å®æ”¶ä»·æ ¼'].sum() if 'å®æ”¶ä»·æ ¼' in order_agg.columns else 0
    total_profit = order_agg['è®¢å•å®é™…åˆ©æ¶¦'].sum() if 'è®¢å•å®é™…åˆ©æ¶¦' in order_agg.columns else 0
    avg_order_value = total_sales / order_count if order_count > 0 else 0
    profit_rate = (total_profit / total_sales * 100) if total_sales > 0 else 0
    
    # åŠ¨é”€å•†å“æ•°
    sales_field = 'æœˆå”®' if 'æœˆå”®' in df.columns else 'é”€é‡'
    if 'å•†å“åç§°' in df.columns and sales_field in df.columns:
        active_products = df[df[sales_field] > 0]['å•†å“åç§°'].nunique()
    else:
        active_products = df['å•†å“åç§°'].nunique() if 'å•†å“åç§°' in df.columns else 0
    
    return {
        "order_count": int(order_count),
        "total_sales": round(float(total_sales), 2),
        "total_profit": round(float(total_profit), 2),
        "avg_order_value": round(float(avg_order_value), 2),
        "profit_rate": round(float(profit_rate), 2),
        "active_products": int(active_products)
    }


@router.get("/channel-comparison")
async def get_channel_comparison(
    store_name: Optional[str] = Query(None, description="é—¨åº—åç§°ç­›é€‰"),
    start_date: Optional[date] = Query(None, description="å¼€å§‹æ—¥æœŸ"),
    end_date: Optional[date] = Query(None, description="ç»“æŸæ—¥æœŸ")
) -> Dict[str, Any]:
    """
    è·å–æ¸ é“ç¯æ¯”å¯¹æ¯”æ•°æ®ï¼ˆä¸è€ç‰ˆæœ¬å®Œå…¨ä¸€è‡´ï¼‰
    
    æ¯ä¸ªæ¸ é“åŒ…å«:
    - è®¢å•æ•° + ç¯æ¯”
    - é”€å”®é¢ + ç¯æ¯”
    - åˆ©æ¶¦é¢ + ç¯æ¯”
    - å®¢å•ä»· + ç¯æ¯”
    - åˆ©æ¶¦ç‡ + ç¯æ¯”
    """
    df = get_order_data()
    if df.empty:
        return {"success": True, "data": []}
    
    # é—¨åº—ç­›é€‰
    if store_name and 'é—¨åº—åç§°' in df.columns:
        df = df[df['é—¨åº—åç§°'] == store_name]
    
    if 'æ—¥æœŸ' not in df.columns or 'æ¸ é“' not in df.columns:
        return {"success": True, "data": []}
    
    df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'], errors='coerce')
    df = df.dropna(subset=['æ—¥æœŸ'])
    
    if df.empty:
        return {"success": True, "data": []}
    
    # ç¡®å®šæ—¥æœŸèŒƒå›´
    max_date = df['æ—¥æœŸ'].max()
    if pd.isna(max_date):
        return {"success": True, "data": []}
    
    if start_date is None:
        end_date = max_date.date()
        start_date = end_date - timedelta(days=6)
    elif end_date is None:
        end_date = start_date + timedelta(days=6)
    
    period_days = (end_date - start_date).days + 1
    if period_days <= 0:
        period_days = 7
    
    prev_end_date = start_date - timedelta(days=1)
    prev_start_date = prev_end_date - timedelta(days=period_days - 1)
    
    # å½“å‰å‘¨æœŸå’Œä¸Šä¸€å‘¨æœŸæ•°æ®
    current_df = df[(df['æ—¥æœŸ'].dt.date >= start_date) & (df['æ—¥æœŸ'].dt.date <= end_date)]
    prev_df = df[(df['æ—¥æœŸ'].dt.date >= prev_start_date) & (df['æ—¥æœŸ'].dt.date <= prev_end_date)]
    
    # è·å–æ‰€æœ‰æ¸ é“
    channels = df['æ¸ é“'].dropna().unique().tolist()
    
    result = []
    for channel in channels:
        # å½“å‰å‘¨æœŸæ¸ é“æ•°æ®
        curr_ch = current_df[current_df['æ¸ é“'] == channel]
        curr_metrics = calculate_channel_metrics(curr_ch)
        
        # ä¸Šä¸€å‘¨æœŸæ¸ é“æ•°æ®
        prev_ch = prev_df[prev_df['æ¸ é“'] == channel]
        prev_metrics = calculate_channel_metrics(prev_ch)
        
        # è®¡ç®—ç¯æ¯”
        changes = {}
        for key in ['order_count', 'amount', 'profit', 'avg_value']:
            curr_val = curr_metrics.get(key, 0)
            prev_val = prev_metrics.get(key, 0)
            if prev_val > 0:
                changes[key] = round((curr_val - prev_val) / prev_val * 100, 2)
            elif curr_val > 0:
                changes[key] = 100.0
            else:
                changes[key] = 0.0
        
        # åˆ©æ¶¦ç‡ç”¨å·®å€¼
        changes['profit_rate'] = round(curr_metrics.get('profit_rate', 0) - prev_metrics.get('profit_rate', 0), 2)
        
        # è¯„çº§
        rating = get_channel_rating(curr_metrics, changes)
        
        result.append({
            "channel": channel,
            "current": curr_metrics,
            "previous": prev_metrics,
            "changes": changes,
            "rating": rating
        })
    
    # æŒ‰è®¢å•æ•°æ’åº
    result.sort(key=lambda x: x['current'].get('order_count', 0), reverse=True)
    
    return {"success": True, "data": result}


def calculate_channel_metrics(df: pd.DataFrame) -> Dict[str, Any]:
    """è®¡ç®—å•ä¸ªæ¸ é“çš„æŒ‡æ ‡"""
    if df.empty:
        return {
            "order_count": 0,
            "amount": 0,
            "profit": 0,
            "avg_value": 0,
            "profit_rate": 0
        }
    
    order_agg = calculate_order_metrics(df)
    
    order_count = len(order_agg)
    amount = order_agg['å®æ”¶ä»·æ ¼'].sum() if 'å®æ”¶ä»·æ ¼' in order_agg.columns else 0
    profit = order_agg['è®¢å•å®é™…åˆ©æ¶¦'].sum() if 'è®¢å•å®é™…åˆ©æ¶¦' in order_agg.columns else 0
    avg_value = amount / order_count if order_count > 0 else 0
    profit_rate = (profit / amount * 100) if amount > 0 else 0
    
    return {
        "order_count": int(order_count),
        "amount": round(float(amount), 2),
        "profit": round(float(profit), 2),
        "avg_value": round(float(avg_value), 2),
        "profit_rate": round(float(profit_rate), 2)
    }


def get_channel_rating(metrics: Dict, changes: Dict) -> str:
    """æ ¹æ®æŒ‡æ ‡å’Œç¯æ¯”è·å–æ¸ é“è¯„çº§"""
    profit_rate = metrics.get('profit_rate', 0)
    profit_change = changes.get('profit', 0)
    amount_change = changes.get('amount', 0)
    
    # ä¼˜ç§€: åˆ©æ¶¦ç‡>15% ä¸” (é”€å”®é¢ç¯æ¯”>0 æˆ– åˆ©æ¶¦ç¯æ¯”>0)
    if profit_rate > 15 and (amount_change > 0 or profit_change > 0):
        return "ä¼˜ç§€"
    # è‰¯å¥½: åˆ©æ¶¦ç‡>10% ä¸” é”€å”®é¢ç¯æ¯”>-10%
    elif profit_rate > 10 and amount_change > -10:
        return "è‰¯å¥½"
    # éœ€æ”¹è¿›
    else:
        return "éœ€æ”¹è¿›"


@router.get("/anomaly-detection")
async def get_anomaly_detection(
    store_name: Optional[str] = Query(None, description="é—¨åº—åç§°ç­›é€‰"),
    start_date: Optional[date] = Query(None, description="å¼€å§‹æ—¥æœŸ"),
    end_date: Optional[date] = Query(None, description="ç»“æŸæ—¥æœŸ")
) -> Dict[str, Any]:
    """
    è·å–å¼‚å¸¸è¯Šæ–­æ•°æ®ï¼ˆä¸è€ç‰ˆæœ¬å®Œå…¨ä¸€è‡´ï¼‰
    
    ä¸‰ç±»å¼‚å¸¸:
    1. ä½åˆ©æ¶¦ç‡è®¢å•ï¼ˆåˆ©æ¶¦ç‡<10%ï¼‰
    2. é«˜é…é€æˆæœ¬è®¢å•ï¼ˆé…é€æˆæœ¬å æ¯”>30%ï¼‰
    3. è´Ÿåˆ©æ¶¦è®¢å•ï¼ˆè®¢å•å®é™…åˆ©æ¶¦<0ï¼‰
    """
    df = get_order_data()
    if df.empty:
        return {"success": True, "data": {"low_profit": [], "high_delivery": [], "negative_profit": [], "summary": {}}}
    
    # é—¨åº—ç­›é€‰
    if store_name and 'é—¨åº—åç§°' in df.columns:
        df = df[df['é—¨åº—åç§°'] == store_name]
    
    # æ—¥æœŸç­›é€‰
    if 'æ—¥æœŸ' in df.columns:
        df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'], errors='coerce')
        if start_date:
            df = df[df['æ—¥æœŸ'].dt.date >= start_date]
        if end_date:
            df = df[df['æ—¥æœŸ'].dt.date <= end_date]
    
    if df.empty:
        return {"success": True, "data": {"low_profit": [], "high_delivery": [], "negative_profit": [], "summary": {}}}
    
    order_agg = calculate_order_metrics(df)
    
    if order_agg.empty:
        return {"success": True, "data": {"low_profit": [], "high_delivery": [], "negative_profit": [], "summary": {}}}
    
    # è®¡ç®—åˆ©æ¶¦ç‡
    order_agg['åˆ©æ¶¦ç‡'] = order_agg.apply(
        lambda r: r['è®¢å•å®é™…åˆ©æ¶¦'] / r['å®æ”¶ä»·æ ¼'] * 100 if r.get('å®æ”¶ä»·æ ¼', 0) > 0 else 0, axis=1
    )
    
    # è®¡ç®—é…é€æˆæœ¬å æ¯”
    if 'ç‰©æµé…é€è´¹' in order_agg.columns and 'ç”¨æˆ·æ”¯ä»˜é…é€è´¹' in order_agg.columns:
        order_agg['é…é€å‡€æˆæœ¬'] = order_agg['ç‰©æµé…é€è´¹'] - order_agg.get('ç”¨æˆ·æ”¯ä»˜é…é€è´¹', 0) + order_agg.get('é…é€è´¹å‡å…é‡‘é¢', 0)
        order_agg['é…é€æˆæœ¬å æ¯”'] = order_agg.apply(
            lambda r: r['é…é€å‡€æˆæœ¬'] / r['å®æ”¶ä»·æ ¼'] * 100 if r.get('å®æ”¶ä»·æ ¼', 0) > 0 else 0, axis=1
        )
    else:
        order_agg['é…é€æˆæœ¬å æ¯”'] = 0
    
    total_orders = len(order_agg)
    
    # 1. ä½åˆ©æ¶¦ç‡è®¢å•ï¼ˆåˆ©æ¶¦ç‡<10%ï¼‰
    low_profit_df = order_agg[order_agg['åˆ©æ¶¦ç‡'] < 10].head(10)
    low_profit_list = []
    for _, row in low_profit_df.iterrows():
        low_profit_list.append({
            "order_id": row.get('è®¢å•ID', ''),
            "amount": round(float(row.get('å®æ”¶ä»·æ ¼', 0)), 2),
            "profit": round(float(row.get('è®¢å•å®é™…åˆ©æ¶¦', 0)), 2),
            "profit_rate": round(float(row.get('åˆ©æ¶¦ç‡', 0)), 2),
            "channel": row.get('æ¸ é“', ''),
        })
    
    # 2. é«˜é…é€æˆæœ¬è®¢å•ï¼ˆé…é€æˆæœ¬å æ¯”>30%ï¼‰
    high_delivery_df = order_agg[order_agg['é…é€æˆæœ¬å æ¯”'] > 30].head(10)
    high_delivery_list = []
    for _, row in high_delivery_df.iterrows():
        high_delivery_list.append({
            "order_id": row.get('è®¢å•ID', ''),
            "amount": round(float(row.get('å®æ”¶ä»·æ ¼', 0)), 2),
            "delivery_cost": round(float(row.get('é…é€å‡€æˆæœ¬', 0)), 2),
            "delivery_ratio": round(float(row.get('é…é€æˆæœ¬å æ¯”', 0)), 2),
            "channel": row.get('æ¸ é“', ''),
        })
    
    # 3. è´Ÿåˆ©æ¶¦è®¢å•
    negative_profit_df = order_agg[order_agg['è®¢å•å®é™…åˆ©æ¶¦'] < 0].head(10)
    negative_profit_list = []
    for _, row in negative_profit_df.iterrows():
        negative_profit_list.append({
            "order_id": row.get('è®¢å•ID', ''),
            "amount": round(float(row.get('å®æ”¶ä»·æ ¼', 0)), 2),
            "profit": round(float(row.get('è®¢å•å®é™…åˆ©æ¶¦', 0)), 2),
            "loss": round(float(-row.get('è®¢å•å®é™…åˆ©æ¶¦', 0)), 2),
            "channel": row.get('æ¸ é“', ''),
        })
    
    # æ±‡æ€»ç»Ÿè®¡
    low_profit_count = len(order_agg[order_agg['åˆ©æ¶¦ç‡'] < 10])
    high_delivery_count = len(order_agg[order_agg['é…é€æˆæœ¬å æ¯”'] > 30])
    negative_profit_count = len(order_agg[order_agg['è®¢å•å®é™…åˆ©æ¶¦'] < 0])
    
    total_negative_loss = order_agg[order_agg['è®¢å•å®é™…åˆ©æ¶¦'] < 0]['è®¢å•å®é™…åˆ©æ¶¦'].sum()
    
    return {
        "success": True,
        "data": {
            "low_profit": low_profit_list,
            "high_delivery": high_delivery_list,
            "negative_profit": negative_profit_list,
            "summary": {
                "total_orders": total_orders,
                "low_profit_count": int(low_profit_count),
                "low_profit_ratio": round(low_profit_count / total_orders * 100, 2) if total_orders > 0 else 0,
                "high_delivery_count": int(high_delivery_count),
                "high_delivery_ratio": round(high_delivery_count / total_orders * 100, 2) if total_orders > 0 else 0,
                "negative_profit_count": int(negative_profit_count),
                "negative_profit_ratio": round(negative_profit_count / total_orders * 100, 2) if total_orders > 0 else 0,
                "total_loss": round(float(abs(total_negative_loss)), 2)
            }
        }
    }


# ==================== å¯¼å‡ºåŠŸèƒ½ ====================

from fastapi.responses import StreamingResponse
import io

@router.get("/export")
async def export_orders(
    store_name: Optional[str] = Query(None, description="é—¨åº—åç§°ç­›é€‰"),
    start_date: Optional[date] = Query(None, description="å¼€å§‹æ—¥æœŸ"),
    end_date: Optional[date] = Query(None, description="ç»“æŸæ—¥æœŸ")
):
    """
    å¯¼å‡ºè®¢å•æ•°æ®åˆ°Excel
    
    ä¸è€ç‰ˆæœ¬å¯¼å‡ºåŠŸèƒ½ä¸€è‡´ï¼ŒåŒ…å«:
    - è®¢å•ID
    - æ—¥æœŸ
    - é—¨åº—åç§°
    - æ¸ é“
    - å®æ”¶ä»·æ ¼
    - è®¢å•å®é™…åˆ©æ¶¦
    - åˆ©æ¶¦ç‡
    """
    df = get_order_data()
    
    if df.empty:
        # è¿”å›ç©ºExcel
        output = io.BytesIO()
        pd.DataFrame().to_excel(output, index=False, engine='openpyxl')
        output.seek(0)
        return StreamingResponse(
            output,
            media_type="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            headers={"Content-Disposition": "attachment; filename=è®¢å•æ•°æ®_ç©º.xlsx"}
        )
    
    # é—¨åº—ç­›é€‰
    if store_name and 'é—¨åº—åç§°' in df.columns:
        df = df[df['é—¨åº—åç§°'] == store_name]
    
    # æ—¥æœŸç­›é€‰
    if 'æ—¥æœŸ' in df.columns:
        df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'], errors='coerce')
        if start_date:
            df = df[df['æ—¥æœŸ'].dt.date >= start_date]
        if end_date:
            df = df[df['æ—¥æœŸ'].dt.date <= end_date]
    
    if df.empty:
        output = io.BytesIO()
        pd.DataFrame().to_excel(output, index=False, engine='openpyxl')
        output.seek(0)
        return StreamingResponse(
            output,
            media_type="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            headers={"Content-Disposition": "attachment; filename=è®¢å•æ•°æ®_ç©º.xlsx"}
        )
    
    # è®¡ç®—è®¢å•çº§æŒ‡æ ‡
    order_agg = calculate_order_metrics(df)
    
    # è®¡ç®—åˆ©æ¶¦ç‡
    order_agg['åˆ©æ¶¦ç‡'] = order_agg.apply(
        lambda r: round(r['è®¢å•å®é™…åˆ©æ¶¦'] / r['å®æ”¶ä»·æ ¼'] * 100, 2) if r.get('å®æ”¶ä»·æ ¼', 0) > 0 else 0, 
        axis=1
    )
    
    # é€‰æ‹©å¯¼å‡ºå­—æ®µ
    export_cols = ['è®¢å•ID', 'æ—¥æœŸ', 'é—¨åº—åç§°', 'æ¸ é“', 'å®æ”¶ä»·æ ¼', 'è®¢å•å®é™…åˆ©æ¶¦', 'åˆ©æ¶¦ç‡']
    available_cols = [c for c in export_cols if c in order_agg.columns]
    export_df = order_agg[available_cols].copy()
    
    # æ ¼å¼åŒ–æ—¥æœŸ
    if 'æ—¥æœŸ' in export_df.columns:
        export_df['æ—¥æœŸ'] = pd.to_datetime(export_df['æ—¥æœŸ']).dt.strftime('%Y-%m-%d')
    
    # é‡å‘½ååˆ—ï¼ˆæ›´å‹å¥½çš„æ˜¾ç¤ºåï¼‰
    column_rename = {
        'è®¢å•ID': 'è®¢å•ç¼–å·',
        'æ—¥æœŸ': 'è®¢å•æ—¥æœŸ',
        'é—¨åº—åç§°': 'é—¨åº—',
        'æ¸ é“': 'é”€å”®æ¸ é“',
        'å®æ”¶ä»·æ ¼': 'è®¢å•é‡‘é¢(å…ƒ)',
        'è®¢å•å®é™…åˆ©æ¶¦': 'åˆ©æ¶¦(å…ƒ)',
        'åˆ©æ¶¦ç‡': 'åˆ©æ¶¦ç‡(%)'
    }
    export_df = export_df.rename(columns={k: v for k, v in column_rename.items() if k in export_df.columns})
    
    # ç”ŸæˆExcel
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        export_df.to_excel(writer, index=False, sheet_name='è®¢å•æ•°æ®')
        
        # è°ƒæ•´åˆ—å®½
        worksheet = writer.sheets['è®¢å•æ•°æ®']
        for idx, col in enumerate(export_df.columns):
            max_length = max(
                export_df[col].astype(str).map(len).max() if len(export_df) > 0 else 0,
                len(col)
            ) + 2
            worksheet.column_dimensions[chr(65 + idx)].width = min(max_length, 30)
    
    output.seek(0)
    
    # ç”Ÿæˆæ–‡ä»¶å
    filename = f"è®¢å•ç»è¥åˆ†ææŠ¥å‘Š_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx"
    
    return StreamingResponse(
        output,
        media_type="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        headers={"Content-Disposition": f"attachment; filename*=UTF-8''{filename}"}
    )
