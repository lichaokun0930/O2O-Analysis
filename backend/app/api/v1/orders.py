# -*- coding: utf-8 -*-
"""
è®¢å•æ•°æ®æ¦‚è§ˆ API

å®Œå…¨å¯¹é½è€ç‰ˆæœ¬Dashçš„Tab1è®¢å•æ•°æ®æ¦‚è§ˆåŠŸèƒ½ï¼š
- å…­å¤§æ ¸å¿ƒå¡ç‰‡æŒ‡æ ‡
- æ¸ é“è¡¨ç°å¯¹æ¯”
- å®¢å•ä»·åŒºé—´åˆ†å¸ƒ
- ä¸€çº§åˆ†ç±»é”€å”®è¶‹åŠ¿
- è®¢å•è¶‹åŠ¿åˆ†æ
- ç¯æ¯”è®¡ç®—
- å¼‚å¸¸è¯Šæ–­

ä¸šåŠ¡é€»è¾‘æ¥æº: æ™ºèƒ½é—¨åº—çœ‹æ¿_Dashç‰ˆ.py ä¸­çš„ Tab 1 å›è°ƒ
"""

from fastapi import APIRouter, Depends, Query, HTTPException
from typing import Optional, List, Dict, Any
from datetime import date, datetime, timedelta
import pandas as pd
import numpy as np
import hashlib
import json
import time

import sys
from pathlib import Path
APP_DIR = Path(__file__).resolve().parent.parent.parent
PROJECT_ROOT = APP_DIR.parent.parent
if str(APP_DIR) not in sys.path:
    sys.path.insert(0, str(APP_DIR))
if str(PROJECT_ROOT) not in sys.path:
    sys.path.insert(0, str(PROJECT_ROOT))

from database.connection import SessionLocal
from database.models import Order

# å°è¯•å¯¼å…¥Redisç¼“å­˜
try:
    import redis
    REDIS_AVAILABLE = True
    redis_client = redis.Redis(host='localhost', port=6379, db=0, decode_responses=True)
    # æµ‹è¯•è¿æ¥
    redis_client.ping()
    print("âœ… Redisç¼“å­˜å·²è¿æ¥")
except Exception as e:
    REDIS_AVAILABLE = False
    redis_client = None
    print(f"âš ï¸ Redisç¼“å­˜ä¸å¯ç”¨: {e}")

router = APIRouter()

# ==================== ç¼“å­˜é…ç½® ====================
# âœ… ä¼˜åŒ–ï¼šå»¶é•¿TTLåˆ°24å°æ—¶ï¼ˆæ•°æ®æ¯å¤©æ›´æ–°ä¸€æ¬¡ï¼‰
CACHE_TTL = 86400  # ç¼“å­˜æœ‰æ•ˆæœŸ24å°æ—¶
ORDER_DATA_CACHE_KEY = "order_data_cache"
ORDER_DATA_TIMESTAMP_KEY = "order_data_timestamp"
DATA_VERSION_KEY = "order_data_version"  # æ•°æ®ç‰ˆæœ¬å·ï¼ˆç”¨äºæ™ºèƒ½å¤±æ•ˆï¼‰

# å†…å­˜ç¼“å­˜ï¼ˆå¤‡ç”¨ï¼‰
_memory_cache = {
    "order_data": None,
    "timestamp": 0,
    "store_cache": {},  # æŒ‰é—¨åº—ç¼“å­˜: {store_name: {data: df, timestamp: time}}
    "data_version": None  # æ•°æ®ç‰ˆæœ¬å·
}


def get_data_version(store_name: str = None) -> str:
    """
    è·å–æ•°æ®ç‰ˆæœ¬å· (Global Data Versioning)
    
    ä¼˜å…ˆä½¿ç”¨Rediså…¨å±€ç‰ˆæœ¬å· (Generation Clock)
    å½“å‘ç”Ÿä»»ä½•å†™å…¥(ä¸Šä¼ /åˆ é™¤)æ—¶ï¼Œç‰ˆæœ¬å·è‡ªå¢ï¼Œå¯¼è‡´æ‰€æœ‰æ—§ç¼“å­˜å¤±æ•ˆ
    """
    # 1. å°è¯•è·å–å…¨å±€ç‰ˆæœ¬å· (å¥å£®æ¨¡å¼)
    if REDIS_AVAILABLE:
        try:
            from redis_cache_manager import REDIS_CACHE_MANAGER
            if REDIS_CACHE_MANAGER and REDIS_CACHE_MANAGER.enabled:
                return REDIS_CACHE_MANAGER.get_global_version()
        except Exception as e:
            print(f"âš ï¸ è·å–å…¨å±€ç‰ˆæœ¬å¤±è´¥: {e}")

    # 2. é™çº§æ¨¡å¼ï¼šæ•°æ®åº“æ—¶é—´æˆ³ (ä»…å½“Redisä¸å¯ç”¨æ—¶)
    session = SessionLocal()
    try:
        from sqlalchemy import func
        query = session.query(func.max(Order.updated_at))
        if store_name:
            query = query.filter(Order.store_name == store_name)
        
        last_updated = query.scalar()
        if last_updated:
            return last_updated.strftime("%Y%m%d%H%M%S")
        return "0"
    except Exception as e:
        print(f"âš ï¸ è·å–æ•°æ®ç‰ˆæœ¬å¤±è´¥: {e}")
        return "0"
    finally:
        session.close()


def check_cache_valid(store_name: str = None) -> bool:
    """
    æ£€æŸ¥ç¼“å­˜æ˜¯å¦æœ‰æ•ˆï¼ˆåŸºäºæ•°æ®ç‰ˆæœ¬å·ï¼‰
    
    è¿”å› True è¡¨ç¤ºç¼“å­˜æœ‰æ•ˆï¼Œå¯ä»¥ä½¿ç”¨
    è¿”å› False è¡¨ç¤ºæ•°æ®å·²æ›´æ–°ï¼Œéœ€è¦é‡æ–°åŠ è½½
    """
    if not REDIS_AVAILABLE or not redis_client:
        return False
    
    try:
        version_key = f"{DATA_VERSION_KEY}:{store_name}" if store_name else DATA_VERSION_KEY
        cached_version = redis_client.get(version_key)
        current_version = get_data_version(store_name)
        
        if cached_version and cached_version == current_version:
            return True
        return False
    except Exception as e:
        print(f"âš ï¸ æ£€æŸ¥ç¼“å­˜ç‰ˆæœ¬å¤±è´¥: {e}")
        return False

# ==================== æ”¶è´¹æ¸ é“åˆ—è¡¨ï¼ˆä¸è€ç‰ˆæœ¬ä¸€è‡´ï¼‰====================
PLATFORM_FEE_CHANNELS = [
    'é¥¿äº†ä¹ˆ',
    'äº¬ä¸œåˆ°å®¶',
    'ç¾å›¢å…±æ©™',
    'ç¾å›¢é—ªè´­',
    'æŠ–éŸ³',
    'æŠ–éŸ³ç›´æ’­',
    'æ·˜é²œè¾¾',
    'äº¬ä¸œç§’é€',
    'ç¾å›¢å’–å•¡åº—',
    'é¥¿äº†ä¹ˆå’–å•¡åº—'
]


def get_order_data(store_name: str = None) -> pd.DataFrame:
    """
    ä»æ•°æ®åº“åŠ è½½è®¢å•æ•°æ®ï¼ˆå¸¦æ™ºèƒ½ç¼“å­˜ï¼‰
    
    ç¼“å­˜ç­–ç•¥ï¼ˆä¼˜åŒ–ç‰ˆï¼‰:
    1. ä¼˜å…ˆæ£€æŸ¥Redisç¼“å­˜ + æ•°æ®ç‰ˆæœ¬å·
    2. ç‰ˆæœ¬å·åŒ¹é…åˆ™ç›´æ¥ä½¿ç”¨ç¼“å­˜ï¼ˆå³ä½¿åç«¯é‡å¯ï¼‰
    3. ç‰ˆæœ¬å·ä¸åŒ¹é…åˆ™é‡æ–°åŠ è½½ï¼ˆæ•°æ®æœ‰æ›´æ–°ï¼‰
    4. ç¼“å­˜æœ‰æ•ˆæœŸ24å°æ—¶ï¼ˆæ•°æ®æ¯å¤©æ›´æ–°ä¸€æ¬¡ï¼‰
    
    Args:
        store_name: é—¨åº—åç§°ï¼Œå¦‚æœæŒ‡å®šåˆ™åªåŠ è½½è¯¥é—¨åº—æ•°æ®
    """
    global _memory_cache
    current_time = time.time()
    
    # ç”Ÿæˆç¼“å­˜key
    cache_key = f"order_data:{store_name}" if store_name else "order_data:all"
    redis_cache_key = f"{ORDER_DATA_CACHE_KEY}:{store_name}" if store_name else ORDER_DATA_CACHE_KEY
    redis_timestamp_key = f"{ORDER_DATA_TIMESTAMP_KEY}:{store_name}" if store_name else ORDER_DATA_TIMESTAMP_KEY
    version_key = f"{DATA_VERSION_KEY}:{store_name}" if store_name else DATA_VERSION_KEY
    
    # è·å–å½“å‰æ•°æ®ç‰ˆæœ¬
    current_version = get_data_version(store_name)
    
    # 1. å°è¯•ä»Redisè·å–ç¼“å­˜ï¼ˆæ™ºèƒ½ç‰ˆæœ¬æ£€æŸ¥ï¼‰
    if REDIS_AVAILABLE and redis_client:
        try:
            cached_version = redis_client.get(version_key)
            cached_timestamp = redis_client.get(redis_timestamp_key)
            
            # ç‰ˆæœ¬å·åŒ¹é… + æœªè¿‡æœŸ = ç¼“å­˜æœ‰æ•ˆ
            if cached_version and cached_version == current_version:
                if cached_timestamp and (current_time - float(cached_timestamp) < CACHE_TTL):
                    cached_data = redis_client.get(redis_cache_key)
                    if cached_data:
                        data = json.loads(cached_data)
                        print(f"ğŸ“¦ ä½¿ç”¨Redisç¼“å­˜æ•°æ® (é—¨åº—: {store_name or 'å…¨éƒ¨'}, {len(data)} æ¡)")
                        return pd.DataFrame(data)
        except Exception as e:
            print(f"âš ï¸ Redisè¯»å–å¤±è´¥: {e}")
    
    # 2. å°è¯•ä½¿ç”¨å†…å­˜ç¼“å­˜ï¼ˆåŒæ ·æ£€æŸ¥ç‰ˆæœ¬ï¼‰
    cached_version = _memory_cache.get("data_version")
    if cached_version == current_version:
        if store_name:
            store_cache = _memory_cache.get("store_cache", {}).get(store_name)
            if store_cache and current_time - store_cache.get("timestamp", 0) < CACHE_TTL:
                print(f"ğŸ“¦ ä½¿ç”¨å†…å­˜ç¼“å­˜æ•°æ® (é—¨åº—: {store_name})")
                return store_cache["data"].copy()
        else:
            if _memory_cache["order_data"] is not None:
                if current_time - _memory_cache["timestamp"] < CACHE_TTL:
                    print(f"ğŸ“¦ ä½¿ç”¨å†…å­˜ç¼“å­˜æ•°æ® (å…¨éƒ¨é—¨åº—)")
                    return _memory_cache["order_data"].copy()
    
    # 3. ä»æ•°æ®åº“åŠ è½½
    print(f"ğŸ”„ ä»æ•°æ®åº“åŠ è½½è®¢å•æ•°æ® (é—¨åº—: {store_name or 'å…¨éƒ¨'})...")
    session = SessionLocal()
    try:
        query = session.query(Order)
        
        # å¦‚æœæŒ‡å®šé—¨åº—ï¼ŒåªåŠ è½½è¯¥é—¨åº—æ•°æ®
        if store_name:
            query = query.filter(Order.store_name == store_name)
        
        orders = query.all()
        if not orders:
            return pd.DataFrame()
        
        # è½¬æ¢ä¸ºDataFrameï¼ˆå­—æ®µåä¸æ•°æ®åº“æ¨¡å‹ä¸€è‡´ï¼‰
        data = []
        for order in orders:
            data.append({
                'è®¢å•ID': order.order_id,
                'é—¨åº—åç§°': order.store_name,
                'æ—¥æœŸ': order.date,  # æ•°æ®åº“å­—æ®µæ˜¯date
                'æ¸ é“': order.channel,
                'å•†å“åç§°': order.product_name,
                'ä¸€çº§åˆ†ç±»å': order.category_level1,
                'ä¸‰çº§åˆ†ç±»å': order.category_level3,  # æ•°æ®åº“åªæœ‰ä¸‰çº§åˆ†ç±»
                'æœˆå”®': order.quantity if order.quantity is not None else 1,  # é»˜è®¤ä¸º1
                'å®æ”¶ä»·æ ¼': float(order.actual_price or 0),
                'å•†å“å®å”®ä»·': float(order.price or 0),  # æ•°æ®åº“å­—æ®µæ˜¯price
                'å•†å“åŸä»·': float(order.original_price or 0),  # âœ… æ–°å¢ï¼šå•†å“åŸä»·ï¼ˆç”¨äºGMVè®¡ç®—ï¼‰
                'å•†å“é‡‡è´­æˆæœ¬': float(order.cost or 0),  # æ•°æ®åº“å­—æ®µæ˜¯cost
                'åˆ©æ¶¦é¢': float(order.profit or 0),
                'ç‰©æµé…é€è´¹': float(order.delivery_fee or 0),
                'å¹³å°æœåŠ¡è´¹': float(order.platform_service_fee or 0),
                'å¹³å°ä½£é‡‘': float(order.commission or 0),
                'é¢„è®¡è®¢å•æ”¶å…¥': float(order.amount or 0),  # ä½¿ç”¨amountä½œä¸ºé¢„è®¡è®¢å•æ”¶å…¥
                'ä¼å®¢åè¿”': float(order.corporate_rebate or 0),  # æ•°æ®åº“å­—æ®µæ˜¯corporate_rebate
                'ç”¨æˆ·æ”¯ä»˜é…é€è´¹': float(order.user_paid_delivery_fee or 0),
                'é…é€è´¹å‡å…é‡‘é¢': float(order.delivery_discount or 0),
                'æ»¡å‡é‡‘é¢': float(order.full_reduction or 0),
                'å•†å“å‡å…é‡‘é¢': float(order.product_discount or 0),
                'æ–°å®¢å‡å…é‡‘é¢': float(order.new_customer_discount or 0),
                # âœ… æ–°å¢ï¼šå•†å®¶æ´»åŠ¨æˆæœ¬ç›¸å…³å­—æ®µï¼ˆä¸Dashç‰ˆæœ¬ä¸€è‡´ï¼‰
                'å•†å®¶ä»£é‡‘åˆ¸': float(order.merchant_voucher or 0),
                'å•†å®¶æ‰¿æ‹…éƒ¨åˆ†åˆ¸': float(order.merchant_share or 0),
                'æ»¡èµ é‡‘é¢': float(order.gift_amount or 0),
                'å•†å®¶å…¶ä»–ä¼˜æƒ ': float(order.other_merchant_discount or 0),
                'æ‰“åŒ…è¢‹é‡‘é¢': float(order.packaging_fee or 0),  # âœ… æ–°å¢ï¼šæ‰“åŒ…è¢‹é‡‘é¢ï¼ˆç”¨äºGMVè®¡ç®—ï¼‰
                'åº“å­˜': order.stock,
            })
        
        df = pd.DataFrame(data)
        print(f"âœ… æ•°æ®åº“åŠ è½½å®Œæˆ: {len(df)} æ¡è®°å½• (é—¨åº—: {store_name or 'å…¨éƒ¨'})")
        
        # 4. æ›´æ–°ç¼“å­˜ï¼ˆåŒ…å«ç‰ˆæœ¬å·ï¼‰
        # æ›´æ–°å†…å­˜ç¼“å­˜
        _memory_cache["data_version"] = current_version
        if store_name:
            if "store_cache" not in _memory_cache:
                _memory_cache["store_cache"] = {}
            _memory_cache["store_cache"][store_name] = {
                "data": df.copy(),
                "timestamp": current_time
            }
        else:
            _memory_cache["order_data"] = df.copy()
            _memory_cache["timestamp"] = current_time
        
        # æ›´æ–°Redisç¼“å­˜ï¼ˆåŒ…å«ç‰ˆæœ¬å·ï¼‰
        if REDIS_AVAILABLE and redis_client:
            try:
                # å°†æ—¥æœŸè½¬æ¢ä¸ºå­—ç¬¦ä¸²ä»¥ä¾¿JSONåºåˆ—åŒ–
                cache_data = data.copy()
                for item in cache_data:
                    if item.get('æ—¥æœŸ'):
                        item['æ—¥æœŸ'] = str(item['æ—¥æœŸ'])
                
                redis_client.set(redis_cache_key, json.dumps(cache_data, ensure_ascii=False))
                redis_client.set(redis_timestamp_key, str(current_time))
                redis_client.set(version_key, current_version)  # âœ… ä¿å­˜ç‰ˆæœ¬å·
                # è®¾ç½®è¿‡æœŸæ—¶é—´ï¼ˆ24å°æ—¶ï¼‰
                redis_client.expire(redis_cache_key, CACHE_TTL)
                redis_client.expire(redis_timestamp_key, CACHE_TTL)
                redis_client.expire(version_key, CACHE_TTL)
                print(f"âœ… æ•°æ®å·²ç¼“å­˜åˆ°Redis (é—¨åº—: {store_name or 'å…¨éƒ¨'}, ç‰ˆæœ¬: {current_version})")
            except Exception as e:
                print(f"âš ï¸ Redisç¼“å­˜å†™å…¥å¤±è´¥: {e}")
        
        return df
    finally:
        session.close()


def invalidate_cache(store_name: str = None):
    """
    æ¸…é™¤ç¼“å­˜ï¼ˆæ•°æ®æ›´æ–°æ—¶è°ƒç”¨ï¼‰
    
    Args:
        store_name: æŒ‡å®šé—¨åº—åˆ™åªæ¸…é™¤è¯¥é—¨åº—ç¼“å­˜ï¼Œå¦åˆ™æ¸…é™¤å…¨éƒ¨
    """
    global _memory_cache
    
    if store_name:
        # åªæ¸…é™¤æŒ‡å®šé—¨åº—çš„ç¼“å­˜
        if "store_cache" in _memory_cache and store_name in _memory_cache["store_cache"]:
            del _memory_cache["store_cache"][store_name]
            print(f"âœ… å†…å­˜ç¼“å­˜å·²æ¸…é™¤ (é—¨åº—: {store_name})")
    else:
        # æ¸…é™¤å…¨éƒ¨ç¼“å­˜
        _memory_cache = {"order_data": None, "timestamp": 0, "store_cache": {}, "data_version": None}
        print("âœ… å†…å­˜ç¼“å­˜å·²å…¨éƒ¨æ¸…é™¤")
    
    if REDIS_AVAILABLE and redis_client:
        try:
            if store_name:
                # åªæ¸…é™¤æŒ‡å®šé—¨åº—çš„ç¼“å­˜
                redis_client.delete(f"{ORDER_DATA_CACHE_KEY}:{store_name}")
                redis_client.delete(f"{ORDER_DATA_TIMESTAMP_KEY}:{store_name}")
                redis_client.delete(f"{DATA_VERSION_KEY}:{store_name}")
                print(f"âœ… Redisç¼“å­˜å·²æ¸…é™¤ (é—¨åº—: {store_name})")
            else:
                # æ¸…é™¤æ‰€æœ‰è®¢å•ç›¸å…³çš„ç¼“å­˜
                keys = redis_client.keys(f"{ORDER_DATA_CACHE_KEY}:*")
                if keys:
                    redis_client.delete(*keys)
                keys = redis_client.keys(f"{ORDER_DATA_TIMESTAMP_KEY}:*")
                if keys:
                    redis_client.delete(*keys)
                keys = redis_client.keys(f"{DATA_VERSION_KEY}:*")
                if keys:
                    redis_client.delete(*keys)
                redis_client.delete(ORDER_DATA_CACHE_KEY)
                redis_client.delete(ORDER_DATA_TIMESTAMP_KEY)
                redis_client.delete(DATA_VERSION_KEY)
                print("âœ… Redisç¼“å­˜å·²å…¨éƒ¨æ¸…é™¤")
        except Exception as e:
            print(f"âš ï¸ Redisç¼“å­˜æ¸…é™¤å¤±è´¥: {e}")
            redis_client.delete(ORDER_DATA_TIMESTAMP_KEY)
            print("âœ… Redisç¼“å­˜å·²æ¸…é™¤")
        except Exception as e:
            print(f"âš ï¸ Redisç¼“å­˜æ¸…é™¤å¤±è´¥: {e}")


@router.post("/clear-cache")
async def clear_cache(store_name: Optional[str] = Query(None, description="é—¨åº—åç§°ï¼Œä¸æŒ‡å®šåˆ™æ¸…é™¤å…¨éƒ¨")):
    """
    æ¸…é™¤è®¢å•æ•°æ®ç¼“å­˜
    
    Args:
        store_name: æŒ‡å®šé—¨åº—åˆ™åªæ¸…é™¤è¯¥é—¨åº—ç¼“å­˜ï¼Œå¦åˆ™æ¸…é™¤å…¨éƒ¨
    """
    invalidate_cache(store_name)
    return {
        "success": True, 
        "message": f"ç¼“å­˜å·²æ¸…é™¤ (é—¨åº—: {store_name or 'å…¨éƒ¨'})"
    }


def calculate_order_metrics(df: pd.DataFrame) -> pd.DataFrame:
    """
    ç»Ÿä¸€çš„è®¢å•æŒ‡æ ‡è®¡ç®—å‡½æ•°ï¼ˆä¸è€ç‰ˆæœ¬å®Œå…¨ä¸€è‡´ï¼‰
    
    æ ¸å¿ƒè®¡ç®—é€»è¾‘:
    1. è®¢å•çº§èšåˆï¼ˆè®¢å•çº§å­—æ®µç”¨firstï¼Œå•†å“çº§å­—æ®µç”¨sumï¼‰
    2. è®¡ç®—è®¢å•å®é™…åˆ©æ¶¦ = åˆ©æ¶¦é¢ - å¹³å°æœåŠ¡è´¹ - ç‰©æµé…é€è´¹ + ä¼å®¢åè¿”
    3. æŒ‰æ¸ é“ç±»å‹è¿‡æ»¤å¼‚å¸¸è®¢å•
    """
    if df.empty or 'è®¢å•ID' not in df.columns:
        return pd.DataFrame()
    
    df = df.copy()
    
    # ç»Ÿä¸€è®¢å•IDç±»å‹ä¸ºå­—ç¬¦ä¸²
    df['è®¢å•ID'] = df['è®¢å•ID'].astype(str)
    
    # å…¼å®¹ä¸åŒæˆæœ¬å­—æ®µå
    cost_field = 'å•†å“é‡‡è´­æˆæœ¬' if 'å•†å“é‡‡è´­æˆæœ¬' in df.columns else 'æˆæœ¬'
    sales_field = 'æœˆå”®' if 'æœˆå”®' in df.columns else 'é”€é‡'
    
    # ç©ºå€¼å¡«å……
    df['ç‰©æµé…é€è´¹'] = df['ç‰©æµé…é€è´¹'].fillna(0)
    df['é…é€è´¹å‡å…é‡‘é¢'] = df['é…é€è´¹å‡å…é‡‘é¢'].fillna(0)
    df['ç”¨æˆ·æ”¯ä»˜é…é€è´¹'] = df['ç”¨æˆ·æ”¯ä»˜é…é€è´¹'].fillna(0)
    
    # è®¡ç®—è®¢å•æ€»æ”¶å…¥ï¼ˆå®æ”¶ä»·æ ¼ Ã— é”€é‡ï¼‰
    if 'å®æ”¶ä»·æ ¼' in df.columns and sales_field in df.columns:
        df['è®¢å•æ€»æ”¶å…¥'] = df['å®æ”¶ä»·æ ¼'] * df[sales_field]
    
    # è®¢å•çº§èšåˆ
    agg_dict = {
        'å•†å“å®å”®ä»·': 'sum',
        'é¢„è®¡è®¢å•æ”¶å…¥': 'sum',
        'ç”¨æˆ·æ”¯ä»˜é…é€è´¹': 'first',
        'é…é€è´¹å‡å…é‡‘é¢': 'first',
        'ç‰©æµé…é€è´¹': 'first',
        'å¹³å°ä½£é‡‘': 'first',
    }
    
    if sales_field in df.columns:
        agg_dict[sales_field] = 'sum'
    if 'å¹³å°æœåŠ¡è´¹' in df.columns:
        agg_dict['å¹³å°æœåŠ¡è´¹'] = 'sum'
    if 'è®¢å•æ€»æ”¶å…¥' in df.columns:
        agg_dict['è®¢å•æ€»æ”¶å…¥'] = 'sum'
    if 'åˆ©æ¶¦é¢' in df.columns:
        agg_dict['åˆ©æ¶¦é¢'] = 'sum'
    if 'ä¼å®¢åè¿”' in df.columns:
        agg_dict['ä¼å®¢åè¿”'] = 'sum'
    if cost_field in df.columns:
        agg_dict[cost_field] = 'sum'
    
    # è®¢å•çº§å­—æ®µç”¨first
    for field in ['æ»¡å‡é‡‘é¢', 'å•†å“å‡å…é‡‘é¢', 'æ–°å®¢å‡å…é‡‘é¢', 'æ¸ é“', 'é—¨åº—åç§°', 'æ—¥æœŸ', 
                  'å•†å®¶ä»£é‡‘åˆ¸', 'å•†å®¶æ‰¿æ‹…éƒ¨åˆ†åˆ¸', 'æ»¡èµ é‡‘é¢', 'å•†å®¶å…¶ä»–ä¼˜æƒ ']:
        if field in df.columns:
            agg_dict[field] = 'first'
    
    order_agg = df.groupby('è®¢å•ID').agg(agg_dict).reset_index()
    
    # å°†è®¢å•æ€»æ”¶å…¥é‡å‘½åä¸ºå®æ”¶ä»·æ ¼
    if 'è®¢å•æ€»æ”¶å…¥' in order_agg.columns:
        order_agg['å®æ”¶ä»·æ ¼'] = order_agg['è®¢å•æ€»æ”¶å…¥']
    
    # ç»Ÿä¸€æˆæœ¬å­—æ®µå
    if cost_field == 'æˆæœ¬' and cost_field in order_agg.columns:
        order_agg['å•†å“é‡‡è´­æˆæœ¬'] = order_agg['æˆæœ¬']
    
    # å…³é”®å­—æ®µå…œåº•
    if 'å¹³å°æœåŠ¡è´¹' not in order_agg.columns:
        order_agg['å¹³å°æœåŠ¡è´¹'] = 0
    order_agg['å¹³å°æœåŠ¡è´¹'] = order_agg['å¹³å°æœåŠ¡è´¹'].fillna(0)
    
    if 'ä¼å®¢åè¿”' not in order_agg.columns:
        order_agg['ä¼å®¢åè¿”'] = 0
    order_agg['ä¼å®¢åè¿”'] = order_agg['ä¼å®¢åè¿”'].fillna(0)
    
    if 'å¹³å°ä½£é‡‘' not in order_agg.columns:
        order_agg['å¹³å°ä½£é‡‘'] = order_agg['å¹³å°æœåŠ¡è´¹']
    order_agg['å¹³å°ä½£é‡‘'] = order_agg['å¹³å°ä½£é‡‘'].fillna(0)
    
    if 'åˆ©æ¶¦é¢' not in order_agg.columns:
        order_agg['åˆ©æ¶¦é¢'] = 0
    order_agg['åˆ©æ¶¦é¢'] = order_agg['åˆ©æ¶¦é¢'].fillna(0)
    
    # è®¡ç®—è®¢å•å®é™…åˆ©æ¶¦ï¼ˆæ ¸å¿ƒå…¬å¼ï¼‰
    # å…¬å¼: è®¢å•å®é™…åˆ©æ¶¦ = åˆ©æ¶¦é¢ - å¹³å°æœåŠ¡è´¹ - ç‰©æµé…é€è´¹ + ä¼å®¢åè¿”
    order_agg['è®¢å•å®é™…åˆ©æ¶¦'] = (
        order_agg['åˆ©æ¶¦é¢'] -
        order_agg['å¹³å°æœåŠ¡è´¹'] -
        order_agg['ç‰©æµé…é€è´¹'] +
        order_agg['ä¼å®¢åè¿”']
    )
    
    # ==================== è®¡ç®—é…é€å‡€æˆæœ¬ï¼ˆä¸Dashç‰ˆæœ¬ä¸€è‡´ï¼‰ ====================
    # å…¬å¼: é…é€å‡€æˆæœ¬ = ç‰©æµé…é€è´¹ - (ç”¨æˆ·æ”¯ä»˜é…é€è´¹ - é…é€è´¹å‡å…é‡‘é¢) - ä¼å®¢åè¿”
    order_agg['é…é€å‡€æˆæœ¬'] = (
        order_agg['ç‰©æµé…é€è´¹'] -
        (order_agg['ç”¨æˆ·æ”¯ä»˜é…é€è´¹'] - order_agg['é…é€è´¹å‡å…é‡‘é¢']) -
        order_agg['ä¼å®¢åè¿”']
    )
    
    # ==================== è®¡ç®—å•†å®¶æ´»åŠ¨æˆæœ¬ï¼ˆå¯¹é½Dashç‰ˆæœ¬ï¼š7ä¸ªè¥é”€å­—æ®µï¼‰ ====================
    # å…¬å¼: å•†å®¶æ´»åŠ¨æˆæœ¬ = æ»¡å‡é‡‘é¢ + å•†å“å‡å…é‡‘é¢ + å•†å®¶ä»£é‡‘åˆ¸ + å•†å®¶æ‰¿æ‹…éƒ¨åˆ†åˆ¸ + æ»¡èµ é‡‘é¢ + å•†å®¶å…¶ä»–ä¼˜æƒ  + æ–°å®¢å‡å…é‡‘é¢
    # è¯´æ˜: é…é€è´¹å‡å…é‡‘é¢å±äºé…é€æˆæœ¬ï¼Œä¸å±äºè¥é”€æˆæœ¬
    marketing_fields = ['æ»¡å‡é‡‘é¢', 'å•†å“å‡å…é‡‘é¢', 'å•†å®¶ä»£é‡‘åˆ¸', 'å•†å®¶æ‰¿æ‹…éƒ¨åˆ†åˆ¸', 'æ»¡èµ é‡‘é¢', 'å•†å®¶å…¶ä»–ä¼˜æƒ ', 'æ–°å®¢å‡å…é‡‘é¢']
    order_agg['å•†å®¶æ´»åŠ¨æˆæœ¬'] = 0
    for field in marketing_fields:
        if field in order_agg.columns:
            order_agg['å•†å®¶æ´»åŠ¨æˆæœ¬'] += order_agg[field].fillna(0)
    
    # æŒ‰æ¸ é“ç±»å‹è¿‡æ»¤å¼‚å¸¸è®¢å•
    if 'æ¸ é“' in order_agg.columns:
        is_fee_channel = order_agg['æ¸ é“'].isin(PLATFORM_FEE_CHANNELS)
        is_zero_fee = order_agg['å¹³å°æœåŠ¡è´¹'] <= 0
        invalid_orders = is_fee_channel & is_zero_fee
        order_agg = order_agg[~invalid_orders].copy()
    
    return order_agg


def calculate_gmv(df: pd.DataFrame) -> Dict[str, float]:
    """
    è®¡ç®—é—¨åº—GMVï¼ˆè¥ä¸šé¢ï¼‰
    
    GMVè®¡ç®—å…¬å¼ï¼ˆç”¨æˆ·ç¡®è®¤ï¼‰ï¼š
    GMV = Î£(å•†å“åŸä»· Ã— é”€é‡) + Î£(æ‰“åŒ…è¢‹é‡‘é¢) + Î£(ç”¨æˆ·æ”¯ä»˜é…é€è´¹)
    
    æ•°æ®æ¸…æ´—è§„åˆ™ï¼ˆé‡è¦ï¼ï¼‰ï¼š
    1. **å‰”é™¤å•†å“åŸä»· <= 0 çš„æ•´è¡Œæ•°æ®**ï¼ˆåŒ…æ‹¬è¯¥è¡Œçš„æ‰“åŒ…è¢‹é‡‘é¢å’Œç”¨æˆ·æ”¯ä»˜é…é€è´¹ï¼‰
    2. å•†å“åŸä»·æ˜¯å•†å“çº§å­—æ®µï¼Œéœ€è¦ä¹˜ä»¥é”€é‡æ‰èƒ½å¾—å‡ºå‡†ç¡®çš„åŸä»·é”€å”®é‡‘é¢
    3. æ‰“åŒ…è¢‹é‡‘é¢æ˜¯è®¢å•çº§å­—æ®µï¼Œä¸€ä¸ªè®¢å•åªæ”¶å–ä¸€æ¬¡æ‰“åŒ…è´¹ï¼Œéœ€è¦ç”¨firstèšåˆé¿å…é‡å¤
    4. ç”¨æˆ·æ”¯ä»˜é…é€è´¹æ˜¯è®¢å•çº§å­—æ®µï¼Œæ¸…æ´—é€»è¾‘å’Œæ‰“åŒ…è¢‹é‡‘é¢ä¸€è‡´
    
    è¥é”€æˆæœ¬ç‡è®¡ç®—ï¼š
    è¥é”€æˆæœ¬ç‡ = è¥é”€æˆæœ¬ / GMV Ã— 100%
    
    éªŒè¯æ•°æ®ï¼ˆæƒ å®œé€‰è¶…å¸‚æ˜†å±±æ·€å±±æ¹–é•‡åº— 2026-01-18ï¼‰ï¼š
    - é¢„æœŸGMV: 8440.66
    - é¢„æœŸè¥é”€æˆæœ¬: 1122
    - é¢„æœŸè¥é”€æˆæœ¬ç‡: ~13.30%
    
    Args:
        df: åŸå§‹è®¢å•æ•°æ®DataFrameï¼ˆå•†å“çº§ï¼Œæœªèšåˆï¼‰
    
    Returns:
        DictåŒ…å«:
        - gmv: è¥ä¸šé¢
        - original_price_sales: å•†å“åŸä»·é”€å”®é¢
        - packaging_fee: æ‰“åŒ…è¢‹é‡‘é¢
        - user_delivery_fee: ç”¨æˆ·æ”¯ä»˜é…é€è´¹
        - marketing_cost: è¥é”€æˆæœ¬ï¼ˆ7å­—æ®µï¼‰
        - marketing_cost_rate: è¥é”€æˆæœ¬ç‡
    """
    if df.empty:
        return {
            "gmv": 0,
            "original_price_sales": 0,
            "packaging_fee": 0,
            "user_delivery_fee": 0,
            "marketing_cost": 0,
            "marketing_cost_rate": 0
        }
    
    df = df.copy()
    
    # ç¡®ä¿å¿…è¦å­—æ®µå­˜åœ¨
    sales_field = 'æœˆå”®' if 'æœˆå”®' in df.columns else 'é”€é‡'
    
    # 1. å‰”é™¤å•†å“åŸä»· <= 0 çš„æ•´è¡Œæ•°æ®ï¼ˆå…³é”®ï¼åŒ…æ‹¬è¯¥è¡Œçš„æ‰“åŒ…è¢‹é‡‘é¢å’Œç”¨æˆ·æ”¯ä»˜é…é€è´¹ï¼‰
    # ç”¨æˆ·ç¡®è®¤ï¼šå•†å“åŸä»·=0çš„è®¢å•æ²¡æœ‰å®é™…å•†å“é”€å”®ï¼Œå…¶æ‰“åŒ…è¢‹å’Œé…é€è´¹ä¹Ÿä¸åº”è®¡å…¥GMV
    if 'å•†å“åŸä»·' in df.columns:
        df = df[df['å•†å“åŸä»·'] > 0].copy()
    
    if df.empty:
        return {
            "gmv": 0,
            "original_price_sales": 0,
            "packaging_fee": 0,
            "user_delivery_fee": 0,
            "marketing_cost": 0,
            "marketing_cost_rate": 0
        }
    
    # 2. è®¡ç®—å•†å“åŸä»·é”€å”®é¢ = Î£(å•†å“åŸä»· Ã— é”€é‡)
    # å•†å“åŸä»·æ˜¯å•†å“çº§å­—æ®µï¼ˆå•ä»·ï¼‰ï¼Œéœ€è¦ä¹˜ä»¥é”€é‡
    if 'å•†å“åŸä»·' in df.columns and sales_field in df.columns:
        df['åŸä»·é”€å”®é¢'] = df['å•†å“åŸä»·'].fillna(0) * df[sales_field].fillna(1)
        original_price_sales = df['åŸä»·é”€å”®é¢'].sum()
    else:
        original_price_sales = 0
    
    # 3. è®¡ç®—è®¢å•çº§å­—æ®µï¼ˆæ‰“åŒ…è¢‹é‡‘é¢ã€ç”¨æˆ·æ”¯ä»˜é…é€è´¹ï¼‰
    # è¿™äº›æ˜¯è®¢å•çº§å­—æ®µï¼Œéœ€è¦æŒ‰è®¢å•IDèšåˆåç”¨firstå–å€¼ï¼Œé¿å…é‡å¤è®¡ç®—
    # æ³¨æ„ï¼šæ­¤æ—¶dfå·²ç»å‰”é™¤äº†å•†å“åŸä»·<=0çš„è¡Œï¼Œæ‰€ä»¥åªæœ‰æœ‰æ•ˆè®¢å•çš„æ•°æ®ä¼šè¢«è®¡å…¥
    if 'è®¢å•ID' in df.columns:
        # è®¢å•çº§å­—æ®µèšåˆ
        order_level_agg = df.groupby('è®¢å•ID').agg({
            'æ‰“åŒ…è¢‹é‡‘é¢': 'first' if 'æ‰“åŒ…è¢‹é‡‘é¢' in df.columns else lambda x: 0,
            'ç”¨æˆ·æ”¯ä»˜é…é€è´¹': 'first' if 'ç”¨æˆ·æ”¯ä»˜é…é€è´¹' in df.columns else lambda x: 0,
            # è¥é”€æˆæœ¬å­—æ®µï¼ˆè®¢å•çº§ï¼‰
            'æ»¡å‡é‡‘é¢': 'first' if 'æ»¡å‡é‡‘é¢' in df.columns else lambda x: 0,
            'å•†å“å‡å…é‡‘é¢': 'first' if 'å•†å“å‡å…é‡‘é¢' in df.columns else lambda x: 0,
            'å•†å®¶ä»£é‡‘åˆ¸': 'first' if 'å•†å®¶ä»£é‡‘åˆ¸' in df.columns else lambda x: 0,
            'å•†å®¶æ‰¿æ‹…éƒ¨åˆ†åˆ¸': 'first' if 'å•†å®¶æ‰¿æ‹…éƒ¨åˆ†åˆ¸' in df.columns else lambda x: 0,
            'æ»¡èµ é‡‘é¢': 'first' if 'æ»¡èµ é‡‘é¢' in df.columns else lambda x: 0,
            'å•†å®¶å…¶ä»–ä¼˜æƒ ': 'first' if 'å•†å®¶å…¶ä»–ä¼˜æƒ ' in df.columns else lambda x: 0,
            'æ–°å®¢å‡å…é‡‘é¢': 'first' if 'æ–°å®¢å‡å…é‡‘é¢' in df.columns else lambda x: 0,
        }).reset_index()
        
        packaging_fee = order_level_agg['æ‰“åŒ…è¢‹é‡‘é¢'].sum() if 'æ‰“åŒ…è¢‹é‡‘é¢' in order_level_agg.columns else 0
        user_delivery_fee = order_level_agg['ç”¨æˆ·æ”¯ä»˜é…é€è´¹'].sum() if 'ç”¨æˆ·æ”¯ä»˜é…é€è´¹' in order_level_agg.columns else 0
        
        # è®¡ç®—è¥é”€æˆæœ¬ï¼ˆ7å­—æ®µï¼‰
        marketing_fields = ['æ»¡å‡é‡‘é¢', 'å•†å“å‡å…é‡‘é¢', 'å•†å®¶ä»£é‡‘åˆ¸', 'å•†å®¶æ‰¿æ‹…éƒ¨åˆ†åˆ¸', 'æ»¡èµ é‡‘é¢', 'å•†å®¶å…¶ä»–ä¼˜æƒ ', 'æ–°å®¢å‡å…é‡‘é¢']
        marketing_cost = 0
        for field in marketing_fields:
            if field in order_level_agg.columns:
                marketing_cost += order_level_agg[field].fillna(0).sum()
    else:
        packaging_fee = 0
        user_delivery_fee = 0
        marketing_cost = 0
    
    # 4. è®¡ç®—GMV
    gmv = original_price_sales + packaging_fee + user_delivery_fee
    
    # 5. è®¡ç®—è¥é”€æˆæœ¬ç‡
    marketing_cost_rate = (marketing_cost / gmv * 100) if gmv > 0 else 0
    
    return {
        "gmv": round(gmv, 2),
        "original_price_sales": round(original_price_sales, 2),
        "packaging_fee": round(packaging_fee, 2),
        "user_delivery_fee": round(user_delivery_fee, 2),
        "marketing_cost": round(marketing_cost, 2),
        "marketing_cost_rate": round(marketing_cost_rate, 2)
    }


@router.get("/overview")
async def get_order_overview(
    store_name: Optional[str] = Query(None, description="é—¨åº—åç§°ç­›é€‰"),
    start_date: Optional[date] = Query(None, description="å¼€å§‹æ—¥æœŸ"),
    end_date: Optional[date] = Query(None, description="ç»“æŸæ—¥æœŸ"),
    use_aggregation: bool = Query(False, description="æ˜¯å¦ä½¿ç”¨é¢„èšåˆè¡¨ï¼ˆé»˜è®¤ç¦ç”¨ï¼Œç¡®ä¿æ•°æ®ä¸çœ‹æ¿ç³»ç»Ÿä¸€è‡´ï¼‰")
) -> Dict[str, Any]:
    """
    è·å–è®¢å•æ•°æ®æ¦‚è§ˆï¼ˆå…­å¤§æ ¸å¿ƒå¡ç‰‡ï¼‰
    
    ä¸è€ç‰ˆæœ¬Tab1å®Œå…¨ä¸€è‡´çš„æŒ‡æ ‡:
    - ğŸ“¦ è®¢å•æ€»æ•°
    - ğŸ’° å•†å“å®æ”¶é¢
    - ğŸ’ æ€»åˆ©æ¶¦ï¼ˆè®¢å•å®é™…åˆ©æ¶¦ = åˆ©æ¶¦é¢ - å¹³å°æœåŠ¡è´¹ - ç‰©æµé…é€è´¹ + ä¼å®¢åè¿”ï¼‰
    - ğŸ›’ å¹³å‡å®¢å•ä»·
    - ğŸ“ˆ æ€»åˆ©æ¶¦ç‡
    - ğŸ·ï¸ åŠ¨é”€å•†å“æ•°
    
    æ³¨æ„ï¼šé»˜è®¤ä½¿ç”¨åŸå§‹æŸ¥è¯¢ï¼Œç¡®ä¿æ•°æ®ä¸çœ‹æ¿ç³»ç»Ÿä¸€è‡´
    ï¼ˆåŸå§‹æŸ¥è¯¢ä¼šè¿‡æ»¤æ”¶è´¹æ¸ é“ä¸­å¹³å°æœåŠ¡è´¹=0çš„å¼‚å¸¸è®¢å•ï¼‰
    """
    import time
    query_start = time.time()
    
    # âœ… ä¼˜å…ˆä½¿ç”¨é¢„èšåˆè¡¨ï¼ˆåŒ…å«GMVå­—æ®µï¼‰
    if use_aggregation:
        try:
            from app.services.aggregation_service import aggregation_service
            result = aggregation_service.get_store_overview(
                store_name=store_name,
                start_date=start_date,
                end_date=end_date
            )
            # ğŸ”§ ä¿®å¤ï¼šæ£€æŸ¥é¢„èšåˆè¡¨æ˜¯å¦æœ‰æœ‰æ•ˆæ•°æ®ï¼ˆè®¢å•æ•° > 0ï¼‰
            if result and result.get("total_orders", 0) > 0:
                # é¢„èšåˆè¡¨æœ‰æ•°æ®
                if result.get("gmv", 0) > 0:
                    # é¢„èšåˆè¡¨æœ‰GMVæ•°æ®ï¼Œç›´æ¥ä½¿ç”¨
                    print(f"âœ… [é¢„èšåˆè¡¨+GMV] overviewæŸ¥è¯¢è€—æ—¶: {(time.time()-query_start)*1000:.1f}ms")
                    return {"success": True, "data": result}
                else:
                    # é¢„èšåˆè¡¨æ²¡æœ‰GMVæ•°æ®ï¼Œéœ€è¦ä»åŸå§‹æ•°æ®è®¡ç®—GMV
                    df = get_order_data(store_name)
                    if not df.empty:
                        # æ—¥æœŸç­›é€‰
                        if 'æ—¥æœŸ' in df.columns:
                            df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'], errors='coerce')
                            if start_date:
                                df = df[df['æ—¥æœŸ'].dt.date >= start_date]
                            if end_date:
                                df = df[df['æ—¥æœŸ'].dt.date <= end_date]
                        
                        # è®¡ç®—GMVå’Œè¥é”€æˆæœ¬ç‡
                        gmv_data = calculate_gmv(df)
                        result["gmv"] = gmv_data["gmv"]
                        result["marketing_cost"] = gmv_data["marketing_cost"]
                        result["marketing_cost_rate"] = gmv_data["marketing_cost_rate"]
                    else:
                        result["gmv"] = 0
                        result["marketing_cost"] = 0
                        result["marketing_cost_rate"] = 0
                    
                    print(f"âœ… [é¢„èšåˆè¡¨+åŸå§‹GMV] overviewæŸ¥è¯¢è€—æ—¶: {(time.time()-query_start)*1000:.1f}ms")
                    return {"success": True, "data": result}
            else:
                # ğŸ”§ é¢„èšåˆè¡¨æ²¡æœ‰æ•°æ®ï¼Œå›é€€åˆ°åŸå§‹æŸ¥è¯¢
                print(f"âš ï¸ é¢„èšåˆè¡¨æ— æ•°æ®(store={store_name})ï¼Œå›é€€åˆ°åŸå§‹æŸ¥è¯¢")
        except Exception as e:
            print(f"âš ï¸ é¢„èšåˆè¡¨æŸ¥è¯¢å¤±è´¥ï¼Œå›é€€åˆ°åŸå§‹æŸ¥è¯¢: {e}")
    
    # å›é€€åˆ°åŸå§‹æŸ¥è¯¢
    # æŒ‰é—¨åº—åŠ è½½æ•°æ®ï¼ˆåˆ©ç”¨ç¼“å­˜ï¼‰
    df = get_order_data(store_name)
    if df.empty:
        return {
            "success": True,
            "data": {
                "total_orders": 0,
                "total_actual_sales": 0,
                "total_profit": 0,
                "avg_order_value": 0,
                "profit_rate": 0,
                "active_products": 0,
            }
        }
    
    # æ—¥æœŸç­›é€‰
    if 'æ—¥æœŸ' in df.columns:
        df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'], errors='coerce')
        if start_date:
            df = df[df['æ—¥æœŸ'].dt.date >= start_date]
        if end_date:
            df = df[df['æ—¥æœŸ'].dt.date <= end_date]
    
    if df.empty:
        return {
            "success": True,
            "data": {
                "total_orders": 0,
                "total_actual_sales": 0,
                "total_profit": 0,
                "avg_order_value": 0,
                "profit_rate": 0,
                "active_products": 0,
            }
        }
    
    # è®¡ç®—è®¢å•çº§æŒ‡æ ‡
    order_agg = calculate_order_metrics(df)
    
    # å…­å¤§æ ¸å¿ƒå¡ç‰‡
    total_orders = len(order_agg)
    total_actual_sales = order_agg['å®æ”¶ä»·æ ¼'].sum() if 'å®æ”¶ä»·æ ¼' in order_agg.columns else 0
    total_profit = order_agg['è®¢å•å®é™…åˆ©æ¶¦'].sum() if 'è®¢å•å®é™…åˆ©æ¶¦' in order_agg.columns else 0
    avg_order_value = total_actual_sales / total_orders if total_orders > 0 else 0
    profit_rate = (total_profit / total_actual_sales * 100) if total_actual_sales > 0 else 0
    
    # åŠ¨é”€å•†å“æ•°ï¼ˆæœ‰é”€é‡çš„SKUï¼‰
    sales_field = 'æœˆå”®' if 'æœˆå”®' in df.columns else 'é”€é‡'
    if 'å•†å“åç§°' in df.columns and sales_field in df.columns:
        active_products = df[df[sales_field] > 0]['å•†å“åç§°'].nunique()
    else:
        active_products = df['å•†å“åç§°'].nunique() if 'å•†å“åç§°' in df.columns else 0
    
    # âœ… æ–°å¢ï¼šè®¡ç®—GMVå’Œè¥é”€æˆæœ¬ç‡ï¼ˆåŸºäºç”¨æˆ·ç¡®è®¤çš„å…¬å¼ï¼‰
    gmv_data = calculate_gmv(df)
    
    print(f"âš ï¸ [åŸå§‹æŸ¥è¯¢] overviewæŸ¥è¯¢è€—æ—¶: {(time.time()-query_start)*1000:.1f}ms")
    
    return {
        "success": True,
        "data": {
            "total_orders": int(total_orders),
            "total_actual_sales": round(float(total_actual_sales), 2),
            "total_profit": round(float(total_profit), 2),
            "avg_order_value": round(float(avg_order_value), 2),
            "profit_rate": round(float(profit_rate), 2),
            "active_products": int(active_products),
            # âœ… æ–°å¢ï¼šGMVå’Œè¥é”€æˆæœ¬ç‡
            "gmv": gmv_data["gmv"],
            "marketing_cost": gmv_data["marketing_cost"],
            "marketing_cost_rate": gmv_data["marketing_cost_rate"],
        }
    }


@router.get("/all-stores-overview")
async def get_all_stores_overview(
    start_date: Optional[date] = Query(None, description="å¼€å§‹æ—¥æœŸ"),
    end_date: Optional[date] = Query(None, description="ç»“æŸæ—¥æœŸ"),
    channels: Optional[str] = Query(None, description="æ¸ é“ç­›é€‰ï¼Œå¤šä¸ªæ¸ é“ç”¨é€—å·åˆ†éš”"),
) -> Dict[str, Any]:
    """
    è·å–å…¨é—¨åº—é”€å”®æ€»è§ˆæ•°æ®ï¼ˆç»è¥æ€»è§ˆ - å…¨é—¨åº—æ¨ªå‘å¯¹æ¯”ï¼‰
    
    ä¸ä¾èµ– selectedStoreï¼Œå§‹ç»ˆåŠ è½½æ‰€æœ‰é—¨åº—è¿›è¡Œå¯¹æ¯”ã€‚
    å¤ç”¨ calculate_order_metrics å’Œ calculate_gmv ç¡®ä¿è®¡ç®—ç»“æœä¸å•é—¨åº—æ¦‚è§ˆä¸€è‡´ã€‚
    
    è¿”å›æ¯ä¸ªé—¨åº—çš„ 8 ä¸ªæŒ‡æ ‡ï¼š
    - é”€å”®é¢ã€è®¢å•é‡ã€åˆ©æ¶¦ã€åˆ©æ¶¦ç‡
    - å®¢å•ä»·ã€è¥é”€æˆæœ¬ç‡ã€å•å‡é…é€è´¹ã€å•å‡åˆ©æ¶¦
    """
    import time
    query_start = time.time()
    
    # åŠ è½½å…¨éƒ¨é—¨åº—æ•°æ®ï¼ˆä¸æŒ‡å®š store_nameï¼‰
    df = get_order_data(store_name=None)
    
    if df.empty or 'é—¨åº—åç§°' not in df.columns:
        return {"success": True, "data": {"stores": []}}
    
    # æ¸ é“ç­›é€‰ï¼ˆæ”¯æŒå¤šé€‰ï¼Œé€—å·åˆ†éš”ï¼‰
    if channels and 'æ¸ é“' in df.columns:
        channel_list = [ch.strip() for ch in channels.split(',') if ch.strip()]
        if channel_list:
            df = df[df['æ¸ é“'].isin(channel_list)]
            if df.empty:
                return {"success": True, "data": {"stores": []}}
    
    # æ—¥æœŸé¢„å¤„ç†
    if 'æ—¥æœŸ' in df.columns:
        df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'], errors='coerce')
    
    # 1. è®¡ç®—å½“å‰å‘¨æœŸæ•°æ®
    current_df = df.copy()
    
    # DEBUG: Print data types
    print(f"DEBUG: start_date={start_date} type={type(start_date)}, end_date={end_date} type={type(end_date)}, channels={channels}")
    
    # å¼ºåˆ¶ç¡®ä¿æ—¥æœŸåˆ—ä¸º datetime
    if 'æ—¥æœŸ' in current_df.columns:
         current_df['æ—¥æœŸ'] = pd.to_datetime(current_df['æ—¥æœŸ'])

    if start_date:
        # start_date å·²ç»æ˜¯ date å¯¹è±¡ (Line 767)
        current_df = current_df[current_df['æ—¥æœŸ'].dt.date >= start_date]
    if end_date:
        current_df = current_df[current_df['æ—¥æœŸ'].dt.date <= end_date]
        
    if current_df.empty:
        return {"success": True, "data": {"stores": []}}

    # 2. è®¡ç®—ç¯æ¯”å‘¨æœŸæ•°æ® (Previous Period)
    prev_start_date = None
    prev_end_date = None
    prev_metrics_map = {}  # {store_name: {metric: value, ...}}
    
    # å½“æœªæŒ‡å®šæ—¥æœŸèŒƒå›´æ—¶ï¼Œè‡ªåŠ¨ä½¿ç”¨æœ€è¿‘7å¤© vs å‰7å¤©è®¡ç®—ç¯æ¯”
    effective_start = start_date
    effective_end = end_date
    auto_trend_mode = False
    current_sales_map = {}  # è‡ªåŠ¨ç¯æ¯”æ¨¡å¼ä¸‹çš„å½“æœŸé”€å”®é¢
    if not start_date or not end_date:
        if 'æ—¥æœŸ' in current_df.columns and not current_df.empty:
            max_date = current_df['æ—¥æœŸ'].dt.date.max()
            effective_end = max_date
            effective_start = max_date - timedelta(days=6)  # æœ€è¿‘7å¤©
            auto_trend_mode = True
            # è®¡ç®—å½“æœŸï¼ˆæœ€è¿‘7å¤©ï¼‰æ¯é—¨åº—çš„é”€å”®é¢
            curr_mask = (current_df['æ—¥æœŸ'].dt.date >= effective_start) & (current_df['æ—¥æœŸ'].dt.date <= effective_end)
            curr_trend_df = current_df[curr_mask]
            if not curr_trend_df.empty and 'å®æ”¶ä»·æ ¼' in curr_trend_df.columns:
                current_sales_map = curr_trend_df.groupby('é—¨åº—åç§°')['å®æ”¶ä»·æ ¼'].sum().to_dict()
    
    if effective_start and effective_end:
        duration = effective_end - effective_start
        prev_end_date = effective_start - timedelta(days=1)
        prev_start_date = prev_end_date - duration
        
        prev_mask = (df['æ—¥æœŸ'].dt.date >= prev_start_date) & (df['æ—¥æœŸ'].dt.date <= prev_end_date)
        prev_df = df[prev_mask]
        
        if not prev_df.empty:
            # é¢„è®¡ç®—æ‰€æœ‰é—¨åº—çš„ä¸ŠæœŸé”€å”®é¢ï¼Œé¿å…å¾ªç¯å†…é‡å¤è¿‡æ»¤
            # æ³¨æ„ï¼šéœ€ç¡®ä¿ 'å®æ”¶ä»·æ ¼' åˆ—å­˜åœ¨ä¸”ä¸ºæ•°å€¼
            if 'å®æ”¶ä»·æ ¼' in prev_df.columns:
                # é¢„è®¡ç®—æ‰€æœ‰é—¨åº—çš„ä¸ŠæœŸå…¨éƒ¨æŒ‡æ ‡
                for prev_store in prev_df['é—¨åº—åç§°'].dropna().unique():
                    prev_store_df = prev_df[prev_df['é—¨åº—åç§°'] == prev_store]
                    prev_order_agg = calculate_order_metrics(prev_store_df)
                    if prev_order_agg.empty:
                        continue
                    prev_oc = len(prev_order_agg)
                    prev_ts = float(prev_order_agg['å®æ”¶ä»·æ ¼'].sum()) if 'å®æ”¶ä»·æ ¼' in prev_order_agg.columns else 0
                    prev_tp = float(prev_order_agg['è®¢å•å®é™…åˆ©æ¶¦'].sum()) if 'è®¢å•å®é™…åˆ©æ¶¦' in prev_order_agg.columns else 0
                    prev_tdf = float(prev_order_agg['ç‰©æµé…é€è´¹'].sum()) if 'ç‰©æµé…é€è´¹' in prev_order_agg.columns else 0
                    prev_pr = (prev_tp / prev_ts * 100) if prev_ts > 0 else 0
                    prev_aov = prev_ts / prev_oc if prev_oc > 0 else 0
                    prev_adf = prev_tdf / prev_oc if prev_oc > 0 else 0
                    prev_ap = prev_tp / prev_oc if prev_oc > 0 else 0
                    prev_gmv = calculate_gmv(prev_store_df)
                    prev_mcr = prev_gmv["marketing_cost_rate"]
                    prev_metrics_map[prev_store] = {
                        'total_sales': prev_ts, 'order_count': prev_oc,
                        'total_profit': prev_tp, 'profit_rate': prev_pr,
                        'avg_order_value': prev_aov, 'marketing_cost_rate': prev_mcr,
                        'avg_delivery_fee': prev_adf, 'avg_profit': prev_ap,
                    }

    # è‡ªåŠ¨ç¯æ¯”æ¨¡å¼ï¼šä¹Ÿéœ€è¦è®¡ç®—å½“æœŸï¼ˆæœ€è¿‘7å¤©ï¼‰çš„æŒ‡æ ‡ç”¨äºå¯¹æ¯”
    current_trend_metrics_map = {}
    if auto_trend_mode and effective_start and effective_end:
        curr_mask = (current_df['æ—¥æœŸ'].dt.date >= effective_start) & (current_df['æ—¥æœŸ'].dt.date <= effective_end)
        curr_trend_df = current_df[curr_mask]
        if not curr_trend_df.empty:
            for ct_store in curr_trend_df['é—¨åº—åç§°'].dropna().unique():
                ct_store_df = curr_trend_df[curr_trend_df['é—¨åº—åç§°'] == ct_store]
                ct_order_agg = calculate_order_metrics(ct_store_df)
                if ct_order_agg.empty:
                    continue
                ct_oc = len(ct_order_agg)
                ct_ts = float(ct_order_agg['å®æ”¶ä»·æ ¼'].sum()) if 'å®æ”¶ä»·æ ¼' in ct_order_agg.columns else 0
                ct_tp = float(ct_order_agg['è®¢å•å®é™…åˆ©æ¶¦'].sum()) if 'è®¢å•å®é™…åˆ©æ¶¦' in ct_order_agg.columns else 0
                ct_tdf = float(ct_order_agg['ç‰©æµé…é€è´¹'].sum()) if 'ç‰©æµé…é€è´¹' in ct_order_agg.columns else 0
                ct_pr = (ct_tp / ct_ts * 100) if ct_ts > 0 else 0
                ct_aov = ct_ts / ct_oc if ct_oc > 0 else 0
                ct_adf = ct_tdf / ct_oc if ct_oc > 0 else 0
                ct_ap = ct_tp / ct_oc if ct_oc > 0 else 0
                ct_gmv = calculate_gmv(ct_store_df)
                ct_mcr = ct_gmv["marketing_cost_rate"]
                current_trend_metrics_map[ct_store] = {
                    'total_sales': ct_ts, 'order_count': ct_oc,
                    'total_profit': ct_tp, 'profit_rate': ct_pr,
                    'avg_order_value': ct_aov, 'marketing_cost_rate': ct_mcr,
                    'avg_delivery_fee': ct_adf, 'avg_profit': ct_ap,
                }

    # æŒ‰é—¨åº—åˆ†ç»„è®¡ç®—
    store_names = current_df['é—¨åº—åç§°'].dropna().unique().tolist()
    stores_result = []
    
    # ç¯æ¯”è®¡ç®—è¾…åŠ©å‡½æ•°
    def calc_trend_pct(curr_val: float, prev_val: float) -> float:
        """ç™¾åˆ†æ¯”å˜åŒ–ç‡ï¼Œç”¨äºç»å¯¹å€¼æŒ‡æ ‡"""
        if prev_val > 0:
            return round(((curr_val - prev_val) / prev_val) * 100, 1)
        return 0.0
    
    def calc_trend_pt(curr_val: float, prev_val: float) -> float:
        """ç™¾åˆ†ç‚¹å·®å€¼ï¼Œç”¨äºç‡ç±»æŒ‡æ ‡"""
        return round(curr_val - prev_val, 1)
    
    for store in store_names:
        store_df = current_df[current_df['é—¨åº—åç§°'] == store]
        if store_df.empty:
            continue
        
        # 3. è®¢å•çº§èšåˆ (Current Metrics)
        order_agg = calculate_order_metrics(store_df)
        if order_agg.empty:
            continue
        
        order_count = len(order_agg)
        total_sales = float(order_agg['å®æ”¶ä»·æ ¼'].sum()) if 'å®æ”¶ä»·æ ¼' in order_agg.columns else 0
        total_profit = float(order_agg['è®¢å•å®é™…åˆ©æ¶¦'].sum()) if 'è®¢å•å®é™…åˆ©æ¶¦' in order_agg.columns else 0
        total_delivery_fee = float(order_agg['ç‰©æµé…é€è´¹'].sum()) if 'ç‰©æµé…é€è´¹' in order_agg.columns else 0
        
        profit_rate = (total_profit / total_sales * 100) if total_sales > 0 else 0
        avg_order_value = total_sales / order_count if order_count > 0 else 0
        avg_delivery_fee = total_delivery_fee / order_count if order_count > 0 else 0
        avg_profit = total_profit / order_count if order_count > 0 else 0
        
        # 4. GMV & è¥é”€æˆæœ¬ç‡
        gmv_data = calculate_gmv(store_df)
        marketing_cost_rate = gmv_data["marketing_cost_rate"]
        
        # 5. æ¯ä¸ªæŒ‡æ ‡çš„ç¯æ¯”
        # è‡ªåŠ¨ç¯æ¯”æ¨¡å¼ç”¨ current_trend_metrics_mapï¼Œæœ‰æ—¥æœŸèŒƒå›´æ—¶ç”¨å½“å‰å®Œæ•´æ•°æ®
        if auto_trend_mode:
            curr_m = current_trend_metrics_map.get(store, {})
        else:
            curr_m = {
                'total_sales': total_sales, 'order_count': order_count,
                'total_profit': total_profit, 'profit_rate': profit_rate,
                'avg_order_value': avg_order_value, 'marketing_cost_rate': marketing_cost_rate,
                'avg_delivery_fee': avg_delivery_fee, 'avg_profit': avg_profit,
            }
        prev_m = prev_metrics_map.get(store, {})
        
        # ä¸ŠæœŸæ— æ•°æ®æ—¶ï¼Œæ‰€æœ‰ç¯æ¯”è¿”å› Noneï¼ˆå‰ç«¯ä¸æ¸²æŸ“ï¼‰
        if not prev_m:
            trends = {
                'trend_sales': None, 'trend_orders': None,
                'trend_profit': None, 'trend_profit_rate': None,
                'trend_avg_value': None, 'trend_marketing_rate': None,
                'trend_delivery_fee': None, 'trend_avg_profit': None,
            }
        else:
            trends = {
                'trend_sales': calc_trend_pct(curr_m.get('total_sales', 0), prev_m.get('total_sales', 0)),
                'trend_orders': calc_trend_pct(curr_m.get('order_count', 0), prev_m.get('order_count', 0)),
                'trend_profit': calc_trend_pct(curr_m.get('total_profit', 0), prev_m.get('total_profit', 0)),
                'trend_profit_rate': calc_trend_pt(curr_m.get('profit_rate', 0), prev_m.get('profit_rate', 0)),
                'trend_avg_value': calc_trend_pct(curr_m.get('avg_order_value', 0), prev_m.get('avg_order_value', 0)),
                'trend_marketing_rate': calc_trend_pt(curr_m.get('marketing_cost_rate', 0), prev_m.get('marketing_cost_rate', 0)),
                'trend_delivery_fee': calc_trend_pct(curr_m.get('avg_delivery_fee', 0), prev_m.get('avg_delivery_fee', 0)),
                'trend_avg_profit': calc_trend_pct(curr_m.get('avg_profit', 0), prev_m.get('avg_profit', 0)),
            }

        stores_result.append({
            "store_name": store,
            "total_sales": round(total_sales, 2),
            "order_count": int(order_count),
            "total_profit": round(total_profit, 2),
            "profit_rate": round(profit_rate, 2),
            "avg_order_value": round(avg_order_value, 2),
            "marketing_cost_rate": round(marketing_cost_rate, 2),
            "avg_delivery_fee": round(avg_delivery_fee, 2),
            "avg_profit": round(avg_profit, 2),
            **trends,
        })
    
    # æŒ‰é”€å”®é¢é™åºæ’åˆ—
    stores_result.sort(key=lambda x: x["total_sales"], reverse=True)
    
    print(f"ğŸ“Š [å…¨é—¨åº—æ€»è§ˆ] {len(stores_result)} ä¸ªé—¨åº—, è€—æ—¶: {(time.time()-query_start)*1000:.1f}ms")
    
    return {"success": True, "data": {"stores": stores_result}}


@router.get("/channels")
async def get_channel_stats(
    store_name: Optional[str] = Query(None, description="é—¨åº—åç§°ç­›é€‰"),
    start_date: Optional[date] = Query(None, description="å¼€å§‹æ—¥æœŸ"),
    end_date: Optional[date] = Query(None, description="ç»“æŸæ—¥æœŸ")
) -> Dict[str, Any]:
    """
    è·å–æ¸ é“è¡¨ç°å¯¹æ¯”æ•°æ®
    
    ä¸è€ç‰ˆæœ¬Tab1æ¸ é“å¡ç‰‡å®Œå…¨ä¸€è‡´
    æ³¨æ„ï¼šæ’é™¤å’–å•¡æ¸ é“ï¼ˆç¾å›¢å’–å•¡åº—ã€é¥¿äº†ä¹ˆå’–å•¡åº—ï¼‰
    """
    # æŒ‰é—¨åº—åŠ è½½æ•°æ®
    df = get_order_data(store_name)
    if df.empty:
        return {"success": True, "data": []}
    
    # æ—¥æœŸç­›é€‰
    if 'æ—¥æœŸ' in df.columns:
        df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'], errors='coerce')
    if start_date:
        df = df[df['æ—¥æœŸ'].dt.date >= start_date]
    if end_date:
        df = df[df['æ—¥æœŸ'].dt.date <= end_date]
    
    if df.empty or 'æ¸ é“' not in df.columns:
        return {"success": True, "data": []}
    
    # è®¡ç®—è®¢å•çº§æŒ‡æ ‡
    order_agg = calculate_order_metrics(df)
    
    if order_agg.empty or 'æ¸ é“' not in order_agg.columns:
        return {"success": True, "data": []}
    
    # æ’é™¤å’–å•¡æ¸ é“ï¼ˆä¸è€ç‰ˆæœ¬ä¸€è‡´ï¼‰
    CHANNELS_TO_REMOVE = ['ç¾å›¢å’–å•¡åº—', 'é¥¿äº†ä¹ˆå’–å•¡åº—']
    order_agg = order_agg[~order_agg['æ¸ é“'].isin(CHANNELS_TO_REMOVE)]
    
    if order_agg.empty:
        return {"success": True, "data": []}
    
    # æŒ‰æ¸ é“èšåˆ
    channel_stats = order_agg.groupby('æ¸ é“').agg({
        'è®¢å•ID': 'count',
        'å®æ”¶ä»·æ ¼': 'sum',
        'è®¢å•å®é™…åˆ©æ¶¦': 'sum',
    }).reset_index()
    
    channel_stats.columns = ['channel', 'order_count', 'amount', 'profit']
    
    # è®¡ç®—æ´¾ç”ŸæŒ‡æ ‡
    total_orders = channel_stats['order_count'].sum()
    total_amount = channel_stats['amount'].sum()
    
    channel_stats['order_ratio'] = (channel_stats['order_count'] / total_orders * 100) if total_orders > 0 else 0
    channel_stats['amount_ratio'] = (channel_stats['amount'] / total_amount * 100) if total_amount > 0 else 0
    channel_stats['avg_value'] = channel_stats.apply(
        lambda r: r['amount'] / r['order_count'] if r['order_count'] > 0 else 0, axis=1
    )
    channel_stats['profit_rate'] = channel_stats.apply(
        lambda r: r['profit'] / r['amount'] * 100 if r['amount'] > 0 else 0, axis=1
    )
    
    # æŒ‰è®¢å•æ•°æ’åº
    channel_stats = channel_stats.sort_values('order_count', ascending=False)
    
    # è½¬æ¢ä¸ºåˆ—è¡¨
    result = []
    for _, row in channel_stats.iterrows():
        result.append({
            "channel": row['channel'],
            "order_count": int(row['order_count']),
            "amount": round(float(row['amount']), 2),
            "profit": round(float(row['profit']), 2),
            "order_ratio": round(float(row['order_ratio']), 2),
            "amount_ratio": round(float(row['amount_ratio']), 2),
            "avg_value": round(float(row['avg_value']), 2),
            "profit_rate": round(float(row['profit_rate']), 2),
        })
    
    return {"success": True, "data": result}


@router.get("/trend")
async def get_order_trend(
    days: int = Query(30, ge=1, le=365, description="ç»Ÿè®¡å¤©æ•°"),
    store_name: Optional[str] = Query(None, description="é—¨åº—åç§°ç­›é€‰"),
    channel: Optional[str] = Query(None, description="æ¸ é“ç­›é€‰ï¼Œ'all'æˆ–ç©ºè¡¨ç¤ºå…¨éƒ¨æ¸ é“"),
    start_date: Optional[str] = Query(None, description="æ—¥æœŸèŒƒå›´å¼€å§‹(YYYY-MM-DDæ ¼å¼)"),
    end_date: Optional[str] = Query(None, description="æ—¥æœŸèŒƒå›´ç»“æŸ(YYYY-MM-DDæ ¼å¼)"),
    granularity: str = Query("day", description="ç²’åº¦: day/week/month"),
    use_aggregation: bool = Query(False, description="æ˜¯å¦ä½¿ç”¨é¢„èšåˆè¡¨ï¼ˆé»˜è®¤ç¦ç”¨ï¼Œç¡®ä¿æ•°æ®ä¸€è‡´æ€§ï¼‰")
) -> Dict[str, Any]:
    """
    è·å–è®¢å•è¶‹åŠ¿æ•°æ®ï¼ˆä¸Dashç‰ˆæœ¬é”€å”®è¶‹åŠ¿åˆ†æä¸€è‡´ï¼‰
    
    è¿”å›æ¯æ—¥/æ¯å‘¨/æ¯æœˆçš„è®¢å•æ•°ã€é”€å”®é¢ã€åˆ©æ¶¦ã€å®¢å•ä»·ã€åˆ©æ¶¦ç‡
    
    æ”¯æŒä¸¤ç§æ—¥æœŸç­›é€‰æ–¹å¼ï¼š
    - days: æœ€è¿‘Nå¤©ï¼ˆé»˜è®¤30å¤©ï¼‰
    - start_date + end_date: æŒ‡å®šæ—¥æœŸèŒƒå›´ï¼ˆä¼˜å…ˆçº§æ›´é«˜ï¼‰
    
    è®¡ç®—é€»è¾‘ä¸Dashç‰ˆæœ¬ calculate_daily_sales_with_channel å®Œå…¨ä¸€è‡´ï¼š
    - åˆ©æ¶¦ç‡ = æ€»åˆ©æ¶¦ / é”€å”®é¢ * 100
    - æ¸ é“ç­›é€‰ï¼šæ”¯æŒæŒ‰æ¸ é“è¿‡æ»¤æ•°æ®
    
    æ³¨æ„ï¼šé»˜è®¤ä½¿ç”¨åŸå§‹æŸ¥è¯¢ï¼Œç¡®ä¿æ•°æ®ä¸çœ‹æ¿ç³»ç»Ÿä¸€è‡´
    """
    import time
    query_start = time.time()
    
    empty_result = {
        "success": True, 
        "data": {
            "dates": [], "order_counts": [], "amounts": [], 
            "profits": [], "avg_values": [], "profit_rates": []
        }
    }
    
    # âœ… ä¼˜å…ˆä½¿ç”¨é¢„èšåˆè¡¨ï¼ˆä»…æ”¯æŒæ—¥ç²’åº¦ï¼Œæ— æ¸ é“ç­›é€‰æ—¶ï¼‰
    if use_aggregation and granularity == 'day':
        try:
            from app.services.aggregation_service import aggregation_service
            
            # è§£ææ—¥æœŸå‚æ•°
            from datetime import date as date_type
            agg_start = None
            agg_end = None
            
            if start_date and end_date:
                try:
                    agg_start = date_type.fromisoformat(start_date)
                    agg_end = date_type.fromisoformat(end_date)
                except:
                    pass
            
            # æ˜ å°„æ¸ é“å‚æ•°
            agg_channel = None
            if channel and channel != 'all':
                agg_channel = channel
            
            result = aggregation_service.get_daily_trend(
                store_name=store_name,
                start_date=agg_start,
                end_date=agg_end,
                channel=agg_channel
            )
            
            if result and len(result) > 0:
                # è½¬æ¢ä¸ºAPIå“åº”æ ¼å¼
                dates = [r['date'] for r in result]
                order_counts = [r['orders'] for r in result]
                amounts = [r['revenue'] for r in result]
                profits = [r['profit'] for r in result]
                avg_values = [round(r['revenue'] / r['orders'], 2) if r['orders'] > 0 else 0 for r in result]
                profit_rates = [round(r['profit'] / r['revenue'] * 100, 2) if r['revenue'] > 0 else 0 for r in result]
                
                print(f"âœ… [é¢„èšåˆè¡¨] trendæŸ¥è¯¢è€—æ—¶: {(time.time()-query_start)*1000:.1f}ms, {len(result)}æ¡è®°å½•")
                
                return {
                    "success": True,
                    "data": {
                        "dates": dates,
                        "order_counts": order_counts,
                        "amounts": amounts,
                        "profits": profits,
                        "avg_values": avg_values,
                        "profit_rates": profit_rates,
                    }
                }
        except Exception as e:
            print(f"âš ï¸ é¢„èšåˆè¡¨æŸ¥è¯¢å¤±è´¥ï¼Œå›é€€åˆ°åŸå§‹æŸ¥è¯¢: {e}")
    
    # å›é€€åˆ°åŸå§‹æŸ¥è¯¢
    # æŒ‰é—¨åº—åŠ è½½æ•°æ®ï¼ˆåˆ©ç”¨ç¼“å­˜ï¼‰
    df = get_order_data(store_name)
    
    if df.empty:
        return empty_result
    
    if 'æ—¥æœŸ' not in df.columns:
        return {"success": False, "error": "ç¼ºå°‘æ—¥æœŸå­—æ®µ"}
    
    df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'], errors='coerce')
    df = df.dropna(subset=['æ—¥æœŸ'])
    
    if df.empty:
        return empty_result
    
    # ğŸ†• æ—¥æœŸç­›é€‰ï¼šä¼˜å…ˆä½¿ç”¨æ—¥æœŸèŒƒå›´ï¼Œå¦åˆ™ä½¿ç”¨æœ€è¿‘Nå¤©
    if start_date and end_date:
        try:
            range_start = pd.to_datetime(start_date)
            range_end = pd.to_datetime(end_date)
            df = df[(df['æ—¥æœŸ'].dt.date >= range_start.date()) & (df['æ—¥æœŸ'].dt.date <= range_end.date())]
        except:
            # æ—¥æœŸè§£æå¤±è´¥ï¼Œå›é€€åˆ°é»˜è®¤è¡Œä¸º
            max_date = df['æ—¥æœŸ'].max()
            min_date = max_date - timedelta(days=days)
            df = df[df['æ—¥æœŸ'] >= min_date]
    else:
        # ç­›é€‰æœ€è¿‘Nå¤©
        max_date = df['æ—¥æœŸ'].max()
        if pd.isna(max_date):
            return empty_result
        
        min_date = max_date - timedelta(days=days)
        df = df[df['æ—¥æœŸ'] >= min_date]
    
    if df.empty:
        return empty_result
    
    # å…ˆèšåˆåˆ°è®¢å•çº§ï¼ˆä¸Dashç‰ˆæœ¬ä¸€è‡´ï¼‰
    order_agg = calculate_order_metrics(df)
    
    if order_agg.empty:
        return empty_result
    
    # ğŸ†• æ¸ é“ç­›é€‰ï¼ˆä¸Dashç‰ˆæœ¬ calculate_daily_sales_with_channel ä¸€è‡´ï¼‰
    if channel and channel != 'all' and 'æ¸ é“' in order_agg.columns:
        before_filter = len(order_agg)
        order_agg = order_agg[order_agg['æ¸ é“'] == channel].copy()
        after_filter = len(order_agg)
        print(f"ğŸ” [trend API] æ¸ é“ç­›é€‰: {before_filter} -> {after_filter} è®¢å• (æ¸ é“='{channel}')")
        
        if order_agg.empty:
            return empty_result
    
    # æ ¹æ®ç²’åº¦åˆ†ç»„
    if 'æ—¥æœŸ' in order_agg.columns:
        order_agg['æ—¥æœŸ'] = pd.to_datetime(order_agg['æ—¥æœŸ'])
        if granularity == 'week':
            order_agg['period'] = order_agg['æ—¥æœŸ'].dt.to_period('W').apply(lambda x: x.start_time)
        elif granularity == 'month':
            order_agg['period'] = order_agg['æ—¥æœŸ'].dt.to_period('M').apply(lambda x: x.start_time)
        else:
            order_agg['period'] = order_agg['æ—¥æœŸ'].dt.date
        
        # æŒ‰å‘¨æœŸèšåˆï¼ˆä¸Dashç‰ˆæœ¬ä¸€è‡´ï¼‰
        daily = order_agg.groupby('period').agg({
            'è®¢å•ID': 'count',
            'å®æ”¶ä»·æ ¼': 'sum',
            'è®¢å•å®é™…åˆ©æ¶¦': 'sum',
        }).reset_index()
        
        daily.columns = ['date', 'order_count', 'amount', 'profit']
    else:
        # å¤‡ç”¨æ–¹æ¡ˆï¼šæŒ‰åŸå§‹æ•°æ®æ—¥æœŸèšåˆ
        if granularity == 'week':
            df['period'] = df['æ—¥æœŸ'].dt.to_period('W').apply(lambda x: x.start_time)
        elif granularity == 'month':
            df['period'] = df['æ—¥æœŸ'].dt.to_period('M').apply(lambda x: x.start_time)
        else:
            df['period'] = df['æ—¥æœŸ'].dt.date
            
        daily = df.groupby('period').agg({
            'è®¢å•ID': 'nunique' if 'è®¢å•ID' in df.columns else 'count',
            'å®æ”¶ä»·æ ¼': 'sum' if 'å®æ”¶ä»·æ ¼' in df.columns else lambda x: 0,
            'åˆ©æ¶¦é¢': 'sum' if 'åˆ©æ¶¦é¢' in df.columns else lambda x: 0,
        }).reset_index()
        daily.columns = ['date', 'order_count', 'amount', 'profit']
    
    daily = daily.sort_values('date')
    
    # è®¡ç®—å®¢å•ä»·
    daily['avg_value'] = daily.apply(
        lambda r: r['amount'] / r['order_count'] if r['order_count'] > 0 else 0, axis=1
    )
    
    # ğŸ†• è®¡ç®—åˆ©æ¶¦ç‡ï¼ˆä¸Dashç‰ˆæœ¬ä¸€è‡´ï¼šåˆ©æ¶¦ç‡ = æ€»åˆ©æ¶¦ / é”€å”®é¢ * 100ï¼‰
    daily['profit_rate'] = daily.apply(
        lambda r: round(r['profit'] / r['amount'] * 100, 2) if r['amount'] > 0 else 0, axis=1
    )
    
    print(f"âš ï¸ [åŸå§‹æŸ¥è¯¢] trendæŸ¥è¯¢è€—æ—¶: {(time.time()-query_start)*1000:.1f}ms")
    
    return {
        "success": True,
        "data": {
            "dates": [str(d) for d in daily['date'].tolist()],
            "order_counts": [int(x) for x in daily['order_count'].tolist()],
            "amounts": [round(float(x), 2) for x in daily['amount'].tolist()],
            "profits": [round(float(x), 2) for x in daily['profit'].tolist()],
            "avg_values": [round(float(x), 2) for x in daily['avg_value'].tolist()],
            "profit_rates": [float(x) for x in daily['profit_rate'].tolist()],
        }
    }


@router.get("/list")
async def get_order_list(
    page: int = Query(1, ge=1, description="é¡µç "),
    page_size: int = Query(20, ge=1, le=100, description="æ¯é¡µæ•°é‡"),
    store_name: Optional[str] = Query(None, description="é—¨åº—ç­›é€‰"),
    channel: Optional[str] = Query(None, description="æ¸ é“ç­›é€‰"),
    start_date: Optional[date] = Query(None, description="å¼€å§‹æ—¥æœŸ"),
    end_date: Optional[date] = Query(None, description="ç»“æŸæ—¥æœŸ"),
    sort_by: str = Query("date", description="æ’åºå­—æ®µ"),
    sort_order: str = Query("desc", description="æ’åºæ–¹å‘")
) -> Dict[str, Any]:
    """
    è·å–è®¢å•åˆ—è¡¨ï¼ˆæ”¯æŒåˆ†é¡µå’Œç­›é€‰ï¼‰
    """
    # æŒ‰é—¨åº—åŠ è½½æ•°æ®ï¼ˆåˆ©ç”¨ç¼“å­˜ï¼‰
    df = get_order_data(store_name)
    if df.empty:
        return {"success": True, "data": [], "total": 0, "page": page, "page_size": page_size, "total_pages": 0}
    
    # æ¸ é“ç­›é€‰
    if channel and 'æ¸ é“' in df.columns:
        df = df[df['æ¸ é“'] == channel]
    
    # æ—¥æœŸç­›é€‰
    if 'æ—¥æœŸ' in df.columns:
        df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'], errors='coerce')
        if start_date:
            df = df[df['æ—¥æœŸ'].dt.date >= start_date]
        if end_date:
            df = df[df['æ—¥æœŸ'].dt.date <= end_date]
    
    if df.empty:
        return {"success": True, "data": [], "total": 0, "page": page, "page_size": page_size, "total_pages": 0}
    
    # è®¡ç®—è®¢å•çº§æŒ‡æ ‡
    order_agg = calculate_order_metrics(df)
    
    # æ’åº
    sort_col_map = {
        'date': 'æ—¥æœŸ',
        'amount': 'å®æ”¶ä»·æ ¼',
        'profit': 'è®¢å•å®é™…åˆ©æ¶¦',
    }
    sort_col = sort_col_map.get(sort_by, 'æ—¥æœŸ')
    if sort_col in order_agg.columns:
        order_agg = order_agg.sort_values(sort_col, ascending=(sort_order == 'asc'))
    
    # åˆ†é¡µ
    total = len(order_agg)
    start = (page - 1) * page_size
    end = start + page_size
    page_data = order_agg.iloc[start:end]
    
    # é€‰æ‹©å±•ç¤ºå­—æ®µ
    result = []
    for _, row in page_data.iterrows():
        item = {
            "order_id": row.get('è®¢å•ID', ''),
            "order_date": str(row.get('æ—¥æœŸ', ''))[:10] if pd.notna(row.get('æ—¥æœŸ')) else '',
            "store_name": row.get('é—¨åº—åç§°', ''),
            "channel": row.get('æ¸ é“', ''),
            "amount": round(float(row.get('å®æ”¶ä»·æ ¼', 0)), 2),
            "profit": round(float(row.get('è®¢å•å®é™…åˆ©æ¶¦', 0)), 2),
            "profit_rate": round(float(row.get('è®¢å•å®é™…åˆ©æ¶¦', 0)) / float(row.get('å®æ”¶ä»·æ ¼', 1)) * 100, 2) if row.get('å®æ”¶ä»·æ ¼', 0) > 0 else 0,
        }
        result.append(item)
    
    return {
        "success": True,
        "data": result,
        "total": total,
        "page": page,
        "page_size": page_size,
        "total_pages": (total + page_size - 1) // page_size
    }


@router.get("/stores")
async def get_store_list() -> Dict[str, Any]:
    """è·å–é—¨åº—åˆ—è¡¨ï¼ˆç›´æ¥ä»æ•°æ®åº“æŸ¥è¯¢ï¼‰"""
    try:
        from database.connection import SessionLocal
        from database.models import Order
        from sqlalchemy import distinct
        
        session = SessionLocal()
        try:
            # ç›´æ¥æŸ¥è¯¢æ•°æ®åº“ä¸­çš„é—¨åº—åˆ—è¡¨
            stores = session.query(distinct(Order.store_name)).filter(
                Order.store_name.isnot(None)
            ).all()
            
            store_list = sorted([s[0] for s in stores if s[0]])
            print(f"âœ… é—¨åº—åˆ—è¡¨æŸ¥è¯¢æˆåŠŸ: {len(store_list)} ä¸ªé—¨åº—")
            return {"success": True, "data": store_list}
        finally:
            session.close()
    except Exception as e:
        print(f"âš ï¸ é—¨åº—åˆ—è¡¨æŸ¥è¯¢å¤±è´¥: {e}")
        # å¤‡ç”¨æ–¹æ¡ˆï¼šä»ç¼“å­˜æ•°æ®è·å–
        df = get_order_data()
        if df.empty or 'é—¨åº—åç§°' not in df.columns:
            return {"success": True, "data": []}
        
        stores = sorted(df['é—¨åº—åç§°'].dropna().unique().tolist())
        return {"success": True, "data": stores}


@router.get("/channel-list")
async def get_channel_list(
    store_name: Optional[str] = Query(None, description="é—¨åº—åç§°ç­›é€‰")
) -> Dict[str, Any]:
    """è·å–æ¸ é“åˆ—è¡¨ï¼ˆç›´æ¥ä»æ•°æ®åº“æŸ¥è¯¢ï¼Œæ”¯æŒé—¨åº—ç­›é€‰ï¼‰"""
    try:
        from database.connection import SessionLocal
        from database.models import Order
        from sqlalchemy import distinct
        
        session = SessionLocal()
        try:
            # æ„å»ºæŸ¥è¯¢
            query = session.query(distinct(Order.channel)).filter(
                Order.channel.isnot(None)
            )
            
            # å¦‚æœæŒ‡å®šäº†é—¨åº—ï¼Œåªè¿”å›è¯¥é—¨åº—çš„æ¸ é“
            if store_name:
                query = query.filter(Order.store_name == store_name)
            
            channels = query.all()
            
            channel_list = sorted([c[0] for c in channels if c[0]])
            print(f"âœ… æ¸ é“åˆ—è¡¨æŸ¥è¯¢æˆåŠŸ: {len(channel_list)} ä¸ªæ¸ é“, é—¨åº—: {store_name or 'å…¨éƒ¨'}")
            return {"success": True, "data": channel_list}
        finally:
            session.close()
    except Exception as e:
        print(f"âš ï¸ æ¸ é“åˆ—è¡¨æŸ¥è¯¢å¤±è´¥: {e}")
        # å¤‡ç”¨æ–¹æ¡ˆï¼šä»ç¼“å­˜æ•°æ®è·å–
        df = get_order_data(store_name)
        if df.empty or 'æ¸ é“' not in df.columns:
            return {"success": True, "data": []}
        
        channels = sorted(df['æ¸ é“'].dropna().unique().tolist())
        return {"success": True, "data": channels}


# [Phase 2] Migrated to orders_analysis.py


# [Phase 2] Migrated to orders_analysis.py


# [Phase 2] Migrated to orders_analysis.py


# [Phase 2] Migrated to orders_analysis.py


@router.get("/comparison")
async def get_order_comparison(
    store_name: Optional[str] = Query(None, description="é—¨åº—åç§°ç­›é€‰"),
    start_date: Optional[date] = Query(None, description="å¼€å§‹æ—¥æœŸ"),
    end_date: Optional[date] = Query(None, description="ç»“æŸæ—¥æœŸ")
) -> Dict[str, Any]:
    """
    è·å–è®¢å•ç¯æ¯”æ•°æ®ï¼ˆä¸è€ç‰ˆæœ¬å®Œå…¨ä¸€è‡´ï¼‰
    
    è®¡ç®—å½“å‰å‘¨æœŸä¸ä¸Šä¸€å‘¨æœŸçš„ç¯æ¯”å˜åŒ–:
    - è®¢å•æ•°ç¯æ¯”
    - é”€å”®é¢ç¯æ¯”
    - åˆ©æ¶¦ç¯æ¯”
    - å®¢å•ä»·ç¯æ¯”
    - åˆ©æ¶¦ç‡ç¯æ¯”ï¼ˆä½¿ç”¨å·®å€¼ï¼‰
    - åŠ¨é”€å•†å“æ•°ç¯æ¯”
    
    æ³¨æ„ï¼šå¦‚æœä¸ä¼ æ—¥æœŸå‚æ•°ï¼Œä½¿ç”¨æ•°æ®çš„å®Œæ•´æ—¥æœŸèŒƒå›´ä½œä¸ºå½“å‰å‘¨æœŸ
    """
    # æŒ‰é—¨åº—åŠ è½½æ•°æ®ï¼ˆåˆ©ç”¨ç¼“å­˜ï¼‰
    df = get_order_data(store_name)
    if df.empty:
        return {"success": True, "data": {"current": {}, "previous": {}, "changes": {}, "period": {}}}
    
    if 'æ—¥æœŸ' not in df.columns:
        return {"success": True, "data": {"current": {}, "previous": {}, "changes": {}, "period": {}}}
    
    df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'], errors='coerce')
    df = df.dropna(subset=['æ—¥æœŸ'])  # ç§»é™¤æ— æ•ˆæ—¥æœŸ
    
    if df.empty:
        return {"success": True, "data": {"current": {}, "previous": {}, "changes": {}, "period": {}}}
    
    # ç¡®å®šæ—¥æœŸèŒƒå›´
    min_date_in_data = df['æ—¥æœŸ'].min()
    max_date_in_data = df['æ—¥æœŸ'].max()
    
    if pd.isna(max_date_in_data) or pd.isna(min_date_in_data):
        return {"success": True, "data": {"current": {}, "previous": {}, "changes": {}, "period": {}}}
    
    # å¦‚æœä¸ä¼ æ—¥æœŸå‚æ•°ï¼Œä½¿ç”¨æ•°æ®çš„å®Œæ•´æ—¥æœŸèŒƒå›´ï¼ˆå…¨éƒ¨æ•°æ®ï¼‰
    if start_date is None and end_date is None:
        start_date = min_date_in_data.date()
        end_date = max_date_in_data.date()
    elif start_date is None:
        start_date = min_date_in_data.date()
    elif end_date is None:
        end_date = max_date_in_data.date()
    
    # è®¡ç®—å‘¨æœŸé•¿åº¦
    period_days = (end_date - start_date).days + 1
    if period_days <= 0:
        period_days = 1
    
    # è®¡ç®—ä¸Šä¸€å‘¨æœŸæ—¥æœŸèŒƒå›´
    prev_end_date = start_date - timedelta(days=1)
    prev_start_date = prev_end_date - timedelta(days=period_days - 1)
    
    # å½“å‰å‘¨æœŸæ•°æ®
    current_df = df[(df['æ—¥æœŸ'].dt.date >= start_date) & (df['æ—¥æœŸ'].dt.date <= end_date)]
    # ä¸Šä¸€å‘¨æœŸæ•°æ®
    prev_df = df[(df['æ—¥æœŸ'].dt.date >= prev_start_date) & (df['æ—¥æœŸ'].dt.date <= prev_end_date)]
    
    print(f"ğŸ“Š ç¯æ¯”è®¡ç®—: å½“å‰å‘¨æœŸ {start_date} ~ {end_date} ({len(current_df)}æ¡)")
    print(f"            ä¸Šä¸€å‘¨æœŸ {prev_start_date} ~ {prev_end_date} ({len(prev_df)}æ¡)")
    # è®¡ç®—å½“å‰å‘¨æœŸæŒ‡æ ‡
    current_metrics = calculate_period_metrics(current_df)
    # è®¡ç®—ä¸Šä¸€å‘¨æœŸæŒ‡æ ‡
    prev_metrics = calculate_period_metrics(prev_df)
    
    # è®¡ç®—ç¯æ¯”å˜åŒ–
    changes = {}
    for key in ['order_count', 'total_sales', 'total_profit', 'avg_order_value', 'active_products']:
        curr_val = current_metrics.get(key, 0)
        prev_val = prev_metrics.get(key, 0)
        if prev_val > 0:
            change_rate = round((curr_val - prev_val) / prev_val * 100, 2)
        elif curr_val > 0:
            change_rate = 100.0
        else:
            change_rate = 0.0
        changes[key] = change_rate
    
    # åˆ©æ¶¦ç‡ä½¿ç”¨å·®å€¼ï¼ˆä¸æ˜¯ç™¾åˆ†æ¯”å˜åŒ–ï¼‰
    changes['profit_rate'] = round(current_metrics.get('profit_rate', 0) - prev_metrics.get('profit_rate', 0), 2)
    
    return {
        "success": True,
        "data": {
            "current": current_metrics,
            "previous": prev_metrics,
            "changes": changes,
            "period": {
                "current_start": str(start_date),
                "current_end": str(end_date),
                "previous_start": str(prev_start_date),
                "previous_end": str(prev_end_date),
                "period_days": period_days
            }
        }
    }


def calculate_period_metrics(df: pd.DataFrame) -> Dict[str, Any]:
    """è®¡ç®—å•ä¸ªå‘¨æœŸçš„æŒ‡æ ‡"""
    if df.empty:
        return {
            "order_count": 0,
            "total_sales": 0,
            "total_profit": 0,
            "avg_order_value": 0,
            "profit_rate": 0,
            "active_products": 0
        }
    
    order_agg = calculate_order_metrics(df)
    
    order_count = len(order_agg)
    total_sales = order_agg['å®æ”¶ä»·æ ¼'].sum() if 'å®æ”¶ä»·æ ¼' in order_agg.columns else 0
    total_profit = order_agg['è®¢å•å®é™…åˆ©æ¶¦'].sum() if 'è®¢å•å®é™…åˆ©æ¶¦' in order_agg.columns else 0
    avg_order_value = total_sales / order_count if order_count > 0 else 0
    profit_rate = (total_profit / total_sales * 100) if total_sales > 0 else 0
    
    # åŠ¨é”€å•†å“æ•°
    sales_field = 'æœˆå”®' if 'æœˆå”®' in df.columns else 'é”€é‡'
    if 'å•†å“åç§°' in df.columns and sales_field in df.columns:
        active_products = df[df[sales_field] > 0]['å•†å“åç§°'].nunique()
    else:
        active_products = df['å•†å“åç§°'].nunique() if 'å•†å“åç§°' in df.columns else 0
    
    return {
        "order_count": int(order_count),
        "total_sales": round(float(total_sales), 2),
        "total_profit": round(float(total_profit), 2),
        "avg_order_value": round(float(avg_order_value), 2),
        "profit_rate": round(float(profit_rate), 2),
        "active_products": int(active_products)
    }


@router.get("/channel-comparison")
async def get_channel_comparison(
    store_name: Optional[str] = Query(None, description="é—¨åº—åç§°ç­›é€‰"),
    start_date: Optional[date] = Query(None, description="å¼€å§‹æ—¥æœŸ"),
    end_date: Optional[date] = Query(None, description="ç»“æŸæ—¥æœŸ")
) -> Dict[str, Any]:
    """
    è·å–æ¸ é“ç¯æ¯”å¯¹æ¯”æ•°æ®ï¼ˆä¸è€ç‰ˆæœ¬å®Œå…¨ä¸€è‡´ï¼‰
    
    æ¯ä¸ªæ¸ é“åŒ…å«:
    - è®¢å•æ•° + ç¯æ¯”
    - é”€å”®é¢ + ç¯æ¯”
    - åˆ©æ¶¦é¢ + ç¯æ¯”
    - å®¢å•ä»· + ç¯æ¯”
    - åˆ©æ¶¦ç‡ + ç¯æ¯”
    
    æ³¨æ„ï¼šæ’é™¤å’–å•¡æ¸ é“ï¼ˆç¾å›¢å’–å•¡åº—ã€é¥¿äº†ä¹ˆå’–å•¡åº—ï¼‰
    
    æ—¥æœŸé€»è¾‘ï¼š
    - å¦‚æœä¼ äº†æ—¥æœŸèŒƒå›´ï¼Œä½¿ç”¨ä¼ å…¥çš„æ—¥æœŸèŒƒå›´
    - å¦‚æœæ²¡ä¼ æ—¥æœŸèŒƒå›´ï¼Œä½¿ç”¨æ•°æ®çš„å®Œæ•´æ—¥æœŸèŒƒå›´
    - ç¯æ¯”è®¡ç®—ï¼šå½“å‰å‘¨æœŸ vs ä¸Šä¸€ä¸ªç›¸åŒé•¿åº¦çš„å‘¨æœŸ
    """
    # æŒ‰é—¨åº—åŠ è½½æ•°æ®ï¼ˆåˆ©ç”¨ç¼“å­˜ï¼‰
    df = get_order_data(store_name)
    if df.empty:
        return {"success": True, "data": []}
    
    if 'æ—¥æœŸ' not in df.columns or 'æ¸ é“' not in df.columns:
        return {"success": True, "data": []}
    
    df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'], errors='coerce')
    df = df.dropna(subset=['æ—¥æœŸ'])
    
    if df.empty:
        return {"success": True, "data": []}
    
    # æ’é™¤å’–å•¡æ¸ é“ï¼ˆä¸è€ç‰ˆæœ¬ä¸€è‡´ï¼‰
    CHANNELS_TO_REMOVE = ['ç¾å›¢å’–å•¡åº—', 'é¥¿äº†ä¹ˆå’–å•¡åº—']
    df = df[~df['æ¸ é“'].isin(CHANNELS_TO_REMOVE)]
    
    if df.empty:
        return {"success": True, "data": []}
    
    # ç¡®å®šæ—¥æœŸèŒƒå›´
    min_date = df['æ—¥æœŸ'].min()
    max_date = df['æ—¥æœŸ'].max()
    if pd.isna(max_date) or pd.isna(min_date):
        return {"success": True, "data": []}
    
    # åˆ¤æ–­æ˜¯å¦ä½¿ç”¨å…¨éƒ¨æ•°æ®ï¼ˆæ²¡æœ‰ä¼ æ—¥æœŸå‚æ•°ï¼‰
    use_full_data = (start_date is None and end_date is None)
    
    # å¦‚æœæ²¡æœ‰ä¼ æ—¥æœŸå‚æ•°ï¼Œä½¿ç”¨æ•°æ®çš„å®Œæ•´æ—¥æœŸèŒƒå›´
    if start_date is None and end_date is None:
        start_date = min_date.date()
        end_date = max_date.date()
    elif start_date is None:
        start_date = min_date.date()
    elif end_date is None:
        end_date = max_date.date()
    
    period_days = (end_date - start_date).days + 1
    if period_days <= 0:
        period_days = 1
    
    # è®¡ç®—ä¸Šä¸€å‘¨æœŸï¼ˆç”¨äºç¯æ¯”ï¼‰
    prev_end_date = start_date - timedelta(days=1)
    prev_start_date = prev_end_date - timedelta(days=period_days - 1)
    
    # å½“å‰å‘¨æœŸæ•°æ®
    current_df = df[(df['æ—¥æœŸ'].dt.date >= start_date) & (df['æ—¥æœŸ'].dt.date <= end_date)]
    # ä¸Šä¸€å‘¨æœŸæ•°æ®ï¼ˆç”¨äºç¯æ¯”ï¼‰
    prev_df = df[(df['æ—¥æœŸ'].dt.date >= prev_start_date) & (df['æ—¥æœŸ'].dt.date <= prev_end_date)]
    
    # å¦‚æœä½¿ç”¨å…¨éƒ¨æ•°æ®æˆ–ä¸Šä¸€å‘¨æœŸæ²¡æœ‰æ•°æ®ï¼Œåˆ™ä¸è®¡ç®—ç¯æ¯”
    has_prev_data = len(prev_df) > 0 and not use_full_data
    
    # è·å–å½“å‰å‘¨æœŸçš„æ‰€æœ‰æ¸ é“
    channels = current_df['æ¸ é“'].dropna().unique().tolist()
    
    result = []
    for channel in channels:
        # å½“å‰å‘¨æœŸæ¸ é“æ•°æ®
        curr_ch = current_df[current_df['æ¸ é“'] == channel]
        curr_metrics = calculate_channel_metrics(curr_ch)
        
        # å¦‚æœæœ‰ä¸Šä¸€å‘¨æœŸæ•°æ®ï¼Œè®¡ç®—ç¯æ¯”
        if has_prev_data:
            # ä¸Šä¸€å‘¨æœŸæ¸ é“æ•°æ®
            prev_ch = prev_df[prev_df['æ¸ é“'] == channel]
            prev_metrics = calculate_channel_metrics(prev_ch)
            
            # è®¡ç®—ç¯æ¯”
            changes = {}
            for key in ['order_count', 'amount', 'profit', 'avg_value']:
                curr_val = curr_metrics.get(key, 0)
                prev_val = prev_metrics.get(key, 0)
                if prev_val > 0:
                    changes[key] = round((curr_val - prev_val) / prev_val * 100, 2)
                elif curr_val > 0:
                    changes[key] = 100.0
                else:
                    changes[key] = 0.0
            
            # åˆ©æ¶¦ç‡ç”¨å·®å€¼
            changes['profit_rate'] = round(curr_metrics.get('profit_rate', 0) - prev_metrics.get('profit_rate', 0), 2)
        else:
            # æ²¡æœ‰ä¸Šä¸€å‘¨æœŸæ•°æ®ï¼Œç¯æ¯”æ˜¾ç¤ºä¸ºnull
            prev_metrics = {"order_count": 0, "amount": 0, "profit": 0, "avg_value": 0, "profit_rate": 0}
            changes = {"order_count": None, "amount": None, "profit": None, "avg_value": None, "profit_rate": None}
        
        # è¯„çº§ï¼ˆåŸºäºå½“å‰æ•°æ®ï¼‰
        rating = get_channel_rating(curr_metrics, changes if has_prev_data else {})
        
        result.append({
            "channel": channel,
            "current": curr_metrics,
            "previous": prev_metrics if has_prev_data else None,
            "changes": changes,
            "rating": rating
        })
    
    # æŒ‰è®¢å•æ•°æ’åº
    result.sort(key=lambda x: x['current'].get('order_count', 0), reverse=True)
    
    return {"success": True, "data": result}


def calculate_channel_metrics(df: pd.DataFrame) -> Dict[str, Any]:
    """
    è®¡ç®—å•ä¸ªæ¸ é“çš„å®Œæ•´æŒ‡æ ‡ï¼ˆåŒ…å«æˆæœ¬ç»“æ„ï¼‰
    
    ä¸è€ç‰ˆæœ¬Dashå®Œå…¨ä¸€è‡´çš„æŒ‡æ ‡:
    - åŸºç¡€æŒ‡æ ‡: è®¢å•æ•°ã€é”€å”®é¢ã€åˆ©æ¶¦ã€å®¢å•ä»·ã€åˆ©æ¶¦ç‡
    - æˆæœ¬ç»“æ„: å•†å“æˆæœ¬ã€è€—ææˆæœ¬ã€å•†å“å‡å…ã€æ´»åŠ¨è¡¥è´´ã€é…é€æˆæœ¬ã€å¹³å°æœåŠ¡è´¹
    - å•å‡ç»æµ: å•å‡åˆ©æ¶¦ã€å•å‡è¥é”€ã€å•å‡é…é€
    """
    if df.empty:
        return {
            "order_count": 0,
            "amount": 0,
            "profit": 0,
            "avg_value": 0,
            "profit_rate": 0,
            # æˆæœ¬ç»“æ„
            "product_cost": 0,
            "product_cost_rate": 0,
            "consumable_cost": 0,
            "consumable_cost_rate": 0,
            "product_discount": 0,
            "product_discount_rate": 0,
            "activity_subsidy": 0,
            "activity_subsidy_rate": 0,
            "delivery_cost": 0,
            "delivery_cost_rate": 0,
            "platform_fee": 0,
            "platform_fee_rate": 0,
            "total_cost_rate": 0,
            # å•å‡ç»æµ
            "avg_profit_per_order": 0,
            "avg_marketing_per_order": 0,
            "avg_delivery_per_order": 0,
        }
    
    order_agg = calculate_order_metrics(df)
    
    order_count = len(order_agg)
    amount = order_agg['å®æ”¶ä»·æ ¼'].sum() if 'å®æ”¶ä»·æ ¼' in order_agg.columns else 0
    profit = order_agg['è®¢å•å®é™…åˆ©æ¶¦'].sum() if 'è®¢å•å®é™…åˆ©æ¶¦' in order_agg.columns else 0
    avg_value = amount / order_count if order_count > 0 else 0
    profit_rate = (profit / amount * 100) if amount > 0 else 0
    
    # æˆæœ¬ç»“æ„è®¡ç®—
    # å•†å“æˆæœ¬ï¼ˆä»åŸå§‹dfè®¡ç®—ï¼Œå› ä¸ºæ˜¯å•†å“çº§å­—æ®µï¼‰
    product_cost = 0
    if 'å•†å“é‡‡è´­æˆæœ¬' in df.columns:
        product_cost = df['å•†å“é‡‡è´­æˆæœ¬'].sum()
    
    # è€—ææˆæœ¬ï¼ˆä¸€çº§åˆ†ç±»ä¸º"è€—æ"çš„å•†å“æˆæœ¬ï¼‰
    consumable_cost = 0
    if 'ä¸€çº§åˆ†ç±»å' in df.columns and 'å•†å“é‡‡è´­æˆæœ¬' in df.columns:
        consumable_mask = df['ä¸€çº§åˆ†ç±»å'] == 'è€—æ'
        consumable_cost = df.loc[consumable_mask, 'å•†å“é‡‡è´­æˆæœ¬'].sum()
        # ä»å•†å“æˆæœ¬ä¸­æ‰£é™¤è€—ææˆæœ¬
        product_cost = product_cost - consumable_cost
    
    # å•†å“å‡å…é‡‘é¢ï¼ˆè®¢å•çº§å­—æ®µï¼Œä»order_aggè®¡ç®—ï¼‰
    product_discount = 0
    if 'å•†å“å‡å…é‡‘é¢' in order_agg.columns:
        product_discount = order_agg['å•†å“å‡å…é‡‘é¢'].sum()
    
    # è¥é”€æˆæœ¬ï¼ˆ7ä¸ªè¥é”€å­—æ®µï¼Œå¯¹é½Dashç‰ˆæœ¬ï¼Œå‰”é™¤é…é€è´¹å‡å…é‡‘é¢ï¼‰
    # é…é€è´¹å‡å…é‡‘é¢å±äºé…é€æˆæœ¬ï¼Œä¸å±äºè¥é”€æˆæœ¬
    marketing_cost = 0
    marketing_fields = ['æ»¡å‡é‡‘é¢', 'å•†å“å‡å…é‡‘é¢', 'å•†å®¶ä»£é‡‘åˆ¸', 
                       'å•†å®¶æ‰¿æ‹…éƒ¨åˆ†åˆ¸', 'æ»¡èµ é‡‘é¢', 'å•†å®¶å…¶ä»–ä¼˜æƒ ', 'æ–°å®¢å‡å…é‡‘é¢']
    
    # è°ƒè¯•ï¼šæ‰“å°å„å­—æ®µçš„å€¼
    print(f"\n[DEBUG] è¥é”€æˆæœ¬è®¡ç®— - è®¢å•æ•°: {order_count}")
    for field in marketing_fields:
        if field in order_agg.columns:
            field_sum = order_agg[field].fillna(0).sum()
            marketing_cost += field_sum
            print(f"[DEBUG]   {field}: Â¥{field_sum:.2f}")
        else:
            print(f"[DEBUG]   {field}: å­—æ®µä¸å­˜åœ¨")
    print(f"[DEBUG] è¥é”€æˆæœ¬æ€»è®¡: Â¥{marketing_cost:.2f}")
    
    # æ´»åŠ¨è¡¥è´´ = è¥é”€æˆæœ¬ - å•†å“å‡å…
    activity_subsidy = max(0, marketing_cost - product_discount)
    
    # é…é€å‡€æˆæœ¬ = ç‰©æµé…é€è´¹ - ç”¨æˆ·æ”¯ä»˜é…é€è´¹ + é…é€è´¹å‡å…é‡‘é¢
    delivery_cost = 0
    if 'ç‰©æµé…é€è´¹' in order_agg.columns:
        delivery_cost = order_agg['ç‰©æµé…é€è´¹'].sum()
    if 'ç”¨æˆ·æ”¯ä»˜é…é€è´¹' in order_agg.columns:
        delivery_cost -= order_agg['ç”¨æˆ·æ”¯ä»˜é…é€è´¹'].sum()
    if 'é…é€è´¹å‡å…é‡‘é¢' in order_agg.columns:
        delivery_cost += order_agg['é…é€è´¹å‡å…é‡‘é¢'].sum()
    
    # å¹³å°æœåŠ¡è´¹
    platform_fee = 0
    if 'å¹³å°æœåŠ¡è´¹' in order_agg.columns:
        platform_fee = order_agg['å¹³å°æœåŠ¡è´¹'].sum()
    
    # è®¡ç®—æˆæœ¬ç‡
    product_cost_rate = (product_cost / amount * 100) if amount > 0 else 0
    consumable_cost_rate = (consumable_cost / amount * 100) if amount > 0 else 0
    product_discount_rate = (product_discount / amount * 100) if amount > 0 else 0
    activity_subsidy_rate = (activity_subsidy / amount * 100) if amount > 0 else 0
    delivery_cost_rate = (delivery_cost / amount * 100) if amount > 0 else 0
    platform_fee_rate = (platform_fee / amount * 100) if amount > 0 else 0
    
    # æ€»æˆæœ¬ç‡
    total_cost_rate = product_cost_rate + consumable_cost_rate + product_discount_rate + activity_subsidy_rate + delivery_cost_rate + platform_fee_rate
    
    # å•å‡ç»æµ
    avg_profit_per_order = profit / order_count if order_count > 0 else 0
    avg_marketing_per_order = marketing_cost / order_count if order_count > 0 else 0
    avg_delivery_per_order = delivery_cost / order_count if order_count > 0 else 0
    
    return {
        "order_count": int(order_count),
        "amount": round(float(amount), 2),
        "profit": round(float(profit), 2),
        "avg_value": round(float(avg_value), 2),
        "profit_rate": round(float(profit_rate), 2),
        # æˆæœ¬ç»“æ„
        "product_cost": round(float(product_cost), 2),
        "product_cost_rate": round(float(product_cost_rate), 2),
        "consumable_cost": round(float(consumable_cost), 2),
        "consumable_cost_rate": round(float(consumable_cost_rate), 2),
        "product_discount": round(float(product_discount), 2),
        "product_discount_rate": round(float(product_discount_rate), 2),
        "activity_subsidy": round(float(activity_subsidy), 2),
        "activity_subsidy_rate": round(float(activity_subsidy_rate), 2),
        "delivery_cost": round(float(delivery_cost), 2),
        "delivery_cost_rate": round(float(delivery_cost_rate), 2),
        "platform_fee": round(float(platform_fee), 2),
        "platform_fee_rate": round(float(platform_fee_rate), 2),
        "total_cost_rate": round(float(total_cost_rate), 2),
        # å•å‡ç»æµ
        "avg_profit_per_order": round(float(avg_profit_per_order), 2),
        "avg_marketing_per_order": round(float(avg_marketing_per_order), 2),
        "avg_delivery_per_order": round(float(avg_delivery_per_order), 2),
    }


def get_channel_rating(metrics: Dict, changes: Dict) -> str:
    """æ ¹æ®æŒ‡æ ‡å’Œç¯æ¯”è·å–æ¸ é“è¯„çº§"""
    profit_rate = metrics.get('profit_rate', 0)
    profit_change = changes.get('profit', 0)
    amount_change = changes.get('amount', 0)
    
    # ä¼˜ç§€: åˆ©æ¶¦ç‡>15% ä¸” (é”€å”®é¢ç¯æ¯”>0 æˆ– åˆ©æ¶¦ç¯æ¯”>0)
    if profit_rate > 15 and (amount_change > 0 or profit_change > 0):
        return "ä¼˜ç§€"
    # è‰¯å¥½: åˆ©æ¶¦ç‡>10% ä¸” é”€å”®é¢ç¯æ¯”>-10%
    elif profit_rate > 10 and amount_change > -10:
        return "è‰¯å¥½"
    # éœ€æ”¹è¿›
    else:
        return "éœ€æ”¹è¿›"


# [Phase 2] Migrated to orders_analysis.py


# ==================== å¯¼å‡ºåŠŸèƒ½ ====================

from fastapi.responses import StreamingResponse
import io

@router.get("/export")
async def export_orders(
    store_name: Optional[str] = Query(None, description="é—¨åº—åç§°ç­›é€‰"),
    start_date: Optional[date] = Query(None, description="å¼€å§‹æ—¥æœŸ"),
    end_date: Optional[date] = Query(None, description="ç»“æŸæ—¥æœŸ")
):
    """
    å¯¼å‡ºè®¢å•æ•°æ®åˆ°Excel
    
    ä¸è€ç‰ˆæœ¬å¯¼å‡ºåŠŸèƒ½ä¸€è‡´ï¼ŒåŒ…å«:
    - è®¢å•ID
    - æ—¥æœŸ
    - é—¨åº—åç§°
    - æ¸ é“
    - å®æ”¶ä»·æ ¼
    - è®¢å•å®é™…åˆ©æ¶¦
    - åˆ©æ¶¦ç‡
    """
    # æŒ‰é—¨åº—åŠ è½½æ•°æ®ï¼ˆåˆ©ç”¨ç¼“å­˜ï¼‰
    df = get_order_data(store_name)
    
    if df.empty:
        # è¿”å›ç©ºExcel
        output = io.BytesIO()
        pd.DataFrame().to_excel(output, index=False, engine='openpyxl')
        output.seek(0)
        return StreamingResponse(
            output,
            media_type="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            headers={"Content-Disposition": "attachment; filename=è®¢å•æ•°æ®_ç©º.xlsx"}
        )
    
    # æ—¥æœŸç­›é€‰
    if 'æ—¥æœŸ' in df.columns:
        df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'], errors='coerce')
        if start_date:
            df = df[df['æ—¥æœŸ'].dt.date >= start_date]
        if end_date:
            df = df[df['æ—¥æœŸ'].dt.date <= end_date]
    
    if df.empty:
        output = io.BytesIO()
        pd.DataFrame().to_excel(output, index=False, engine='openpyxl')
        output.seek(0)
        return StreamingResponse(
            output,
            media_type="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            headers={"Content-Disposition": "attachment; filename=è®¢å•æ•°æ®_ç©º.xlsx"}
        )
    
    # è®¡ç®—è®¢å•çº§æŒ‡æ ‡
    order_agg = calculate_order_metrics(df)
    
    # è®¡ç®—åˆ©æ¶¦ç‡
    order_agg['åˆ©æ¶¦ç‡'] = order_agg.apply(
        lambda r: round(r['è®¢å•å®é™…åˆ©æ¶¦'] / r['å®æ”¶ä»·æ ¼'] * 100, 2) if r.get('å®æ”¶ä»·æ ¼', 0) > 0 else 0, 
        axis=1
    )
    
    # é€‰æ‹©å¯¼å‡ºå­—æ®µ
    export_cols = ['è®¢å•ID', 'æ—¥æœŸ', 'é—¨åº—åç§°', 'æ¸ é“', 'å®æ”¶ä»·æ ¼', 'è®¢å•å®é™…åˆ©æ¶¦', 'åˆ©æ¶¦ç‡']
    available_cols = [c for c in export_cols if c in order_agg.columns]
    export_df = order_agg[available_cols].copy()
    
    # æ ¼å¼åŒ–æ—¥æœŸ
    if 'æ—¥æœŸ' in export_df.columns:
        export_df['æ—¥æœŸ'] = pd.to_datetime(export_df['æ—¥æœŸ']).dt.strftime('%Y-%m-%d')
    
    # é‡å‘½ååˆ—ï¼ˆæ›´å‹å¥½çš„æ˜¾ç¤ºåï¼‰
    column_rename = {
        'è®¢å•ID': 'è®¢å•ç¼–å·',
        'æ—¥æœŸ': 'è®¢å•æ—¥æœŸ',
        'é—¨åº—åç§°': 'é—¨åº—',
        'æ¸ é“': 'é”€å”®æ¸ é“',
        'å®æ”¶ä»·æ ¼': 'è®¢å•é‡‘é¢(å…ƒ)',
        'è®¢å•å®é™…åˆ©æ¶¦': 'åˆ©æ¶¦(å…ƒ)',
        'åˆ©æ¶¦ç‡': 'åˆ©æ¶¦ç‡(%)'
    }
    export_df = export_df.rename(columns={k: v for k, v in column_rename.items() if k in export_df.columns})
    
    # ç”ŸæˆExcel
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        export_df.to_excel(writer, index=False, sheet_name='è®¢å•æ•°æ®')
        
        # è°ƒæ•´åˆ—å®½
        worksheet = writer.sheets['è®¢å•æ•°æ®']
        for idx, col in enumerate(export_df.columns):
            max_length = max(
                export_df[col].astype(str).map(len).max() if len(export_df) > 0 else 0,
                len(col)
            ) + 2
            worksheet.column_dimensions[chr(65 + idx)].width = min(max_length, 30)
    
    output.seek(0)
    
    # ç”Ÿæˆæ–‡ä»¶å
    filename = f"è®¢å•ç»è¥åˆ†ææŠ¥å‘Š_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx"
    
    return StreamingResponse(
        output,
        media_type="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        headers={"Content-Disposition": f"attachment; filename*=UTF-8''{filename}"}
    )



@router.get("/date-range")
async def get_date_range(
    store_name: Optional[str] = Query(None, description="é—¨åº—åç§°ç­›é€‰")
) -> Dict[str, Any]:
    """
    è·å–é—¨åº—æ•°æ®çš„æ—¥æœŸèŒƒå›´
    
    ç”¨äºå‰ç«¯æ—¥å†é€‰æ‹©å™¨é™åˆ¶å¯é€‰æ—¥æœŸèŒƒå›´
    """
    # æŒ‰é—¨åº—åŠ è½½æ•°æ®ï¼ˆåˆ©ç”¨ç¼“å­˜ï¼‰
    df = get_order_data(store_name)
    if df.empty:
        return {
            "success": True,
            "data": {
                "min_date": None,
                "max_date": None,
                "total_days": 0
            }
        }
    
    if 'æ—¥æœŸ' not in df.columns:
        return {
            "success": True,
            "data": {
                "min_date": None,
                "max_date": None,
                "total_days": 0
            }
        }
    
    df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'], errors='coerce')
    df = df.dropna(subset=['æ—¥æœŸ'])
    
    if df.empty:
        return {
            "success": True,
            "data": {
                "min_date": None,
                "max_date": None,
                "total_days": 0
            }
        }
    
    min_date = df['æ—¥æœŸ'].min()
    max_date = df['æ—¥æœŸ'].max()
    total_days = (max_date - min_date).days + 1
    
    return {
        "success": True,
        "data": {
            "min_date": min_date.strftime('%Y-%m-%d'),
            "max_date": max_date.strftime('%Y-%m-%d'),
            "total_days": total_days
        }
    }


# ==================== å›¾è¡¨è”åŠ¨APIï¼ˆé”€å”®è¶‹åŠ¿ä¸‹é’»ï¼‰ ====================

# [Phase 2] Migrated to orders_analysis.py


# [Phase 2] Migrated to orders_analysis.py


# ==================== åˆ†æ—¶åˆ©æ¶¦åˆ†æ API ====================

# [Phase 3] Migrated to orders_delivery.py


# [Phase 3] Migrated to orders_delivery.py


# ==================== æˆæœ¬ç»“æ„åˆ†æAPIï¼ˆèµ„é‡‘æµå‘å…¨æ™¯æ¡‘åŸºå›¾ä¸“ç”¨ï¼‰ ====================

# [Phase 3] Migrated to orders_delivery.py
# [Phase 3] Migrated to orders_delivery.py
# [Phase 3] Migrated to orders_delivery.py


# [Phase 3] Migrated to orders_delivery.py


# [Phase 3] Migrated to orders_delivery.py


# ==================== é…é€æº¢ä»·é›·è¾¾æ•°æ® API ====================

# [Phase 3] Migrated to orders_delivery.py

