# -*- coding: utf-8 -*-
"""
è®¢å•æ•°æ®æ¦‚è§ˆ API

å®Œå…¨å¯¹é½è€ç‰ˆæœ¬Dashçš„Tab1è®¢å•æ•°æ®æ¦‚è§ˆåŠŸèƒ½ï¼š
- å…­å¤§æ ¸å¿ƒå¡ç‰‡æŒ‡æ ‡
- æ¸ é“è¡¨ç°å¯¹æ¯”
- å®¢å•ä»·åŒºé—´åˆ†å¸ƒ
- ä¸€çº§åˆ†ç±»é”€å”®è¶‹åŠ¿
- è®¢å•è¶‹åŠ¿åˆ†æ
- ç¯æ¯”è®¡ç®—
- å¼‚å¸¸è¯Šæ–­

ä¸šåŠ¡é€»è¾‘æ¥æº: æ™ºèƒ½é—¨åº—çœ‹æ¿_Dashç‰ˆ.py ä¸­çš„ Tab 1 å›è°ƒ
"""

from fastapi import APIRouter, Depends, Query, HTTPException
from typing import Optional, List, Dict, Any
from datetime import date, datetime, timedelta
import pandas as pd
import numpy as np
import hashlib
import json
import time

import sys
from pathlib import Path
APP_DIR = Path(__file__).resolve().parent.parent.parent
PROJECT_ROOT = APP_DIR.parent.parent
if str(APP_DIR) not in sys.path:
    sys.path.insert(0, str(APP_DIR))
if str(PROJECT_ROOT) not in sys.path:
    sys.path.insert(0, str(PROJECT_ROOT))

from database.connection import SessionLocal
from database.models import Order

# å°è¯•å¯¼å…¥Redisç¼“å­˜
try:
    import redis
    REDIS_AVAILABLE = True
    redis_client = redis.Redis(host='localhost', port=6379, db=0, decode_responses=True)
    # æµ‹è¯•è¿æ¥
    redis_client.ping()
    print("âœ… Redisç¼“å­˜å·²è¿æ¥")
except Exception as e:
    REDIS_AVAILABLE = False
    redis_client = None
    print(f"âš ï¸ Redisç¼“å­˜ä¸å¯ç”¨: {e}")

router = APIRouter()

# ==================== ç¼“å­˜é…ç½® ====================
# âœ… ä¼˜åŒ–ï¼šå»¶é•¿TTLåˆ°24å°æ—¶ï¼ˆæ•°æ®æ¯å¤©æ›´æ–°ä¸€æ¬¡ï¼‰
CACHE_TTL = 86400  # ç¼“å­˜æœ‰æ•ˆæœŸ24å°æ—¶
ORDER_DATA_CACHE_KEY = "order_data_cache"
ORDER_DATA_TIMESTAMP_KEY = "order_data_timestamp"
DATA_VERSION_KEY = "order_data_version"  # æ•°æ®ç‰ˆæœ¬å·ï¼ˆç”¨äºæ™ºèƒ½å¤±æ•ˆï¼‰

# å†…å­˜ç¼“å­˜ï¼ˆå¤‡ç”¨ï¼‰
_memory_cache = {
    "order_data": None,
    "timestamp": 0,
    "store_cache": {},  # æŒ‰é—¨åº—ç¼“å­˜: {store_name: {data: df, timestamp: time}}
    "data_version": None  # æ•°æ®ç‰ˆæœ¬å·
}


def get_data_version(store_name: str = None) -> str:
    """
    è·å–æ•°æ®ç‰ˆæœ¬å·ï¼ˆåŸºäºæ•°æ®åº“æœ€åæ›´æ–°æ—¶é—´ï¼‰
    
    ç‰ˆæœ¬å· = é—¨åº—æœ€æ–°è®¢å•çš„updated_atæ—¶é—´æˆ³
    å½“æ•°æ®æœ‰æ›´æ–°æ—¶ï¼Œç‰ˆæœ¬å·ä¼šå˜åŒ–ï¼Œè§¦å‘ç¼“å­˜å¤±æ•ˆ
    """
    session = SessionLocal()
    try:
        from sqlalchemy import func
        query = session.query(func.max(Order.updated_at))
        if store_name:
            query = query.filter(Order.store_name == store_name)
        
        last_updated = query.scalar()
        if last_updated:
            return last_updated.strftime("%Y%m%d%H%M%S")
        return "0"
    except Exception as e:
        print(f"âš ï¸ è·å–æ•°æ®ç‰ˆæœ¬å¤±è´¥: {e}")
        return "0"
    finally:
        session.close()


def check_cache_valid(store_name: str = None) -> bool:
    """
    æ£€æŸ¥ç¼“å­˜æ˜¯å¦æœ‰æ•ˆï¼ˆåŸºäºæ•°æ®ç‰ˆæœ¬å·ï¼‰
    
    è¿”å› True è¡¨ç¤ºç¼“å­˜æœ‰æ•ˆï¼Œå¯ä»¥ä½¿ç”¨
    è¿”å› False è¡¨ç¤ºæ•°æ®å·²æ›´æ–°ï¼Œéœ€è¦é‡æ–°åŠ è½½
    """
    if not REDIS_AVAILABLE or not redis_client:
        return False
    
    try:
        version_key = f"{DATA_VERSION_KEY}:{store_name}" if store_name else DATA_VERSION_KEY
        cached_version = redis_client.get(version_key)
        current_version = get_data_version(store_name)
        
        if cached_version and cached_version == current_version:
            return True
        return False
    except Exception as e:
        print(f"âš ï¸ æ£€æŸ¥ç¼“å­˜ç‰ˆæœ¬å¤±è´¥: {e}")
        return False

# ==================== æ”¶è´¹æ¸ é“åˆ—è¡¨ï¼ˆä¸è€ç‰ˆæœ¬ä¸€è‡´ï¼‰====================
PLATFORM_FEE_CHANNELS = [
    'é¥¿äº†ä¹ˆ',
    'äº¬ä¸œåˆ°å®¶',
    'ç¾å›¢å…±æ©™',
    'ç¾å›¢é—ªè´­',
    'æŠ–éŸ³',
    'æŠ–éŸ³ç›´æ’­',
    'æ·˜é²œè¾¾',
    'äº¬ä¸œç§’é€',
    'ç¾å›¢å’–å•¡åº—',
    'é¥¿äº†ä¹ˆå’–å•¡åº—'
]


def get_order_data(store_name: str = None) -> pd.DataFrame:
    """
    ä»æ•°æ®åº“åŠ è½½è®¢å•æ•°æ®ï¼ˆå¸¦æ™ºèƒ½ç¼“å­˜ï¼‰
    
    ç¼“å­˜ç­–ç•¥ï¼ˆä¼˜åŒ–ç‰ˆï¼‰:
    1. ä¼˜å…ˆæ£€æŸ¥Redisç¼“å­˜ + æ•°æ®ç‰ˆæœ¬å·
    2. ç‰ˆæœ¬å·åŒ¹é…åˆ™ç›´æ¥ä½¿ç”¨ç¼“å­˜ï¼ˆå³ä½¿åç«¯é‡å¯ï¼‰
    3. ç‰ˆæœ¬å·ä¸åŒ¹é…åˆ™é‡æ–°åŠ è½½ï¼ˆæ•°æ®æœ‰æ›´æ–°ï¼‰
    4. ç¼“å­˜æœ‰æ•ˆæœŸ24å°æ—¶ï¼ˆæ•°æ®æ¯å¤©æ›´æ–°ä¸€æ¬¡ï¼‰
    
    Args:
        store_name: é—¨åº—åç§°ï¼Œå¦‚æœæŒ‡å®šåˆ™åªåŠ è½½è¯¥é—¨åº—æ•°æ®
    """
    global _memory_cache
    current_time = time.time()
    
    # ç”Ÿæˆç¼“å­˜key
    cache_key = f"order_data:{store_name}" if store_name else "order_data:all"
    redis_cache_key = f"{ORDER_DATA_CACHE_KEY}:{store_name}" if store_name else ORDER_DATA_CACHE_KEY
    redis_timestamp_key = f"{ORDER_DATA_TIMESTAMP_KEY}:{store_name}" if store_name else ORDER_DATA_TIMESTAMP_KEY
    version_key = f"{DATA_VERSION_KEY}:{store_name}" if store_name else DATA_VERSION_KEY
    
    # è·å–å½“å‰æ•°æ®ç‰ˆæœ¬
    current_version = get_data_version(store_name)
    
    # 1. å°è¯•ä»Redisè·å–ç¼“å­˜ï¼ˆæ™ºèƒ½ç‰ˆæœ¬æ£€æŸ¥ï¼‰
    if REDIS_AVAILABLE and redis_client:
        try:
            cached_version = redis_client.get(version_key)
            cached_timestamp = redis_client.get(redis_timestamp_key)
            
            # ç‰ˆæœ¬å·åŒ¹é… + æœªè¿‡æœŸ = ç¼“å­˜æœ‰æ•ˆ
            if cached_version and cached_version == current_version:
                if cached_timestamp and (current_time - float(cached_timestamp) < CACHE_TTL):
                    cached_data = redis_client.get(redis_cache_key)
                    if cached_data:
                        data = json.loads(cached_data)
                        print(f"ğŸ“¦ ä½¿ç”¨Redisç¼“å­˜æ•°æ® (é—¨åº—: {store_name or 'å…¨éƒ¨'}, {len(data)} æ¡)")
                        return pd.DataFrame(data)
        except Exception as e:
            print(f"âš ï¸ Redisè¯»å–å¤±è´¥: {e}")
    
    # 2. å°è¯•ä½¿ç”¨å†…å­˜ç¼“å­˜ï¼ˆåŒæ ·æ£€æŸ¥ç‰ˆæœ¬ï¼‰
    cached_version = _memory_cache.get("data_version")
    if cached_version == current_version:
        if store_name:
            store_cache = _memory_cache.get("store_cache", {}).get(store_name)
            if store_cache and current_time - store_cache.get("timestamp", 0) < CACHE_TTL:
                print(f"ğŸ“¦ ä½¿ç”¨å†…å­˜ç¼“å­˜æ•°æ® (é—¨åº—: {store_name})")
                return store_cache["data"].copy()
        else:
            if _memory_cache["order_data"] is not None:
                if current_time - _memory_cache["timestamp"] < CACHE_TTL:
                    print(f"ğŸ“¦ ä½¿ç”¨å†…å­˜ç¼“å­˜æ•°æ® (å…¨éƒ¨é—¨åº—)")
                    return _memory_cache["order_data"].copy()
    
    # 3. ä»æ•°æ®åº“åŠ è½½
    print(f"ğŸ”„ ä»æ•°æ®åº“åŠ è½½è®¢å•æ•°æ® (é—¨åº—: {store_name or 'å…¨éƒ¨'})...")
    session = SessionLocal()
    try:
        query = session.query(Order)
        
        # å¦‚æœæŒ‡å®šé—¨åº—ï¼ŒåªåŠ è½½è¯¥é—¨åº—æ•°æ®
        if store_name:
            query = query.filter(Order.store_name == store_name)
        
        orders = query.all()
        if not orders:
            return pd.DataFrame()
        
        # è½¬æ¢ä¸ºDataFrameï¼ˆå­—æ®µåä¸æ•°æ®åº“æ¨¡å‹ä¸€è‡´ï¼‰
        data = []
        for order in orders:
            data.append({
                'è®¢å•ID': order.order_id,
                'é—¨åº—åç§°': order.store_name,
                'æ—¥æœŸ': order.date,  # æ•°æ®åº“å­—æ®µæ˜¯date
                'æ¸ é“': order.channel,
                'å•†å“åç§°': order.product_name,
                'ä¸€çº§åˆ†ç±»å': order.category_level1,
                'ä¸‰çº§åˆ†ç±»å': order.category_level3,  # æ•°æ®åº“åªæœ‰ä¸‰çº§åˆ†ç±»
                'æœˆå”®': order.quantity if order.quantity is not None else 1,  # é»˜è®¤ä¸º1
                'å®æ”¶ä»·æ ¼': float(order.actual_price or 0),
                'å•†å“å®å”®ä»·': float(order.price or 0),  # æ•°æ®åº“å­—æ®µæ˜¯price
                'å•†å“åŸä»·': float(order.original_price or 0),  # âœ… æ–°å¢ï¼šå•†å“åŸä»·ï¼ˆç”¨äºGMVè®¡ç®—ï¼‰
                'å•†å“é‡‡è´­æˆæœ¬': float(order.cost or 0),  # æ•°æ®åº“å­—æ®µæ˜¯cost
                'åˆ©æ¶¦é¢': float(order.profit or 0),
                'ç‰©æµé…é€è´¹': float(order.delivery_fee or 0),
                'å¹³å°æœåŠ¡è´¹': float(order.platform_service_fee or 0),
                'å¹³å°ä½£é‡‘': float(order.commission or 0),
                'é¢„è®¡è®¢å•æ”¶å…¥': float(order.amount or 0),  # ä½¿ç”¨amountä½œä¸ºé¢„è®¡è®¢å•æ”¶å…¥
                'ä¼å®¢åè¿”': float(order.corporate_rebate or 0),  # æ•°æ®åº“å­—æ®µæ˜¯corporate_rebate
                'ç”¨æˆ·æ”¯ä»˜é…é€è´¹': float(order.user_paid_delivery_fee or 0),
                'é…é€è´¹å‡å…é‡‘é¢': float(order.delivery_discount or 0),
                'æ»¡å‡é‡‘é¢': float(order.full_reduction or 0),
                'å•†å“å‡å…é‡‘é¢': float(order.product_discount or 0),
                'æ–°å®¢å‡å…é‡‘é¢': float(order.new_customer_discount or 0),
                # âœ… æ–°å¢ï¼šå•†å®¶æ´»åŠ¨æˆæœ¬ç›¸å…³å­—æ®µï¼ˆä¸Dashç‰ˆæœ¬ä¸€è‡´ï¼‰
                'å•†å®¶ä»£é‡‘åˆ¸': float(order.merchant_voucher or 0),
                'å•†å®¶æ‰¿æ‹…éƒ¨åˆ†åˆ¸': float(order.merchant_share or 0),
                'æ»¡èµ é‡‘é¢': float(order.gift_amount or 0),
                'å•†å®¶å…¶ä»–ä¼˜æƒ ': float(order.other_merchant_discount or 0),
                'æ‰“åŒ…è¢‹é‡‘é¢': float(order.packaging_fee or 0),  # âœ… æ–°å¢ï¼šæ‰“åŒ…è¢‹é‡‘é¢ï¼ˆç”¨äºGMVè®¡ç®—ï¼‰
                'åº“å­˜': order.stock,
            })
        
        df = pd.DataFrame(data)
        print(f"âœ… æ•°æ®åº“åŠ è½½å®Œæˆ: {len(df)} æ¡è®°å½• (é—¨åº—: {store_name or 'å…¨éƒ¨'})")
        
        # 4. æ›´æ–°ç¼“å­˜ï¼ˆåŒ…å«ç‰ˆæœ¬å·ï¼‰
        # æ›´æ–°å†…å­˜ç¼“å­˜
        _memory_cache["data_version"] = current_version
        if store_name:
            if "store_cache" not in _memory_cache:
                _memory_cache["store_cache"] = {}
            _memory_cache["store_cache"][store_name] = {
                "data": df.copy(),
                "timestamp": current_time
            }
        else:
            _memory_cache["order_data"] = df.copy()
            _memory_cache["timestamp"] = current_time
        
        # æ›´æ–°Redisç¼“å­˜ï¼ˆåŒ…å«ç‰ˆæœ¬å·ï¼‰
        if REDIS_AVAILABLE and redis_client:
            try:
                # å°†æ—¥æœŸè½¬æ¢ä¸ºå­—ç¬¦ä¸²ä»¥ä¾¿JSONåºåˆ—åŒ–
                cache_data = data.copy()
                for item in cache_data:
                    if item.get('æ—¥æœŸ'):
                        item['æ—¥æœŸ'] = str(item['æ—¥æœŸ'])
                
                redis_client.set(redis_cache_key, json.dumps(cache_data, ensure_ascii=False))
                redis_client.set(redis_timestamp_key, str(current_time))
                redis_client.set(version_key, current_version)  # âœ… ä¿å­˜ç‰ˆæœ¬å·
                # è®¾ç½®è¿‡æœŸæ—¶é—´ï¼ˆ24å°æ—¶ï¼‰
                redis_client.expire(redis_cache_key, CACHE_TTL)
                redis_client.expire(redis_timestamp_key, CACHE_TTL)
                redis_client.expire(version_key, CACHE_TTL)
                print(f"âœ… æ•°æ®å·²ç¼“å­˜åˆ°Redis (é—¨åº—: {store_name or 'å…¨éƒ¨'}, ç‰ˆæœ¬: {current_version})")
            except Exception as e:
                print(f"âš ï¸ Redisç¼“å­˜å†™å…¥å¤±è´¥: {e}")
        
        return df
    finally:
        session.close()


def invalidate_cache(store_name: str = None):
    """
    æ¸…é™¤ç¼“å­˜ï¼ˆæ•°æ®æ›´æ–°æ—¶è°ƒç”¨ï¼‰
    
    Args:
        store_name: æŒ‡å®šé—¨åº—åˆ™åªæ¸…é™¤è¯¥é—¨åº—ç¼“å­˜ï¼Œå¦åˆ™æ¸…é™¤å…¨éƒ¨
    """
    global _memory_cache
    
    if store_name:
        # åªæ¸…é™¤æŒ‡å®šé—¨åº—çš„ç¼“å­˜
        if "store_cache" in _memory_cache and store_name in _memory_cache["store_cache"]:
            del _memory_cache["store_cache"][store_name]
            print(f"âœ… å†…å­˜ç¼“å­˜å·²æ¸…é™¤ (é—¨åº—: {store_name})")
    else:
        # æ¸…é™¤å…¨éƒ¨ç¼“å­˜
        _memory_cache = {"order_data": None, "timestamp": 0, "store_cache": {}, "data_version": None}
        print("âœ… å†…å­˜ç¼“å­˜å·²å…¨éƒ¨æ¸…é™¤")
    
    if REDIS_AVAILABLE and redis_client:
        try:
            if store_name:
                # åªæ¸…é™¤æŒ‡å®šé—¨åº—çš„ç¼“å­˜
                redis_client.delete(f"{ORDER_DATA_CACHE_KEY}:{store_name}")
                redis_client.delete(f"{ORDER_DATA_TIMESTAMP_KEY}:{store_name}")
                redis_client.delete(f"{DATA_VERSION_KEY}:{store_name}")
                print(f"âœ… Redisç¼“å­˜å·²æ¸…é™¤ (é—¨åº—: {store_name})")
            else:
                # æ¸…é™¤æ‰€æœ‰è®¢å•ç›¸å…³çš„ç¼“å­˜
                keys = redis_client.keys(f"{ORDER_DATA_CACHE_KEY}:*")
                if keys:
                    redis_client.delete(*keys)
                keys = redis_client.keys(f"{ORDER_DATA_TIMESTAMP_KEY}:*")
                if keys:
                    redis_client.delete(*keys)
                keys = redis_client.keys(f"{DATA_VERSION_KEY}:*")
                if keys:
                    redis_client.delete(*keys)
                redis_client.delete(ORDER_DATA_CACHE_KEY)
                redis_client.delete(ORDER_DATA_TIMESTAMP_KEY)
                redis_client.delete(DATA_VERSION_KEY)
                print("âœ… Redisç¼“å­˜å·²å…¨éƒ¨æ¸…é™¤")
        except Exception as e:
            print(f"âš ï¸ Redisç¼“å­˜æ¸…é™¤å¤±è´¥: {e}")
            redis_client.delete(ORDER_DATA_TIMESTAMP_KEY)
            print("âœ… Redisç¼“å­˜å·²æ¸…é™¤")
        except Exception as e:
            print(f"âš ï¸ Redisç¼“å­˜æ¸…é™¤å¤±è´¥: {e}")


@router.post("/clear-cache")
async def clear_cache(store_name: Optional[str] = Query(None, description="é—¨åº—åç§°ï¼Œä¸æŒ‡å®šåˆ™æ¸…é™¤å…¨éƒ¨")):
    """
    æ¸…é™¤è®¢å•æ•°æ®ç¼“å­˜
    
    Args:
        store_name: æŒ‡å®šé—¨åº—åˆ™åªæ¸…é™¤è¯¥é—¨åº—ç¼“å­˜ï¼Œå¦åˆ™æ¸…é™¤å…¨éƒ¨
    """
    invalidate_cache(store_name)
    return {
        "success": True, 
        "message": f"ç¼“å­˜å·²æ¸…é™¤ (é—¨åº—: {store_name or 'å…¨éƒ¨'})"
    }


def calculate_order_metrics(df: pd.DataFrame) -> pd.DataFrame:
    """
    ç»Ÿä¸€çš„è®¢å•æŒ‡æ ‡è®¡ç®—å‡½æ•°ï¼ˆä¸è€ç‰ˆæœ¬å®Œå…¨ä¸€è‡´ï¼‰
    
    æ ¸å¿ƒè®¡ç®—é€»è¾‘:
    1. è®¢å•çº§èšåˆï¼ˆè®¢å•çº§å­—æ®µç”¨firstï¼Œå•†å“çº§å­—æ®µç”¨sumï¼‰
    2. è®¡ç®—è®¢å•å®é™…åˆ©æ¶¦ = åˆ©æ¶¦é¢ - å¹³å°æœåŠ¡è´¹ - ç‰©æµé…é€è´¹ + ä¼å®¢åè¿”
    3. æŒ‰æ¸ é“ç±»å‹è¿‡æ»¤å¼‚å¸¸è®¢å•
    """
    if df.empty or 'è®¢å•ID' not in df.columns:
        return pd.DataFrame()
    
    df = df.copy()
    
    # ç»Ÿä¸€è®¢å•IDç±»å‹ä¸ºå­—ç¬¦ä¸²
    df['è®¢å•ID'] = df['è®¢å•ID'].astype(str)
    
    # å…¼å®¹ä¸åŒæˆæœ¬å­—æ®µå
    cost_field = 'å•†å“é‡‡è´­æˆæœ¬' if 'å•†å“é‡‡è´­æˆæœ¬' in df.columns else 'æˆæœ¬'
    sales_field = 'æœˆå”®' if 'æœˆå”®' in df.columns else 'é”€é‡'
    
    # ç©ºå€¼å¡«å……
    df['ç‰©æµé…é€è´¹'] = df['ç‰©æµé…é€è´¹'].fillna(0)
    df['é…é€è´¹å‡å…é‡‘é¢'] = df['é…é€è´¹å‡å…é‡‘é¢'].fillna(0)
    df['ç”¨æˆ·æ”¯ä»˜é…é€è´¹'] = df['ç”¨æˆ·æ”¯ä»˜é…é€è´¹'].fillna(0)
    
    # è®¡ç®—è®¢å•æ€»æ”¶å…¥ï¼ˆå®æ”¶ä»·æ ¼ Ã— é”€é‡ï¼‰
    if 'å®æ”¶ä»·æ ¼' in df.columns and sales_field in df.columns:
        df['è®¢å•æ€»æ”¶å…¥'] = df['å®æ”¶ä»·æ ¼'] * df[sales_field]
    
    # è®¢å•çº§èšåˆ
    agg_dict = {
        'å•†å“å®å”®ä»·': 'sum',
        'é¢„è®¡è®¢å•æ”¶å…¥': 'sum',
        'ç”¨æˆ·æ”¯ä»˜é…é€è´¹': 'first',
        'é…é€è´¹å‡å…é‡‘é¢': 'first',
        'ç‰©æµé…é€è´¹': 'first',
        'å¹³å°ä½£é‡‘': 'first',
    }
    
    if sales_field in df.columns:
        agg_dict[sales_field] = 'sum'
    if 'å¹³å°æœåŠ¡è´¹' in df.columns:
        agg_dict['å¹³å°æœåŠ¡è´¹'] = 'sum'
    if 'è®¢å•æ€»æ”¶å…¥' in df.columns:
        agg_dict['è®¢å•æ€»æ”¶å…¥'] = 'sum'
    if 'åˆ©æ¶¦é¢' in df.columns:
        agg_dict['åˆ©æ¶¦é¢'] = 'sum'
    if 'ä¼å®¢åè¿”' in df.columns:
        agg_dict['ä¼å®¢åè¿”'] = 'sum'
    if cost_field in df.columns:
        agg_dict[cost_field] = 'sum'
    
    # è®¢å•çº§å­—æ®µç”¨first
    for field in ['æ»¡å‡é‡‘é¢', 'å•†å“å‡å…é‡‘é¢', 'æ–°å®¢å‡å…é‡‘é¢', 'æ¸ é“', 'é—¨åº—åç§°', 'æ—¥æœŸ', 
                  'å•†å®¶ä»£é‡‘åˆ¸', 'å•†å®¶æ‰¿æ‹…éƒ¨åˆ†åˆ¸', 'æ»¡èµ é‡‘é¢', 'å•†å®¶å…¶ä»–ä¼˜æƒ ']:
        if field in df.columns:
            agg_dict[field] = 'first'
    
    order_agg = df.groupby('è®¢å•ID').agg(agg_dict).reset_index()
    
    # å°†è®¢å•æ€»æ”¶å…¥é‡å‘½åä¸ºå®æ”¶ä»·æ ¼
    if 'è®¢å•æ€»æ”¶å…¥' in order_agg.columns:
        order_agg['å®æ”¶ä»·æ ¼'] = order_agg['è®¢å•æ€»æ”¶å…¥']
    
    # ç»Ÿä¸€æˆæœ¬å­—æ®µå
    if cost_field == 'æˆæœ¬' and cost_field in order_agg.columns:
        order_agg['å•†å“é‡‡è´­æˆæœ¬'] = order_agg['æˆæœ¬']
    
    # å…³é”®å­—æ®µå…œåº•
    if 'å¹³å°æœåŠ¡è´¹' not in order_agg.columns:
        order_agg['å¹³å°æœåŠ¡è´¹'] = 0
    order_agg['å¹³å°æœåŠ¡è´¹'] = order_agg['å¹³å°æœåŠ¡è´¹'].fillna(0)
    
    if 'ä¼å®¢åè¿”' not in order_agg.columns:
        order_agg['ä¼å®¢åè¿”'] = 0
    order_agg['ä¼å®¢åè¿”'] = order_agg['ä¼å®¢åè¿”'].fillna(0)
    
    if 'å¹³å°ä½£é‡‘' not in order_agg.columns:
        order_agg['å¹³å°ä½£é‡‘'] = order_agg['å¹³å°æœåŠ¡è´¹']
    order_agg['å¹³å°ä½£é‡‘'] = order_agg['å¹³å°ä½£é‡‘'].fillna(0)
    
    if 'åˆ©æ¶¦é¢' not in order_agg.columns:
        order_agg['åˆ©æ¶¦é¢'] = 0
    order_agg['åˆ©æ¶¦é¢'] = order_agg['åˆ©æ¶¦é¢'].fillna(0)
    
    # è®¡ç®—è®¢å•å®é™…åˆ©æ¶¦ï¼ˆæ ¸å¿ƒå…¬å¼ï¼‰
    # å…¬å¼: è®¢å•å®é™…åˆ©æ¶¦ = åˆ©æ¶¦é¢ - å¹³å°æœåŠ¡è´¹ - ç‰©æµé…é€è´¹ + ä¼å®¢åè¿”
    order_agg['è®¢å•å®é™…åˆ©æ¶¦'] = (
        order_agg['åˆ©æ¶¦é¢'] -
        order_agg['å¹³å°æœåŠ¡è´¹'] -
        order_agg['ç‰©æµé…é€è´¹'] +
        order_agg['ä¼å®¢åè¿”']
    )
    
    # ==================== è®¡ç®—é…é€å‡€æˆæœ¬ï¼ˆä¸Dashç‰ˆæœ¬ä¸€è‡´ï¼‰ ====================
    # å…¬å¼: é…é€å‡€æˆæœ¬ = ç‰©æµé…é€è´¹ - (ç”¨æˆ·æ”¯ä»˜é…é€è´¹ - é…é€è´¹å‡å…é‡‘é¢) - ä¼å®¢åè¿”
    order_agg['é…é€å‡€æˆæœ¬'] = (
        order_agg['ç‰©æµé…é€è´¹'] -
        (order_agg['ç”¨æˆ·æ”¯ä»˜é…é€è´¹'] - order_agg['é…é€è´¹å‡å…é‡‘é¢']) -
        order_agg['ä¼å®¢åè¿”']
    )
    
    # ==================== è®¡ç®—å•†å®¶æ´»åŠ¨æˆæœ¬ï¼ˆå¯¹é½Dashç‰ˆæœ¬ï¼š7ä¸ªè¥é”€å­—æ®µï¼‰ ====================
    # å…¬å¼: å•†å®¶æ´»åŠ¨æˆæœ¬ = æ»¡å‡é‡‘é¢ + å•†å“å‡å…é‡‘é¢ + å•†å®¶ä»£é‡‘åˆ¸ + å•†å®¶æ‰¿æ‹…éƒ¨åˆ†åˆ¸ + æ»¡èµ é‡‘é¢ + å•†å®¶å…¶ä»–ä¼˜æƒ  + æ–°å®¢å‡å…é‡‘é¢
    # è¯´æ˜: é…é€è´¹å‡å…é‡‘é¢å±äºé…é€æˆæœ¬ï¼Œä¸å±äºè¥é”€æˆæœ¬
    marketing_fields = ['æ»¡å‡é‡‘é¢', 'å•†å“å‡å…é‡‘é¢', 'å•†å®¶ä»£é‡‘åˆ¸', 'å•†å®¶æ‰¿æ‹…éƒ¨åˆ†åˆ¸', 'æ»¡èµ é‡‘é¢', 'å•†å®¶å…¶ä»–ä¼˜æƒ ', 'æ–°å®¢å‡å…é‡‘é¢']
    order_agg['å•†å®¶æ´»åŠ¨æˆæœ¬'] = 0
    for field in marketing_fields:
        if field in order_agg.columns:
            order_agg['å•†å®¶æ´»åŠ¨æˆæœ¬'] += order_agg[field].fillna(0)
    
    # æŒ‰æ¸ é“ç±»å‹è¿‡æ»¤å¼‚å¸¸è®¢å•
    if 'æ¸ é“' in order_agg.columns:
        is_fee_channel = order_agg['æ¸ é“'].isin(PLATFORM_FEE_CHANNELS)
        is_zero_fee = order_agg['å¹³å°æœåŠ¡è´¹'] <= 0
        invalid_orders = is_fee_channel & is_zero_fee
        order_agg = order_agg[~invalid_orders].copy()
    
    return order_agg


def calculate_gmv(df: pd.DataFrame) -> Dict[str, float]:
    """
    è®¡ç®—é—¨åº—GMVï¼ˆè¥ä¸šé¢ï¼‰
    
    GMVè®¡ç®—å…¬å¼ï¼ˆç”¨æˆ·ç¡®è®¤ï¼‰ï¼š
    GMV = Î£(å•†å“åŸä»· Ã— é”€é‡) + Î£(æ‰“åŒ…è¢‹é‡‘é¢) + Î£(ç”¨æˆ·æ”¯ä»˜é…é€è´¹)
    
    æ•°æ®æ¸…æ´—è§„åˆ™ï¼ˆé‡è¦ï¼ï¼‰ï¼š
    1. **å‰”é™¤å•†å“åŸä»· <= 0 çš„æ•´è¡Œæ•°æ®**ï¼ˆåŒ…æ‹¬è¯¥è¡Œçš„æ‰“åŒ…è¢‹é‡‘é¢å’Œç”¨æˆ·æ”¯ä»˜é…é€è´¹ï¼‰
    2. å•†å“åŸä»·æ˜¯å•†å“çº§å­—æ®µï¼Œéœ€è¦ä¹˜ä»¥é”€é‡æ‰èƒ½å¾—å‡ºå‡†ç¡®çš„åŸä»·é”€å”®é‡‘é¢
    3. æ‰“åŒ…è¢‹é‡‘é¢æ˜¯è®¢å•çº§å­—æ®µï¼Œä¸€ä¸ªè®¢å•åªæ”¶å–ä¸€æ¬¡æ‰“åŒ…è´¹ï¼Œéœ€è¦ç”¨firstèšåˆé¿å…é‡å¤
    4. ç”¨æˆ·æ”¯ä»˜é…é€è´¹æ˜¯è®¢å•çº§å­—æ®µï¼Œæ¸…æ´—é€»è¾‘å’Œæ‰“åŒ…è¢‹é‡‘é¢ä¸€è‡´
    
    è¥é”€æˆæœ¬ç‡è®¡ç®—ï¼š
    è¥é”€æˆæœ¬ç‡ = è¥é”€æˆæœ¬ / GMV Ã— 100%
    
    éªŒè¯æ•°æ®ï¼ˆæƒ å®œé€‰è¶…å¸‚æ˜†å±±æ·€å±±æ¹–é•‡åº— 2026-01-18ï¼‰ï¼š
    - é¢„æœŸGMV: 8440.66
    - é¢„æœŸè¥é”€æˆæœ¬: 1122
    - é¢„æœŸè¥é”€æˆæœ¬ç‡: ~13.30%
    
    Args:
        df: åŸå§‹è®¢å•æ•°æ®DataFrameï¼ˆå•†å“çº§ï¼Œæœªèšåˆï¼‰
    
    Returns:
        DictåŒ…å«:
        - gmv: è¥ä¸šé¢
        - original_price_sales: å•†å“åŸä»·é”€å”®é¢
        - packaging_fee: æ‰“åŒ…è¢‹é‡‘é¢
        - user_delivery_fee: ç”¨æˆ·æ”¯ä»˜é…é€è´¹
        - marketing_cost: è¥é”€æˆæœ¬ï¼ˆ7å­—æ®µï¼‰
        - marketing_cost_rate: è¥é”€æˆæœ¬ç‡
    """
    if df.empty:
        return {
            "gmv": 0,
            "original_price_sales": 0,
            "packaging_fee": 0,
            "user_delivery_fee": 0,
            "marketing_cost": 0,
            "marketing_cost_rate": 0
        }
    
    df = df.copy()
    
    # ç¡®ä¿å¿…è¦å­—æ®µå­˜åœ¨
    sales_field = 'æœˆå”®' if 'æœˆå”®' in df.columns else 'é”€é‡'
    
    # 1. å‰”é™¤å•†å“åŸä»· <= 0 çš„æ•´è¡Œæ•°æ®ï¼ˆå…³é”®ï¼åŒ…æ‹¬è¯¥è¡Œçš„æ‰“åŒ…è¢‹é‡‘é¢å’Œç”¨æˆ·æ”¯ä»˜é…é€è´¹ï¼‰
    # ç”¨æˆ·ç¡®è®¤ï¼šå•†å“åŸä»·=0çš„è®¢å•æ²¡æœ‰å®é™…å•†å“é”€å”®ï¼Œå…¶æ‰“åŒ…è¢‹å’Œé…é€è´¹ä¹Ÿä¸åº”è®¡å…¥GMV
    if 'å•†å“åŸä»·' in df.columns:
        df = df[df['å•†å“åŸä»·'] > 0].copy()
    
    if df.empty:
        return {
            "gmv": 0,
            "original_price_sales": 0,
            "packaging_fee": 0,
            "user_delivery_fee": 0,
            "marketing_cost": 0,
            "marketing_cost_rate": 0
        }
    
    # 2. è®¡ç®—å•†å“åŸä»·é”€å”®é¢ = Î£(å•†å“åŸä»· Ã— é”€é‡)
    # å•†å“åŸä»·æ˜¯å•†å“çº§å­—æ®µï¼ˆå•ä»·ï¼‰ï¼Œéœ€è¦ä¹˜ä»¥é”€é‡
    if 'å•†å“åŸä»·' in df.columns and sales_field in df.columns:
        df['åŸä»·é”€å”®é¢'] = df['å•†å“åŸä»·'].fillna(0) * df[sales_field].fillna(1)
        original_price_sales = df['åŸä»·é”€å”®é¢'].sum()
    else:
        original_price_sales = 0
    
    # 3. è®¡ç®—è®¢å•çº§å­—æ®µï¼ˆæ‰“åŒ…è¢‹é‡‘é¢ã€ç”¨æˆ·æ”¯ä»˜é…é€è´¹ï¼‰
    # è¿™äº›æ˜¯è®¢å•çº§å­—æ®µï¼Œéœ€è¦æŒ‰è®¢å•IDèšåˆåç”¨firstå–å€¼ï¼Œé¿å…é‡å¤è®¡ç®—
    # æ³¨æ„ï¼šæ­¤æ—¶dfå·²ç»å‰”é™¤äº†å•†å“åŸä»·<=0çš„è¡Œï¼Œæ‰€ä»¥åªæœ‰æœ‰æ•ˆè®¢å•çš„æ•°æ®ä¼šè¢«è®¡å…¥
    if 'è®¢å•ID' in df.columns:
        # è®¢å•çº§å­—æ®µèšåˆ
        order_level_agg = df.groupby('è®¢å•ID').agg({
            'æ‰“åŒ…è¢‹é‡‘é¢': 'first' if 'æ‰“åŒ…è¢‹é‡‘é¢' in df.columns else lambda x: 0,
            'ç”¨æˆ·æ”¯ä»˜é…é€è´¹': 'first' if 'ç”¨æˆ·æ”¯ä»˜é…é€è´¹' in df.columns else lambda x: 0,
            # è¥é”€æˆæœ¬å­—æ®µï¼ˆè®¢å•çº§ï¼‰
            'æ»¡å‡é‡‘é¢': 'first' if 'æ»¡å‡é‡‘é¢' in df.columns else lambda x: 0,
            'å•†å“å‡å…é‡‘é¢': 'first' if 'å•†å“å‡å…é‡‘é¢' in df.columns else lambda x: 0,
            'å•†å®¶ä»£é‡‘åˆ¸': 'first' if 'å•†å®¶ä»£é‡‘åˆ¸' in df.columns else lambda x: 0,
            'å•†å®¶æ‰¿æ‹…éƒ¨åˆ†åˆ¸': 'first' if 'å•†å®¶æ‰¿æ‹…éƒ¨åˆ†åˆ¸' in df.columns else lambda x: 0,
            'æ»¡èµ é‡‘é¢': 'first' if 'æ»¡èµ é‡‘é¢' in df.columns else lambda x: 0,
            'å•†å®¶å…¶ä»–ä¼˜æƒ ': 'first' if 'å•†å®¶å…¶ä»–ä¼˜æƒ ' in df.columns else lambda x: 0,
            'æ–°å®¢å‡å…é‡‘é¢': 'first' if 'æ–°å®¢å‡å…é‡‘é¢' in df.columns else lambda x: 0,
        }).reset_index()
        
        packaging_fee = order_level_agg['æ‰“åŒ…è¢‹é‡‘é¢'].sum() if 'æ‰“åŒ…è¢‹é‡‘é¢' in order_level_agg.columns else 0
        user_delivery_fee = order_level_agg['ç”¨æˆ·æ”¯ä»˜é…é€è´¹'].sum() if 'ç”¨æˆ·æ”¯ä»˜é…é€è´¹' in order_level_agg.columns else 0
        
        # è®¡ç®—è¥é”€æˆæœ¬ï¼ˆ7å­—æ®µï¼‰
        marketing_fields = ['æ»¡å‡é‡‘é¢', 'å•†å“å‡å…é‡‘é¢', 'å•†å®¶ä»£é‡‘åˆ¸', 'å•†å®¶æ‰¿æ‹…éƒ¨åˆ†åˆ¸', 'æ»¡èµ é‡‘é¢', 'å•†å®¶å…¶ä»–ä¼˜æƒ ', 'æ–°å®¢å‡å…é‡‘é¢']
        marketing_cost = 0
        for field in marketing_fields:
            if field in order_level_agg.columns:
                marketing_cost += order_level_agg[field].fillna(0).sum()
    else:
        packaging_fee = 0
        user_delivery_fee = 0
        marketing_cost = 0
    
    # 4. è®¡ç®—GMV
    gmv = original_price_sales + packaging_fee + user_delivery_fee
    
    # 5. è®¡ç®—è¥é”€æˆæœ¬ç‡
    marketing_cost_rate = (marketing_cost / gmv * 100) if gmv > 0 else 0
    
    return {
        "gmv": round(gmv, 2),
        "original_price_sales": round(original_price_sales, 2),
        "packaging_fee": round(packaging_fee, 2),
        "user_delivery_fee": round(user_delivery_fee, 2),
        "marketing_cost": round(marketing_cost, 2),
        "marketing_cost_rate": round(marketing_cost_rate, 2)
    }


@router.get("/overview")
async def get_order_overview(
    store_name: Optional[str] = Query(None, description="é—¨åº—åç§°ç­›é€‰"),
    start_date: Optional[date] = Query(None, description="å¼€å§‹æ—¥æœŸ"),
    end_date: Optional[date] = Query(None, description="ç»“æŸæ—¥æœŸ"),
    use_aggregation: bool = Query(True, description="æ˜¯å¦ä½¿ç”¨é¢„èšåˆè¡¨ï¼ˆæ€§èƒ½ä¼˜åŒ–ï¼‰")
) -> Dict[str, Any]:
    """
    è·å–è®¢å•æ•°æ®æ¦‚è§ˆï¼ˆå…­å¤§æ ¸å¿ƒå¡ç‰‡ï¼‰
    
    ä¸è€ç‰ˆæœ¬Tab1å®Œå…¨ä¸€è‡´çš„æŒ‡æ ‡:
    - ğŸ“¦ è®¢å•æ€»æ•°
    - ğŸ’° å•†å“å®æ”¶é¢
    - ğŸ’ æ€»åˆ©æ¶¦
    - ğŸ›’ å¹³å‡å®¢å•ä»·
    - ğŸ“ˆ æ€»åˆ©æ¶¦ç‡
    - ğŸ·ï¸ åŠ¨é”€å•†å“æ•°
    
    ä¼˜åŒ–ï¼šä¼˜å…ˆä½¿ç”¨é¢„èšåˆè¡¨ï¼ŒæŸ¥è¯¢æ—¶é—´ä»~500msé™åˆ°~2ms
    """
    import time
    query_start = time.time()
    
    # âœ… ä¼˜å…ˆä½¿ç”¨é¢„èšåˆè¡¨ï¼ˆåŒ…å«GMVå­—æ®µï¼‰
    if use_aggregation:
        try:
            from app.services.aggregation_service import aggregation_service
            result = aggregation_service.get_store_overview(
                store_name=store_name,
                start_date=start_date,
                end_date=end_date
            )
            if result:
                # æ£€æŸ¥é¢„èšåˆè¡¨æ˜¯å¦æœ‰GMVæ•°æ®
                if result.get("gmv", 0) > 0:
                    # é¢„èšåˆè¡¨æœ‰GMVæ•°æ®ï¼Œç›´æ¥ä½¿ç”¨
                    print(f"âœ… [é¢„èšåˆè¡¨+GMV] overviewæŸ¥è¯¢è€—æ—¶: {(time.time()-query_start)*1000:.1f}ms")
                    return {"success": True, "data": result}
                else:
                    # é¢„èšåˆè¡¨æ²¡æœ‰GMVæ•°æ®ï¼Œéœ€è¦ä»åŸå§‹æ•°æ®è®¡ç®—
                    df = get_order_data(store_name)
                    if not df.empty:
                        # æ—¥æœŸç­›é€‰
                        if 'æ—¥æœŸ' in df.columns:
                            df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'], errors='coerce')
                            if start_date:
                                df = df[df['æ—¥æœŸ'].dt.date >= start_date]
                            if end_date:
                                df = df[df['æ—¥æœŸ'].dt.date <= end_date]
                        
                        # è®¡ç®—GMVå’Œè¥é”€æˆæœ¬ç‡
                        gmv_data = calculate_gmv(df)
                        result["gmv"] = gmv_data["gmv"]
                        result["marketing_cost"] = gmv_data["marketing_cost"]
                        result["marketing_cost_rate"] = gmv_data["marketing_cost_rate"]
                    else:
                        result["gmv"] = 0
                        result["marketing_cost"] = 0
                        result["marketing_cost_rate"] = 0
                    
                    print(f"âœ… [é¢„èšåˆè¡¨+åŸå§‹GMV] overviewæŸ¥è¯¢è€—æ—¶: {(time.time()-query_start)*1000:.1f}ms")
                    return {"success": True, "data": result}
        except Exception as e:
            print(f"âš ï¸ é¢„èšåˆè¡¨æŸ¥è¯¢å¤±è´¥ï¼Œå›é€€åˆ°åŸå§‹æŸ¥è¯¢: {e}")
    
    # å›é€€åˆ°åŸå§‹æŸ¥è¯¢
    # æŒ‰é—¨åº—åŠ è½½æ•°æ®ï¼ˆåˆ©ç”¨ç¼“å­˜ï¼‰
    df = get_order_data(store_name)
    if df.empty:
        return {
            "success": True,
            "data": {
                "total_orders": 0,
                "total_actual_sales": 0,
                "total_profit": 0,
                "avg_order_value": 0,
                "profit_rate": 0,
                "active_products": 0,
            }
        }
    
    # æ—¥æœŸç­›é€‰
    if 'æ—¥æœŸ' in df.columns:
        df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'], errors='coerce')
        if start_date:
            df = df[df['æ—¥æœŸ'].dt.date >= start_date]
        if end_date:
            df = df[df['æ—¥æœŸ'].dt.date <= end_date]
    
    if df.empty:
        return {
            "success": True,
            "data": {
                "total_orders": 0,
                "total_actual_sales": 0,
                "total_profit": 0,
                "avg_order_value": 0,
                "profit_rate": 0,
                "active_products": 0,
            }
        }
    
    # è®¡ç®—è®¢å•çº§æŒ‡æ ‡
    order_agg = calculate_order_metrics(df)
    
    # å…­å¤§æ ¸å¿ƒå¡ç‰‡
    total_orders = len(order_agg)
    total_actual_sales = order_agg['å®æ”¶ä»·æ ¼'].sum() if 'å®æ”¶ä»·æ ¼' in order_agg.columns else 0
    total_profit = order_agg['è®¢å•å®é™…åˆ©æ¶¦'].sum() if 'è®¢å•å®é™…åˆ©æ¶¦' in order_agg.columns else 0
    avg_order_value = total_actual_sales / total_orders if total_orders > 0 else 0
    profit_rate = (total_profit / total_actual_sales * 100) if total_actual_sales > 0 else 0
    
    # åŠ¨é”€å•†å“æ•°ï¼ˆæœ‰é”€é‡çš„SKUï¼‰
    sales_field = 'æœˆå”®' if 'æœˆå”®' in df.columns else 'é”€é‡'
    if 'å•†å“åç§°' in df.columns and sales_field in df.columns:
        active_products = df[df[sales_field] > 0]['å•†å“åç§°'].nunique()
    else:
        active_products = df['å•†å“åç§°'].nunique() if 'å•†å“åç§°' in df.columns else 0
    
    # âœ… æ–°å¢ï¼šè®¡ç®—GMVå’Œè¥é”€æˆæœ¬ç‡ï¼ˆåŸºäºç”¨æˆ·ç¡®è®¤çš„å…¬å¼ï¼‰
    gmv_data = calculate_gmv(df)
    
    print(f"âš ï¸ [åŸå§‹æŸ¥è¯¢] overviewæŸ¥è¯¢è€—æ—¶: {(time.time()-query_start)*1000:.1f}ms")
    
    return {
        "success": True,
        "data": {
            "total_orders": int(total_orders),
            "total_actual_sales": round(float(total_actual_sales), 2),
            "total_profit": round(float(total_profit), 2),
            "avg_order_value": round(float(avg_order_value), 2),
            "profit_rate": round(float(profit_rate), 2),
            "active_products": int(active_products),
            # âœ… æ–°å¢ï¼šGMVå’Œè¥é”€æˆæœ¬ç‡
            "gmv": gmv_data["gmv"],
            "marketing_cost": gmv_data["marketing_cost"],
            "marketing_cost_rate": gmv_data["marketing_cost_rate"],
        }
    }


@router.get("/channels")
async def get_channel_stats(
    store_name: Optional[str] = Query(None, description="é—¨åº—åç§°ç­›é€‰"),
    start_date: Optional[date] = Query(None, description="å¼€å§‹æ—¥æœŸ"),
    end_date: Optional[date] = Query(None, description="ç»“æŸæ—¥æœŸ")
) -> Dict[str, Any]:
    """
    è·å–æ¸ é“è¡¨ç°å¯¹æ¯”æ•°æ®
    
    ä¸è€ç‰ˆæœ¬Tab1æ¸ é“å¡ç‰‡å®Œå…¨ä¸€è‡´
    æ³¨æ„ï¼šæ’é™¤å’–å•¡æ¸ é“ï¼ˆç¾å›¢å’–å•¡åº—ã€é¥¿äº†ä¹ˆå’–å•¡åº—ï¼‰
    """
    # æŒ‰é—¨åº—åŠ è½½æ•°æ®
    df = get_order_data(store_name)
    if df.empty:
        return {"success": True, "data": []}
    
    # æ—¥æœŸç­›é€‰
    if 'æ—¥æœŸ' in df.columns:
        df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'], errors='coerce')
        if start_date:
            df = df[df['æ—¥æœŸ'].dt.date >= start_date]
        if end_date:
            df = df[df['æ—¥æœŸ'].dt.date <= end_date]
    
    if df.empty or 'æ¸ é“' not in df.columns:
        return {"success": True, "data": []}
    
    # è®¡ç®—è®¢å•çº§æŒ‡æ ‡
    order_agg = calculate_order_metrics(df)
    
    if order_agg.empty or 'æ¸ é“' not in order_agg.columns:
        return {"success": True, "data": []}
    
    # æ’é™¤å’–å•¡æ¸ é“ï¼ˆä¸è€ç‰ˆæœ¬ä¸€è‡´ï¼‰
    CHANNELS_TO_REMOVE = ['ç¾å›¢å’–å•¡åº—', 'é¥¿äº†ä¹ˆå’–å•¡åº—']
    order_agg = order_agg[~order_agg['æ¸ é“'].isin(CHANNELS_TO_REMOVE)]
    
    if order_agg.empty:
        return {"success": True, "data": []}
    
    # æŒ‰æ¸ é“èšåˆ
    channel_stats = order_agg.groupby('æ¸ é“').agg({
        'è®¢å•ID': 'count',
        'å®æ”¶ä»·æ ¼': 'sum',
        'è®¢å•å®é™…åˆ©æ¶¦': 'sum',
    }).reset_index()
    
    channel_stats.columns = ['channel', 'order_count', 'amount', 'profit']
    
    # è®¡ç®—æ´¾ç”ŸæŒ‡æ ‡
    total_orders = channel_stats['order_count'].sum()
    total_amount = channel_stats['amount'].sum()
    
    channel_stats['order_ratio'] = (channel_stats['order_count'] / total_orders * 100) if total_orders > 0 else 0
    channel_stats['amount_ratio'] = (channel_stats['amount'] / total_amount * 100) if total_amount > 0 else 0
    channel_stats['avg_value'] = channel_stats.apply(
        lambda r: r['amount'] / r['order_count'] if r['order_count'] > 0 else 0, axis=1
    )
    channel_stats['profit_rate'] = channel_stats.apply(
        lambda r: r['profit'] / r['amount'] * 100 if r['amount'] > 0 else 0, axis=1
    )
    
    # æŒ‰è®¢å•æ•°æ’åº
    channel_stats = channel_stats.sort_values('order_count', ascending=False)
    
    # è½¬æ¢ä¸ºåˆ—è¡¨
    result = []
    for _, row in channel_stats.iterrows():
        result.append({
            "channel": row['channel'],
            "order_count": int(row['order_count']),
            "amount": round(float(row['amount']), 2),
            "profit": round(float(row['profit']), 2),
            "order_ratio": round(float(row['order_ratio']), 2),
            "amount_ratio": round(float(row['amount_ratio']), 2),
            "avg_value": round(float(row['avg_value']), 2),
            "profit_rate": round(float(row['profit_rate']), 2),
        })
    
    return {"success": True, "data": result}


@router.get("/trend")
async def get_order_trend(
    days: int = Query(30, ge=1, le=365, description="ç»Ÿè®¡å¤©æ•°"),
    store_name: Optional[str] = Query(None, description="é—¨åº—åç§°ç­›é€‰"),
    channel: Optional[str] = Query(None, description="æ¸ é“ç­›é€‰ï¼Œ'all'æˆ–ç©ºè¡¨ç¤ºå…¨éƒ¨æ¸ é“"),
    start_date: Optional[str] = Query(None, description="æ—¥æœŸèŒƒå›´å¼€å§‹(YYYY-MM-DDæ ¼å¼)"),
    end_date: Optional[str] = Query(None, description="æ—¥æœŸèŒƒå›´ç»“æŸ(YYYY-MM-DDæ ¼å¼)"),
    granularity: str = Query("day", description="ç²’åº¦: day/week/month"),
    use_aggregation: bool = Query(True, description="æ˜¯å¦ä½¿ç”¨é¢„èšåˆè¡¨ï¼ˆæ€§èƒ½ä¼˜åŒ–ï¼‰")
) -> Dict[str, Any]:
    """
    è·å–è®¢å•è¶‹åŠ¿æ•°æ®ï¼ˆä¸Dashç‰ˆæœ¬é”€å”®è¶‹åŠ¿åˆ†æä¸€è‡´ï¼‰
    
    è¿”å›æ¯æ—¥/æ¯å‘¨/æ¯æœˆçš„è®¢å•æ•°ã€é”€å”®é¢ã€åˆ©æ¶¦ã€å®¢å•ä»·ã€åˆ©æ¶¦ç‡
    
    æ”¯æŒä¸¤ç§æ—¥æœŸç­›é€‰æ–¹å¼ï¼š
    - days: æœ€è¿‘Nå¤©ï¼ˆé»˜è®¤30å¤©ï¼‰
    - start_date + end_date: æŒ‡å®šæ—¥æœŸèŒƒå›´ï¼ˆä¼˜å…ˆçº§æ›´é«˜ï¼‰
    
    è®¡ç®—é€»è¾‘ä¸Dashç‰ˆæœ¬ calculate_daily_sales_with_channel å®Œå…¨ä¸€è‡´ï¼š
    - åˆ©æ¶¦ç‡ = æ€»åˆ©æ¶¦ / é”€å”®é¢ * 100
    - æ¸ é“ç­›é€‰ï¼šæ”¯æŒæŒ‰æ¸ é“è¿‡æ»¤æ•°æ®
    
    ä¼˜åŒ–ï¼šä¼˜å…ˆä½¿ç”¨é¢„èšåˆè¡¨ï¼ŒæŸ¥è¯¢æ—¶é—´ä»~200msé™åˆ°~5ms
    """
    import time
    query_start = time.time()
    
    empty_result = {
        "success": True, 
        "data": {
            "dates": [], "order_counts": [], "amounts": [], 
            "profits": [], "avg_values": [], "profit_rates": []
        }
    }
    
    # âœ… ä¼˜å…ˆä½¿ç”¨é¢„èšåˆè¡¨ï¼ˆä»…æ”¯æŒæ—¥ç²’åº¦ï¼Œæ— æ¸ é“ç­›é€‰æ—¶ï¼‰
    if use_aggregation and granularity == 'day':
        try:
            from app.services.aggregation_service import aggregation_service
            
            # è§£ææ—¥æœŸå‚æ•°
            from datetime import date as date_type
            agg_start = None
            agg_end = None
            
            if start_date and end_date:
                try:
                    agg_start = date_type.fromisoformat(start_date)
                    agg_end = date_type.fromisoformat(end_date)
                except:
                    pass
            
            # æ˜ å°„æ¸ é“å‚æ•°
            agg_channel = None
            if channel and channel != 'all':
                agg_channel = channel
            
            result = aggregation_service.get_daily_trend(
                store_name=store_name,
                start_date=agg_start,
                end_date=agg_end,
                channel=agg_channel
            )
            
            if result and len(result) > 0:
                # è½¬æ¢ä¸ºAPIå“åº”æ ¼å¼
                dates = [r['date'] for r in result]
                order_counts = [r['orders'] for r in result]
                amounts = [r['revenue'] for r in result]
                profits = [r['profit'] for r in result]
                avg_values = [round(r['revenue'] / r['orders'], 2) if r['orders'] > 0 else 0 for r in result]
                profit_rates = [round(r['profit'] / r['revenue'] * 100, 2) if r['revenue'] > 0 else 0 for r in result]
                
                print(f"âœ… [é¢„èšåˆè¡¨] trendæŸ¥è¯¢è€—æ—¶: {(time.time()-query_start)*1000:.1f}ms, {len(result)}æ¡è®°å½•")
                
                return {
                    "success": True,
                    "data": {
                        "dates": dates,
                        "order_counts": order_counts,
                        "amounts": amounts,
                        "profits": profits,
                        "avg_values": avg_values,
                        "profit_rates": profit_rates,
                    }
                }
        except Exception as e:
            print(f"âš ï¸ é¢„èšåˆè¡¨æŸ¥è¯¢å¤±è´¥ï¼Œå›é€€åˆ°åŸå§‹æŸ¥è¯¢: {e}")
    
    # å›é€€åˆ°åŸå§‹æŸ¥è¯¢
    # æŒ‰é—¨åº—åŠ è½½æ•°æ®ï¼ˆåˆ©ç”¨ç¼“å­˜ï¼‰
    df = get_order_data(store_name)
    
    if df.empty:
        return empty_result
    
    if 'æ—¥æœŸ' not in df.columns:
        return {"success": False, "error": "ç¼ºå°‘æ—¥æœŸå­—æ®µ"}
    
    df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'], errors='coerce')
    df = df.dropna(subset=['æ—¥æœŸ'])
    
    if df.empty:
        return empty_result
    
    # ğŸ†• æ—¥æœŸç­›é€‰ï¼šä¼˜å…ˆä½¿ç”¨æ—¥æœŸèŒƒå›´ï¼Œå¦åˆ™ä½¿ç”¨æœ€è¿‘Nå¤©
    if start_date and end_date:
        try:
            range_start = pd.to_datetime(start_date)
            range_end = pd.to_datetime(end_date)
            df = df[(df['æ—¥æœŸ'].dt.date >= range_start.date()) & (df['æ—¥æœŸ'].dt.date <= range_end.date())]
        except:
            # æ—¥æœŸè§£æå¤±è´¥ï¼Œå›é€€åˆ°é»˜è®¤è¡Œä¸º
            max_date = df['æ—¥æœŸ'].max()
            min_date = max_date - timedelta(days=days)
            df = df[df['æ—¥æœŸ'] >= min_date]
    else:
        # ç­›é€‰æœ€è¿‘Nå¤©
        max_date = df['æ—¥æœŸ'].max()
        if pd.isna(max_date):
            return empty_result
        
        min_date = max_date - timedelta(days=days)
        df = df[df['æ—¥æœŸ'] >= min_date]
    
    if df.empty:
        return empty_result
    
    # å…ˆèšåˆåˆ°è®¢å•çº§ï¼ˆä¸Dashç‰ˆæœ¬ä¸€è‡´ï¼‰
    order_agg = calculate_order_metrics(df)
    
    if order_agg.empty:
        return empty_result
    
    # ğŸ†• æ¸ é“ç­›é€‰ï¼ˆä¸Dashç‰ˆæœ¬ calculate_daily_sales_with_channel ä¸€è‡´ï¼‰
    if channel and channel != 'all' and 'æ¸ é“' in order_agg.columns:
        before_filter = len(order_agg)
        order_agg = order_agg[order_agg['æ¸ é“'] == channel].copy()
        after_filter = len(order_agg)
        print(f"ğŸ” [trend API] æ¸ é“ç­›é€‰: {before_filter} -> {after_filter} è®¢å• (æ¸ é“='{channel}')")
        
        if order_agg.empty:
            return empty_result
    
    # æ ¹æ®ç²’åº¦åˆ†ç»„
    if 'æ—¥æœŸ' in order_agg.columns:
        order_agg['æ—¥æœŸ'] = pd.to_datetime(order_agg['æ—¥æœŸ'])
        if granularity == 'week':
            order_agg['period'] = order_agg['æ—¥æœŸ'].dt.to_period('W').apply(lambda x: x.start_time)
        elif granularity == 'month':
            order_agg['period'] = order_agg['æ—¥æœŸ'].dt.to_period('M').apply(lambda x: x.start_time)
        else:
            order_agg['period'] = order_agg['æ—¥æœŸ'].dt.date
        
        # æŒ‰å‘¨æœŸèšåˆï¼ˆä¸Dashç‰ˆæœ¬ä¸€è‡´ï¼‰
        daily = order_agg.groupby('period').agg({
            'è®¢å•ID': 'count',
            'å®æ”¶ä»·æ ¼': 'sum',
            'è®¢å•å®é™…åˆ©æ¶¦': 'sum',
        }).reset_index()
        
        daily.columns = ['date', 'order_count', 'amount', 'profit']
    else:
        # å¤‡ç”¨æ–¹æ¡ˆï¼šæŒ‰åŸå§‹æ•°æ®æ—¥æœŸèšåˆ
        if granularity == 'week':
            df['period'] = df['æ—¥æœŸ'].dt.to_period('W').apply(lambda x: x.start_time)
        elif granularity == 'month':
            df['period'] = df['æ—¥æœŸ'].dt.to_period('M').apply(lambda x: x.start_time)
        else:
            df['period'] = df['æ—¥æœŸ'].dt.date
            
        daily = df.groupby('period').agg({
            'è®¢å•ID': 'nunique' if 'è®¢å•ID' in df.columns else 'count',
            'å®æ”¶ä»·æ ¼': 'sum' if 'å®æ”¶ä»·æ ¼' in df.columns else lambda x: 0,
            'åˆ©æ¶¦é¢': 'sum' if 'åˆ©æ¶¦é¢' in df.columns else lambda x: 0,
        }).reset_index()
        daily.columns = ['date', 'order_count', 'amount', 'profit']
    
    daily = daily.sort_values('date')
    
    # è®¡ç®—å®¢å•ä»·
    daily['avg_value'] = daily.apply(
        lambda r: r['amount'] / r['order_count'] if r['order_count'] > 0 else 0, axis=1
    )
    
    # ğŸ†• è®¡ç®—åˆ©æ¶¦ç‡ï¼ˆä¸Dashç‰ˆæœ¬ä¸€è‡´ï¼šåˆ©æ¶¦ç‡ = æ€»åˆ©æ¶¦ / é”€å”®é¢ * 100ï¼‰
    daily['profit_rate'] = daily.apply(
        lambda r: round(r['profit'] / r['amount'] * 100, 2) if r['amount'] > 0 else 0, axis=1
    )
    
    print(f"âš ï¸ [åŸå§‹æŸ¥è¯¢] trendæŸ¥è¯¢è€—æ—¶: {(time.time()-query_start)*1000:.1f}ms")
    
    return {
        "success": True,
        "data": {
            "dates": [str(d) for d in daily['date'].tolist()],
            "order_counts": [int(x) for x in daily['order_count'].tolist()],
            "amounts": [round(float(x), 2) for x in daily['amount'].tolist()],
            "profits": [round(float(x), 2) for x in daily['profit'].tolist()],
            "avg_values": [round(float(x), 2) for x in daily['avg_value'].tolist()],
            "profit_rates": [float(x) for x in daily['profit_rate'].tolist()],
        }
    }


@router.get("/list")
async def get_order_list(
    page: int = Query(1, ge=1, description="é¡µç "),
    page_size: int = Query(20, ge=1, le=100, description="æ¯é¡µæ•°é‡"),
    store_name: Optional[str] = Query(None, description="é—¨åº—ç­›é€‰"),
    channel: Optional[str] = Query(None, description="æ¸ é“ç­›é€‰"),
    start_date: Optional[date] = Query(None, description="å¼€å§‹æ—¥æœŸ"),
    end_date: Optional[date] = Query(None, description="ç»“æŸæ—¥æœŸ"),
    sort_by: str = Query("date", description="æ’åºå­—æ®µ"),
    sort_order: str = Query("desc", description="æ’åºæ–¹å‘")
) -> Dict[str, Any]:
    """
    è·å–è®¢å•åˆ—è¡¨ï¼ˆæ”¯æŒåˆ†é¡µå’Œç­›é€‰ï¼‰
    """
    # æŒ‰é—¨åº—åŠ è½½æ•°æ®ï¼ˆåˆ©ç”¨ç¼“å­˜ï¼‰
    df = get_order_data(store_name)
    if df.empty:
        return {"success": True, "data": [], "total": 0, "page": page, "page_size": page_size, "total_pages": 0}
    
    # æ¸ é“ç­›é€‰
    if channel and 'æ¸ é“' in df.columns:
        df = df[df['æ¸ é“'] == channel]
    
    # æ—¥æœŸç­›é€‰
    if 'æ—¥æœŸ' in df.columns:
        df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'], errors='coerce')
        if start_date:
            df = df[df['æ—¥æœŸ'].dt.date >= start_date]
        if end_date:
            df = df[df['æ—¥æœŸ'].dt.date <= end_date]
    
    if df.empty:
        return {"success": True, "data": [], "total": 0, "page": page, "page_size": page_size, "total_pages": 0}
    
    # è®¡ç®—è®¢å•çº§æŒ‡æ ‡
    order_agg = calculate_order_metrics(df)
    
    # æ’åº
    sort_col_map = {
        'date': 'æ—¥æœŸ',
        'amount': 'å®æ”¶ä»·æ ¼',
        'profit': 'è®¢å•å®é™…åˆ©æ¶¦',
    }
    sort_col = sort_col_map.get(sort_by, 'æ—¥æœŸ')
    if sort_col in order_agg.columns:
        order_agg = order_agg.sort_values(sort_col, ascending=(sort_order == 'asc'))
    
    # åˆ†é¡µ
    total = len(order_agg)
    start = (page - 1) * page_size
    end = start + page_size
    page_data = order_agg.iloc[start:end]
    
    # é€‰æ‹©å±•ç¤ºå­—æ®µ
    result = []
    for _, row in page_data.iterrows():
        item = {
            "order_id": row.get('è®¢å•ID', ''),
            "order_date": str(row.get('æ—¥æœŸ', ''))[:10] if pd.notna(row.get('æ—¥æœŸ')) else '',
            "store_name": row.get('é—¨åº—åç§°', ''),
            "channel": row.get('æ¸ é“', ''),
            "amount": round(float(row.get('å®æ”¶ä»·æ ¼', 0)), 2),
            "profit": round(float(row.get('è®¢å•å®é™…åˆ©æ¶¦', 0)), 2),
            "profit_rate": round(float(row.get('è®¢å•å®é™…åˆ©æ¶¦', 0)) / float(row.get('å®æ”¶ä»·æ ¼', 1)) * 100, 2) if row.get('å®æ”¶ä»·æ ¼', 0) > 0 else 0,
        }
        result.append(item)
    
    return {
        "success": True,
        "data": result,
        "total": total,
        "page": page,
        "page_size": page_size,
        "total_pages": (total + page_size - 1) // page_size
    }


@router.get("/stores")
async def get_store_list() -> Dict[str, Any]:
    """è·å–é—¨åº—åˆ—è¡¨ï¼ˆç›´æ¥ä»æ•°æ®åº“æŸ¥è¯¢ï¼‰"""
    try:
        from database.connection import SessionLocal
        from database.models import Order
        from sqlalchemy import distinct
        
        session = SessionLocal()
        try:
            # ç›´æ¥æŸ¥è¯¢æ•°æ®åº“ä¸­çš„é—¨åº—åˆ—è¡¨
            stores = session.query(distinct(Order.store_name)).filter(
                Order.store_name.isnot(None)
            ).all()
            
            store_list = sorted([s[0] for s in stores if s[0]])
            print(f"âœ… é—¨åº—åˆ—è¡¨æŸ¥è¯¢æˆåŠŸ: {len(store_list)} ä¸ªé—¨åº—")
            return {"success": True, "data": store_list}
        finally:
            session.close()
    except Exception as e:
        print(f"âš ï¸ é—¨åº—åˆ—è¡¨æŸ¥è¯¢å¤±è´¥: {e}")
        # å¤‡ç”¨æ–¹æ¡ˆï¼šä»ç¼“å­˜æ•°æ®è·å–
        df = get_order_data()
        if df.empty or 'é—¨åº—åç§°' not in df.columns:
            return {"success": True, "data": []}
        
        stores = sorted(df['é—¨åº—åç§°'].dropna().unique().tolist())
        return {"success": True, "data": stores}


@router.get("/channel-list")
async def get_channel_list(
    store_name: Optional[str] = Query(None, description="é—¨åº—åç§°ç­›é€‰")
) -> Dict[str, Any]:
    """è·å–æ¸ é“åˆ—è¡¨ï¼ˆç›´æ¥ä»æ•°æ®åº“æŸ¥è¯¢ï¼Œæ”¯æŒé—¨åº—ç­›é€‰ï¼‰"""
    try:
        from database.connection import SessionLocal
        from database.models import Order
        from sqlalchemy import distinct
        
        session = SessionLocal()
        try:
            # æ„å»ºæŸ¥è¯¢
            query = session.query(distinct(Order.channel)).filter(
                Order.channel.isnot(None)
            )
            
            # å¦‚æœæŒ‡å®šäº†é—¨åº—ï¼Œåªè¿”å›è¯¥é—¨åº—çš„æ¸ é“
            if store_name:
                query = query.filter(Order.store_name == store_name)
            
            channels = query.all()
            
            channel_list = sorted([c[0] for c in channels if c[0]])
            print(f"âœ… æ¸ é“åˆ—è¡¨æŸ¥è¯¢æˆåŠŸ: {len(channel_list)} ä¸ªæ¸ é“, é—¨åº—: {store_name or 'å…¨éƒ¨'}")
            return {"success": True, "data": channel_list}
        finally:
            session.close()
    except Exception as e:
        print(f"âš ï¸ æ¸ é“åˆ—è¡¨æŸ¥è¯¢å¤±è´¥: {e}")
        # å¤‡ç”¨æ–¹æ¡ˆï¼šä»ç¼“å­˜æ•°æ®è·å–
        df = get_order_data(store_name)
        if df.empty or 'æ¸ é“' not in df.columns:
            return {"success": True, "data": []}
        
        channels = sorted(df['æ¸ é“'].dropna().unique().tolist())
        return {"success": True, "data": channels}


@router.get("/profit-distribution")
async def get_profit_distribution(
    store_name: Optional[str] = Query(None, description="é—¨åº—åç§°ç­›é€‰"),
    start_date: Optional[date] = Query(None, description="å¼€å§‹æ—¥æœŸ"),
    end_date: Optional[date] = Query(None, description="ç»“æŸæ—¥æœŸ")
) -> Dict[str, Any]:
    """
    è·å–åˆ©æ¶¦åŒºé—´åˆ†å¸ƒ
    
    ä¸è€ç‰ˆæœ¬çš„åˆ©æ¶¦åŒºé—´åˆ†å¸ƒå›¾ä¸€è‡´
    """
    # æŒ‰é—¨åº—åŠ è½½æ•°æ®ï¼ˆåˆ©ç”¨ç¼“å­˜ï¼‰
    df = get_order_data(store_name)
    if df.empty:
        return {"success": True, "data": {"labels": [], "counts": [], "colors": []}}
    
    # æ—¥æœŸç­›é€‰
    if 'æ—¥æœŸ' in df.columns:
        df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'], errors='coerce')
        if start_date:
            df = df[df['æ—¥æœŸ'].dt.date >= start_date]
        if end_date:
            df = df[df['æ—¥æœŸ'].dt.date <= end_date]
    
    if df.empty:
        return {"success": True, "data": {"labels": [], "counts": [], "colors": []}}
    
    # è®¡ç®—è®¢å•çº§æŒ‡æ ‡
    order_agg = calculate_order_metrics(df)
    
    if order_agg.empty or 'è®¢å•å®é™…åˆ©æ¶¦' not in order_agg.columns:
        return {"success": True, "data": {"labels": [], "counts": [], "colors": []}}
    
    profit_values = order_agg['è®¢å•å®é™…åˆ©æ¶¦'].values
    
    # å®šä¹‰åˆ©æ¶¦åŒºé—´
    bins = [-np.inf, -100, -50, -20, 0, 20, 50, 100, np.inf]
    labels = ['é‡åº¦äºæŸ(<-100)', 'ä¸­åº¦äºæŸ(-100~-50)', 'è½»åº¦äºæŸ(-50~-20)', 
              'å¾®äºæŸ(-20~0)', 'å¾®ç›ˆåˆ©(0~20)', 'è‰¯å¥½ç›ˆåˆ©(20~50)', 
              'ä¼˜ç§€ç›ˆåˆ©(50~100)', 'è¶…çº§ç›ˆåˆ©(>100)']
    
    # ç»Ÿè®¡å„åŒºé—´è®¢å•æ•°
    counts, _ = np.histogram(profit_values, bins=bins)
    
    # é¢œè‰²ï¼ˆäºæŸçº¢è‰²ç³»ï¼Œç›ˆåˆ©ç»¿è‰²ç³»ï¼‰
    colors = ['#C0392B', '#E74C3C', '#FF6B6B', '#FFA07A',
              '#98FB98', '#2ECC71', '#27AE60', '#229954']
    
    return {
        "success": True,
        "data": {
            "labels": labels,
            "counts": [int(c) for c in counts.tolist()],
            "colors": colors,
            "total_orders": len(profit_values)
        }
    }


@router.get("/price-distribution")
async def get_price_distribution(
    store_name: Optional[str] = Query(None, description="é—¨åº—åç§°ç­›é€‰"),
    start_date: Optional[date] = Query(None, description="å¼€å§‹æ—¥æœŸ"),
    end_date: Optional[date] = Query(None, description="ç»“æŸæ—¥æœŸ")
) -> Dict[str, Any]:
    """
    è·å–å®¢å•ä»·åŒºé—´åˆ†å¸ƒï¼ˆä¸è€ç‰ˆæœ¬å®Œå…¨ä¸€è‡´ï¼‰
    
    8ä¸ªæ ‡å‡†ä»·æ ¼åŒºé—´:
    - Â¥0-10, Â¥10-20, Â¥20-30, Â¥30-40, Â¥40-50, Â¥50-100, Â¥100-200, Â¥200+
    
    4å¤§ä¸šåŠ¡ä»·æ ¼ç»„:
    - æµé‡åŒº (< Â¥15): å¼•æµä½ä»·å•†å“
    - ä¸»æµåŒº (Â¥15-30): æ—¥å¸¸é«˜é¢‘å•†å“
    - åˆ©æ¶¦åŒº (Â¥30-50): æ¯›åˆ©è´¡çŒ®ä¸»åŠ›
    - é«˜ä»·åŒº (â‰¥ Â¥50): é«˜ç«¯/å¤§å•å•†å“
    """
    # æŒ‰é—¨åº—åŠ è½½æ•°æ®ï¼ˆåˆ©ç”¨ç¼“å­˜ï¼‰
    df = get_order_data(store_name)
    if df.empty:
        return {"success": True, "data": {"price_ranges": [], "business_zones": {}, "avg_basket_depth": 0}}
    
    # æ—¥æœŸç­›é€‰
    if 'æ—¥æœŸ' in df.columns:
        df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'], errors='coerce')
        if start_date:
            df = df[df['æ—¥æœŸ'].dt.date >= start_date]
        if end_date:
            df = df[df['æ—¥æœŸ'].dt.date <= end_date]
    
    if df.empty:
        return {"success": True, "data": {"price_ranges": [], "business_zones": {}, "avg_basket_depth": 0}}
    
    # è®¡ç®—è®¢å•çº§æŒ‡æ ‡
    order_agg = calculate_order_metrics(df)
    
    if order_agg.empty or 'å®æ”¶ä»·æ ¼' not in order_agg.columns:
        return {"success": True, "data": {"price_ranges": [], "business_zones": {}, "avg_basket_depth": 0}}
    
    prices = order_agg['å®æ”¶ä»·æ ¼'].values
    total_orders = len(prices)
    
    # 8ä¸ªæ ‡å‡†ä»·æ ¼åŒºé—´
    price_ranges = [
        (0, 10, 'Â¥0-10'),
        (10, 20, 'Â¥10-20'),
        (20, 30, 'Â¥20-30'),
        (30, 40, 'Â¥30-40'),
        (40, 50, 'Â¥40-50'),
        (50, 100, 'Â¥50-100'),
        (100, 200, 'Â¥100-200'),
        (200, float('inf'), 'Â¥200+')
    ]
    
    range_data = []
    for low, high, label in price_ranges:
        if high == float('inf'):
            count = int(np.sum(prices >= low))
        else:
            count = int(np.sum((prices >= low) & (prices < high)))
        
        ratio = round(count / total_orders * 100, 2) if total_orders > 0 else 0
        range_data.append({
            "label": label,
            "count": count,
            "ratio": ratio,
            "color": get_price_range_color(low)
        })
    
    # 4å¤§ä¸šåŠ¡ä»·æ ¼ç»„
    flow_zone = int(np.sum(prices < 15))  # æµé‡åŒº
    main_zone = int(np.sum((prices >= 15) & (prices < 30)))  # ä¸»æµåŒº
    profit_zone = int(np.sum((prices >= 30) & (prices < 50)))  # åˆ©æ¶¦åŒº
    high_zone = int(np.sum(prices >= 50))  # é«˜ä»·åŒº
    
    business_zones = {
        "flow_zone": {"label": "æµé‡åŒº(<Â¥15)", "count": flow_zone, "ratio": round(flow_zone / total_orders * 100, 2) if total_orders > 0 else 0},
        "main_zone": {"label": "ä¸»æµåŒº(Â¥15-30)", "count": main_zone, "ratio": round(main_zone / total_orders * 100, 2) if total_orders > 0 else 0},
        "profit_zone": {"label": "åˆ©æ¶¦åŒº(Â¥30-50)", "count": profit_zone, "ratio": round(profit_zone / total_orders * 100, 2) if total_orders > 0 else 0},
        "high_zone": {"label": "é«˜ä»·åŒº(â‰¥Â¥50)", "count": high_zone, "ratio": round(high_zone / total_orders * 100, 2) if total_orders > 0 else 0},
    }
    
    # è´­ç‰©ç¯®æ·±åº¦ï¼ˆå¹³å‡SKUæ•°ï¼‰
    if 'è®¢å•ID' in df.columns:
        basket_depth = df.groupby('è®¢å•ID').size().mean()
    else:
        basket_depth = 1.0
    
    return {
        "success": True,
        "data": {
            "price_ranges": range_data,
            "business_zones": business_zones,
            "avg_basket_depth": round(float(basket_depth), 2),
            "total_orders": total_orders,
            "avg_order_value": round(float(np.mean(prices)), 2) if len(prices) > 0 else 0
        }
    }


def get_price_range_color(price: float) -> str:
    """æ ¹æ®ä»·æ ¼è¿”å›é¢œè‰²"""
    if price < 15:
        return "#3498DB"  # è“è‰² - æµé‡åŒº
    elif price < 30:
        return "#27AE60"  # ç»¿è‰² - ä¸»æµåŒº
    elif price < 50:
        return "#F39C12"  # æ©™è‰² - åˆ©æ¶¦åŒº
    else:
        return "#9B59B6"  # ç´«è‰² - é«˜ä»·åŒº


@router.get("/category-trend")
async def get_category_trend(
    store_name: Optional[str] = Query(None, description="é—¨åº—åç§°ç­›é€‰"),
    channel: Optional[str] = Query(None, description="æ¸ é“ç­›é€‰"),
    weeks: int = Query(4, ge=1, le=12, description="ç»Ÿè®¡å‘¨æ•°")
) -> Dict[str, Any]:
    """
    è·å–ä¸€çº§åˆ†ç±»é”€å”®è¶‹åŠ¿ï¼ˆä¸è€ç‰ˆæœ¬å®Œå…¨ä¸€è‡´ï¼‰
    
    è¿”å›å„ä¸€çº§åˆ†ç±»çš„å‘¨é”€å”®è¶‹åŠ¿æ•°æ®
    """
    # æŒ‰é—¨åº—åŠ è½½æ•°æ®ï¼ˆåˆ©ç”¨ç¼“å­˜ï¼‰
    df = get_order_data(store_name)
    if df.empty:
        return {"success": True, "data": {"categories": [], "weeks": [], "series": []}}
    
    # æ¸ é“ç­›é€‰
    if channel and 'æ¸ é“' in df.columns:
        df = df[df['æ¸ é“'] == channel]
    
    if 'æ—¥æœŸ' not in df.columns or 'ä¸€çº§åˆ†ç±»å' not in df.columns:
        return {"success": True, "data": {"categories": [], "weeks": [], "series": []}}
    
    df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'], errors='coerce')
    df = df.dropna(subset=['æ—¥æœŸ'])
    
    if df.empty:
        return {"success": True, "data": {"categories": [], "weeks": [], "series": []}}
    
    # ç­›é€‰æœ€è¿‘Nå‘¨
    max_date = df['æ—¥æœŸ'].max()
    if pd.isna(max_date):
        return {"success": True, "data": {"categories": [], "weeks": [], "series": []}}
    
    min_date = max_date - timedelta(weeks=weeks)
    df = df[df['æ—¥æœŸ'] >= min_date]
    
    if df.empty:
        return {"success": True, "data": {"categories": [], "weeks": [], "series": []}}
    
    # æ·»åŠ å‘¨æ ‡è¯†
    df['å‘¨'] = df['æ—¥æœŸ'].dt.to_period('W').apply(lambda x: x.start_time.strftime('%Y-%m-%d'))
    
    # æŒ‰ä¸€çº§åˆ†ç±»å’Œå‘¨èšåˆ
    sales_field = 'å®æ”¶ä»·æ ¼' if 'å®æ”¶ä»·æ ¼' in df.columns else 'å•†å“å®å”®ä»·'
    if sales_field not in df.columns:
        return {"success": True, "data": {"categories": [], "weeks": [], "series": []}}
    
    category_weekly = df.groupby(['ä¸€çº§åˆ†ç±»å', 'å‘¨'])[sales_field].sum().reset_index()
    category_weekly.columns = ['category', 'week', 'sales']
    
    # è·å–æ‰€æœ‰åˆ†ç±»å’Œå‘¨
    categories = sorted(category_weekly['category'].unique().tolist())
    weeks_list = sorted(category_weekly['week'].unique().tolist())
    
    # æ„å»ºç³»åˆ—æ•°æ®
    series = []
    colors = ['#5470c6', '#91cc75', '#fac858', '#ee6666', '#73c0de', '#3ba272', '#fc8452', '#9a60b4']
    
    for i, cat in enumerate(categories):
        cat_data = category_weekly[category_weekly['category'] == cat]
        values = []
        for week in weeks_list:
            week_val = cat_data[cat_data['week'] == week]['sales'].values
            values.append(round(float(week_val[0]), 2) if len(week_val) > 0 else 0)
        
        series.append({
            "name": cat,
            "data": values,
            "color": colors[i % len(colors)]
        })
    
    return {
        "success": True,
        "data": {
            "categories": categories,
            "weeks": weeks_list,
            "series": series
        }
    }


@router.get("/comparison")
async def get_order_comparison(
    store_name: Optional[str] = Query(None, description="é—¨åº—åç§°ç­›é€‰"),
    start_date: Optional[date] = Query(None, description="å¼€å§‹æ—¥æœŸ"),
    end_date: Optional[date] = Query(None, description="ç»“æŸæ—¥æœŸ")
) -> Dict[str, Any]:
    """
    è·å–è®¢å•ç¯æ¯”æ•°æ®ï¼ˆä¸è€ç‰ˆæœ¬å®Œå…¨ä¸€è‡´ï¼‰
    
    è®¡ç®—å½“å‰å‘¨æœŸä¸ä¸Šä¸€å‘¨æœŸçš„ç¯æ¯”å˜åŒ–:
    - è®¢å•æ•°ç¯æ¯”
    - é”€å”®é¢ç¯æ¯”
    - åˆ©æ¶¦ç¯æ¯”
    - å®¢å•ä»·ç¯æ¯”
    - åˆ©æ¶¦ç‡ç¯æ¯”ï¼ˆä½¿ç”¨å·®å€¼ï¼‰
    - åŠ¨é”€å•†å“æ•°ç¯æ¯”
    
    æ³¨æ„ï¼šå¦‚æœä¸ä¼ æ—¥æœŸå‚æ•°ï¼Œä½¿ç”¨æ•°æ®çš„å®Œæ•´æ—¥æœŸèŒƒå›´ä½œä¸ºå½“å‰å‘¨æœŸ
    """
    # æŒ‰é—¨åº—åŠ è½½æ•°æ®ï¼ˆåˆ©ç”¨ç¼“å­˜ï¼‰
    df = get_order_data(store_name)
    if df.empty:
        return {"success": True, "data": {"current": {}, "previous": {}, "changes": {}, "period": {}}}
    
    if 'æ—¥æœŸ' not in df.columns:
        return {"success": True, "data": {"current": {}, "previous": {}, "changes": {}, "period": {}}}
    
    df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'], errors='coerce')
    df = df.dropna(subset=['æ—¥æœŸ'])  # ç§»é™¤æ— æ•ˆæ—¥æœŸ
    
    if df.empty:
        return {"success": True, "data": {"current": {}, "previous": {}, "changes": {}, "period": {}}}
    
    # ç¡®å®šæ—¥æœŸèŒƒå›´
    min_date_in_data = df['æ—¥æœŸ'].min()
    max_date_in_data = df['æ—¥æœŸ'].max()
    
    if pd.isna(max_date_in_data) or pd.isna(min_date_in_data):
        return {"success": True, "data": {"current": {}, "previous": {}, "changes": {}, "period": {}}}
    
    # å¦‚æœä¸ä¼ æ—¥æœŸå‚æ•°ï¼Œä½¿ç”¨æ•°æ®çš„å®Œæ•´æ—¥æœŸèŒƒå›´ï¼ˆå…¨éƒ¨æ•°æ®ï¼‰
    if start_date is None and end_date is None:
        start_date = min_date_in_data.date()
        end_date = max_date_in_data.date()
    elif start_date is None:
        start_date = min_date_in_data.date()
    elif end_date is None:
        end_date = max_date_in_data.date()
    
    # è®¡ç®—å‘¨æœŸé•¿åº¦
    period_days = (end_date - start_date).days + 1
    if period_days <= 0:
        period_days = 1
    
    # è®¡ç®—ä¸Šä¸€å‘¨æœŸæ—¥æœŸèŒƒå›´
    prev_end_date = start_date - timedelta(days=1)
    prev_start_date = prev_end_date - timedelta(days=period_days - 1)
    
    # å½“å‰å‘¨æœŸæ•°æ®
    current_df = df[(df['æ—¥æœŸ'].dt.date >= start_date) & (df['æ—¥æœŸ'].dt.date <= end_date)]
    # ä¸Šä¸€å‘¨æœŸæ•°æ®
    prev_df = df[(df['æ—¥æœŸ'].dt.date >= prev_start_date) & (df['æ—¥æœŸ'].dt.date <= prev_end_date)]
    
    print(f"ğŸ“Š ç¯æ¯”è®¡ç®—: å½“å‰å‘¨æœŸ {start_date} ~ {end_date} ({len(current_df)}æ¡)")
    print(f"            ä¸Šä¸€å‘¨æœŸ {prev_start_date} ~ {prev_end_date} ({len(prev_df)}æ¡)")
    # è®¡ç®—å½“å‰å‘¨æœŸæŒ‡æ ‡
    current_metrics = calculate_period_metrics(current_df)
    # è®¡ç®—ä¸Šä¸€å‘¨æœŸæŒ‡æ ‡
    prev_metrics = calculate_period_metrics(prev_df)
    
    # è®¡ç®—ç¯æ¯”å˜åŒ–
    changes = {}
    for key in ['order_count', 'total_sales', 'total_profit', 'avg_order_value', 'active_products']:
        curr_val = current_metrics.get(key, 0)
        prev_val = prev_metrics.get(key, 0)
        if prev_val > 0:
            change_rate = round((curr_val - prev_val) / prev_val * 100, 2)
        elif curr_val > 0:
            change_rate = 100.0
        else:
            change_rate = 0.0
        changes[key] = change_rate
    
    # åˆ©æ¶¦ç‡ä½¿ç”¨å·®å€¼ï¼ˆä¸æ˜¯ç™¾åˆ†æ¯”å˜åŒ–ï¼‰
    changes['profit_rate'] = round(current_metrics.get('profit_rate', 0) - prev_metrics.get('profit_rate', 0), 2)
    
    return {
        "success": True,
        "data": {
            "current": current_metrics,
            "previous": prev_metrics,
            "changes": changes,
            "period": {
                "current_start": str(start_date),
                "current_end": str(end_date),
                "previous_start": str(prev_start_date),
                "previous_end": str(prev_end_date),
                "period_days": period_days
            }
        }
    }


def calculate_period_metrics(df: pd.DataFrame) -> Dict[str, Any]:
    """è®¡ç®—å•ä¸ªå‘¨æœŸçš„æŒ‡æ ‡"""
    if df.empty:
        return {
            "order_count": 0,
            "total_sales": 0,
            "total_profit": 0,
            "avg_order_value": 0,
            "profit_rate": 0,
            "active_products": 0
        }
    
    order_agg = calculate_order_metrics(df)
    
    order_count = len(order_agg)
    total_sales = order_agg['å®æ”¶ä»·æ ¼'].sum() if 'å®æ”¶ä»·æ ¼' in order_agg.columns else 0
    total_profit = order_agg['è®¢å•å®é™…åˆ©æ¶¦'].sum() if 'è®¢å•å®é™…åˆ©æ¶¦' in order_agg.columns else 0
    avg_order_value = total_sales / order_count if order_count > 0 else 0
    profit_rate = (total_profit / total_sales * 100) if total_sales > 0 else 0
    
    # åŠ¨é”€å•†å“æ•°
    sales_field = 'æœˆå”®' if 'æœˆå”®' in df.columns else 'é”€é‡'
    if 'å•†å“åç§°' in df.columns and sales_field in df.columns:
        active_products = df[df[sales_field] > 0]['å•†å“åç§°'].nunique()
    else:
        active_products = df['å•†å“åç§°'].nunique() if 'å•†å“åç§°' in df.columns else 0
    
    return {
        "order_count": int(order_count),
        "total_sales": round(float(total_sales), 2),
        "total_profit": round(float(total_profit), 2),
        "avg_order_value": round(float(avg_order_value), 2),
        "profit_rate": round(float(profit_rate), 2),
        "active_products": int(active_products)
    }


@router.get("/channel-comparison")
async def get_channel_comparison(
    store_name: Optional[str] = Query(None, description="é—¨åº—åç§°ç­›é€‰"),
    start_date: Optional[date] = Query(None, description="å¼€å§‹æ—¥æœŸ"),
    end_date: Optional[date] = Query(None, description="ç»“æŸæ—¥æœŸ")
) -> Dict[str, Any]:
    """
    è·å–æ¸ é“ç¯æ¯”å¯¹æ¯”æ•°æ®ï¼ˆä¸è€ç‰ˆæœ¬å®Œå…¨ä¸€è‡´ï¼‰
    
    æ¯ä¸ªæ¸ é“åŒ…å«:
    - è®¢å•æ•° + ç¯æ¯”
    - é”€å”®é¢ + ç¯æ¯”
    - åˆ©æ¶¦é¢ + ç¯æ¯”
    - å®¢å•ä»· + ç¯æ¯”
    - åˆ©æ¶¦ç‡ + ç¯æ¯”
    
    æ³¨æ„ï¼šæ’é™¤å’–å•¡æ¸ é“ï¼ˆç¾å›¢å’–å•¡åº—ã€é¥¿äº†ä¹ˆå’–å•¡åº—ï¼‰
    
    æ—¥æœŸé€»è¾‘ï¼š
    - å¦‚æœä¼ äº†æ—¥æœŸèŒƒå›´ï¼Œä½¿ç”¨ä¼ å…¥çš„æ—¥æœŸèŒƒå›´
    - å¦‚æœæ²¡ä¼ æ—¥æœŸèŒƒå›´ï¼Œä½¿ç”¨æ•°æ®çš„å®Œæ•´æ—¥æœŸèŒƒå›´
    - ç¯æ¯”è®¡ç®—ï¼šå½“å‰å‘¨æœŸ vs ä¸Šä¸€ä¸ªç›¸åŒé•¿åº¦çš„å‘¨æœŸ
    """
    # æŒ‰é—¨åº—åŠ è½½æ•°æ®ï¼ˆåˆ©ç”¨ç¼“å­˜ï¼‰
    df = get_order_data(store_name)
    if df.empty:
        return {"success": True, "data": []}
    
    if 'æ—¥æœŸ' not in df.columns or 'æ¸ é“' not in df.columns:
        return {"success": True, "data": []}
    
    df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'], errors='coerce')
    df = df.dropna(subset=['æ—¥æœŸ'])
    
    if df.empty:
        return {"success": True, "data": []}
    
    # æ’é™¤å’–å•¡æ¸ é“ï¼ˆä¸è€ç‰ˆæœ¬ä¸€è‡´ï¼‰
    CHANNELS_TO_REMOVE = ['ç¾å›¢å’–å•¡åº—', 'é¥¿äº†ä¹ˆå’–å•¡åº—']
    df = df[~df['æ¸ é“'].isin(CHANNELS_TO_REMOVE)]
    
    if df.empty:
        return {"success": True, "data": []}
    
    # ç¡®å®šæ—¥æœŸèŒƒå›´
    min_date = df['æ—¥æœŸ'].min()
    max_date = df['æ—¥æœŸ'].max()
    if pd.isna(max_date) or pd.isna(min_date):
        return {"success": True, "data": []}
    
    # åˆ¤æ–­æ˜¯å¦ä½¿ç”¨å…¨éƒ¨æ•°æ®ï¼ˆæ²¡æœ‰ä¼ æ—¥æœŸå‚æ•°ï¼‰
    use_full_data = (start_date is None and end_date is None)
    
    # å¦‚æœæ²¡æœ‰ä¼ æ—¥æœŸå‚æ•°ï¼Œä½¿ç”¨æ•°æ®çš„å®Œæ•´æ—¥æœŸèŒƒå›´
    if start_date is None and end_date is None:
        start_date = min_date.date()
        end_date = max_date.date()
    elif start_date is None:
        start_date = min_date.date()
    elif end_date is None:
        end_date = max_date.date()
    
    period_days = (end_date - start_date).days + 1
    if period_days <= 0:
        period_days = 1
    
    # è®¡ç®—ä¸Šä¸€å‘¨æœŸï¼ˆç”¨äºç¯æ¯”ï¼‰
    prev_end_date = start_date - timedelta(days=1)
    prev_start_date = prev_end_date - timedelta(days=period_days - 1)
    
    # å½“å‰å‘¨æœŸæ•°æ®
    current_df = df[(df['æ—¥æœŸ'].dt.date >= start_date) & (df['æ—¥æœŸ'].dt.date <= end_date)]
    # ä¸Šä¸€å‘¨æœŸæ•°æ®ï¼ˆç”¨äºç¯æ¯”ï¼‰
    prev_df = df[(df['æ—¥æœŸ'].dt.date >= prev_start_date) & (df['æ—¥æœŸ'].dt.date <= prev_end_date)]
    
    # å¦‚æœä½¿ç”¨å…¨éƒ¨æ•°æ®æˆ–ä¸Šä¸€å‘¨æœŸæ²¡æœ‰æ•°æ®ï¼Œåˆ™ä¸è®¡ç®—ç¯æ¯”
    has_prev_data = len(prev_df) > 0 and not use_full_data
    
    # è·å–å½“å‰å‘¨æœŸçš„æ‰€æœ‰æ¸ é“
    channels = current_df['æ¸ é“'].dropna().unique().tolist()
    
    result = []
    for channel in channels:
        # å½“å‰å‘¨æœŸæ¸ é“æ•°æ®
        curr_ch = current_df[current_df['æ¸ é“'] == channel]
        curr_metrics = calculate_channel_metrics(curr_ch)
        
        # å¦‚æœæœ‰ä¸Šä¸€å‘¨æœŸæ•°æ®ï¼Œè®¡ç®—ç¯æ¯”
        if has_prev_data:
            # ä¸Šä¸€å‘¨æœŸæ¸ é“æ•°æ®
            prev_ch = prev_df[prev_df['æ¸ é“'] == channel]
            prev_metrics = calculate_channel_metrics(prev_ch)
            
            # è®¡ç®—ç¯æ¯”
            changes = {}
            for key in ['order_count', 'amount', 'profit', 'avg_value']:
                curr_val = curr_metrics.get(key, 0)
                prev_val = prev_metrics.get(key, 0)
                if prev_val > 0:
                    changes[key] = round((curr_val - prev_val) / prev_val * 100, 2)
                elif curr_val > 0:
                    changes[key] = 100.0
                else:
                    changes[key] = 0.0
            
            # åˆ©æ¶¦ç‡ç”¨å·®å€¼
            changes['profit_rate'] = round(curr_metrics.get('profit_rate', 0) - prev_metrics.get('profit_rate', 0), 2)
        else:
            # æ²¡æœ‰ä¸Šä¸€å‘¨æœŸæ•°æ®ï¼Œç¯æ¯”æ˜¾ç¤ºä¸ºnull
            prev_metrics = {"order_count": 0, "amount": 0, "profit": 0, "avg_value": 0, "profit_rate": 0}
            changes = {"order_count": None, "amount": None, "profit": None, "avg_value": None, "profit_rate": None}
        
        # è¯„çº§ï¼ˆåŸºäºå½“å‰æ•°æ®ï¼‰
        rating = get_channel_rating(curr_metrics, changes if has_prev_data else {})
        
        result.append({
            "channel": channel,
            "current": curr_metrics,
            "previous": prev_metrics if has_prev_data else None,
            "changes": changes,
            "rating": rating
        })
    
    # æŒ‰è®¢å•æ•°æ’åº
    result.sort(key=lambda x: x['current'].get('order_count', 0), reverse=True)
    
    return {"success": True, "data": result}


def calculate_channel_metrics(df: pd.DataFrame) -> Dict[str, Any]:
    """
    è®¡ç®—å•ä¸ªæ¸ é“çš„å®Œæ•´æŒ‡æ ‡ï¼ˆåŒ…å«æˆæœ¬ç»“æ„ï¼‰
    
    ä¸è€ç‰ˆæœ¬Dashå®Œå…¨ä¸€è‡´çš„æŒ‡æ ‡:
    - åŸºç¡€æŒ‡æ ‡: è®¢å•æ•°ã€é”€å”®é¢ã€åˆ©æ¶¦ã€å®¢å•ä»·ã€åˆ©æ¶¦ç‡
    - æˆæœ¬ç»“æ„: å•†å“æˆæœ¬ã€è€—ææˆæœ¬ã€å•†å“å‡å…ã€æ´»åŠ¨è¡¥è´´ã€é…é€æˆæœ¬ã€å¹³å°æœåŠ¡è´¹
    - å•å‡ç»æµ: å•å‡åˆ©æ¶¦ã€å•å‡è¥é”€ã€å•å‡é…é€
    """
    if df.empty:
        return {
            "order_count": 0,
            "amount": 0,
            "profit": 0,
            "avg_value": 0,
            "profit_rate": 0,
            # æˆæœ¬ç»“æ„
            "product_cost": 0,
            "product_cost_rate": 0,
            "consumable_cost": 0,
            "consumable_cost_rate": 0,
            "product_discount": 0,
            "product_discount_rate": 0,
            "activity_subsidy": 0,
            "activity_subsidy_rate": 0,
            "delivery_cost": 0,
            "delivery_cost_rate": 0,
            "platform_fee": 0,
            "platform_fee_rate": 0,
            "total_cost_rate": 0,
            # å•å‡ç»æµ
            "avg_profit_per_order": 0,
            "avg_marketing_per_order": 0,
            "avg_delivery_per_order": 0,
        }
    
    order_agg = calculate_order_metrics(df)
    
    order_count = len(order_agg)
    amount = order_agg['å®æ”¶ä»·æ ¼'].sum() if 'å®æ”¶ä»·æ ¼' in order_agg.columns else 0
    profit = order_agg['è®¢å•å®é™…åˆ©æ¶¦'].sum() if 'è®¢å•å®é™…åˆ©æ¶¦' in order_agg.columns else 0
    avg_value = amount / order_count if order_count > 0 else 0
    profit_rate = (profit / amount * 100) if amount > 0 else 0
    
    # æˆæœ¬ç»“æ„è®¡ç®—
    # å•†å“æˆæœ¬ï¼ˆä»åŸå§‹dfè®¡ç®—ï¼Œå› ä¸ºæ˜¯å•†å“çº§å­—æ®µï¼‰
    product_cost = 0
    if 'å•†å“é‡‡è´­æˆæœ¬' in df.columns:
        product_cost = df['å•†å“é‡‡è´­æˆæœ¬'].sum()
    
    # è€—ææˆæœ¬ï¼ˆä¸€çº§åˆ†ç±»ä¸º"è€—æ"çš„å•†å“æˆæœ¬ï¼‰
    consumable_cost = 0
    if 'ä¸€çº§åˆ†ç±»å' in df.columns and 'å•†å“é‡‡è´­æˆæœ¬' in df.columns:
        consumable_mask = df['ä¸€çº§åˆ†ç±»å'] == 'è€—æ'
        consumable_cost = df.loc[consumable_mask, 'å•†å“é‡‡è´­æˆæœ¬'].sum()
        # ä»å•†å“æˆæœ¬ä¸­æ‰£é™¤è€—ææˆæœ¬
        product_cost = product_cost - consumable_cost
    
    # å•†å“å‡å…é‡‘é¢ï¼ˆè®¢å•çº§å­—æ®µï¼Œä»order_aggè®¡ç®—ï¼‰
    product_discount = 0
    if 'å•†å“å‡å…é‡‘é¢' in order_agg.columns:
        product_discount = order_agg['å•†å“å‡å…é‡‘é¢'].sum()
    
    # è¥é”€æˆæœ¬ï¼ˆ7ä¸ªè¥é”€å­—æ®µï¼Œå¯¹é½Dashç‰ˆæœ¬ï¼Œå‰”é™¤é…é€è´¹å‡å…é‡‘é¢ï¼‰
    # é…é€è´¹å‡å…é‡‘é¢å±äºé…é€æˆæœ¬ï¼Œä¸å±äºè¥é”€æˆæœ¬
    marketing_cost = 0
    marketing_fields = ['æ»¡å‡é‡‘é¢', 'å•†å“å‡å…é‡‘é¢', 'å•†å®¶ä»£é‡‘åˆ¸', 
                       'å•†å®¶æ‰¿æ‹…éƒ¨åˆ†åˆ¸', 'æ»¡èµ é‡‘é¢', 'å•†å®¶å…¶ä»–ä¼˜æƒ ', 'æ–°å®¢å‡å…é‡‘é¢']
    
    # è°ƒè¯•ï¼šæ‰“å°å„å­—æ®µçš„å€¼
    print(f"\n[DEBUG] è¥é”€æˆæœ¬è®¡ç®— - è®¢å•æ•°: {order_count}")
    for field in marketing_fields:
        if field in order_agg.columns:
            field_sum = order_agg[field].fillna(0).sum()
            marketing_cost += field_sum
            print(f"[DEBUG]   {field}: Â¥{field_sum:.2f}")
        else:
            print(f"[DEBUG]   {field}: å­—æ®µä¸å­˜åœ¨")
    print(f"[DEBUG] è¥é”€æˆæœ¬æ€»è®¡: Â¥{marketing_cost:.2f}")
    
    # æ´»åŠ¨è¡¥è´´ = è¥é”€æˆæœ¬ - å•†å“å‡å…
    activity_subsidy = max(0, marketing_cost - product_discount)
    
    # é…é€å‡€æˆæœ¬ = ç‰©æµé…é€è´¹ - ç”¨æˆ·æ”¯ä»˜é…é€è´¹ + é…é€è´¹å‡å…é‡‘é¢
    delivery_cost = 0
    if 'ç‰©æµé…é€è´¹' in order_agg.columns:
        delivery_cost = order_agg['ç‰©æµé…é€è´¹'].sum()
    if 'ç”¨æˆ·æ”¯ä»˜é…é€è´¹' in order_agg.columns:
        delivery_cost -= order_agg['ç”¨æˆ·æ”¯ä»˜é…é€è´¹'].sum()
    if 'é…é€è´¹å‡å…é‡‘é¢' in order_agg.columns:
        delivery_cost += order_agg['é…é€è´¹å‡å…é‡‘é¢'].sum()
    
    # å¹³å°æœåŠ¡è´¹
    platform_fee = 0
    if 'å¹³å°æœåŠ¡è´¹' in order_agg.columns:
        platform_fee = order_agg['å¹³å°æœåŠ¡è´¹'].sum()
    
    # è®¡ç®—æˆæœ¬ç‡
    product_cost_rate = (product_cost / amount * 100) if amount > 0 else 0
    consumable_cost_rate = (consumable_cost / amount * 100) if amount > 0 else 0
    product_discount_rate = (product_discount / amount * 100) if amount > 0 else 0
    activity_subsidy_rate = (activity_subsidy / amount * 100) if amount > 0 else 0
    delivery_cost_rate = (delivery_cost / amount * 100) if amount > 0 else 0
    platform_fee_rate = (platform_fee / amount * 100) if amount > 0 else 0
    
    # æ€»æˆæœ¬ç‡
    total_cost_rate = product_cost_rate + consumable_cost_rate + product_discount_rate + activity_subsidy_rate + delivery_cost_rate + platform_fee_rate
    
    # å•å‡ç»æµ
    avg_profit_per_order = profit / order_count if order_count > 0 else 0
    avg_marketing_per_order = marketing_cost / order_count if order_count > 0 else 0
    avg_delivery_per_order = delivery_cost / order_count if order_count > 0 else 0
    
    return {
        "order_count": int(order_count),
        "amount": round(float(amount), 2),
        "profit": round(float(profit), 2),
        "avg_value": round(float(avg_value), 2),
        "profit_rate": round(float(profit_rate), 2),
        # æˆæœ¬ç»“æ„
        "product_cost": round(float(product_cost), 2),
        "product_cost_rate": round(float(product_cost_rate), 2),
        "consumable_cost": round(float(consumable_cost), 2),
        "consumable_cost_rate": round(float(consumable_cost_rate), 2),
        "product_discount": round(float(product_discount), 2),
        "product_discount_rate": round(float(product_discount_rate), 2),
        "activity_subsidy": round(float(activity_subsidy), 2),
        "activity_subsidy_rate": round(float(activity_subsidy_rate), 2),
        "delivery_cost": round(float(delivery_cost), 2),
        "delivery_cost_rate": round(float(delivery_cost_rate), 2),
        "platform_fee": round(float(platform_fee), 2),
        "platform_fee_rate": round(float(platform_fee_rate), 2),
        "total_cost_rate": round(float(total_cost_rate), 2),
        # å•å‡ç»æµ
        "avg_profit_per_order": round(float(avg_profit_per_order), 2),
        "avg_marketing_per_order": round(float(avg_marketing_per_order), 2),
        "avg_delivery_per_order": round(float(avg_delivery_per_order), 2),
    }


def get_channel_rating(metrics: Dict, changes: Dict) -> str:
    """æ ¹æ®æŒ‡æ ‡å’Œç¯æ¯”è·å–æ¸ é“è¯„çº§"""
    profit_rate = metrics.get('profit_rate', 0)
    profit_change = changes.get('profit', 0)
    amount_change = changes.get('amount', 0)
    
    # ä¼˜ç§€: åˆ©æ¶¦ç‡>15% ä¸” (é”€å”®é¢ç¯æ¯”>0 æˆ– åˆ©æ¶¦ç¯æ¯”>0)
    if profit_rate > 15 and (amount_change > 0 or profit_change > 0):
        return "ä¼˜ç§€"
    # è‰¯å¥½: åˆ©æ¶¦ç‡>10% ä¸” é”€å”®é¢ç¯æ¯”>-10%
    elif profit_rate > 10 and amount_change > -10:
        return "è‰¯å¥½"
    # éœ€æ”¹è¿›
    else:
        return "éœ€æ”¹è¿›"


@router.get("/anomaly-detection")
async def get_anomaly_detection(
    store_name: Optional[str] = Query(None, description="é—¨åº—åç§°ç­›é€‰"),
    start_date: Optional[date] = Query(None, description="å¼€å§‹æ—¥æœŸ"),
    end_date: Optional[date] = Query(None, description="ç»“æŸæ—¥æœŸ")
) -> Dict[str, Any]:
    """
    è·å–å¼‚å¸¸è¯Šæ–­æ•°æ®ï¼ˆä¸è€ç‰ˆæœ¬å®Œå…¨ä¸€è‡´ï¼‰
    
    ä¸‰ç±»å¼‚å¸¸:
    1. ä½åˆ©æ¶¦ç‡è®¢å•ï¼ˆåˆ©æ¶¦ç‡<10%ï¼‰
    2. é«˜é…é€æˆæœ¬è®¢å•ï¼ˆé…é€æˆæœ¬å æ¯”>30%ï¼‰
    3. è´Ÿåˆ©æ¶¦è®¢å•ï¼ˆè®¢å•å®é™…åˆ©æ¶¦<0ï¼‰
    """
    # æŒ‰é—¨åº—åŠ è½½æ•°æ®ï¼ˆåˆ©ç”¨ç¼“å­˜ï¼‰
    df = get_order_data(store_name)
    if df.empty:
        return {"success": True, "data": {"low_profit": [], "high_delivery": [], "negative_profit": [], "summary": {}}}
    
    # æ—¥æœŸç­›é€‰
    if 'æ—¥æœŸ' in df.columns:
        df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'], errors='coerce')
        if start_date:
            df = df[df['æ—¥æœŸ'].dt.date >= start_date]
        if end_date:
            df = df[df['æ—¥æœŸ'].dt.date <= end_date]
    
    if df.empty:
        return {"success": True, "data": {"low_profit": [], "high_delivery": [], "negative_profit": [], "summary": {}}}
    
    order_agg = calculate_order_metrics(df)
    
    if order_agg.empty:
        return {"success": True, "data": {"low_profit": [], "high_delivery": [], "negative_profit": [], "summary": {}}}
    
    # è®¡ç®—åˆ©æ¶¦ç‡
    order_agg['åˆ©æ¶¦ç‡'] = order_agg.apply(
        lambda r: r['è®¢å•å®é™…åˆ©æ¶¦'] / r['å®æ”¶ä»·æ ¼'] * 100 if r.get('å®æ”¶ä»·æ ¼', 0) > 0 else 0, axis=1
    )
    
    # è®¡ç®—é…é€æˆæœ¬å æ¯”
    if 'ç‰©æµé…é€è´¹' in order_agg.columns and 'ç”¨æˆ·æ”¯ä»˜é…é€è´¹' in order_agg.columns:
        order_agg['é…é€å‡€æˆæœ¬'] = order_agg['ç‰©æµé…é€è´¹'] - order_agg.get('ç”¨æˆ·æ”¯ä»˜é…é€è´¹', 0) + order_agg.get('é…é€è´¹å‡å…é‡‘é¢', 0)
        order_agg['é…é€æˆæœ¬å æ¯”'] = order_agg.apply(
            lambda r: r['é…é€å‡€æˆæœ¬'] / r['å®æ”¶ä»·æ ¼'] * 100 if r.get('å®æ”¶ä»·æ ¼', 0) > 0 else 0, axis=1
        )
    else:
        order_agg['é…é€æˆæœ¬å æ¯”'] = 0
    
    total_orders = len(order_agg)
    
    # 1. ä½åˆ©æ¶¦ç‡è®¢å•ï¼ˆåˆ©æ¶¦ç‡<10%ï¼‰
    low_profit_df = order_agg[order_agg['åˆ©æ¶¦ç‡'] < 10].head(10)
    low_profit_list = []
    for _, row in low_profit_df.iterrows():
        low_profit_list.append({
            "order_id": row.get('è®¢å•ID', ''),
            "amount": round(float(row.get('å®æ”¶ä»·æ ¼', 0)), 2),
            "profit": round(float(row.get('è®¢å•å®é™…åˆ©æ¶¦', 0)), 2),
            "profit_rate": round(float(row.get('åˆ©æ¶¦ç‡', 0)), 2),
            "channel": row.get('æ¸ é“', ''),
        })
    
    # 2. é«˜é…é€æˆæœ¬è®¢å•ï¼ˆé…é€æˆæœ¬å æ¯”>30%ï¼‰
    high_delivery_df = order_agg[order_agg['é…é€æˆæœ¬å æ¯”'] > 30].head(10)
    high_delivery_list = []
    for _, row in high_delivery_df.iterrows():
        high_delivery_list.append({
            "order_id": row.get('è®¢å•ID', ''),
            "amount": round(float(row.get('å®æ”¶ä»·æ ¼', 0)), 2),
            "delivery_cost": round(float(row.get('é…é€å‡€æˆæœ¬', 0)), 2),
            "delivery_ratio": round(float(row.get('é…é€æˆæœ¬å æ¯”', 0)), 2),
            "channel": row.get('æ¸ é“', ''),
        })
    
    # 3. è´Ÿåˆ©æ¶¦è®¢å•
    negative_profit_df = order_agg[order_agg['è®¢å•å®é™…åˆ©æ¶¦'] < 0].head(10)
    negative_profit_list = []
    for _, row in negative_profit_df.iterrows():
        negative_profit_list.append({
            "order_id": row.get('è®¢å•ID', ''),
            "amount": round(float(row.get('å®æ”¶ä»·æ ¼', 0)), 2),
            "profit": round(float(row.get('è®¢å•å®é™…åˆ©æ¶¦', 0)), 2),
            "loss": round(float(-row.get('è®¢å•å®é™…åˆ©æ¶¦', 0)), 2),
            "channel": row.get('æ¸ é“', ''),
        })
    
    # æ±‡æ€»ç»Ÿè®¡
    low_profit_count = len(order_agg[order_agg['åˆ©æ¶¦ç‡'] < 10])
    high_delivery_count = len(order_agg[order_agg['é…é€æˆæœ¬å æ¯”'] > 30])
    negative_profit_count = len(order_agg[order_agg['è®¢å•å®é™…åˆ©æ¶¦'] < 0])
    
    total_negative_loss = order_agg[order_agg['è®¢å•å®é™…åˆ©æ¶¦'] < 0]['è®¢å•å®é™…åˆ©æ¶¦'].sum()
    
    return {
        "success": True,
        "data": {
            "low_profit": low_profit_list,
            "high_delivery": high_delivery_list,
            "negative_profit": negative_profit_list,
            "summary": {
                "total_orders": total_orders,
                "low_profit_count": int(low_profit_count),
                "low_profit_ratio": round(low_profit_count / total_orders * 100, 2) if total_orders > 0 else 0,
                "high_delivery_count": int(high_delivery_count),
                "high_delivery_ratio": round(high_delivery_count / total_orders * 100, 2) if total_orders > 0 else 0,
                "negative_profit_count": int(negative_profit_count),
                "negative_profit_ratio": round(negative_profit_count / total_orders * 100, 2) if total_orders > 0 else 0,
                "total_loss": round(float(abs(total_negative_loss)), 2)
            }
        }
    }


# ==================== å¯¼å‡ºåŠŸèƒ½ ====================

from fastapi.responses import StreamingResponse
import io

@router.get("/export")
async def export_orders(
    store_name: Optional[str] = Query(None, description="é—¨åº—åç§°ç­›é€‰"),
    start_date: Optional[date] = Query(None, description="å¼€å§‹æ—¥æœŸ"),
    end_date: Optional[date] = Query(None, description="ç»“æŸæ—¥æœŸ")
):
    """
    å¯¼å‡ºè®¢å•æ•°æ®åˆ°Excel
    
    ä¸è€ç‰ˆæœ¬å¯¼å‡ºåŠŸèƒ½ä¸€è‡´ï¼ŒåŒ…å«:
    - è®¢å•ID
    - æ—¥æœŸ
    - é—¨åº—åç§°
    - æ¸ é“
    - å®æ”¶ä»·æ ¼
    - è®¢å•å®é™…åˆ©æ¶¦
    - åˆ©æ¶¦ç‡
    """
    # æŒ‰é—¨åº—åŠ è½½æ•°æ®ï¼ˆåˆ©ç”¨ç¼“å­˜ï¼‰
    df = get_order_data(store_name)
    
    if df.empty:
        # è¿”å›ç©ºExcel
        output = io.BytesIO()
        pd.DataFrame().to_excel(output, index=False, engine='openpyxl')
        output.seek(0)
        return StreamingResponse(
            output,
            media_type="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            headers={"Content-Disposition": "attachment; filename=è®¢å•æ•°æ®_ç©º.xlsx"}
        )
    
    # æ—¥æœŸç­›é€‰
    if 'æ—¥æœŸ' in df.columns:
        df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'], errors='coerce')
        if start_date:
            df = df[df['æ—¥æœŸ'].dt.date >= start_date]
        if end_date:
            df = df[df['æ—¥æœŸ'].dt.date <= end_date]
    
    if df.empty:
        output = io.BytesIO()
        pd.DataFrame().to_excel(output, index=False, engine='openpyxl')
        output.seek(0)
        return StreamingResponse(
            output,
            media_type="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            headers={"Content-Disposition": "attachment; filename=è®¢å•æ•°æ®_ç©º.xlsx"}
        )
    
    # è®¡ç®—è®¢å•çº§æŒ‡æ ‡
    order_agg = calculate_order_metrics(df)
    
    # è®¡ç®—åˆ©æ¶¦ç‡
    order_agg['åˆ©æ¶¦ç‡'] = order_agg.apply(
        lambda r: round(r['è®¢å•å®é™…åˆ©æ¶¦'] / r['å®æ”¶ä»·æ ¼'] * 100, 2) if r.get('å®æ”¶ä»·æ ¼', 0) > 0 else 0, 
        axis=1
    )
    
    # é€‰æ‹©å¯¼å‡ºå­—æ®µ
    export_cols = ['è®¢å•ID', 'æ—¥æœŸ', 'é—¨åº—åç§°', 'æ¸ é“', 'å®æ”¶ä»·æ ¼', 'è®¢å•å®é™…åˆ©æ¶¦', 'åˆ©æ¶¦ç‡']
    available_cols = [c for c in export_cols if c in order_agg.columns]
    export_df = order_agg[available_cols].copy()
    
    # æ ¼å¼åŒ–æ—¥æœŸ
    if 'æ—¥æœŸ' in export_df.columns:
        export_df['æ—¥æœŸ'] = pd.to_datetime(export_df['æ—¥æœŸ']).dt.strftime('%Y-%m-%d')
    
    # é‡å‘½ååˆ—ï¼ˆæ›´å‹å¥½çš„æ˜¾ç¤ºåï¼‰
    column_rename = {
        'è®¢å•ID': 'è®¢å•ç¼–å·',
        'æ—¥æœŸ': 'è®¢å•æ—¥æœŸ',
        'é—¨åº—åç§°': 'é—¨åº—',
        'æ¸ é“': 'é”€å”®æ¸ é“',
        'å®æ”¶ä»·æ ¼': 'è®¢å•é‡‘é¢(å…ƒ)',
        'è®¢å•å®é™…åˆ©æ¶¦': 'åˆ©æ¶¦(å…ƒ)',
        'åˆ©æ¶¦ç‡': 'åˆ©æ¶¦ç‡(%)'
    }
    export_df = export_df.rename(columns={k: v for k, v in column_rename.items() if k in export_df.columns})
    
    # ç”ŸæˆExcel
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        export_df.to_excel(writer, index=False, sheet_name='è®¢å•æ•°æ®')
        
        # è°ƒæ•´åˆ—å®½
        worksheet = writer.sheets['è®¢å•æ•°æ®']
        for idx, col in enumerate(export_df.columns):
            max_length = max(
                export_df[col].astype(str).map(len).max() if len(export_df) > 0 else 0,
                len(col)
            ) + 2
            worksheet.column_dimensions[chr(65 + idx)].width = min(max_length, 30)
    
    output.seek(0)
    
    # ç”Ÿæˆæ–‡ä»¶å
    filename = f"è®¢å•ç»è¥åˆ†ææŠ¥å‘Š_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx"
    
    return StreamingResponse(
        output,
        media_type="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        headers={"Content-Disposition": f"attachment; filename*=UTF-8''{filename}"}
    )



@router.get("/date-range")
async def get_date_range(
    store_name: Optional[str] = Query(None, description="é—¨åº—åç§°ç­›é€‰")
) -> Dict[str, Any]:
    """
    è·å–é—¨åº—æ•°æ®çš„æ—¥æœŸèŒƒå›´
    
    ç”¨äºå‰ç«¯æ—¥å†é€‰æ‹©å™¨é™åˆ¶å¯é€‰æ—¥æœŸèŒƒå›´
    """
    # æŒ‰é—¨åº—åŠ è½½æ•°æ®ï¼ˆåˆ©ç”¨ç¼“å­˜ï¼‰
    df = get_order_data(store_name)
    if df.empty:
        return {
            "success": True,
            "data": {
                "min_date": None,
                "max_date": None,
                "total_days": 0
            }
        }
    
    if 'æ—¥æœŸ' not in df.columns:
        return {
            "success": True,
            "data": {
                "min_date": None,
                "max_date": None,
                "total_days": 0
            }
        }
    
    df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'], errors='coerce')
    df = df.dropna(subset=['æ—¥æœŸ'])
    
    if df.empty:
        return {
            "success": True,
            "data": {
                "min_date": None,
                "max_date": None,
                "total_days": 0
            }
        }
    
    min_date = df['æ—¥æœŸ'].min()
    max_date = df['æ—¥æœŸ'].max()
    total_days = (max_date - min_date).days + 1
    
    return {
        "success": True,
        "data": {
            "min_date": min_date.strftime('%Y-%m-%d'),
            "max_date": max_date.strftime('%Y-%m-%d'),
            "total_days": total_days
        }
    }


# ==================== å›¾è¡¨è”åŠ¨APIï¼ˆé”€å”®è¶‹åŠ¿ä¸‹é’»ï¼‰ ====================

@router.get("/category-hourly-trend")
async def get_category_hourly_trend(
    store_name: Optional[str] = Query(None, description="é—¨åº—åç§°ç­›é€‰"),
    date: Optional[str] = Query(None, description="æŒ‡å®šæ—¥æœŸ(YYYY-MM-DDæˆ–MM-DDæ ¼å¼)"),
    start_date: Optional[str] = Query(None, description="æ—¥æœŸèŒƒå›´å¼€å§‹(YYYY-MM-DDæ ¼å¼)"),
    end_date: Optional[str] = Query(None, description="æ—¥æœŸèŒƒå›´ç»“æŸ(YYYY-MM-DDæ ¼å¼)"),
    channel: Optional[str] = Query(None, description="æ¸ é“ç­›é€‰")
) -> Dict[str, Any]:
    """
    è·å–åˆ†æ—¶æ®µå“ç±»èµ°åŠ¿æ•°æ®ï¼ˆé”€å”®è¶‹åŠ¿å›¾è¡¨è”åŠ¨ï¼‰
    
    - å¦‚æœæŒ‡å®šå•æ—¥æœŸ(date)ï¼šè¿”å›è¯¥æ—¥æœŸçš„24å°æ—¶åˆ†æ—¶æ®µå“ç±»é”€å”®æ•°æ®
    - å¦‚æœæŒ‡å®šæ—¥æœŸèŒƒå›´(start_date, end_date)ï¼šè¿”å›èŒƒå›´å†…æ¯æ—¥å“ç±»é”€å”®æ•°æ®
    - å¦‚æœä¸æŒ‡å®šæ—¥æœŸï¼šè¿”å›è¿‘7å¤©çš„æ¯æ—¥å“ç±»é”€å”®æ•°æ®
    
    ä¸Dashç‰ˆæœ¬ä¸€è‡´çš„è®¡ç®—é€»è¾‘ï¼š
    - ğŸ”´ å‰”é™¤è€—ææ•°æ®ï¼ˆä¸€çº§åˆ†ç±»å='è€—æ'ï¼Œå¦‚è´­ç‰©è¢‹ï¼‰
    - æŒ‰ä¸€çº§åˆ†ç±»èšåˆ
    - ä½¿ç”¨å®æ”¶ä»·æ ¼ä½œä¸ºé”€å”®é¢
    - æŒ‰é”€å”®é¢é™åºæ’åºï¼ˆé”€å”®é¢æœ€é«˜çš„åˆ†ç±»æ’åœ¨å‰é¢ï¼‰
    - è¿‡æ»¤æ‰ç©ºåˆ†ç±»å
    """
    # æŒ‰é—¨åº—åŠ è½½æ•°æ®
    df = get_order_data(store_name)
    if df.empty:
        return {"success": True, "data": {"labels": [], "categories": [], "series": []}}
    
    # ğŸ”´ å…³é”®ä¸šåŠ¡è§„åˆ™ï¼šå‰”é™¤è€—ææ•°æ®ï¼ˆè´­ç‰©è¢‹ç­‰ï¼‰
    # ä¸Dashç‰ˆæœ¬ä¿æŒä¸€è‡´ï¼šåˆ†ç±»åˆ†æä¸å±•ç¤ºè€—æ
    if 'ä¸€çº§åˆ†ç±»å' in df.columns:
        original_count = len(df)
        df = df[df['ä¸€çº§åˆ†ç±»å'] != 'è€—æ'].copy()
        filtered_count = original_count - len(df)
        if filtered_count > 0:
            print(f"[category-hourly-trend] å‰”é™¤è€—ææ•°æ®: {filtered_count} æ¡")
    
    # æ¸ é“ç­›é€‰
    if channel and channel != 'all' and 'æ¸ é“' in df.columns:
        df = df[df['æ¸ é“'] == channel]
    
    if 'æ—¥æœŸ' not in df.columns or 'ä¸€çº§åˆ†ç±»å' not in df.columns:
        return {"success": True, "data": {"labels": [], "categories": [], "series": []}}
    
    df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'], errors='coerce')
    df = df.dropna(subset=['æ—¥æœŸ'])
    
    # ğŸ†• å¤„ç†ç©ºåˆ†ç±»åï¼šå¡«å……ä¸º"æœªåˆ†ç±»"è€Œä¸æ˜¯è¿‡æ»¤æ‰
    df['ä¸€çº§åˆ†ç±»å'] = df['ä¸€çº§åˆ†ç±»å'].fillna('æœªåˆ†ç±»')
    df.loc[df['ä¸€çº§åˆ†ç±»å'].astype(str).isin(['', 'nan', 'None']), 'ä¸€çº§åˆ†ç±»å'] = 'æœªåˆ†ç±»'
    
    if df.empty:
        return {"success": True, "data": {"labels": [], "categories": [], "series": []}}
    
    # é”€å”®é¢å­—æ®µ
    sales_field = 'å®æ”¶ä»·æ ¼' if 'å®æ”¶ä»·æ ¼' in df.columns else 'å•†å“å®å”®ä»·'
    if sales_field not in df.columns:
        return {"success": True, "data": {"labels": [], "categories": [], "series": []}}
    
    # ğŸ†• è§£ææ—¥æœŸå‚æ•°ï¼šæ”¯æŒå•æ—¥æœŸæˆ–æ—¥æœŸèŒƒå›´
    target_date = None
    range_start = None
    range_end = None
    
    # ä¼˜å…ˆå¤„ç†æ—¥æœŸèŒƒå›´
    if start_date and end_date:
        try:
            range_start = pd.to_datetime(start_date)
            range_end = pd.to_datetime(end_date)
        except:
            range_start = None
            range_end = None
    elif date:
        try:
            # æ”¯æŒ MM-DD æ ¼å¼ï¼ˆä»æ•°æ®ä¸­æ¨æ–­å¹´ä»½ï¼‰
            if len(date) == 5 and '-' in date:
                max_date = df['æ—¥æœŸ'].max()
                year = max_date.year
                target_date = pd.to_datetime(f"{year}-{date}")
            else:
                target_date = pd.to_datetime(date)
        except:
            target_date = None
    
    # ğŸ†• æ—¥æœŸèŒƒå›´æ¨¡å¼ï¼šè¿”å›èŒƒå›´å†…æ¯æ—¥å“ç±»é”€å”®æ•°æ®
    # ğŸ”´ ç‰¹æ®Šå¤„ç†ï¼šå½“ start_date === end_date æ—¶ï¼Œè§†ä¸ºå•æ—¥æœŸæ¨¡å¼ï¼Œè¿”å›å°æ—¶æ•°æ®
    if range_start and range_end:
        # å¦‚æœæ˜¯åŒä¸€å¤©ï¼Œè½¬æ¢ä¸ºå•æ—¥æœŸæ¨¡å¼
        if range_start.date() == range_end.date():
            target_date = range_start
            range_start = None
            range_end = None
            # ç»§ç»­æ‰§è¡Œä¸‹é¢çš„å•æ—¥æœŸé€»è¾‘
        else:
            range_df = df[(df['æ—¥æœŸ'].dt.date >= range_start.date()) & (df['æ—¥æœŸ'].dt.date <= range_end.date())]
            if range_df.empty:
                return {"success": True, "data": {"labels": [], "categories": [], "series": [], "mode": "daily"}}
            
            # æŒ‰æ—¥æœŸå’Œåˆ†ç±»èšåˆ
            daily_category = range_df.groupby([range_df['æ—¥æœŸ'].dt.strftime('%m-%d'), 'ä¸€çº§åˆ†ç±»å'])[sales_field].sum().reset_index()
            daily_category.columns = ['date', 'category', 'revenue']
            
            # æŒ‰æ€»é”€å”®é¢é™åºæ’åºåˆ†ç±»
            category_totals = daily_category.groupby('category')['revenue'].sum().sort_values(ascending=False)
            categories = category_totals.index.tolist()
            
            # ç”Ÿæˆå®Œæ•´çš„æ—¥æœŸåºåˆ—
            all_dates = []
            current_date = range_start
            while current_date <= range_end:
                all_dates.append(current_date.strftime('%m-%d'))
                current_date += timedelta(days=1)
            
            # æ„å»ºç³»åˆ—æ•°æ®
            series = []
            colors = ['#8b5cf6', '#3b82f6', '#06b6d4', '#10b981', '#f59e0b', '#ef4444', '#ec4899', '#6366f1']
            
            for i, cat in enumerate(categories):
                cat_data = daily_category[daily_category['category'] == cat]
                values = []
                for d in all_dates:
                    day_val = cat_data[cat_data['date'] == d]['revenue'].values
                    values.append(round(float(day_val[0]), 2) if len(day_val) > 0 else 0)
                
                series.append({
                    "name": cat,
                    "data": values,
                    "color": colors[i % len(colors)]
                })
            
            return {
                "success": True,
                "data": {
                    "labels": all_dates,
                    "categories": categories,
                    "series": series,
                    "mode": "daily",
                    "start_date": range_start.strftime('%Y-%m-%d'),
                    "end_date": range_end.strftime('%Y-%m-%d')
                }
            }
    
    if target_date:
        # æŒ‡å®šæ—¥æœŸï¼šè¿”å›24å°æ—¶åˆ†æ—¶æ®µæ•°æ®
        day_df = df[df['æ—¥æœŸ'].dt.date == target_date.date()]
        if day_df.empty:
            return {"success": True, "data": {"labels": [], "categories": [], "series": [], "mode": "hourly"}}
        
        # æå–å°æ—¶
        if 'ä¸‹å•æ—¶é—´' in day_df.columns:
            day_df = day_df.copy()
            day_df['å°æ—¶'] = pd.to_datetime(day_df['ä¸‹å•æ—¶é—´'], errors='coerce').dt.hour
        else:
            day_df = day_df.copy()
            day_df['å°æ—¶'] = day_df['æ—¥æœŸ'].dt.hour
        
        # æŒ‰å°æ—¶å’Œåˆ†ç±»èšåˆ
        hourly_category = day_df.groupby(['å°æ—¶', 'ä¸€çº§åˆ†ç±»å'])[sales_field].sum().reset_index()
        hourly_category.columns = ['hour', 'category', 'revenue']
        
        # ğŸ†• æŒ‰æ€»é”€å”®é¢é™åºæ’åºåˆ†ç±»ï¼ˆè¿”å›æ‰€æœ‰åˆ†ç±»ï¼Œå‰ç«¯åšç­›é€‰ï¼‰
        category_totals = hourly_category.groupby('category')['revenue'].sum().sort_values(ascending=False)
        categories = category_totals.index.tolist()  # è¿”å›æ‰€æœ‰åˆ†ç±»
        
        hours = list(range(0, 24, 2))  # æ¯2å°æ—¶ä¸€ä¸ªç‚¹
        labels = [f"{h}:00" for h in hours]
        
        # æ„å»ºç³»åˆ—æ•°æ®ï¼ˆæ‰€æœ‰åˆ†ç±»ï¼‰
        series = []
        colors = ['#8b5cf6', '#3b82f6', '#06b6d4', '#10b981', '#f59e0b', '#ef4444', '#ec4899', '#6366f1']
        
        for i, cat in enumerate(categories):
            cat_data = hourly_category[hourly_category['category'] == cat]
            values = []
            for h in hours:
                # èšåˆ2å°æ—¶å†…çš„æ•°æ®
                hour_val = cat_data[(cat_data['hour'] >= h) & (cat_data['hour'] < h + 2)]['revenue'].sum()
                values.append(round(float(hour_val), 2))
            
            series.append({
                "name": cat,
                "data": values,
                "color": colors[i % len(colors)]
            })
        
        return {
            "success": True,
            "data": {
                "labels": labels,
                "categories": categories,
                "series": series,
                "mode": "hourly",
                "date": target_date.strftime('%Y-%m-%d')
            }
        }
    else:
        # ä¸æŒ‡å®šæ—¥æœŸï¼šè¿”å›è¿‘7å¤©æ¯æ—¥æ•°æ®
        max_date = df['æ—¥æœŸ'].max()
        # ğŸ†• ç¡®ä¿ä½¿ç”¨æ—¥æœŸéƒ¨åˆ†ï¼Œå»æ‰æ—¶é—´éƒ¨åˆ†ï¼Œé¿å…è¾¹ç•Œé—®é¢˜
        max_date_only = pd.Timestamp(max_date.date())
        min_date_only = max_date_only - timedelta(days=6)
        
        # ğŸ†• ä½¿ç”¨ .dt.date è¿›è¡Œæ—¥æœŸæ¯”è¾ƒï¼Œé¿å…æ—¶é—´éƒ¨åˆ†å½±å“
        week_df = df[(df['æ—¥æœŸ'].dt.date >= min_date_only.date()) & (df['æ—¥æœŸ'].dt.date <= max_date_only.date())]
        
        if week_df.empty:
            return {"success": True, "data": {"labels": [], "categories": [], "series": [], "mode": "daily"}}
        
        # æŒ‰æ—¥æœŸå’Œåˆ†ç±»èšåˆ
        daily_category = week_df.groupby([week_df['æ—¥æœŸ'].dt.strftime('%m-%d'), 'ä¸€çº§åˆ†ç±»å'])[sales_field].sum().reset_index()
        daily_category.columns = ['date', 'category', 'revenue']
        
        # ğŸ†• æŒ‰æ€»é”€å”®é¢é™åºæ’åºåˆ†ç±»ï¼ˆè¿”å›æ‰€æœ‰åˆ†ç±»ï¼Œå‰ç«¯åšç­›é€‰ï¼‰
        category_totals = daily_category.groupby('category')['revenue'].sum().sort_values(ascending=False)
        categories = category_totals.index.tolist()  # è¿”å›æ‰€æœ‰åˆ†ç±»
        
        # ğŸ†• ç”Ÿæˆå®Œæ•´çš„æ—¥æœŸåºåˆ—ï¼ˆç¡®ä¿æ¯å¤©éƒ½æœ‰æ•°æ®ç‚¹ï¼‰
        all_dates = []
        current_date = min_date_only
        while current_date <= max_date_only:
            all_dates.append(current_date.strftime('%m-%d'))
            current_date += timedelta(days=1)
        
        # æ„å»ºç³»åˆ—æ•°æ®ï¼ˆæ‰€æœ‰åˆ†ç±»ï¼‰
        series = []
        colors = ['#8b5cf6', '#3b82f6', '#06b6d4', '#10b981', '#f59e0b', '#ef4444', '#ec4899', '#6366f1']
        
        for i, cat in enumerate(categories):
            cat_data = daily_category[daily_category['category'] == cat]
            values = []
            for d in all_dates:
                day_val = cat_data[cat_data['date'] == d]['revenue'].values
                values.append(round(float(day_val[0]), 2) if len(day_val) > 0 else 0)
            
            series.append({
                "name": cat,
                "data": values,
                "color": colors[i % len(colors)]
            })
        
        return {
            "success": True,
            "data": {
                "labels": all_dates,
                "categories": categories,
                "series": series,
                "mode": "daily"
            }
        }


@router.get("/top-products-by-date")
async def get_top_products_by_date(
    store_name: Optional[str] = Query(None, description="é—¨åº—åç§°ç­›é€‰"),
    date: Optional[str] = Query(None, description="æŒ‡å®šæ—¥æœŸ(YYYY-MM-DDæˆ–MM-DDæ ¼å¼)"),
    start_date: Optional[str] = Query(None, description="æ—¥æœŸèŒƒå›´å¼€å§‹(YYYY-MM-DDæ ¼å¼)"),
    end_date: Optional[str] = Query(None, description="æ—¥æœŸèŒƒå›´ç»“æŸ(YYYY-MM-DDæ ¼å¼)"),
    channel: Optional[str] = Query(None, description="æ¸ é“ç­›é€‰"),
    sort_by: str = Query("quantity", description="æ’åºç»´åº¦: quantity/revenue/profit/loss"),
    limit: int = Query(15, ge=5, le=50, description="è¿”å›æ•°é‡")
) -> Dict[str, Any]:
    """
    è·å–å•†å“é”€é‡æ’è¡Œæ•°æ®ï¼ˆé”€å”®è¶‹åŠ¿å›¾è¡¨è”åŠ¨ï¼‰
    
    æ”¯æŒå¤šç»´åº¦æ’åºï¼š
    - quantity: é”€é‡æ¦œï¼ˆæŒ‰é”€é‡é™åºï¼‰
    - revenue: è¥æ”¶æ¦œï¼ˆæŒ‰é”€å”®é¢é™åºï¼‰
    - profit: æ¯›åˆ©æ¦œï¼ˆæŒ‰åˆ©æ¶¦é¢é™åºï¼Œæ­£å‘ï¼‰
    - loss: äºæŸæ¦œï¼ˆæŒ‰åˆ©æ¶¦é¢å‡åºï¼Œè´Ÿå‘ï¼‰
    
    æ”¯æŒå•æ—¥æœŸæˆ–æ—¥æœŸèŒƒå›´ç­›é€‰
    
    ä¸Dashç‰ˆæœ¬ä¸€è‡´çš„è®¡ç®—é€»è¾‘ï¼š
    - ğŸ”´ å‰”é™¤è€—ææ•°æ®ï¼ˆä¸€çº§åˆ†ç±»å='è€—æ'ï¼Œå¦‚è´­ç‰©è¢‹ï¼‰
    - åˆ©æ¶¦é¢ï¼šä½¿ç”¨ExcelåŸå§‹å­—æ®µï¼ˆå•†å“çº§æ¯›åˆ©ï¼‰
    - é”€å”®é¢ï¼šå®æ”¶ä»·æ ¼ Ã— é”€é‡ï¼ˆæˆ–å•†å“å®å”®ä»·ï¼‰
    - æ¯›åˆ©ç‡ï¼šåˆ©æ¶¦é¢ / é”€å”®é¢ Ã— 100
    """
    # æŒ‰é—¨åº—åŠ è½½æ•°æ®
    df = get_order_data(store_name)
    if df.empty:
        return {"success": True, "data": {"products": [], "sort_by": sort_by}}
    
    # ğŸ”´ å…³é”®ä¸šåŠ¡è§„åˆ™ï¼šå‰”é™¤è€—ææ•°æ®ï¼ˆè´­ç‰©è¢‹ç­‰ï¼‰
    # ä¸Dashç‰ˆæœ¬ä¿æŒä¸€è‡´ï¼šå•†å“æ’è¡Œæ¦œä¸å±•ç¤ºè€—æ
    if 'ä¸€çº§åˆ†ç±»å' in df.columns:
        original_count = len(df)
        df = df[df['ä¸€çº§åˆ†ç±»å'] != 'è€—æ'].copy()
        filtered_count = original_count - len(df)
        if filtered_count > 0:
            print(f"[top-products-by-date] å‰”é™¤è€—ææ•°æ®: {filtered_count} æ¡")
    
    # æ¸ é“ç­›é€‰
    if channel and channel != 'all' and 'æ¸ é“' in df.columns:
        df = df[df['æ¸ é“'] == channel]
    
    if 'æ—¥æœŸ' not in df.columns or 'å•†å“åç§°' not in df.columns:
        return {"success": True, "data": {"products": [], "sort_by": sort_by}}
    
    df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'], errors='coerce')
    df = df.dropna(subset=['æ—¥æœŸ'])
    
    if df.empty:
        return {"success": True, "data": {"products": [], "sort_by": sort_by}}
    
    # ğŸ†• è§£ææ—¥æœŸå‚æ•°ï¼šæ”¯æŒå•æ—¥æœŸæˆ–æ—¥æœŸèŒƒå›´
    target_date = None
    range_start = None
    range_end = None
    
    # ä¼˜å…ˆå¤„ç†æ—¥æœŸèŒƒå›´
    if start_date and end_date:
        try:
            range_start = pd.to_datetime(start_date)
            range_end = pd.to_datetime(end_date)
        except:
            range_start = None
            range_end = None
    elif date:
        try:
            if len(date) == 5 and '-' in date:
                max_date = df['æ—¥æœŸ'].max()
                year = max_date.year
                target_date = pd.to_datetime(f"{year}-{date}")
            else:
                target_date = pd.to_datetime(date)
        except:
            target_date = None
    
    # ç­›é€‰æ—¥æœŸ
    # ğŸ”´ ç‰¹æ®Šå¤„ç†ï¼šå½“ start_date === end_date æ—¶ï¼Œè§†ä¸ºå•æ—¥æœŸæ¨¡å¼
    if range_start and range_end:
        if range_start.date() == range_end.date():
            # åŒä¸€å¤©ï¼Œè½¬æ¢ä¸ºå•æ—¥æœŸæ¨¡å¼
            target_date = range_start
            range_start = None
            range_end = None
        else:
            df = df[(df['æ—¥æœŸ'].dt.date >= range_start.date()) & (df['æ—¥æœŸ'].dt.date <= range_end.date())]
    
    if target_date:
        df = df[df['æ—¥æœŸ'].dt.date == target_date.date()]
    
    if df.empty:
        return {"success": True, "data": {"products": [], "sort_by": sort_by}}
    
    # å­—æ®µæ˜ å°„ï¼ˆä¸Dashç‰ˆæœ¬ä¸€è‡´ï¼‰
    quantity_field = 'æœˆå”®' if 'æœˆå”®' in df.columns else 'é”€é‡'
    
    # ğŸ”´ é”€å”®é¢è®¡ç®—ï¼šå®æ”¶ä»·æ ¼ Ã— é”€é‡ï¼ˆä¸Dashç‰ˆæœ¬ä¸€è‡´ï¼‰
    # å®æ”¶ä»·æ ¼æ˜¯å•ä»·ï¼Œéœ€è¦ä¹˜ä»¥é”€é‡å¾—åˆ°é”€å”®é¢
    if 'å®æ”¶ä»·æ ¼' in df.columns and quantity_field in df.columns:
        df['_é”€å”®é¢'] = df['å®æ”¶ä»·æ ¼'].fillna(0) * df[quantity_field].fillna(1)
        sales_field = '_é”€å”®é¢'
    elif 'å•†å“å®å”®ä»·' in df.columns:
        # å•†å“å®å”®ä»·å·²ç»æ˜¯æ€»ä»·
        sales_field = 'å•†å“å®å”®ä»·'
    else:
        sales_field = None
    
    # æŒ‰å•†å“èšåˆï¼ˆä½¿ç”¨åº—å†…ç ä¼˜å…ˆï¼Œé¿å…åŒåä¸åŒè§„æ ¼å•†å“æ··æ·†ï¼‰
    group_key = 'åº—å†…ç ' if 'åº—å†…ç ' in df.columns else 'å•†å“åç§°'
    
    agg_dict = {}
    
    # å•†å“åç§°ï¼ˆå¦‚æœæŒ‰åº—å†…ç èšåˆï¼‰
    if group_key == 'åº—å†…ç ':
        agg_dict['name'] = ('å•†å“åç§°', 'first')
    
    # é”€é‡
    if quantity_field in df.columns:
        agg_dict['quantity'] = (quantity_field, 'sum')
    
    # é”€å”®é¢
    if sales_field and sales_field in df.columns:
        agg_dict['revenue'] = (sales_field, 'sum')
    
    # ğŸ”´ åˆ©æ¶¦é¢ï¼šç›´æ¥ä½¿ç”¨ExcelåŸå§‹å­—æ®µï¼ˆå•†å“çº§æ¯›åˆ©ï¼Œå·²ä¹˜ä»¥é”€é‡ï¼‰
    if 'åˆ©æ¶¦é¢' in df.columns:
        agg_dict['profit'] = ('åˆ©æ¶¦é¢', 'sum')
    
    # åˆ†ç±»
    if 'ä¸€çº§åˆ†ç±»å' in df.columns:
        agg_dict['category'] = ('ä¸€çº§åˆ†ç±»å', 'first')
    
    if not agg_dict:
        return {"success": True, "data": {"products": [], "sort_by": sort_by}}
    
    product_agg = df.groupby(group_key).agg(**agg_dict).reset_index()
    
    # å¦‚æœæŒ‰åº—å†…ç èšåˆï¼Œé‡å‘½ååˆ—
    if group_key == 'åº—å†…ç ':
        product_agg = product_agg.rename(columns={group_key: 'store_code'})
    else:
        product_agg = product_agg.rename(columns={group_key: 'name'})
    
    # ç¡®ä¿æœ‰nameåˆ—
    if 'name' not in product_agg.columns and 'store_code' in product_agg.columns:
        product_agg['name'] = product_agg['store_code']
    
    # è®¡ç®—æ¯›åˆ©ç‡
    if 'profit' in product_agg.columns and 'revenue' in product_agg.columns:
        product_agg['profit_rate'] = (product_agg['profit'] / product_agg['revenue'].replace(0, float('nan')) * 100).round(2)
        product_agg['profit_rate'] = product_agg['profit_rate'].fillna(0)
    else:
        product_agg['profit_rate'] = 0
    
    # æ’åº
    ascending = False
    actual_sort_by = sort_by
    if sort_by == 'loss':
        actual_sort_by = 'profit'
        ascending = True  # äºæŸæ¦œï¼šåˆ©æ¶¦ä»ä½åˆ°é«˜
    
    sort_field = actual_sort_by if actual_sort_by in product_agg.columns else 'quantity'
    if sort_field not in product_agg.columns:
        sort_field = list(product_agg.columns)[1] if len(product_agg.columns) > 1 else product_agg.columns[0]
    
    product_agg = product_agg.sort_values(sort_field, ascending=ascending).head(limit)
    
    # æ„å»ºè¿”å›æ•°æ®
    products = []
    for _, row in product_agg.iterrows():
        product = {
            "name": str(row.get('name', 'æœªçŸ¥å•†å“')),
            "quantity": int(row.get('quantity', 0)),
            "revenue": round(float(row.get('revenue', 0)), 2),
            "profit": round(float(row.get('profit', 0)), 2),
            "profit_rate": round(float(row.get('profit_rate', 0)), 2),
            "category": str(row.get('category', 'æœªåˆ†ç±»')),
            "growth": 0  # ç¯æ¯”å¢é•¿ï¼ˆæš‚ä¸è®¡ç®—ï¼‰
        }
        products.append(product)
    
    return {
        "success": True,
        "data": {
            "products": products,
            "sort_by": sort_by,
            "date": target_date.strftime('%Y-%m-%d') if target_date else None,
            "total_count": len(product_agg)
        }
    }


# ==================== åˆ†æ—¶åˆ©æ¶¦åˆ†æ API ====================

def identify_peak_periods(hourly_orders: pd.Series) -> List[Dict[str, Any]]:
    """
    æ™ºèƒ½è¯†åˆ«é«˜å³°æ—¶æ®µ
    
    ç®—æ³•ï¼šè®¢å•é‡ > å¹³å‡å€¼ + 0.5å€æ ‡å‡†å·®
    
    Args:
        hourly_orders: æ¯å°æ—¶è®¢å•æ•° Seriesï¼Œindexä¸ºå°æ—¶(0-23)
    
    Returns:
        é«˜å³°æ—¶æ®µåˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å« start, end, name
    """
    if hourly_orders.empty or hourly_orders.sum() == 0:
        return []
    
    mean_orders = hourly_orders.mean()
    std_orders = hourly_orders.std()
    
    # é«˜å³°é˜ˆå€¼ï¼šå‡å€¼ + 0.5å€æ ‡å‡†å·®
    threshold = mean_orders + 0.5 * std_orders
    
    # æ‰¾å‡ºé«˜å³°å°æ—¶
    peak_hours = hourly_orders[hourly_orders > threshold].index.tolist()
    
    if not peak_hours:
        return []
    
    # åˆå¹¶è¿ç»­æ—¶æ®µ
    peak_periods = []
    peak_hours = sorted(peak_hours)
    
    start = peak_hours[0]
    end = peak_hours[0]
    
    for hour in peak_hours[1:]:
        if hour == end + 1:
            # è¿ç»­ï¼Œæ‰©å±•åŒºé—´
            end = hour
        else:
            # ä¸è¿ç»­ï¼Œä¿å­˜å½“å‰åŒºé—´ï¼Œå¼€å§‹æ–°åŒºé—´
            peak_periods.append((start, end))
            start = hour
            end = hour
    
    # ä¿å­˜æœ€åä¸€ä¸ªåŒºé—´
    peak_periods.append((start, end))
    
    # å‘½åæ—¶æ®µ
    result = []
    for start_hour, end_hour in peak_periods:
        # æ ¹æ®æ—¶é—´èŒƒå›´å‘½å
        if 6 <= start_hour <= 9:
            name = "æ—©é«˜å³°"
        elif 11 <= start_hour <= 14:
            name = "åˆé«˜å³°"
        elif 17 <= start_hour <= 20:
            name = "æ™šé«˜å³°"
        elif 20 <= start_hour or start_hour <= 2:
            name = "å¤œé«˜å³°"
        else:
            name = "é«˜å³°æ—¶æ®µ"
        
        result.append({
            "start": f"{start_hour:02d}:00",
            "end": f"{end_hour + 1:02d}:00",  # ç»“æŸæ—¶é—´æ˜¯ä¸‹ä¸€ä¸ªå°æ—¶
            "name": name,
            "start_hour": start_hour,
            "end_hour": end_hour
        })
    
    return result


@router.get("/hourly-profit")
async def get_hourly_profit(
    store_name: Optional[str] = Query(None, description="é—¨åº—åç§°ç­›é€‰"),
    target_date: Optional[str] = Query(None, description="ç›®æ ‡æ—¥æœŸ(YYYY-MM-DDæˆ–MM-DDæ ¼å¼)ï¼Œé»˜è®¤ä¸ºæ•°æ®æœ€åä¸€å¤©"),
    start_date: Optional[str] = Query(None, description="å¼€å§‹æ—¥æœŸ(YYYY-MM-DDæ ¼å¼)"),
    end_date: Optional[str] = Query(None, description="ç»“æŸæ—¥æœŸ(YYYY-MM-DDæ ¼å¼)"),
    channel: Optional[str] = Query(None, description="æ¸ é“ç­›é€‰")
) -> Dict[str, Any]:
    """
    è·å–åˆ†æ—¶åˆ©æ¶¦æ•°æ®ï¼ˆåˆ†æ—¶æ®µè¯Šæ–­å›¾è¡¨ä¸“ç”¨ï¼‰
    
    æ ¸å¿ƒåŠŸèƒ½ï¼š
    1. æŒ‰å°æ—¶èšåˆè®¢å•æ•°å’Œå‡€åˆ©æ¶¦
    2. æ™ºèƒ½è¯†åˆ«é«˜å³°æ—¶æ®µï¼ˆè®¢å•é‡ > å‡å€¼+0.5Ïƒï¼‰
    3. è®¡ç®—å•å‡åˆ©æ¶¦
    
    åˆ©æ¶¦è®¡ç®—å…¬å¼ï¼ˆä¸æƒå¨æ‰‹å†Œä¸€è‡´ï¼‰ï¼š
    è®¢å•å®é™…åˆ©æ¶¦ = åˆ©æ¶¦é¢ - å¹³å°æœåŠ¡è´¹ - ç‰©æµé…é€è´¹ + ä¼å®¢åè¿”
    
    Returns:
        {
            "success": true,
            "data": {
                "date": "2025-01-07",
                "hours": ["00:00", "01:00", ..., "23:00"],
                "orders": [2, 0, 0, ...],
                "profits": [-15.5, 0, 0, ...],
                "revenues": [58.0, 0, 0, ...],
                "avg_profits": [-7.75, 0, 0, ...],  // å•å‡åˆ©æ¶¦
                "peak_periods": [
                    {"start": "11:00", "end": "14:00", "name": "åˆé«˜å³°"},
                    {"start": "17:00", "end": "20:00", "name": "æ™šé«˜å³°"}
                ]
            }
        }
    """
    # åŠ è½½æ•°æ®
    df = get_order_data(store_name)
    
    empty_result = {
        "success": True,
        "data": {
            "date": None,
            "hours": [f"{h:02d}:00" for h in range(24)],
            "orders": [0] * 24,
            "profits": [0] * 24,
            "revenues": [0] * 24,
            "avg_profits": [0] * 24,
            "peak_periods": []
        }
    }
    
    if df.empty:
        return empty_result
    
    # ç¡®ä¿æ—¥æœŸåˆ—å­˜åœ¨
    if 'æ—¥æœŸ' not in df.columns:
        return {"success": False, "error": "ç¼ºå°‘æ—¥æœŸå­—æ®µ"}
    
    df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'], errors='coerce')
    df = df.dropna(subset=['æ—¥æœŸ'])
    
    if df.empty:
        return empty_result
    
    # ç¡®å®šæ—¥æœŸç­›é€‰æ–¹å¼
    date_label = None  # ç”¨äºè¿”å›çš„æ—¥æœŸæ ‡ç­¾
    
    if target_date:
        # å•æ—¥æœŸæ¨¡å¼
        try:
            # æ”¯æŒ MM-DD æ ¼å¼ï¼ˆä»æ•°æ®ä¸­æ¨æ–­å¹´ä»½ï¼‰
            if len(target_date) == 5 and '-' in target_date:
                max_date = df['æ—¥æœŸ'].max()
                year = max_date.year
                analysis_date = pd.to_datetime(f"{year}-{target_date}")
            else:
                analysis_date = pd.to_datetime(target_date)
            df = df[df['æ—¥æœŸ'].dt.date == analysis_date.date()]
            date_label = analysis_date.strftime('%Y-%m-%d')
        except:
            pass
    elif start_date and end_date:
        # ğŸ†• æ—¥æœŸèŒƒå›´æ¨¡å¼
        try:
            start_dt = pd.to_datetime(start_date)
            end_dt = pd.to_datetime(end_date)
            df = df[(df['æ—¥æœŸ'].dt.date >= start_dt.date()) & (df['æ—¥æœŸ'].dt.date <= end_dt.date())]
            date_label = f"{start_date} ~ {end_date}"
        except:
            pass
    elif start_date:
        try:
            start_dt = pd.to_datetime(start_date)
            df = df[df['æ—¥æœŸ'].dt.date >= start_dt.date()]
            date_label = f"{start_date} ~"
        except:
            pass
    elif end_date:
        try:
            end_dt = pd.to_datetime(end_date)
            df = df[df['æ—¥æœŸ'].dt.date <= end_dt.date()]
            date_label = f"~ {end_date}"
        except:
            pass
    else:
        # é»˜è®¤ä½¿ç”¨æ•°æ®æœ€åä¸€å¤©
        analysis_date = df['æ—¥æœŸ'].max().normalize()
        df = df[df['æ—¥æœŸ'].dt.date == analysis_date.date()]
        date_label = analysis_date.strftime('%Y-%m-%d')
    
    if df.empty:
        return {
            "success": True,
            "data": {
                "date": date_label,
                "hours": [f"{h:02d}:00" for h in range(24)],
                "orders": [0] * 24,
                "profits": [0] * 24,
                "revenues": [0] * 24,
                "avg_profits": [0] * 24,
                "peak_periods": []
            }
        }
    
    # æ¸ é“ç­›é€‰
    if channel and channel != 'all' and 'æ¸ é“' in df.columns:
        df = df[df['æ¸ é“'] == channel]
        if df.empty:
            return {
                "success": True,
                "data": {
                    "date": date_label,
                    "hours": [f"{h:02d}:00" for h in range(24)],
                    "orders": [0] * 24,
                    "profits": [0] * 24,
                    "revenues": [0] * 24,
                    "avg_profits": [0] * 24,
                    "peak_periods": []
                }
            }
    
    # æå–å°æ—¶
    df['å°æ—¶'] = df['æ—¥æœŸ'].dt.hour
    
    # è®¡ç®—é”€å”®é¢ï¼ˆå®æ”¶ä»·æ ¼ Ã— é”€é‡ï¼‰
    quantity_field = 'æœˆå”®' if 'æœˆå”®' in df.columns else 'é”€é‡'
    if 'å®æ”¶ä»·æ ¼' in df.columns and quantity_field in df.columns:
        df['_é”€å”®é¢'] = df['å®æ”¶ä»·æ ¼'].fillna(0) * df[quantity_field].fillna(1)
    else:
        df['_é”€å”®é¢'] = df.get('å•†å“å®å”®ä»·', 0)
    
    # æŒ‰è®¢å•IDå’Œå°æ—¶èšåˆï¼ˆå…ˆèšåˆåˆ°è®¢å•çº§ï¼‰
    order_agg_dict = {
        'åˆ©æ¶¦é¢': 'sum',
        'ç‰©æµé…é€è´¹': 'first',
        '_é”€å”®é¢': 'sum',
        'å°æ—¶': 'first',
    }
    
    if 'å¹³å°æœåŠ¡è´¹' in df.columns:
        order_agg_dict['å¹³å°æœåŠ¡è´¹'] = 'sum'
    if 'ä¼å®¢åè¿”' in df.columns:
        order_agg_dict['ä¼å®¢åè¿”'] = 'sum'
    
    order_agg = df.groupby('è®¢å•ID').agg(order_agg_dict).reset_index()
    
    # è®¡ç®—è®¢å•å®é™…åˆ©æ¶¦
    order_agg['è®¢å•å®é™…åˆ©æ¶¦'] = (
        order_agg['åˆ©æ¶¦é¢'].fillna(0) -
        order_agg.get('å¹³å°æœåŠ¡è´¹', pd.Series(0, index=order_agg.index)).fillna(0) -
        order_agg['ç‰©æµé…é€è´¹'].fillna(0) +
        order_agg.get('ä¼å®¢åè¿”', pd.Series(0, index=order_agg.index)).fillna(0)
    )
    
    # æŒ‰å°æ—¶èšåˆ
    hourly_stats = order_agg.groupby('å°æ—¶').agg({
        'è®¢å•ID': 'count',
        'è®¢å•å®é™…åˆ©æ¶¦': 'sum',
        '_é”€å”®é¢': 'sum'
    }).reset_index()
    
    hourly_stats.columns = ['hour', 'orders', 'profit', 'revenue']
    
    # å¡«å……æ‰€æœ‰24å°æ—¶
    all_hours = pd.DataFrame({'hour': range(24)})
    hourly_stats = all_hours.merge(hourly_stats, on='hour', how='left').fillna(0)
    
    # è®¡ç®—å•å‡åˆ©æ¶¦
    hourly_stats['avg_profit'] = hourly_stats.apply(
        lambda r: round(r['profit'] / r['orders'], 2) if r['orders'] > 0 else 0, axis=1
    )
    
    # æ™ºèƒ½è¯†åˆ«é«˜å³°æ—¶æ®µ
    hourly_orders = hourly_stats.set_index('hour')['orders']
    peak_periods = identify_peak_periods(hourly_orders)
    
    return {
        "success": True,
        "data": {
            "date": date_label,  # ğŸ†• ä½¿ç”¨ date_labelï¼ˆæ”¯æŒæ—¥æœŸèŒƒå›´ï¼‰
            "hours": [f"{h:02d}:00" for h in range(24)],
            "orders": [int(x) for x in hourly_stats['orders'].tolist()],
            "profits": [round(float(x), 2) for x in hourly_stats['profit'].tolist()],
            "revenues": [round(float(x), 2) for x in hourly_stats['revenue'].tolist()],
            "avg_profits": [float(x) for x in hourly_stats['avg_profit'].tolist()],
            "peak_periods": peak_periods
        }
    }


# ==================== æˆæœ¬ç»“æ„åˆ†æAPIï¼ˆèµ„é‡‘æµå‘å…¨æ™¯æ¡‘åŸºå›¾ä¸“ç”¨ï¼‰ ====================

@router.get("/cost-structure")
async def get_cost_structure(
    store_name: Optional[str] = Query(None, description="é—¨åº—åç§°ç­›é€‰"),
    start_date: Optional[date] = Query(None, description="å¼€å§‹æ—¥æœŸ"),
    end_date: Optional[date] = Query(None, description="ç»“æŸæ—¥æœŸ")
) -> Dict[str, Any]:
    """
    è·å–æˆæœ¬ç»“æ„åˆ†ææ•°æ®ï¼ˆèµ„é‡‘æµå‘å…¨æ™¯æ¡‘åŸºå›¾ä¸“ç”¨ï¼‰
    
    ä¸Dashç‰ˆæœ¬Tab1æˆæœ¬ç»“æ„åˆ†æå®Œå…¨ä¸€è‡´ï¼š
    - å››å¤§æˆæœ¬ï¼šå•†å“æˆæœ¬ã€é…é€å‡€æˆæœ¬ã€å•†å®¶æ´»åŠ¨æˆæœ¬ã€å¹³å°æœåŠ¡è´¹
    - æŒ‰æ¸ é“åˆ†ç»„ï¼Œæ”¯æŒæ¡‘åŸºå›¾å±•ç¤ºèµ„é‡‘æµå‘
    
    è®¡ç®—å…¬å¼ï¼ˆæ¥è‡ªã€æƒå¨ã€‘ä¸šåŠ¡é€»è¾‘ä¸æ•°æ®å­—å…¸å®Œæ•´æ‰‹å†Œï¼‰ï¼š
    - å•†å“æˆæœ¬ï¼šå•†å“é‡‡è´­æˆæœ¬ä¹‹å’Œ
    - é…é€å‡€æˆæœ¬ï¼šç‰©æµé…é€è´¹ - (ç”¨æˆ·æ”¯ä»˜é…é€è´¹ - é…é€è´¹å‡å…é‡‘é¢) - ä¼å®¢åè¿”
    - å•†å®¶æ´»åŠ¨æˆæœ¬ï¼šæ»¡å‡é‡‘é¢ + å•†å“å‡å…é‡‘é¢ + å•†å®¶ä»£é‡‘åˆ¸ + å•†å®¶æ‰¿æ‹…éƒ¨åˆ†åˆ¸ + æ»¡èµ é‡‘é¢ + å•†å®¶å…¶ä»–ä¼˜æƒ 
    - å¹³å°æœåŠ¡è´¹ï¼šå¹³å°æœåŠ¡è´¹ä¹‹å’Œï¼ˆå•†å“çº§å­—æ®µï¼‰
    """
    # æŒ‰é—¨åº—åŠ è½½æ•°æ®
    df = get_order_data(store_name)
    
    empty_result = {
        "success": True,
        "data": {
            "channels": [],
            "total": {
                "revenue": 0,
                "profit": 0,
                "cogs": 0,
                "delivery": 0,
                "marketing": 0,
                "commission": 0
            }
        }
    }
    
    if df.empty:
        return empty_result
    
    # æ—¥æœŸç­›é€‰
    if 'æ—¥æœŸ' in df.columns:
        df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'], errors='coerce')
        if start_date:
            df = df[df['æ—¥æœŸ'].dt.date >= start_date]
        if end_date:
            df = df[df['æ—¥æœŸ'].dt.date <= end_date]
    
    if df.empty or 'æ¸ é“' not in df.columns:
        return empty_result
    
    # è®¡ç®—è®¢å•çº§æŒ‡æ ‡ï¼ˆä½¿ç”¨ç»Ÿä¸€å‡½æ•°ï¼‰
    order_agg = calculate_order_metrics(df)
    
    if order_agg.empty or 'æ¸ é“' not in order_agg.columns:
        return empty_result
    
    # æ’é™¤å’–å•¡æ¸ é“ï¼ˆä¸Dashç‰ˆæœ¬ä¸€è‡´ï¼‰
    CHANNELS_TO_REMOVE = ['ç¾å›¢å’–å•¡åº—', 'é¥¿äº†ä¹ˆå’–å•¡åº—', 'é¥¿äº†ä¹ˆå’–å•¡', 'ç¾å›¢å’–å•¡']
    order_agg = order_agg[~order_agg['æ¸ é“'].isin(CHANNELS_TO_REMOVE)]
    
    if order_agg.empty:
        return empty_result
    
    # ==================== è®¡ç®—å•†å“æˆæœ¬ï¼ˆä»åŸå§‹dfï¼Œé¿å…èšåˆæŸå¤±ï¼‰ ====================
    # ä¸Dashç‰ˆæœ¬Tab1æˆæœ¬ç»“æ„åˆ†æé€»è¾‘ä¸€è‡´
    valid_order_ids = order_agg['è®¢å•ID'].unique()
    df_valid = df[df['è®¢å•ID'].astype(str).isin([str(x) for x in valid_order_ids])]
    
    # æŒ‰æ¸ é“å’Œè®¢å•IDè®¡ç®—å•†å“æˆæœ¬
    cost_field = 'å•†å“é‡‡è´­æˆæœ¬' if 'å•†å“é‡‡è´­æˆæœ¬' in df_valid.columns else 'æˆæœ¬'
    if cost_field in df_valid.columns:
        product_cost_by_channel = df_valid.groupby('æ¸ é“')[cost_field].sum().to_dict()
    else:
        product_cost_by_channel = {}
    
    # ==================== æŒ‰æ¸ é“èšåˆæˆæœ¬ç»“æ„ ====================
    agg_dict = {
        'è®¢å•ID': 'count',
        'å®æ”¶ä»·æ ¼': 'sum',
        'è®¢å•å®é™…åˆ©æ¶¦': 'sum',
    }
    
    # æ£€æŸ¥å¹¶æ·»åŠ å¯é€‰å­—æ®µ
    if 'é…é€å‡€æˆæœ¬' in order_agg.columns:
        agg_dict['é…é€å‡€æˆæœ¬'] = 'sum'
    if 'å•†å®¶æ´»åŠ¨æˆæœ¬' in order_agg.columns:
        agg_dict['å•†å®¶æ´»åŠ¨æˆæœ¬'] = 'sum'
    if 'å¹³å°æœåŠ¡è´¹' in order_agg.columns:
        agg_dict['å¹³å°æœåŠ¡è´¹'] = 'sum'
    elif 'å¹³å°ä½£é‡‘' in order_agg.columns:
        agg_dict['å¹³å°ä½£é‡‘'] = 'sum'
    
    channel_stats = order_agg.groupby('æ¸ é“').agg(agg_dict).reset_index()
    
    # æ„å»ºè¿”å›æ•°æ®
    channels_data = []
    total_revenue = 0
    total_profit = 0
    total_cogs = 0
    total_delivery = 0
    total_marketing = 0
    total_commission = 0
    
    for _, row in channel_stats.iterrows():
        channel_name = row['æ¸ é“']
        revenue = float(row['å®æ”¶ä»·æ ¼'])
        profit = float(row['è®¢å•å®é™…åˆ©æ¶¦'])
        order_count = int(row['è®¢å•ID'])
        
        # å•†å“æˆæœ¬ï¼ˆä»åŸå§‹dfè·å–ï¼‰
        cogs = float(product_cost_by_channel.get(channel_name, 0))
        
        # é…é€å‡€æˆæœ¬
        delivery = float(row['é…é€å‡€æˆæœ¬']) if 'é…é€å‡€æˆæœ¬' in channel_stats.columns else 0
        
        # å•†å®¶æ´»åŠ¨æˆæœ¬
        marketing = float(row['å•†å®¶æ´»åŠ¨æˆæœ¬']) if 'å•†å®¶æ´»åŠ¨æˆæœ¬' in channel_stats.columns else 0
        
        # å¹³å°æœåŠ¡è´¹
        if 'å¹³å°æœåŠ¡è´¹' in channel_stats.columns:
            commission = float(row['å¹³å°æœåŠ¡è´¹'])
        elif 'å¹³å°ä½£é‡‘' in channel_stats.columns:
            commission = float(row['å¹³å°ä½£é‡‘'])
        else:
            commission = 0
        
        # ç´¯è®¡æ€»è®¡
        total_revenue += revenue
        total_profit += profit
        total_cogs += cogs
        total_delivery += delivery
        total_marketing += marketing
        total_commission += commission
        
        channels_data.append({
            "id": str(len(channels_data) + 1),
            "name": channel_name,
            "revenue": round(revenue, 2),
            "profit": round(profit, 2),
            "order_count": order_count,
            "costs": {
                "cogs": round(cogs, 2),
                "delivery": round(delivery, 2),
                "marketing": round(marketing, 2),
                "commission": round(commission, 2)
            },
            "rates": {
                "profit_rate": round(profit / revenue * 100, 2) if revenue > 0 else 0,
                "cogs_rate": round(cogs / revenue * 100, 2) if revenue > 0 else 0,
                "delivery_rate": round(delivery / revenue * 100, 2) if revenue > 0 else 0,
                "marketing_rate": round(marketing / revenue * 100, 2) if revenue > 0 else 0,
                "commission_rate": round(commission / revenue * 100, 2) if revenue > 0 else 0
            }
        })
    
    # æŒ‰é”€å”®é¢æ’åº
    channels_data.sort(key=lambda x: x['revenue'], reverse=True)
    
    # é‡æ–°åˆ†é…ID
    for i, ch in enumerate(channels_data):
        ch['id'] = str(i + 1)
    
    return {
        "success": True,
        "data": {
            "channels": channels_data,
            "total": {
                "revenue": round(total_revenue, 2),
                "profit": round(total_profit, 2),
                "cogs": round(total_cogs, 2),
                "delivery": round(total_delivery, 2),
                "marketing": round(total_marketing, 2),
                "commission": round(total_commission, 2)
            }
        }
    }


# ==================== åˆ†è·ç¦»è®¢å•è¯Šæ–­ API ====================

# 7ä¸ªè·ç¦»åŒºé—´å¸¸é‡å®šä¹‰
DISTANCE_BANDS = [
    {"label": "0-1km", "min": 0, "max": 1},
    {"label": "1-2km", "min": 1, "max": 2},
    {"label": "2-3km", "min": 2, "max": 3},
    {"label": "3-4km", "min": 3, "max": 4},
    {"label": "4-5km", "min": 4, "max": 5},
    {"label": "5-6km", "min": 5, "max": 6},
    {"label": "6km+", "min": 6, "max": float('inf')},
]


def get_distance_band(distance: float) -> dict:
    """
    æ ¹æ®è·ç¦»å€¼è¿”å›æ‰€å±åŒºé—´
    
    Args:
        distance: é…é€è·ç¦»ï¼ˆå…¬é‡Œï¼‰
    
    Returns:
        å¯¹åº”çš„è·ç¦»åŒºé—´å­—å…¸
    """
    if distance < 0:
        distance = 0
    
    for band in DISTANCE_BANDS:
        if band["min"] <= distance < band["max"]:
            return band
    
    # é»˜è®¤è¿”å›æœ€åä¸€ä¸ªåŒºé—´ï¼ˆ6km+ï¼‰
    return DISTANCE_BANDS[-1]


def get_distance_band_index(distance: float) -> int:
    """
    æ ¹æ®è·ç¦»å€¼è¿”å›æ‰€å±åŒºé—´çš„ç´¢å¼•
    
    Args:
        distance: é…é€è·ç¦»ï¼ˆå…¬é‡Œï¼‰
    
    Returns:
        åŒºé—´ç´¢å¼• (0-6)
    """
    if distance < 0:
        distance = 0
    
    for i, band in enumerate(DISTANCE_BANDS):
        if band["min"] <= distance < band["max"]:
            return i
    
    return len(DISTANCE_BANDS) - 1


@router.get("/distance-analysis")
async def get_distance_analysis(
    store_name: Optional[str] = Query(None, description="é—¨åº—åç§°ç­›é€‰"),
    channel: Optional[str] = Query(None, description="æ¸ é“ç­›é€‰"),
    target_date: Optional[str] = Query(None, description="ç›®æ ‡æ—¥æœŸ(YYYY-MM-DDæˆ–MM-DDæ ¼å¼)"),
    start_date: Optional[date] = Query(None, description="å¼€å§‹æ—¥æœŸ"),
    end_date: Optional[date] = Query(None, description="ç»“æŸæ—¥æœŸ")
) -> Dict[str, Any]:
    """
    è·å–åˆ†è·ç¦»è®¢å•è¯Šæ–­æ•°æ®
    
    æ ¸å¿ƒåŠŸèƒ½ï¼š
    1. æŒ‰7ä¸ªè·ç¦»åŒºé—´èšåˆè®¢å•æ•°æ®
    2. è®¡ç®—æ¯ä¸ªåŒºé—´çš„è®¢å•æ•°ã€é”€å”®é¢ã€åˆ©æ¶¦ã€åˆ©æ¶¦ç‡ã€é…é€æˆæœ¬ç­‰æŒ‡æ ‡
    3. è¯†åˆ«æœ€ä¼˜é…é€è·ç¦»åŒºé—´ï¼ˆåˆ©æ¶¦ç‡æœ€é«˜ï¼‰
    
    è·ç¦»åŒºé—´å®šä¹‰ï¼š
    - 0-1km, 1-2km, 2-3km, 3-4km, 4-5km, 5-6km, 6km+
    
    åˆ©æ¶¦è®¡ç®—å…¬å¼ï¼ˆä¸æƒå¨æ‰‹å†Œä¸€è‡´ï¼‰ï¼š
    è®¢å•å®é™…åˆ©æ¶¦ = åˆ©æ¶¦é¢ - å¹³å°æœåŠ¡è´¹ - ç‰©æµé…é€è´¹ + ä¼å®¢åè¿”
    
    Returns:
        {
            "success": true,
            "data": {
                "distance_bands": [
                    {
                        "band_label": "0-1km",
                        "min_distance": 0,
                        "max_distance": 1,
                        "order_count": 150,
                        "revenue": 12500.00,
                        "profit": 2800.00,
                        "profit_rate": 22.4,
                        "delivery_cost": 450.00,
                        "delivery_cost_rate": 3.6,
                        "avg_order_value": 83.33
                    },
                    ...
                ],
                "summary": {
                    "total_orders": 1200,
                    "avg_distance": 2.8,
                    "optimal_distance": "1-2km",
                    "total_revenue": 98000.00,
                    "total_profit": 18500.00
                }
            }
        }
    """
    # ğŸ” è°ƒè¯•æ—¥å¿—ï¼šæ£€æŸ¥æ¥æ”¶çš„å‚æ•°
    print(f"ğŸ“Š [distance-analysis] æ¥æ”¶å‚æ•°: store_name={store_name!r}, channel={channel!r}, target_date={target_date!r}")
    
    # åŠ è½½æ•°æ®
    df = get_order_data(store_name)
    
    # ğŸ” è°ƒè¯•æ—¥å¿—ï¼šæ£€æŸ¥åŠ è½½çš„æ•°æ®é‡
    print(f"ğŸ“Š [distance-analysis] åŠ è½½æ•°æ®: {len(df)} è¡Œ")
    
    # ç©ºæ•°æ®è¿”å›ç»“æ„
    empty_bands = []
    for band in DISTANCE_BANDS:
        empty_bands.append({
            "band_label": band["label"],
            "min_distance": band["min"],
            "max_distance": band["max"] if band["max"] != float('inf') else 999,
            "order_count": 0,
            "revenue": 0,
            "profit": 0,
            "profit_rate": 0,
            "delivery_cost": 0,
            "delivery_cost_rate": 0,
            "avg_order_value": 0
        })
    
    empty_result = {
        "success": True,
        "data": {
            "distance_bands": empty_bands,
            "summary": {
                "total_orders": 0,
                "avg_distance": 0,
                "optimal_distance": None,
                "total_revenue": 0,
                "total_profit": 0
            }
        }
    }
    
    if df.empty:
        return empty_result
    
    # ç¡®ä¿æ—¥æœŸåˆ—å­˜åœ¨
    if 'æ—¥æœŸ' in df.columns:
        df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'], errors='coerce')
        df = df.dropna(subset=['æ—¥æœŸ'])
    
    if df.empty:
        return empty_result
    
    # æ—¥æœŸç­›é€‰ï¼ˆä¸åˆ†æ—¶æ®µè¯Šæ–­ä¸€è‡´ï¼šé»˜è®¤ä½¿ç”¨æœ€æ–°ä¸€å¤©ï¼‰
    analysis_date = None
    if target_date:
        try:
            # æ”¯æŒ MM-DD æ ¼å¼ï¼ˆä»æ•°æ®ä¸­æ¨æ–­å¹´ä»½ï¼‰
            if len(target_date) == 5 and '-' in target_date:
                max_date = df['æ—¥æœŸ'].max()
                year = max_date.year
                analysis_date = pd.to_datetime(f"{year}-{target_date}")
            else:
                analysis_date = pd.to_datetime(target_date)
        except:
            analysis_date = None
    elif start_date or end_date:
        # æœ‰æ—¥æœŸèŒƒå›´æ—¶ä½¿ç”¨èŒƒå›´ç­›é€‰
        if start_date:
            df = df[df['æ—¥æœŸ'].dt.date >= start_date]
        if end_date:
            df = df[df['æ—¥æœŸ'].dt.date <= end_date]
    
    # å¦‚æœæ²¡æœ‰æŒ‡å®šæ—¥æœŸå‚æ•°ï¼Œé»˜è®¤ä½¿ç”¨æ•°æ®æœ€åä¸€å¤©ï¼ˆä¸åˆ†æ—¶æ®µè¯Šæ–­ä¸€è‡´ï¼‰
    if analysis_date is None and start_date is None and end_date is None:
        analysis_date = df['æ—¥æœŸ'].max().normalize()
    
    # å¦‚æœæœ‰å…·ä½“æ—¥æœŸï¼Œç­›é€‰è¯¥æ—¥æœŸæ•°æ®
    if analysis_date is not None:
        df = df[df['æ—¥æœŸ'].dt.date == analysis_date.date()]
    
    if df.empty:
        return empty_result
    
    # æ¸ é“ç­›é€‰
    if channel and channel != 'all' and 'æ¸ é“' in df.columns:
        df = df[df['æ¸ é“'] == channel]
        if df.empty:
            return empty_result
    
    # è®¡ç®—è®¢å•çº§æŒ‡æ ‡
    order_agg = calculate_order_metrics(df)
    
    if order_agg.empty:
        return empty_result
    
    # è·å–é…é€è·ç¦»æ•°æ®
    # ä»åŸå§‹dfè·å–é…é€è·ç¦»ï¼ˆå› ä¸ºorder_aggå¯èƒ½æ²¡æœ‰è¿™ä¸ªå­—æ®µï¼‰
    if 'è®¢å•ID' in df.columns:
        # æŒ‰è®¢å•IDè·å–é…é€è·ç¦»ï¼ˆå–ç¬¬ä¸€ä¸ªå€¼ï¼Œå› ä¸ºåŒä¸€è®¢å•è·ç¦»ç›¸åŒï¼‰
        distance_map = {}
        
        # å°è¯•ä»æ•°æ®åº“ç›´æ¥è·å–é…é€è·ç¦»
        try:
            session = SessionLocal()
            try:
                from sqlalchemy import distinct
                order_ids = order_agg['è®¢å•ID'].unique().tolist()
                
                # æ‰¹é‡æŸ¥è¯¢é…é€è·ç¦»
                orders_with_distance = session.query(
                    Order.order_id, 
                    Order.delivery_distance
                ).filter(
                    Order.order_id.in_(order_ids)
                ).all()
                
                for order_id, distance in orders_with_distance:
                    if distance is not None:
                        distance_map[str(order_id)] = float(distance)
                
                # âœ… æ£€æµ‹è·ç¦»å•ä½ï¼šå¦‚æœå¹³å‡å€¼>100ï¼Œè¯´æ˜æ˜¯ç±³ï¼Œéœ€è¦è½¬æ¢ä¸ºå…¬é‡Œ
                if distance_map:
                    avg_dist = sum(distance_map.values()) / len(distance_map)
                    if avg_dist > 100:
                        print(f"âš ï¸ æ£€æµ‹åˆ°é…é€è·ç¦»å•ä½ä¸ºã€ç±³ã€‘(å¹³å‡å€¼={avg_dist:.1f})ï¼Œè‡ªåŠ¨è½¬æ¢ä¸ºå…¬é‡Œ")
                        distance_map = {k: v / 1000 for k, v in distance_map.items()}
                
                print(f"âœ… ä»æ•°æ®åº“è·å–é…é€è·ç¦»: {len(distance_map)} æ¡")
            finally:
                session.close()
        except Exception as e:
            print(f"âš ï¸ ä»æ•°æ®åº“è·å–é…é€è·ç¦»å¤±è´¥: {e}")
            # å¤‡ç”¨æ–¹æ¡ˆï¼šä»dfè·å–
            for col in ['é…é€è·ç¦»', 'é€è¾¾è·ç¦»', 'distance', 'delivery_distance']:
                if col in df.columns:
                    temp_map = df.groupby('è®¢å•ID')[col].first().to_dict()
                    for k, v in temp_map.items():
                        if pd.notna(v):
                            distance_map[str(k)] = float(v)
                    # âœ… æ£€æµ‹è·ç¦»å•ä½ï¼šå¦‚æœå¹³å‡å€¼>100ï¼Œè¯´æ˜æ˜¯ç±³ï¼Œéœ€è¦è½¬æ¢ä¸ºå…¬é‡Œ
                    if distance_map:
                        avg_dist = sum(distance_map.values()) / len(distance_map)
                        if avg_dist > 100:
                            print(f"âš ï¸ æ£€æµ‹åˆ°é…é€è·ç¦»å•ä½ä¸ºã€ç±³ã€‘(å¹³å‡å€¼={avg_dist:.1f})ï¼Œè‡ªåŠ¨è½¬æ¢ä¸ºå…¬é‡Œ")
                            distance_map = {k: v / 1000 for k, v in distance_map.items()}
                    break
        
        # å°†é…é€è·ç¦»æ·»åŠ åˆ°order_agg
        order_agg['é…é€è·ç¦»'] = order_agg['è®¢å•ID'].astype(str).map(distance_map).fillna(0)
    else:
        order_agg['é…é€è·ç¦»'] = 0
    
    # ä¸ºæ¯ä¸ªè®¢å•åˆ†é…è·ç¦»åŒºé—´
    order_agg['è·ç¦»åŒºé—´'] = order_agg['é…é€è·ç¦»'].apply(get_distance_band_index)
    
    # æŒ‰è·ç¦»åŒºé—´èšåˆ
    band_stats = []
    total_orders = 0
    total_revenue = 0
    total_profit = 0
    total_distance = 0
    optimal_band = None
    max_profit = float('-inf')  # æ”¹ä¸ºåˆ©æ¶¦æ€»é¢æœ€é«˜
    
    for i, band in enumerate(DISTANCE_BANDS):
        band_df = order_agg[order_agg['è·ç¦»åŒºé—´'] == i]
        
        order_count = len(band_df)
        revenue = float(band_df['å®æ”¶ä»·æ ¼'].sum()) if 'å®æ”¶ä»·æ ¼' in band_df.columns and order_count > 0 else 0
        profit = float(band_df['è®¢å•å®é™…åˆ©æ¶¦'].sum()) if 'è®¢å•å®é™…åˆ©æ¶¦' in band_df.columns and order_count > 0 else 0
        
        # é…é€æˆæœ¬ï¼ˆç‰©æµé…é€è´¹ - ç”¨æˆ·æ”¯ä»˜é…é€è´¹ + é…é€è´¹å‡å…é‡‘é¢ï¼‰
        delivery_cost = 0
        if order_count > 0:
            if 'ç‰©æµé…é€è´¹' in band_df.columns:
                delivery_cost = float(band_df['ç‰©æµé…é€è´¹'].sum())
            if 'ç”¨æˆ·æ”¯ä»˜é…é€è´¹' in band_df.columns:
                delivery_cost -= float(band_df['ç”¨æˆ·æ”¯ä»˜é…é€è´¹'].sum())
            if 'é…é€è´¹å‡å…é‡‘é¢' in band_df.columns:
                delivery_cost += float(band_df['é…é€è´¹å‡å…é‡‘é¢'].sum())
        
        # è®¡ç®—æ´¾ç”ŸæŒ‡æ ‡
        profit_rate = round(profit / revenue * 100, 2) if revenue > 0 else 0
        delivery_cost_rate = round(delivery_cost / revenue * 100, 2) if revenue > 0 else 0
        avg_order_value = round(revenue / order_count, 2) if order_count > 0 else 0
        
        # ç´¯è®¡æ€»è®¡
        total_orders += order_count
        total_revenue += revenue
        total_profit += profit
        if order_count > 0:
            total_distance += float(band_df['é…é€è·ç¦»'].sum())
        
        # è¯†åˆ«æœ€ä¼˜è·ç¦»åŒºé—´ï¼ˆåˆ©æ¶¦æ€»é¢æœ€é«˜ä¸”æœ‰è®¢å•ï¼‰
        if order_count > 0 and profit > max_profit:
            max_profit = profit
            optimal_band = band["label"]
        
        band_stats.append({
            "band_label": band["label"],
            "min_distance": band["min"],
            "max_distance": band["max"] if band["max"] != float('inf') else 999,
            "order_count": order_count,
            "revenue": round(revenue, 2),
            "profit": round(profit, 2),
            "profit_rate": profit_rate,
            "delivery_cost": round(delivery_cost, 2),
            "delivery_cost_rate": delivery_cost_rate,
            "avg_order_value": avg_order_value
        })
    
    # è®¡ç®—å¹³å‡é…é€è·ç¦»
    avg_distance = round(total_distance / total_orders, 2) if total_orders > 0 else 0
    
    # è·å–åˆ†ææ—¥æœŸï¼ˆç”¨äºå‰ç«¯æ˜¾ç¤ºï¼‰- æ”¯æŒæ—¥æœŸèŒƒå›´
    analysis_date_str = None
    if analysis_date is not None:
        analysis_date_str = analysis_date.strftime('%Y-%m-%d')
    elif start_date and end_date:
        # ğŸ†• æ—¥æœŸèŒƒå›´æ ¼å¼
        analysis_date_str = f"{start_date} ~ {end_date}"
    elif start_date:
        analysis_date_str = f"{start_date} ~"
    elif end_date:
        analysis_date_str = f"~ {end_date}"
    elif not df.empty and 'æ—¥æœŸ' in df.columns:
        analysis_date_str = df['æ—¥æœŸ'].max().strftime('%Y-%m-%d')
    
    return {
        "success": True,
        "data": {
            "date": analysis_date_str,  # ğŸ†• æ·»åŠ åˆ†ææ—¥æœŸ
            "distance_bands": band_stats,
            "summary": {
                "total_orders": total_orders,
                "avg_distance": avg_distance,
                "optimal_distance": optimal_band,
                "total_revenue": round(total_revenue, 2),
                "total_profit": round(total_profit, 2)
            }
        }
    }


# ==================== é…é€æº¢ä»·é›·è¾¾æ•°æ® API ====================

@router.get("/delivery-radar")
async def get_delivery_radar_data(
    store_name: Optional[str] = Query(None, description="é—¨åº—åç§°"),
    channel: Optional[str] = Query(None, description="æ¸ é“ç­›é€‰"),
    target_date: Optional[str] = Query(None, description="ç›®æ ‡æ—¥æœŸ(YYYY-MM-DDæ ¼å¼)ï¼Œé»˜è®¤ä¸ºæ•°æ®æœ€åä¸€å¤©"),
    start_date: Optional[str] = Query(None, description="å¼€å§‹æ—¥æœŸ"),
    end_date: Optional[str] = Query(None, description="ç»“æŸæ—¥æœŸ"),
    min_distance: Optional[float] = Query(None, description="æœ€å°è·ç¦»(km)"),
    max_distance: Optional[float] = Query(None, description="æœ€å¤§è·ç¦»(km)")
):
    """
    è·å–é…é€æº¢ä»·é›·è¾¾å›¾æ•°æ®
    
    è¿”å›æ¯ä¸ªè®¢å•çš„ï¼š
    - é…é€è·ç¦»ï¼ˆå…¬é‡Œï¼‰
    - ä¸‹å•æ—¶æ®µï¼ˆå°æ—¶ï¼‰
    - é…é€æˆæœ¬ï¼ˆé…é€å‡€æˆæœ¬ï¼‰
    - å®¢å•ä»·
    - è®¢å•åˆ©æ¶¦
    - æ˜¯å¦æº¢ä»·ï¼ˆé…é€å‡€æˆæœ¬ > 6å…ƒï¼Œä¸Dashç‰ˆæœ¬ä¸€è‡´ï¼‰
    
    ç”¨äºé›·è¾¾å›¾å±•ç¤ºé…é€æº¢ä»·è®¢å•çš„æ—¶ç©ºåˆ†å¸ƒ
    """
    if not store_name:
        return {"success": False, "message": "è¯·é€‰æ‹©é—¨åº—", "data": [], "summary": None}
    
    try:
        from sqlalchemy import func  # ğŸ†• å¯¼å…¥ func
        session = SessionLocal()
        try:
            # æ„å»ºæŸ¥è¯¢
            query = session.query(Order).filter(Order.store_name == store_name)
            
            # æ¸ é“ç­›é€‰
            if channel:
                query = query.filter(Order.channel == channel)
            
            # æ—¥æœŸç­›é€‰ï¼ˆæ”¯æŒå•æ—¥æœŸå’Œæ—¥æœŸèŒƒå›´ï¼‰
            analysis_date = None
            date_label = None  # ğŸ†• ç”¨äºè¿”å›çš„æ—¥æœŸæ ‡ç­¾
            
            if target_date:
                # æŒ‡å®šç›®æ ‡æ—¥æœŸ
                analysis_date = datetime.strptime(target_date, '%Y-%m-%d')
                query = query.filter(
                    Order.date >= analysis_date,
                    Order.date < analysis_date + timedelta(days=1)
                )
                date_label = target_date
            elif start_date or end_date:
                # ğŸ†• æ—¥æœŸèŒƒå›´ç­›é€‰
                if start_date:
                    query = query.filter(Order.date >= datetime.strptime(start_date, '%Y-%m-%d'))
                if end_date:
                    query = query.filter(Order.date <= datetime.strptime(end_date, '%Y-%m-%d') + timedelta(days=1))
                # æ„å»ºæ—¥æœŸæ ‡ç­¾
                if start_date and end_date:
                    date_label = f"{start_date} ~ {end_date}"
                elif start_date:
                    date_label = f"{start_date} ~"
                else:
                    date_label = f"~ {end_date}"
            else:
                # é»˜è®¤ä½¿ç”¨æœ€æ–°ä¸€å¤©
                max_date_query = session.query(func.max(Order.date)).filter(Order.store_name == store_name)
                if channel:
                    max_date_query = max_date_query.filter(Order.channel == channel)
                max_date = max_date_query.scalar()
                if max_date:
                    analysis_date = max_date.replace(hour=0, minute=0, second=0, microsecond=0)
                    query = query.filter(
                        Order.date >= analysis_date,
                        Order.date < analysis_date + timedelta(days=1)
                    )
                    date_label = analysis_date.strftime('%Y-%m-%d')
            
            # è·å–æ•°æ®
            orders = query.all()
            
            if not orders:
                return {"success": True, "data": [], "date": date_label, "summary": {"total": 0, "premium_count": 0, "premium_rate": 0}}
            
            # è½¬æ¢ä¸ºDataFrameè¿›è¡Œèšåˆ
            data = []
            for order in orders:
                data.append({
                    'è®¢å•ID': order.order_id,
                    'ä¸‹å•æ—¶é—´': order.date,
                    'é…é€è·ç¦»': order.delivery_distance or 0,
                    'ç‰©æµé…é€è´¹': order.delivery_fee or 0,
                    'ç”¨æˆ·æ”¯ä»˜é…é€è´¹': order.user_paid_delivery_fee or 0,
                    'é…é€è´¹å‡å…é‡‘é¢': order.delivery_discount or 0,
                    'ä¼å®¢åè¿”': order.corporate_rebate or 0,
                    'å•†å“å®å”®ä»·': order.price or 0,
                    'åˆ©æ¶¦é¢': order.profit or 0,
                    'å¹³å°æœåŠ¡è´¹': order.platform_service_fee or 0,
                    'æ¸ é“': order.channel or ''
                })
            
            df = pd.DataFrame(data)
            
            # æŒ‰è®¢å•IDèšåˆï¼ˆä¸€ä¸ªè®¢å•å¯èƒ½æœ‰å¤šä¸ªå•†å“ï¼‰
            order_agg = df.groupby('è®¢å•ID').agg({
                'ä¸‹å•æ—¶é—´': 'first',
                'é…é€è·ç¦»': 'first',  # è®¢å•çº§å­—æ®µ
                'ç‰©æµé…é€è´¹': 'first',
                'ç”¨æˆ·æ”¯ä»˜é…é€è´¹': 'first',
                'é…é€è´¹å‡å…é‡‘é¢': 'first',
                'ä¼å®¢åè¿”': 'first',
                'å•†å“å®å”®ä»·': 'sum',  # å•†å“çº§å­—æ®µæ±‚å’Œ
                'åˆ©æ¶¦é¢': 'sum',
                'å¹³å°æœåŠ¡è´¹': 'sum',
                'æ¸ é“': 'first'
            }).reset_index()
            
            # é…é€è·ç¦»å•ä½è½¬æ¢ï¼ˆå¦‚æœæ˜¯ç±³ï¼Œè½¬æ¢ä¸ºå…¬é‡Œï¼‰
            if len(order_agg) > 0:
                avg_dist = order_agg['é…é€è·ç¦»'].mean()
                if avg_dist > 100:  # å¹³å‡å€¼>100ï¼Œè¯´æ˜å•ä½æ˜¯ç±³
                    order_agg['é…é€è·ç¦»'] = order_agg['é…é€è·ç¦»'] / 1000
            
            # è·ç¦»ç­›é€‰
            if min_distance is not None:
                order_agg = order_agg[order_agg['é…é€è·ç¦»'] >= min_distance]
            if max_distance is not None:
                order_agg = order_agg[order_agg['é…é€è·ç¦»'] < max_distance]
            
            # è®¡ç®—é…é€å‡€æˆæœ¬
            # é…é€å‡€æˆæœ¬ = ç‰©æµé…é€è´¹ - (ç”¨æˆ·æ”¯ä»˜é…é€è´¹ - é…é€è´¹å‡å…) - ä¼å®¢åè¿”
            order_agg['é…é€å‡€æˆæœ¬'] = (
                order_agg['ç‰©æµé…é€è´¹'] 
                - (order_agg['ç”¨æˆ·æ”¯ä»˜é…é€è´¹'] - order_agg['é…é€è´¹å‡å…é‡‘é¢'])
                - order_agg['ä¼å®¢åè¿”']
            )
            
            # è®¡ç®—è®¢å•å®é™…åˆ©æ¶¦
            # è®¢å•å®é™…åˆ©æ¶¦ = åˆ©æ¶¦é¢ - å¹³å°æœåŠ¡è´¹ - ç‰©æµé…é€è´¹ + ä¼å®¢åè¿”
            order_agg['è®¢å•å®é™…åˆ©æ¶¦'] = (
                order_agg['åˆ©æ¶¦é¢'] 
                - order_agg['å¹³å°æœåŠ¡è´¹'] 
                - order_agg['ç‰©æµé…é€è´¹'] 
                + order_agg['ä¼å®¢åè¿”']
            )
            
            # æå–å°æ—¶
            order_agg['å°æ—¶'] = pd.to_datetime(order_agg['ä¸‹å•æ—¶é—´']).dt.hour
            
            # åˆ¤æ–­æ˜¯å¦æº¢ä»·ï¼ˆé«˜é…é€è´¹é¢„è­¦ï¼‰
            # å®šä¹‰ï¼šé…é€å‡€æˆæœ¬ > 6å…ƒï¼ˆä¸Dashç‰ˆæœ¬ä¿æŒä¸€è‡´ï¼‰
            PREMIUM_THRESHOLD = 6
            order_agg['æ˜¯å¦æº¢ä»·'] = order_agg['é…é€å‡€æˆæœ¬'] > PREMIUM_THRESHOLD
            
            # ğŸ”§ æ€§èƒ½ä¼˜åŒ–ï¼šä½¿ç”¨å‘é‡åŒ–æ“ä½œæ›¿ä»£å¾ªç¯
            total_orders = len(order_agg)
            premium_mask = order_agg['æ˜¯å¦æº¢ä»·']
            premium_count = int(premium_mask.sum())
            healthy_count = total_orders - premium_count
            
            premium_profit_sum = float(order_agg.loc[premium_mask, 'è®¢å•å®é™…åˆ©æ¶¦'].sum())
            healthy_profit_sum = float(order_agg.loc[~premium_mask, 'è®¢å•å®é™…åˆ©æ¶¦'].sum())
            
            premium_rate = round(premium_count / total_orders * 100, 1) if total_orders > 0 else 0
            
            # æ„å»ºè¿”å›æ•°æ®ï¼ˆå‘é‡åŒ–ï¼‰
            radar_points = order_agg.apply(lambda row: {
                "distance": round(row['é…é€è·ç¦»'], 2),
                "hour": int(row['å°æ—¶']),
                "delivery_cost": round(row['é…é€å‡€æˆæœ¬'], 2),
                "order_value": round(row['å•†å“å®å”®ä»·'], 2),
                "profit": round(row['è®¢å•å®é™…åˆ©æ¶¦'], 2),
                "is_premium": bool(row['æ˜¯å¦æº¢ä»·']),
                "channel": row['æ¸ é“']
            }, axis=1).tolist()
            
            return {
                "success": True,
                "date": date_label,  # ğŸ†• ä½¿ç”¨ date_labelï¼ˆæ”¯æŒæ—¥æœŸèŒƒå›´ï¼‰
                "data": radar_points,
                "summary": {
                    "total": total_orders,
                    "premium_count": premium_count,
                    "premium_rate": premium_rate,
                    "healthy_avg_profit": round(healthy_profit_sum / healthy_count, 2) if healthy_count > 0 else 0,
                    "premium_avg_profit": round(premium_profit_sum / premium_count, 2) if premium_count > 0 else 0
                }
            }
            
        finally:
            session.close()
            
    except Exception as e:
        print(f"âŒ è·å–é…é€æº¢ä»·é›·è¾¾æ•°æ®å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return {"success": False, "message": str(e), "data": []}


# ==================== è¥é”€æˆæœ¬ç»“æ„åˆ†æAPIï¼ˆè¥é”€æˆæœ¬æ¡‘åŸºå›¾ä¸“ç”¨ï¼‰ ====================

@router.get("/marketing-structure")
async def get_marketing_structure(
    store_name: Optional[str] = Query(None, description="é—¨åº—åç§°ç­›é€‰"),
    start_date: Optional[date] = Query(None, description="å¼€å§‹æ—¥æœŸ"),
    end_date: Optional[date] = Query(None, description="ç»“æŸæ—¥æœŸ")
) -> Dict[str, Any]:
    """
    è·å–è¥é”€æˆæœ¬ç»“æ„åˆ†ææ•°æ®ï¼ˆè¥é”€æˆæœ¬æ¡‘åŸºå›¾ä¸“ç”¨ï¼‰
    
    å±•ç¤ºå„æ¸ é“åœ¨7ä¸ªè¥é”€å­—æ®µä¸Šçš„è´¹ç”¨åˆ†å¸ƒï¼ˆä¸å«é…é€è´¹å‡å…é‡‘é¢ï¼‰ï¼š
    - æ»¡å‡é‡‘é¢ (full_reduction)
    - å•†å“å‡å…é‡‘é¢ (product_discount)
    - å•†å®¶ä»£é‡‘åˆ¸ (merchant_voucher)
    - å•†å®¶æ‰¿æ‹…éƒ¨åˆ†åˆ¸ (merchant_share)
    - æ»¡èµ é‡‘é¢ (gift_amount)
    - å•†å®¶å…¶ä»–ä¼˜æƒ  (other_discount)
    - æ–°å®¢å‡å…é‡‘é¢ (new_customer_discount)
    
    æ³¨æ„ï¼šé…é€è´¹å‡å…é‡‘é¢å±äºé…é€æˆæœ¬ï¼Œä¸å±äºè¥é”€æˆæœ¬ï¼Œå·²å‰”é™¤
    
    æ‰€æœ‰7ä¸ªå­—æ®µéƒ½æ˜¯è®¢å•çº§å­—æ®µï¼Œèšåˆæ—¶ä½¿ç”¨ .first() é¿å…é‡å¤è®¡ç®—
    
    æ±‡æ€»æŒ‡æ ‡ï¼š
    - æ€»è¥é”€æˆæœ¬ = 7ä¸ªè¥é”€å­—æ®µä¹‹å’Œ
    - å•å‡è¥é”€è´¹ç”¨ = æ€»è¥é”€æˆæœ¬ / è®¢å•æ•°
    - è¥é”€æˆæœ¬ç‡ = æ€»è¥é”€æˆæœ¬ / é”€å”®é¢ Ã— 100%
    """
    # æŒ‰é—¨åº—åŠ è½½æ•°æ®
    df = get_order_data(store_name)
    
    empty_result = {
        "success": True,
        "data": {
            "channels": [],
            "summary": {
                "total_marketing_cost": 0,
                "avg_marketing_per_order": 0,
                "marketing_cost_ratio": 0,
                "total_orders": 0,
                "total_revenue": 0
            }
        }
    }
    
    if df.empty:
        return empty_result
    
    # æ—¥æœŸç­›é€‰
    if 'æ—¥æœŸ' in df.columns:
        df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'], errors='coerce')
        if start_date:
            df = df[df['æ—¥æœŸ'].dt.date >= start_date]
        if end_date:
            df = df[df['æ—¥æœŸ'].dt.date <= end_date]
    
    if df.empty or 'æ¸ é“' not in df.columns:
        return empty_result
    
    # è®¡ç®—è®¢å•çº§æŒ‡æ ‡ï¼ˆä½¿ç”¨ç»Ÿä¸€å‡½æ•°ï¼‰
    order_agg = calculate_order_metrics(df)
    
    if order_agg.empty or 'æ¸ é“' not in order_agg.columns:
        return empty_result
    
    # æ’é™¤å’–å•¡æ¸ é“ï¼ˆä¸Dashç‰ˆæœ¬ä¸€è‡´ï¼‰
    CHANNELS_TO_REMOVE = ['ç¾å›¢å’–å•¡åº—', 'é¥¿äº†ä¹ˆå’–å•¡åº—', 'é¥¿äº†ä¹ˆå’–å•¡', 'ç¾å›¢å’–å•¡']
    order_agg = order_agg[~order_agg['æ¸ é“'].isin(CHANNELS_TO_REMOVE)]
    
    if order_agg.empty:
        return empty_result
    
    # 7ä¸ªè¥é”€å­—æ®µæ˜ å°„ï¼ˆä¸­æ–‡å­—æ®µå -> APIè¿”å›å­—æ®µåï¼‰
    # æ³¨æ„ï¼šé…é€è´¹å‡å…é‡‘é¢å±äºé…é€æˆæœ¬ï¼Œä¸å±äºè¥é”€æˆæœ¬ï¼Œå·²å‰”é™¤
    MARKETING_FIELDS = {
        'æ»¡å‡é‡‘é¢': 'full_reduction',
        'å•†å“å‡å…é‡‘é¢': 'product_discount',
        'å•†å®¶ä»£é‡‘åˆ¸': 'merchant_voucher',
        'å•†å®¶æ‰¿æ‹…éƒ¨åˆ†åˆ¸': 'merchant_share',
        'æ»¡èµ é‡‘é¢': 'gift_amount',
        'å•†å®¶å…¶ä»–ä¼˜æƒ ': 'other_discount',
        'æ–°å®¢å‡å…é‡‘é¢': 'new_customer_discount'
    }
    
    # æŒ‰æ¸ é“èšåˆè¥é”€å­—æ®µ
    agg_dict = {
        'è®¢å•ID': 'count',
        'å®æ”¶ä»·æ ¼': 'sum',
    }
    
    # æ·»åŠ 7ä¸ªè¥é”€å­—æ®µçš„èšåˆï¼ˆè®¢å•çº§å­—æ®µå·²åœ¨calculate_order_metricsä¸­ç”¨firstèšåˆï¼‰
    for cn_field in MARKETING_FIELDS.keys():
        if cn_field in order_agg.columns:
            agg_dict[cn_field] = 'sum'
    
    channel_stats = order_agg.groupby('æ¸ é“').agg(agg_dict).reset_index()
    
    # æ„å»ºè¿”å›æ•°æ®
    channels_data = []
    total_marketing_cost = 0
    total_orders = 0
    total_revenue = 0
    
    for _, row in channel_stats.iterrows():
        channel_name = row['æ¸ é“']
        order_count = int(row['è®¢å•ID'])
        revenue = float(row['å®æ”¶ä»·æ ¼'])
        
        # æ„å»ºè¥é”€æˆæœ¬å­—å…¸
        marketing_costs = {}
        channel_marketing_total = 0
        
        for cn_field, en_field in MARKETING_FIELDS.items():
            if cn_field in channel_stats.columns:
                value = float(row[cn_field])
            else:
                value = 0.0
            marketing_costs[en_field] = round(value, 2)
            channel_marketing_total += value
        
        # ç´¯è®¡æ€»è®¡
        total_marketing_cost += channel_marketing_total
        total_orders += order_count
        total_revenue += revenue
        
        channels_data.append({
            "channel": channel_name,
            "order_count": order_count,
            "revenue": round(revenue, 2),
            "marketing_costs": marketing_costs,
            "total_marketing_cost": round(channel_marketing_total, 2)
        })
    
    # æŒ‰æ€»è¥é”€æˆæœ¬æ’åº
    channels_data.sort(key=lambda x: x['total_marketing_cost'], reverse=True)
    
    # è®¡ç®—æ±‡æ€»æŒ‡æ ‡
    avg_marketing_per_order = total_marketing_cost / total_orders if total_orders > 0 else 0
    marketing_cost_ratio = (total_marketing_cost / total_revenue * 100) if total_revenue > 0 else 0
    
    return {
        "success": True,
        "data": {
            "channels": channels_data,
            "summary": {
                "total_marketing_cost": round(total_marketing_cost, 2),
                "avg_marketing_per_order": round(avg_marketing_per_order, 2),
                "marketing_cost_ratio": round(marketing_cost_ratio, 2),
                "total_orders": total_orders,
                "total_revenue": round(total_revenue, 2)
            }
        }
    }


# ==================== è¥é”€æˆæœ¬è¶‹åŠ¿åˆ†æAPIï¼ˆè¥é”€æˆæœ¬è¶‹åŠ¿å›¾ä¸“ç”¨ï¼‰ ====================

@router.get("/marketing-trend")
async def get_marketing_trend(
    store_name: Optional[str] = Query(None, description="é—¨åº—åç§°ç­›é€‰"),
    channel: Optional[str] = Query(None, description="æ¸ é“ç­›é€‰"),
    start_date: Optional[date] = Query(None, description="å¼€å§‹æ—¥æœŸ"),
    end_date: Optional[date] = Query(None, description="ç»“æŸæ—¥æœŸ")
) -> Dict[str, Any]:
    """
    è·å–è¥é”€æˆæœ¬è¶‹åŠ¿åˆ†ææ•°æ®ï¼ˆè¥é”€æˆæœ¬è¶‹åŠ¿å›¾ä¸“ç”¨ï¼‰
    
    æŒ‰æ—¥æœŸèšåˆ7ä¸ªè¥é”€å­—æ®µçš„æˆæœ¬æ•°æ®ï¼Œç”¨äºå±•ç¤ºå„è¥é”€ç±»å‹å æ¯”éšæ—¶é—´çš„å˜åŒ–è¶‹åŠ¿ã€‚
    
    7ä¸ªè¥é”€å­—æ®µï¼ˆä¸å«é…é€è´¹å‡å…é‡‘é¢ï¼‰ï¼š
    - æ»¡å‡é‡‘é¢ (full_reduction)
    - å•†å“å‡å…é‡‘é¢ (product_discount)
    - å•†å®¶ä»£é‡‘åˆ¸ (merchant_voucher)
    - å•†å®¶æ‰¿æ‹…éƒ¨åˆ†åˆ¸ (merchant_share)
    - æ»¡èµ é‡‘é¢ (gift_amount)
    - å•†å®¶å…¶ä»–ä¼˜æƒ  (other_discount)
    - æ–°å®¢å‡å…é‡‘é¢ (new_customer_discount)
    
    æ³¨æ„ï¼šé…é€è´¹å‡å…é‡‘é¢å±äºé…é€æˆæœ¬ï¼Œä¸å±äºè¥é”€æˆæœ¬ï¼Œå·²å‰”é™¤
    
    æ‰€æœ‰7ä¸ªå­—æ®µéƒ½æ˜¯è®¢å•çº§å­—æ®µï¼Œèšåˆæ—¶ä½¿ç”¨ .first() é¿å…é‡å¤è®¡ç®—
    
    è¿”å›æ•°æ®ç»“æ„ï¼š
    - dates: æ—¥æœŸæ•°ç»„
    - series: å„è¥é”€ç±»å‹çš„æ¯æ—¥é‡‘é¢æ•°ç»„
    - totals: æ¯æ—¥æ€»è¥é”€æˆæœ¬æ•°ç»„
    
    Requirements: 1.1, 1.2, 1.3, 1.4, 1.5
    """
    # æŒ‰é—¨åº—åŠ è½½æ•°æ®
    df = get_order_data(store_name)
    
    # 7ä¸ªè¥é”€å­—æ®µæ˜ å°„ï¼ˆä¸­æ–‡å­—æ®µå -> APIè¿”å›å­—æ®µåï¼‰
    # æ³¨æ„ï¼šé…é€è´¹å‡å…é‡‘é¢å±äºé…é€æˆæœ¬ï¼Œä¸å±äºè¥é”€æˆæœ¬ï¼Œå·²å‰”é™¤
    MARKETING_FIELDS = {
        'æ»¡å‡é‡‘é¢': 'full_reduction',
        'å•†å“å‡å…é‡‘é¢': 'product_discount',
        'å•†å®¶ä»£é‡‘åˆ¸': 'merchant_voucher',
        'å•†å®¶æ‰¿æ‹…éƒ¨åˆ†åˆ¸': 'merchant_share',
        'æ»¡èµ é‡‘é¢': 'gift_amount',
        'å•†å®¶å…¶ä»–ä¼˜æƒ ': 'other_discount',
        'æ–°å®¢å‡å…é‡‘é¢': 'new_customer_discount'
    }
    
    empty_result = {
        "success": True,
        "data": {
            "dates": [],
            "series": {
                "full_reduction": [],
                "product_discount": [],
                "merchant_voucher": [],
                "merchant_share": [],
                "gift_amount": [],
                "other_discount": [],
                "new_customer_discount": []
            },
            "totals": []
        }
    }
    
    if df.empty:
        return empty_result
    
    # æ¸ é“ç­›é€‰
    if channel and channel != 'all' and 'æ¸ é“' in df.columns:
        df = df[df['æ¸ é“'] == channel]
    
    if df.empty:
        return empty_result
    
    # æ—¥æœŸç­›é€‰
    if 'æ—¥æœŸ' not in df.columns:
        return empty_result
    
    df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'], errors='coerce')
    df = df.dropna(subset=['æ—¥æœŸ'])
    
    if df.empty:
        return empty_result
    
    # Requirements 1.4: æ”¯æŒæŒ‰æ—¥æœŸèŒƒå›´è¿‡æ»¤
    if start_date:
        df = df[df['æ—¥æœŸ'].dt.date >= start_date]
    if end_date:
        df = df[df['æ—¥æœŸ'].dt.date <= end_date]
    
    if df.empty:
        return empty_result
    
    # Requirements 1.2: è®¡ç®—è®¢å•çº§æŒ‡æ ‡ï¼ˆä½¿ç”¨ç»Ÿä¸€å‡½æ•°ï¼Œè®¢å•çº§å­—æ®µç”¨firstèšåˆï¼‰
    order_agg = calculate_order_metrics(df)
    
    if order_agg.empty or 'æ—¥æœŸ' not in order_agg.columns:
        return empty_result
    
    # ç¡®ä¿æ—¥æœŸåˆ—æ˜¯datetimeç±»å‹
    order_agg['æ—¥æœŸ'] = pd.to_datetime(order_agg['æ—¥æœŸ'], errors='coerce')
    order_agg = order_agg.dropna(subset=['æ—¥æœŸ'])
    
    if order_agg.empty:
        return empty_result
    
    # æå–æ—¥æœŸéƒ¨åˆ†ç”¨äºåˆ†ç»„
    order_agg['æ—¥æœŸ_str'] = order_agg['æ—¥æœŸ'].dt.strftime('%Y-%m-%d')
    
    # æŒ‰æ—¥æœŸèšåˆè¥é”€å­—æ®µ
    agg_dict = {}
    for cn_field in MARKETING_FIELDS.keys():
        if cn_field in order_agg.columns:
            agg_dict[cn_field] = 'sum'
    
    if not agg_dict:
        return empty_result
    
    daily_stats = order_agg.groupby('æ—¥æœŸ_str').agg(agg_dict).reset_index()
    
    # æŒ‰æ—¥æœŸæ’åº
    daily_stats = daily_stats.sort_values('æ—¥æœŸ_str')
    
    # æ„å»ºè¿”å›æ•°æ®
    dates = daily_stats['æ—¥æœŸ_str'].tolist()
    
    # Requirements 1.3: æ„å»ºseriesæ•°æ®ç»“æ„
    series = {}
    for cn_field, en_field in MARKETING_FIELDS.items():
        if cn_field in daily_stats.columns:
            series[en_field] = [round(float(v), 2) for v in daily_stats[cn_field].tolist()]
        else:
            # Requirements 1.5: æŸæ—¥æœŸæŸè¥é”€ç±»å‹é‡‘é¢ä¸º0æ—¶è¿”å›0ï¼ˆä¸çœç•¥ï¼‰
            series[en_field] = [0.0] * len(dates)
    
    # è®¡ç®—æ¯æ—¥æ€»è¥é”€æˆæœ¬
    totals = []
    for i in range(len(dates)):
        daily_total = sum(series[en_field][i] for en_field in MARKETING_FIELDS.values())
        totals.append(round(daily_total, 2))
    
    return {
        "success": True,
        "data": {
            "dates": dates,
            "series": series,
            "totals": totals
        }
    }
