# -*- coding: utf-8 -*-
"""
å…¨é‡é—¨åº—å¯¹æ¯”åˆ†æ API

åŠŸèƒ½ï¼š
- å…¨é‡é—¨åº—å…³é”®æŒ‡æ ‡å¯¹æ¯”
- é—¨åº—æ’è¡Œæ¦œ
- ç¯æ¯”æ•°æ®ï¼ˆæœ¬å‘¨ vs ä¸Šå‘¨ï¼‰+ åŒæ¯”æ•°æ®ï¼ˆå»å¹´åŒæœŸï¼‰
- é—¨åº—æ•ˆç‡åˆ†æ
- å¼‚å¸¸é—¨åº—æ£€æµ‹

è®¡ç®—é€»è¾‘ä¸ç»è¥æ€»è§ˆï¼ˆorders.pyï¼‰å®Œå…¨ä¸€è‡´

ä¼˜åŒ–ç‚¹ï¼š
- SQLå±‚é¢æ¸ é“ç­›é€‰ï¼ˆé¿å…N+1æŸ¥è¯¢ï¼‰
- ç¼“å­˜keyåŒ…å«æ¸ é“å‚æ•°
- å¹³å‡åˆ©æ¶¦ç‡ä½¿ç”¨åŠ æƒå¹³å‡
- æ·»åŠ åŒæ¯”æ•°æ®
- æ·»åŠ å¼‚å¸¸æ£€æµ‹
"""

from fastapi import APIRouter, Depends, Query, HTTPException
from typing import Optional, List, Dict, Any
from datetime import date, datetime, timedelta
import pandas as pd
import numpy as np
import time
import json

import sys
from pathlib import Path
APP_DIR = Path(__file__).resolve().parent.parent.parent
PROJECT_ROOT = APP_DIR.parent.parent
if str(APP_DIR) not in sys.path:
    sys.path.insert(0, str(APP_DIR))
if str(PROJECT_ROOT) not in sys.path:
    sys.path.insert(0, str(PROJECT_ROOT))

from database.connection import SessionLocal
from database.models import Order
from .orders import calculate_order_metrics, calculate_gmv
from sqlalchemy import and_, or_, func, text

# å°è¯•å¯¼å…¥Redisç¼“å­˜
try:
    import redis
    REDIS_AVAILABLE = True
    redis_client = redis.Redis(host='localhost', port=6379, db=0, decode_responses=True)
    # æµ‹è¯•è¿æ¥
    redis_client.ping()
    print("âœ… Redisç¼“å­˜å·²è¿æ¥")
except Exception as e:
    REDIS_AVAILABLE = False
    redis_client = None
    print(f"âš ï¸ Redisç¼“å­˜ä¸å¯ç”¨: {e}")

# æ£€æŸ¥é¢„èšåˆè¡¨æ˜¯å¦å¯ç”¨
AGGREGATION_TABLE_AVAILABLE = False
try:
    session = SessionLocal()
    result = session.execute(text("SELECT COUNT(*) FROM store_daily_summary"))
    count = result.scalar()
    if count and count > 0:
        AGGREGATION_TABLE_AVAILABLE = True
        print(f"âœ… é¢„èšåˆè¡¨å¯ç”¨: {count} æ¡æ±‡æ€»è®°å½•")
    session.close()
except Exception as e:
    print(f"âš ï¸ é¢„èšåˆè¡¨ä¸å¯ç”¨: {e}")

router = APIRouter()

# ==================== ç¼“å­˜é…ç½® ====================
# âœ… ä¼˜åŒ–ï¼šå»¶é•¿TTLåˆ°24å°æ—¶ï¼ˆæ•°æ®æ¯å¤©æ›´æ–°ä¸€æ¬¡ï¼‰
CACHE_TTL = 86400  # ç¼“å­˜æœ‰æ•ˆæœŸ24å°æ—¶
STORE_COMPARISON_CACHE_KEY = "store_comparison_all"
STORE_COMPARISON_TIMESTAMP_KEY = "store_comparison_timestamp"

# æ¸ é“ä¸è®¢å•ç¼–å·å‰ç¼€çš„æ˜ å°„ï¼ˆå…¨å±€å¸¸é‡ï¼‰
CHANNEL_PREFIX_MAP = {
    'ç¾å›¢': 'SG',
    'é¥¿äº†ä¹ˆ': 'ELE',
    'äº¬ä¸œ': 'JD'
}

# å†…å­˜ç¼“å­˜ï¼ˆå¤‡ç”¨ï¼‰- æ”¯æŒæ¸ é“ç»´åº¦
_store_comparison_cache = {}


def get_store_metrics_from_aggregation(
    start_date: Optional[date] = None,
    end_date: Optional[date] = None,
    channel: Optional[str] = None
) -> pd.DataFrame:
    """
    ä»é¢„èšåˆè¡¨å¿«é€Ÿè·å–é—¨åº—æŒ‡æ ‡ï¼ˆæ€§èƒ½ä¼˜åŒ–ç‰ˆï¼‰
    
    ä½¿ç”¨é¢„èšåˆè¡¨ store_daily_summary è¿›è¡ŒæŸ¥è¯¢ï¼Œ
    æŸ¥è¯¢æ—¶é—´ä» ~500ms é™ä½åˆ° ~2ms
    
    æ³¨æ„ï¼šéœ€è¦å…ˆè¿è¡Œ æ›´æ–°é¢„èšåˆè¡¨æ·»åŠ GMVå­—æ®µ.py è„šæœ¬æ·»åŠ GMVå­—æ®µ
    
    Args:
        start_date: å¼€å§‹æ—¥æœŸ
        end_date: ç»“æŸæ—¥æœŸ
        channel: æ¸ é“åç§°ï¼ˆç¾å›¢/é¥¿äº†ä¹ˆ/äº¬ä¸œï¼‰ï¼ŒNoneè¡¨ç¤ºå…¨éƒ¨
    
    Returns:
        DataFrame with store metrics
    """
    if not AGGREGATION_TABLE_AVAILABLE:
        return pd.DataFrame()
    
    session = SessionLocal()
    try:
        # æ£€æŸ¥æ˜¯å¦æœ‰GMVå­—æ®µ
        check_sql = """
            SELECT column_name FROM information_schema.columns 
            WHERE table_name = 'store_daily_summary' AND column_name = 'gmv'
        """
        result = session.execute(text(check_sql))
        has_gmv = result.fetchone() is not None
        
        if not has_gmv:
            print("âš ï¸ [é¢„èšåˆè¡¨] ç¼ºå°‘GMVå­—æ®µï¼Œè¯·è¿è¡Œ æ›´æ–°é¢„èšåˆè¡¨æ·»åŠ GMVå­—æ®µ.py")
            return pd.DataFrame()
        
        # æ„å»ºæŸ¥è¯¢ï¼ˆåŒ…å«GMVå­—æ®µï¼‰
        sql = """
            SELECT 
                store_name,
                SUM(order_count) as order_count,
                SUM(total_revenue) as total_revenue,
                SUM(total_profit) as total_profit,
                SUM(delivery_net_cost) as total_delivery_cost,
                SUM(total_marketing_cost) as total_marketing_cost,
                SUM(COALESCE(gmv, 0)) as total_gmv
            FROM store_daily_summary
            WHERE 1=1
        """
        params = {}
        
        if start_date:
            sql += " AND summary_date >= :start_date"
            params['start_date'] = start_date
        if end_date:
            sql += " AND summary_date <= :end_date"
            params['end_date'] = end_date
        if channel and channel in ['ç¾å›¢', 'é¥¿äº†ä¹ˆ', 'äº¬ä¸œ']:
            sql += " AND channel = :channel"
            params['channel'] = channel
        
        sql += " GROUP BY store_name"
        
        result = session.execute(text(sql), params)
        rows = result.fetchall()
        
        if not rows:
            return pd.DataFrame()
        
        # è½¬æ¢ä¸ºDataFrame
        data = []
        for row in rows:
            store_name = row[0]
            order_count = int(row[1]) if row[1] else 0
            total_revenue = float(row[2]) if row[2] else 0
            total_profit = float(row[3]) if row[3] else 0
            total_delivery_cost = float(row[4]) if row[4] else 0
            total_marketing_cost = float(row[5]) if row[5] else 0
            total_gmv = float(row[6]) if row[6] else 0
            
            # è®¡ç®—æ´¾ç”ŸæŒ‡æ ‡
            profit_margin = (total_profit / total_revenue * 100) if total_revenue > 0 else 0
            aov = total_revenue / order_count if order_count > 0 else 0
            avg_delivery_fee = total_delivery_cost / order_count if order_count > 0 else 0
            avg_marketing_cost = total_marketing_cost / order_count if order_count > 0 else 0
            delivery_cost_rate = (total_delivery_cost / total_revenue * 100) if total_revenue > 0 else 0
            # âœ… è¥é”€æˆæœ¬ç‡ = è¥é”€æˆæœ¬ / GMV Ã— 100%
            marketing_cost_rate = (total_marketing_cost / total_gmv * 100) if total_gmv > 0 else 0
            
            data.append({
                'store_name': store_name,
                'order_count': order_count,
                'total_revenue': total_revenue,
                'total_profit': total_profit,
                'total_delivery_cost': total_delivery_cost,
                'total_marketing_cost': total_marketing_cost,
                'gmv': total_gmv,
                'profit_margin': profit_margin,
                'aov': aov,
                'avg_delivery_fee': avg_delivery_fee,
                'avg_marketing_cost': avg_marketing_cost,
                'delivery_cost_rate': delivery_cost_rate,
                'marketing_cost_rate': marketing_cost_rate
            })
        
        df = pd.DataFrame(data)
        
        # è®¡ç®—æ’å
        df['revenue_rank'] = df['total_revenue'].rank(ascending=False, method='min').astype(int)
        df['profit_rank'] = df['total_profit'].rank(ascending=False, method='min').astype(int)
        df['profit_margin_rank'] = df['profit_margin'].rank(ascending=False, method='min').astype(int)
        
        print(f"âœ… [é¢„èšåˆè¡¨+GMV] å¿«é€ŸæŸ¥è¯¢å®Œæˆ: {len(df)} é—¨åº—, æ¸ é“={channel or 'å…¨éƒ¨'}")
        return df
    except Exception as e:
        print(f"âš ï¸ é¢„èšåˆè¡¨æŸ¥è¯¢å¤±è´¥: {e}")
        return pd.DataFrame()
    finally:
        session.close()


def get_all_stores_data(
    start_date: Optional[date] = None, 
    end_date: Optional[date] = None,
    channel: Optional[str] = None
) -> pd.DataFrame:
    """
    ä»æ•°æ®åº“åŠ è½½æ‰€æœ‰é—¨åº—çš„è®¢å•æ•°æ®ï¼ˆå¸¦ç¼“å­˜ï¼‰
    
    ä¼˜åŒ–ç‚¹ï¼š
    1. SQLå±‚é¢ç›´æ¥ç­›é€‰æ¸ é“ï¼ˆé¿å…N+1æŸ¥è¯¢ï¼‰
    2. ç¼“å­˜keyåŒ…å«æ¸ é“å‚æ•°
    3. ä¼˜å…ˆä½¿ç”¨Redisç¼“å­˜ï¼Œå¤‡ç”¨å†…å­˜ç¼“å­˜
    4. ç¼“å­˜æœ‰æ•ˆæœŸ5åˆ†é’Ÿ
    
    Args:
        start_date: å¼€å§‹æ—¥æœŸ
        end_date: ç»“æŸæ—¥æœŸ
        channel: æ¸ é“åç§°ï¼ˆç¾å›¢/é¥¿äº†ä¹ˆ/äº¬ä¸œï¼‰ï¼ŒNoneè¡¨ç¤ºå…¨éƒ¨
    """
    global _store_comparison_cache
    current_time = time.time()
    
    # ç”Ÿæˆç¼“å­˜keyï¼ˆåŒ…å«æ—¥æœŸèŒƒå›´å’Œæ¸ é“ï¼‰
    channel_key = channel if channel else "all"
    date_key = f"{start_date}:{end_date}:{channel_key}"
    redis_cache_key = f"{STORE_COMPARISON_CACHE_KEY}:{date_key}"
    redis_timestamp_key = f"{STORE_COMPARISON_TIMESTAMP_KEY}:{date_key}"
    
    # 1. å°è¯•ä»Redisè·å–ç¼“å­˜
    if REDIS_AVAILABLE and redis_client:
        try:
            cached_timestamp = redis_client.get(redis_timestamp_key)
            if cached_timestamp:
                if current_time - float(cached_timestamp) < CACHE_TTL:
                    cached_data = redis_client.get(redis_cache_key)
                    if cached_data:
                        data = json.loads(cached_data)
                        print(f"ğŸ“¦ ä½¿ç”¨Redisç¼“å­˜æ•°æ® (å…¨é‡é—¨åº—å¯¹æ¯”, æ¸ é“={channel_key}, {len(data)} æ¡)")
                        return pd.DataFrame(data)
        except Exception as e:
            print(f"âš ï¸ Redisè¯»å–å¤±è´¥: {e}")
    
    # 2. å°è¯•ä½¿ç”¨å†…å­˜ç¼“å­˜
    cache_entry = _store_comparison_cache.get(date_key)
    if cache_entry and current_time - cache_entry.get("timestamp", 0) < CACHE_TTL:
        print(f"ğŸ“¦ ä½¿ç”¨å†…å­˜ç¼“å­˜æ•°æ® (å…¨é‡é—¨åº—å¯¹æ¯”, æ¸ é“={channel_key})")
        return cache_entry["data"].copy()
    
    # 3. ä»æ•°æ®åº“åŠ è½½ï¼ˆSQLå±‚é¢ç›´æ¥ç­›é€‰ï¼‰
    print(f"ğŸ”„ ä»æ•°æ®åº“åŠ è½½å…¨é‡é—¨åº—æ•°æ® (æ—¥æœŸ: {start_date}~{end_date}, æ¸ é“: {channel_key})...")
    session = SessionLocal()
    try:
        query = session.query(Order)
        
        # æ—¥æœŸç­›é€‰
        if start_date:
            query = query.filter(Order.date >= datetime.combine(start_date, datetime.min.time()))
        if end_date:
            query = query.filter(Order.date <= datetime.combine(end_date, datetime.max.time()))
        
        # âœ… SQLå±‚é¢æ¸ é“ç­›é€‰ï¼ˆé¿å…N+1æŸ¥è¯¢ï¼‰
        if channel and channel in CHANNEL_PREFIX_MAP:
            prefix = CHANNEL_PREFIX_MAP[channel]
            query = query.filter(Order.order_number.like(f'{prefix}%'))
            print(f"   SQLæ¸ é“ç­›é€‰: order_number LIKE '{prefix}%'")
        
        orders = query.all()
        if not orders:
            return pd.DataFrame()
        
        # è½¬æ¢ä¸ºDataFrame
        data = []
        for order in orders:
            data.append({
                'è®¢å•ID': order.order_id,
                'é—¨åº—åç§°': order.store_name,
                'é—¨åº—ID': order.store_id,
                'æ—¥æœŸ': order.date,
                'æ¸ é“': order.channel,
                'å•†å“åç§°': order.product_name,
                'ä¸€çº§åˆ†ç±»å': order.category_level1,
                'ä¸‰çº§åˆ†ç±»å': order.category_level3,
                'æœˆå”®': order.quantity if order.quantity is not None else 1,
                'å®æ”¶ä»·æ ¼': float(order.actual_price or 0),
                'å•†å“å®å”®ä»·': float(order.price or 0),
                'å•†å“åŸä»·': float(order.original_price or 0),  # âœ… æ–°å¢ï¼šGMVè®¡ç®—éœ€è¦
                'å•†å“é‡‡è´­æˆæœ¬': float(order.cost or 0),
                'åˆ©æ¶¦é¢': float(order.profit or 0),
                'ç‰©æµé…é€è´¹': float(order.delivery_fee or 0),
                'å¹³å°æœåŠ¡è´¹': float(order.platform_service_fee or 0),
                'å¹³å°ä½£é‡‘': float(order.commission or 0),
                'é¢„è®¡è®¢å•æ”¶å…¥': float(order.amount or 0),
                'ä¼å®¢åè¿”': float(order.corporate_rebate or 0),
                'ç”¨æˆ·æ”¯ä»˜é…é€è´¹': float(order.user_paid_delivery_fee or 0),
                'é…é€è´¹å‡å…é‡‘é¢': float(order.delivery_discount or 0),
                'æ»¡å‡é‡‘é¢': float(order.full_reduction or 0),
                'å•†å“å‡å…é‡‘é¢': float(order.product_discount or 0),
                'æ–°å®¢å‡å…é‡‘é¢': float(order.new_customer_discount or 0),
                'å•†å®¶ä»£é‡‘åˆ¸': float(order.merchant_voucher or 0),
                'å•†å®¶æ‰¿æ‹…éƒ¨åˆ†åˆ¸': float(order.merchant_share or 0),
                'æ»¡èµ é‡‘é¢': float(order.gift_amount or 0),
                'å•†å®¶å…¶ä»–ä¼˜æƒ ': float(order.other_merchant_discount or 0),
                'æ‰“åŒ…è¢‹é‡‘é¢': float(order.packaging_fee or 0),  # âœ… æ–°å¢ï¼šGMVè®¡ç®—éœ€è¦
            })
        
        df = pd.DataFrame(data)
        print(f"âœ… å…¨é‡é—¨åº—æ•°æ®åŠ è½½å®Œæˆ: {len(df)} æ¡è®°å½•, {df['é—¨åº—åç§°'].nunique()} ä¸ªé—¨åº—")
        
        # 4. æ›´æ–°ç¼“å­˜
        # æ›´æ–°å†…å­˜ç¼“å­˜
        _store_comparison_cache[date_key] = {
            "data": df.copy(),
            "timestamp": current_time
        }
        
        # æ›´æ–°Redisç¼“å­˜
        if REDIS_AVAILABLE and redis_client:
            try:
                # å°†æ—¥æœŸè½¬æ¢ä¸ºå­—ç¬¦ä¸²ä»¥ä¾¿JSONåºåˆ—åŒ–
                cache_data = data.copy()
                for item in cache_data:
                    if item.get('æ—¥æœŸ'):
                        item['æ—¥æœŸ'] = str(item['æ—¥æœŸ'])
                
                redis_client.set(redis_cache_key, json.dumps(cache_data, ensure_ascii=False))
                redis_client.set(redis_timestamp_key, str(current_time))
                # è®¾ç½®è¿‡æœŸæ—¶é—´
                redis_client.expire(redis_cache_key, CACHE_TTL)
                redis_client.expire(redis_timestamp_key, CACHE_TTL)
                print(f"âœ… æ•°æ®å·²ç¼“å­˜åˆ°Redis (å…¨é‡é—¨åº—å¯¹æ¯”, æ¸ é“={channel_key})")
            except Exception as e:
                print(f"âš ï¸ Redisç¼“å­˜å†™å…¥å¤±è´¥: {e}")
        
        return df
    finally:
        session.close()


def invalidate_store_comparison_cache():
    """æ¸…é™¤å…¨é‡é—¨åº—å¯¹æ¯”ç¼“å­˜ï¼ˆæ•°æ®æ›´æ–°æ—¶è°ƒç”¨ï¼‰"""
    global _store_comparison_cache
    _store_comparison_cache = {}
    
    if REDIS_AVAILABLE and redis_client:
        try:
            # æ¸…é™¤æ‰€æœ‰é—¨åº—å¯¹æ¯”ç›¸å…³çš„ç¼“å­˜
            keys = redis_client.keys(f"{STORE_COMPARISON_CACHE_KEY}:*")
            if keys:
                redis_client.delete(*keys)
            keys = redis_client.keys(f"{STORE_COMPARISON_TIMESTAMP_KEY}:*")
            if keys:
                redis_client.delete(*keys)
            print("âœ… å…¨é‡é—¨åº—å¯¹æ¯”Redisç¼“å­˜å·²æ¸…é™¤")
        except Exception as e:
            print(f"âš ï¸ Redisç¼“å­˜æ¸…é™¤å¤±è´¥: {e}")
    
    print("âœ… å…¨é‡é—¨åº—å¯¹æ¯”å†…å­˜ç¼“å­˜å·²æ¸…é™¤")


def calculate_store_metrics(df: pd.DataFrame) -> pd.DataFrame:
    """
    è®¡ç®—æ¯ä¸ªé—¨åº—çš„å…³é”®æŒ‡æ ‡
    
    ä½¿ç”¨ä¸ orders.py å®Œå…¨ä¸€è‡´çš„è®¡ç®—é€»è¾‘
    
    å…¬å¼è¯´æ˜ï¼š
    - è¥é”€æˆæœ¬ç‡ = è¥é”€æˆæœ¬ / GMV Ã— 100%ï¼ˆGMV = å•†å“åŸä»·Ã—é”€é‡ + æ‰“åŒ…è¢‹ + ç”¨æˆ·æ”¯ä»˜é…é€è´¹ï¼‰
    - é…é€æˆæœ¬ç‡ = é…é€å‡€æˆæœ¬ / å®æ”¶é‡‘é¢ Ã— 100%
    """
    if df.empty or 'é—¨åº—åç§°' not in df.columns:
        return pd.DataFrame()
    
    # å…ˆè®¡ç®—è®¢å•çº§æŒ‡æ ‡ï¼ˆå¤ç”¨ orders.py çš„å‡½æ•°ï¼‰
    order_agg = calculate_order_metrics(df)
    
    if order_agg.empty or 'é—¨åº—åç§°' not in order_agg.columns:
        return pd.DataFrame()
    
    # ç¡®ä¿é…é€å‡€æˆæœ¬å­—æ®µå­˜åœ¨ï¼ˆä¸ Dash ç‰ˆæœ¬ä¸€è‡´ï¼‰
    if 'é…é€å‡€æˆæœ¬' not in order_agg.columns:
        # è®¡ç®—é…é€å‡€æˆæœ¬ = ç‰©æµé…é€è´¹ - (ç”¨æˆ·æ”¯ä»˜é…é€è´¹ - é…é€è´¹å‡å…é‡‘é¢) - ä¼å®¢åè¿”
        order_agg['é…é€å‡€æˆæœ¬'] = (
            order_agg['ç‰©æµé…é€è´¹'].fillna(0) -
            (order_agg.get('ç”¨æˆ·æ”¯ä»˜é…é€è´¹', 0) - order_agg.get('é…é€è´¹å‡å…é‡‘é¢', 0)) -
            order_agg.get('ä¼å®¢åè¿”', 0)
        )
        print(f"âœ… [calculate_store_metrics] è®¡ç®—é…é€å‡€æˆæœ¬: æ€»è®¡ Â¥{order_agg['é…é€å‡€æˆæœ¬'].sum():,.2f}")
    
    # âœ… æŒ‰é—¨åº—è®¡ç®—GMVï¼ˆä½¿ç”¨æ­£ç¡®çš„å…¬å¼ï¼šå‰”é™¤å•†å“åŸä»·<=0çš„æ•´è¡Œï¼‰
    store_gmv_data = {}
    for store_name in df['é—¨åº—åç§°'].unique():
        store_df = df[df['é—¨åº—åç§°'] == store_name]
        gmv_result = calculate_gmv(store_df)
        store_gmv_data[store_name] = {
            'gmv': gmv_result['gmv'],
            'marketing_cost': gmv_result['marketing_cost'],
            'marketing_cost_rate': gmv_result['marketing_cost_rate']
        }
    
    # æŒ‰é—¨åº—èšåˆ
    store_stats = order_agg.groupby('é—¨åº—åç§°').agg({
        'è®¢å•ID': 'count',
        'å®æ”¶ä»·æ ¼': 'sum',
        'è®¢å•å®é™…åˆ©æ¶¦': 'sum',
        'é…é€å‡€æˆæœ¬': 'sum',
        'å•†å®¶æ´»åŠ¨æˆæœ¬': 'sum',
    }).reset_index()
    
    store_stats.columns = ['store_name', 'order_count', 'total_revenue', 'total_profit', 'total_delivery_cost', 'total_marketing_cost']
    
    # âœ… æ·»åŠ GMVæ•°æ®
    store_stats['gmv'] = store_stats['store_name'].map(lambda x: store_gmv_data.get(x, {}).get('gmv', 0))
    store_stats['gmv_marketing_cost'] = store_stats['store_name'].map(lambda x: store_gmv_data.get(x, {}).get('marketing_cost', 0))
    
    # è®¡ç®—æ´¾ç”ŸæŒ‡æ ‡
    store_stats['profit_margin'] = store_stats.apply(
        lambda r: r['total_profit'] / r['total_revenue'] * 100 if r['total_revenue'] > 0 else 0, axis=1
    )
    store_stats['aov'] = store_stats.apply(
        lambda r: r['total_revenue'] / r['order_count'] if r['order_count'] > 0 else 0, axis=1
    )
    # å•å‡é…é€è´¹ = é…é€å‡€æˆæœ¬ / è®¢å•æ•°
    store_stats['avg_delivery_fee'] = store_stats.apply(
        lambda r: r['total_delivery_cost'] / r['order_count'] if r['order_count'] > 0 else 0, axis=1
    )
    store_stats['avg_marketing_cost'] = store_stats.apply(
        lambda r: r['total_marketing_cost'] / r['order_count'] if r['order_count'] > 0 else 0, axis=1
    )
    # é…é€æˆæœ¬ç‡ = é…é€å‡€æˆæœ¬ / å®æ”¶é‡‘é¢ Ã— 100%
    store_stats['delivery_cost_rate'] = store_stats.apply(
        lambda r: r['total_delivery_cost'] / r['total_revenue'] * 100 if r['total_revenue'] > 0 else 0, axis=1
    )
    # âœ… è¥é”€æˆæœ¬ç‡ = è¥é”€æˆæœ¬(7å­—æ®µ) / GMV Ã— 100%ï¼ˆä½¿ç”¨æ­£ç¡®çš„GMVè®¡ç®—ï¼‰
    store_stats['marketing_cost_rate'] = store_stats.apply(
        lambda r: r['gmv_marketing_cost'] / r['gmv'] * 100 if r['gmv'] > 0 else 0, axis=1
    )
    
    # è®¡ç®—æ’å
    store_stats['revenue_rank'] = store_stats['total_revenue'].rank(ascending=False, method='min').astype(int)
    store_stats['profit_rank'] = store_stats['total_profit'].rank(ascending=False, method='min').astype(int)
    store_stats['profit_margin_rank'] = store_stats['profit_margin'].rank(ascending=False, method='min').astype(int)
    
    return store_stats


@router.post("/comparison/clear-cache")
async def clear_store_comparison_cache():
    """æ¸…é™¤å…¨é‡é—¨åº—å¯¹æ¯”ç¼“å­˜"""
    invalidate_store_comparison_cache()
    return {"success": True, "message": "å…¨é‡é—¨åº—å¯¹æ¯”ç¼“å­˜å·²æ¸…é™¤"}


@router.get("/comparison")
async def get_stores_comparison(
    start_date: Optional[date] = Query(None, description="å¼€å§‹æ—¥æœŸ"),
    end_date: Optional[date] = Query(None, description="ç»“æŸæ—¥æœŸ"),
    sort_by: str = Query("revenue", description="æ’åºå­—æ®µ: revenue, profit, profit_margin, order_count"),
    sort_order: str = Query("desc", description="æ’åºæ–¹å‘: asc, desc"),
    channel: Optional[str] = Query(None, description="æ¸ é“ç­›é€‰ï¼ˆå¯é€‰ï¼Œå¦‚ï¼šç¾å›¢ã€é¥¿äº†ä¹ˆã€äº¬ä¸œï¼‰"),
    use_aggregation: bool = Query(True, description="æ˜¯å¦ä½¿ç”¨é¢„èšåˆè¡¨ï¼ˆæ€§èƒ½ä¼˜åŒ–ï¼‰")
) -> Dict[str, Any]:
    """
    å…¨é‡é—¨åº—å¯¹æ¯”åˆ†æ
    
    è¿”å›æ‰€æœ‰é—¨åº—çš„å…³é”®æŒ‡æ ‡ï¼š
    - è®¢å•é‡ã€é”€å”®é¢ã€åˆ©æ¶¦ã€åˆ©æ¶¦ç‡
    - å•å‡é…é€è´¹ã€å•å‡è¥é”€è´¹ã€å®¢å•ä»·
    - é…é€æˆæœ¬ç‡ã€è¥é”€æˆæœ¬ç‡
    - å¼‚å¸¸æ ‡è¯†ï¼ˆåˆ©æ¶¦ç‡å¼‚å¸¸ã€è®¢å•é‡å¼‚å¸¸ç­‰ï¼‰
    
    æ¸ é“ç­›é€‰è§„åˆ™ï¼ˆåŸºäºè®¢å•ç¼–å·å‰ç¼€ï¼‰ï¼š
    - ç¾å›¢ â†’ SG å¼€å¤´
    - é¥¿äº†ä¹ˆ â†’ ELE å¼€å¤´
    - äº¬ä¸œ â†’ JD å¼€å¤´
    
    ä¼˜åŒ–ç‚¹ï¼š
    - âœ… ä¼˜å…ˆä½¿ç”¨é¢„èšåˆè¡¨ï¼ˆæŸ¥è¯¢æ—¶é—´ä»~500msé™åˆ°~2msï¼‰
    - å¹³å‡åˆ©æ¶¦ç‡ä½¿ç”¨åŠ æƒå¹³å‡ï¼ˆæ€»åˆ©æ¶¦/æ€»é”€å”®é¢ï¼‰
    - SQLå±‚é¢æ¸ é“ç­›é€‰
    - æ·»åŠ å¼‚å¸¸æ£€æµ‹
    """
    import time
    query_start = time.time()
    
    # âœ… ä¼˜å…ˆä½¿ç”¨é¢„èšåˆè¡¨ï¼ˆæ€§èƒ½ä¼˜åŒ–ï¼‰
    store_stats = None
    if use_aggregation and AGGREGATION_TABLE_AVAILABLE:
        store_stats = get_store_metrics_from_aggregation(start_date, end_date, channel)
        if not store_stats.empty:
            print(f"âœ… [é¢„èšåˆè¡¨] æŸ¥è¯¢è€—æ—¶: {(time.time() - query_start)*1000:.1f}ms")
    
    # å¦‚æœé¢„èšåˆè¡¨ä¸å¯ç”¨æˆ–ä¸ºç©ºï¼Œå›é€€åˆ°åŸå§‹æŸ¥è¯¢
    if store_stats is None or store_stats.empty:
        print(f"âš ï¸ é¢„èšåˆè¡¨ä¸å¯ç”¨ï¼Œä½¿ç”¨åŸå§‹æŸ¥è¯¢...")
        df = get_all_stores_data(start_date, end_date, channel)
        
        if df.empty:
            return {
                "success": True,
                "data": {
                    "stores": [],
                    "summary": {
                        "total_stores": 0,
                        "total_orders": 0,
                        "total_revenue": 0,
                        "total_profit": 0,
                        "avg_profit_margin": 0,
                        "weighted_profit_margin": 0
                    }
                }
            }
        
        # è®¡ç®—é—¨åº—æŒ‡æ ‡
        store_stats = calculate_store_metrics(df)
        print(f"âš ï¸ [åŸå§‹æŸ¥è¯¢] æŸ¥è¯¢è€—æ—¶: {(time.time() - query_start)*1000:.1f}ms")
    
    if store_stats.empty:
        return {
            "success": True,
            "data": {
                "stores": [],
                "summary": {
                    "total_stores": 0,
                    "total_orders": 0,
                    "total_revenue": 0,
                    "total_profit": 0,
                    "avg_profit_margin": 0,
                    "weighted_profit_margin": 0
                }
            }
        }
    
    # æ’åº
    sort_col_map = {
        'revenue': 'total_revenue',
        'profit': 'total_profit',
        'profit_margin': 'profit_margin',
        'order_count': 'order_count'
    }
    sort_col = sort_col_map.get(sort_by, 'total_revenue')
    store_stats = store_stats.sort_values(sort_col, ascending=(sort_order == 'asc'))
    
    # âœ… è®¡ç®—æ±‡æ€»æ•°æ®ï¼ˆä¿®å¤ï¼šä½¿ç”¨åŠ æƒå¹³å‡åˆ©æ¶¦ç‡ï¼‰
    total_revenue = float(store_stats['total_revenue'].sum())
    total_profit = float(store_stats['total_profit'].sum())
    weighted_profit_margin = (total_profit / total_revenue * 100) if total_revenue > 0 else 0
    
    summary = {
        "total_stores": len(store_stats),
        "total_orders": int(store_stats['order_count'].sum()),
        "total_revenue": round(total_revenue, 2),
        "total_profit": round(total_profit, 2),
        "avg_profit_margin": round(weighted_profit_margin, 2),  # âœ… ä¿®å¤ï¼šä½¿ç”¨åŠ æƒå¹³å‡
        "weighted_profit_margin": round(weighted_profit_margin, 2)  # æ˜¾å¼å­—æ®µ
    }
    
    # âœ… å¼‚å¸¸æ£€æµ‹é˜ˆå€¼
    avg_profit_margin = store_stats['profit_margin'].mean()
    std_profit_margin = store_stats['profit_margin'].std()
    avg_order_count = store_stats['order_count'].mean()
    std_order_count = store_stats['order_count'].std()
    
    # è½¬æ¢ä¸ºåˆ—è¡¨
    stores_list = []
    for _, row in store_stats.iterrows():
        # âœ… å¼‚å¸¸æ£€æµ‹
        anomalies = []
        
        # åˆ©æ¶¦ç‡å¼‚å¸¸ï¼ˆä½äºå¹³å‡å€¼2ä¸ªæ ‡å‡†å·®ï¼‰
        if std_profit_margin > 0 and row['profit_margin'] < avg_profit_margin - 2 * std_profit_margin:
            anomalies.append({
                "type": "low_profit_margin",
                "message": f"åˆ©æ¶¦ç‡({row['profit_margin']:.1f}%)æ˜¾è‘—ä½äºå¹³å‡æ°´å¹³({avg_profit_margin:.1f}%)",
                "severity": "high"
            })
        
        # è®¢å•é‡å¼‚å¸¸ï¼ˆä½äºå¹³å‡å€¼2ä¸ªæ ‡å‡†å·®ï¼‰
        if std_order_count > 0 and row['order_count'] < avg_order_count - 2 * std_order_count:
            anomalies.append({
                "type": "low_order_count",
                "message": f"è®¢å•é‡({row['order_count']})æ˜¾è‘—ä½äºå¹³å‡æ°´å¹³({avg_order_count:.0f})",
                "severity": "medium"
            })
        
        # è¥é”€æˆæœ¬ç‡è¿‡é«˜ï¼ˆè¶…è¿‡15%ï¼‰
        if row['marketing_cost_rate'] > 15:
            anomalies.append({
                "type": "high_marketing_cost",
                "message": f"è¥é”€æˆæœ¬ç‡({row['marketing_cost_rate']:.1f}%)è¿‡é«˜ï¼Œå»ºè®®ä¼˜åŒ–æ´»åŠ¨ç­–ç•¥",
                "severity": "medium"
            })
        
        # é…é€æˆæœ¬ç‡è¿‡é«˜ï¼ˆè¶…è¿‡20%ï¼‰
        if row['delivery_cost_rate'] > 20:
            anomalies.append({
                "type": "high_delivery_cost",
                "message": f"é…é€æˆæœ¬ç‡({row['delivery_cost_rate']:.1f}%)è¿‡é«˜ï¼Œå»ºè®®ä¼˜åŒ–é…é€èŒƒå›´",
                "severity": "medium"
            })
        
        stores_list.append({
            "store_name": row['store_name'],
            "order_count": int(row['order_count']),
            "total_revenue": round(float(row['total_revenue']), 2),
            "total_profit": round(float(row['total_profit']), 2),
            "profit_margin": round(float(row['profit_margin']), 2),
            "aov": round(float(row['aov']), 2),
            "avg_delivery_fee": round(float(row['avg_delivery_fee']), 2),
            "avg_marketing_cost": round(float(row['avg_marketing_cost']), 2),
            "delivery_cost_rate": round(float(row['delivery_cost_rate']), 2),
            "marketing_cost_rate": round(float(row['marketing_cost_rate']), 2),
            "ranks": {
                "revenue_rank": int(row['revenue_rank']),
                "profit_rank": int(row['profit_rank']),
                "profit_margin_rank": int(row['profit_margin_rank'])
            },
            "anomalies": anomalies  # âœ… å¼‚å¸¸æ£€æµ‹
        })
    
    return {
        "success": True,
        "data": {
            "stores": stores_list,
            "summary": summary
        }
    }


@router.get("/comparison/week-over-week")
async def get_stores_week_over_week(
    end_date: Optional[date] = Query(None, description="æœ¬æœŸç»“æŸæ—¥æœŸï¼ˆé»˜è®¤ä¸ºæ•°æ®æœ€å¤§æ—¥æœŸï¼‰"),
    previous_start: Optional[date] = Query(None, description="ä¸ŠæœŸå¼€å§‹æ—¥æœŸï¼ˆå¯é€‰ï¼Œç”¨äºè‡ªå®šä¹‰å¯¹æ¯”å‘¨æœŸï¼‰"),
    previous_end: Optional[date] = Query(None, description="ä¸ŠæœŸç»“æŸæ—¥æœŸï¼ˆå¯é€‰ï¼Œç”¨äºè‡ªå®šä¹‰å¯¹æ¯”å‘¨æœŸï¼‰"),
    channel: Optional[str] = Query(None, description="æ¸ é“ç­›é€‰ï¼ˆå¯é€‰ï¼Œå¦‚ï¼šç¾å›¢ã€é¥¿äº†ä¹ˆã€äº¬ä¸œï¼‰")
) -> Dict[str, Any]:
    """
    å…¨é‡é—¨åº—ç¯æ¯”æ•°æ®ï¼ˆæ”¯æŒè‡ªå®šä¹‰å¯¹æ¯”å‘¨æœŸå’Œæ¸ é“ç­›é€‰ï¼‰
    
    è®¡ç®—é€»è¾‘ï¼š
    - å¦‚æœæä¾› previous_start å’Œ previous_endï¼Œä½¿ç”¨è‡ªå®šä¹‰ä¸ŠæœŸ
    - å¦åˆ™ï¼Œè‡ªåŠ¨è®¡ç®—ï¼šæœ¬æœŸ=æœ€è¿‘7å¤©ï¼Œä¸ŠæœŸ=å‰7å¤©
    - å¦‚æœæä¾› channelï¼Œæ ¹æ®è®¢å•ç¼–å·å‰ç¼€ç­›é€‰è¯¥æ¸ é“çš„æ•°æ®
    
    ä¼˜åŒ–ç‚¹ï¼š
    - SQLå±‚é¢æ¸ é“ç­›é€‰
    """
    # å¦‚æœæ²¡æœ‰æŒ‡å®šç»“æŸæ—¥æœŸï¼Œä½¿ç”¨æ•°æ®åº“ä¸­çš„æœ€å¤§æ—¥æœŸ
    if not end_date:
        session = SessionLocal()
        try:
            max_date_result = session.query(Order.date).order_by(Order.date.desc()).first()
            if max_date_result and max_date_result[0]:
                end_date = max_date_result[0].date()
            else:
                end_date = date.today()
        finally:
            session.close()
    
    # è®¡ç®—æœ¬æœŸæ—¥æœŸèŒƒå›´
    this_week_end = end_date
    
    # å¦‚æœæä¾›äº†è‡ªå®šä¹‰ä¸ŠæœŸï¼Œä½¿ç”¨è‡ªå®šä¹‰é€»è¾‘
    if previous_start and previous_end:
        # ä½¿ç”¨è‡ªå®šä¹‰ä¸ŠæœŸ
        last_week_start = previous_start
        last_week_end = previous_end
        
        # è®¡ç®—æœ¬æœŸå¼€å§‹æ—¥æœŸï¼ˆæ ¹æ®ä¸ŠæœŸå¤©æ•°ï¼‰
        days = (previous_end - previous_start).days + 1
        this_week_start = this_week_end - timedelta(days=days - 1)
        
        print(f"ğŸ“Š è‡ªå®šä¹‰ç¯æ¯”: æœ¬æœŸ {this_week_start} ~ {this_week_end}, ä¸ŠæœŸ {last_week_start} ~ {last_week_end}")
    else:
        # é»˜è®¤é€»è¾‘ï¼šæœ€è¿‘7å¤© vs å‰7å¤©
        this_week_start = this_week_end - timedelta(days=6)
        last_week_end = this_week_start - timedelta(days=1)
        last_week_start = last_week_end - timedelta(days=6)
        
        print(f"ğŸ“Š é»˜è®¤ç¯æ¯”: æœ¬æœŸ {this_week_start} ~ {this_week_end}, ä¸ŠæœŸ {last_week_start} ~ {last_week_end}")
    
    # SQLå±‚é¢æ¸ é“ç­›é€‰
    this_week_df = get_all_stores_data(this_week_start, this_week_end, channel)
    last_week_df = get_all_stores_data(last_week_start, last_week_end, channel)
    
    # è®¡ç®—æœ¬å‘¨æŒ‡æ ‡
    this_week_stats = calculate_store_metrics(this_week_df) if not this_week_df.empty else pd.DataFrame()
    last_week_stats = calculate_store_metrics(last_week_df) if not last_week_df.empty else pd.DataFrame()
    
    if this_week_stats.empty:
        return {
            "success": True,
            "data": {
                "stores": [],
                "period": {
                    "current": {"start": str(this_week_start), "end": str(this_week_end)},
                    "previous": {"start": str(last_week_start), "end": str(last_week_end)}
                }
            }
        }
    
    # åˆå¹¶æ•°æ®è®¡ç®—ç¯æ¯”
    result = []
    for _, current_row in this_week_stats.iterrows():
        store_name = current_row['store_name']
        
        # æŸ¥æ‰¾ä¸Šå‘¨æ•°æ®
        prev_row = last_week_stats[last_week_stats['store_name'] == store_name]
        
        # è®¡ç®—ç¯æ¯”å˜åŒ–
        if not prev_row.empty:
            prev_row = prev_row.iloc[0]
            order_count_change = ((current_row['order_count'] - prev_row['order_count']) / prev_row['order_count'] * 100) if prev_row['order_count'] > 0 else 0
            revenue_change = ((current_row['total_revenue'] - prev_row['total_revenue']) / prev_row['total_revenue'] * 100) if prev_row['total_revenue'] > 0 else 0
            profit_change = ((current_row['total_profit'] - prev_row['total_profit']) / prev_row['total_profit'] * 100) if prev_row['total_profit'] != 0 else 0
            profit_margin_change = current_row['profit_margin'] - prev_row['profit_margin']
            aov_change = ((current_row['aov'] - prev_row['aov']) / prev_row['aov'] * 100) if prev_row['aov'] > 0 else 0
            avg_delivery_fee_change = ((current_row['avg_delivery_fee'] - prev_row['avg_delivery_fee']) / prev_row['avg_delivery_fee'] * 100) if prev_row['avg_delivery_fee'] > 0 else 0
            avg_marketing_cost_change = ((current_row['avg_marketing_cost'] - prev_row['avg_marketing_cost']) / prev_row['avg_marketing_cost'] * 100) if prev_row['avg_marketing_cost'] > 0 else 0
            delivery_cost_rate_change = current_row['delivery_cost_rate'] - prev_row['delivery_cost_rate']
            marketing_cost_rate_change = current_row['marketing_cost_rate'] - prev_row['marketing_cost_rate']
        else:
            order_count_change = revenue_change = profit_change = profit_margin_change = 0
            aov_change = avg_delivery_fee_change = avg_marketing_cost_change = 0
            delivery_cost_rate_change = marketing_cost_rate_change = 0
        
        store_data = {
            "store_name": store_name,
            "current": {
                "order_count": int(current_row['order_count']),
                "total_revenue": round(float(current_row['total_revenue']), 2),
                "total_profit": round(float(current_row['total_profit']), 2),
                "profit_margin": round(float(current_row['profit_margin']), 2),
                "aov": round(float(current_row['aov']), 2),
                "avg_delivery_fee": round(float(current_row['avg_delivery_fee']), 2),
                "avg_marketing_cost": round(float(current_row['avg_marketing_cost']), 2),
                "delivery_cost_rate": round(float(current_row['delivery_cost_rate']), 2),
                "marketing_cost_rate": round(float(current_row['marketing_cost_rate']), 2)
            },
            "changes": {
                "order_count": round(float(order_count_change), 2),
                "revenue": round(float(revenue_change), 2),
                "profit": round(float(profit_change), 2),
                "profit_margin": round(float(profit_margin_change), 2),
                "aov": round(float(aov_change), 2),
                "avg_delivery_fee": round(float(avg_delivery_fee_change), 2),
                "avg_marketing_cost": round(float(avg_marketing_cost_change), 2),
                "delivery_cost_rate": round(float(delivery_cost_rate_change), 2),
                "marketing_cost_rate": round(float(marketing_cost_rate_change), 2)
            }
        }
        
        result.append(store_data)
    
    return {
        "success": True,
        "data": {
            "stores": result,
            "period": {
                "current": {"start": str(this_week_start), "end": str(this_week_end)},
                "previous": {"start": str(last_week_start), "end": str(last_week_end)}
            }
        }
    }


@router.get("/comparison/ranking")
async def get_stores_ranking(
    metric: str = Query("revenue", description="æ’åæŒ‡æ ‡: revenue, profit, profit_margin, order_count"),
    limit: int = Query(10, ge=1, le=50, description="è¿”å›Top N"),
    start_date: Optional[date] = Query(None, description="å¼€å§‹æ—¥æœŸ"),
    end_date: Optional[date] = Query(None, description="ç»“æŸæ—¥æœŸ")
) -> Dict[str, Any]:
    """
    é—¨åº—æ’è¡Œæ¦œï¼ˆTop Nï¼‰
    """
    # åŠ è½½æ•°æ®
    df = get_all_stores_data(start_date, end_date)
    
    if df.empty:
        return {"success": True, "data": []}
    
    # è®¡ç®—é—¨åº—æŒ‡æ ‡
    store_stats = calculate_store_metrics(df)
    
    if store_stats.empty:
        return {"success": True, "data": []}
    
    # æ’åº
    sort_col_map = {
        'revenue': 'total_revenue',
        'profit': 'total_profit',
        'profit_margin': 'profit_margin',
        'order_count': 'order_count'
    }
    sort_col = sort_col_map.get(metric, 'total_revenue')
    store_stats = store_stats.sort_values(sort_col, ascending=False).head(limit)
    
    # è½¬æ¢ä¸ºåˆ—è¡¨
    result = []
    for idx, row in enumerate(store_stats.iterrows(), 1):
        _, row = row
        result.append({
            "rank": idx,
            "store_name": row['store_name'],
            "value": round(float(row[sort_col]), 2),
            "order_count": int(row['order_count']),
            "total_revenue": round(float(row['total_revenue']), 2),
            "total_profit": round(float(row['total_profit']), 2),
            "profit_margin": round(float(row['profit_margin']), 2)
        })
    
    return {"success": True, "data": result}


@router.get("/comparison/available-channels")
async def get_available_channels(
    start_date: Optional[date] = Query(None, description="å¼€å§‹æ—¥æœŸ"),
    end_date: Optional[date] = Query(None, description="ç»“æŸæ—¥æœŸ")
) -> Dict[str, Any]:
    """
    è·å–å½“å‰æ—¥æœŸèŒƒå›´å†…æœ‰æ•°æ®çš„æ¸ é“åˆ—è¡¨
    
    åªè¿”å›åœ¨æŒ‡å®šæ—¥æœŸèŒƒå›´å†…æœ‰è®¢å•æ•°æ®çš„æ¸ é“
    æ¸ é“è¯†åˆ«è§„åˆ™ï¼ˆåŸºäºè®¢å•ç¼–å·å‰ç¼€ï¼‰ï¼š
    - SG å¼€å¤´ â†’ ç¾å›¢
    - ELE å¼€å¤´ â†’ é¥¿äº†ä¹ˆ
    - JD å¼€å¤´ â†’ äº¬ä¸œ
    """
    # å®šä¹‰æ”¯æŒçš„æ¸ é“åŠå…¶è®¢å•ç¼–å·å‰ç¼€
    CHANNEL_PREFIXES = {
        'ç¾å›¢': 'SG',
        'é¥¿äº†ä¹ˆ': 'ELE',
        'äº¬ä¸œ': 'JD'
    }
    
    # ä»æ•°æ®åº“æŸ¥è¯¢æœ‰æ•°æ®çš„æ¸ é“
    session = SessionLocal()
    try:
        query = session.query(Order.order_number)
        
        if start_date:
            query = query.filter(Order.date >= datetime.combine(start_date, datetime.min.time()))
        if end_date:
            query = query.filter(Order.date <= datetime.combine(end_date, datetime.max.time()))
        
        # è·å–æ‰€æœ‰è®¢å•ç¼–å·
        order_numbers = [r[0] for r in query.distinct().all() if r[0]]
        
        if not order_numbers:
            return {"success": True, "data": []}
        
        # æ ¹æ®è®¢å•ç¼–å·å‰ç¼€è¯†åˆ«æœ‰æ•°æ®çš„æ¸ é“
        available_channels = []
        for channel_name, prefix in CHANNEL_PREFIXES.items():
            # æ£€æŸ¥æ˜¯å¦æœ‰è¯¥å‰ç¼€çš„è®¢å•
            has_orders = any(str(on).startswith(prefix) for on in order_numbers)
            if has_orders:
                available_channels.append(channel_name)
        
        print(f"âœ… å¯ç”¨æ¸ é“åˆ—è¡¨: {available_channels} (æ—¥æœŸ: {start_date} ~ {end_date})")
        
        return {"success": True, "data": sorted(available_channels)}
    finally:
        session.close()


@router.get("/comparison/export")
async def export_stores_comparison(
    start_date: Optional[date] = Query(None, description="å¼€å§‹æ—¥æœŸ"),
    end_date: Optional[date] = Query(None, description="ç»“æŸæ—¥æœŸ"),
    channel: Optional[str] = Query(None, description="æ¸ é“ç­›é€‰"),
    format: str = Query("json", description="å¯¼å‡ºæ ¼å¼: json, csv")
) -> Dict[str, Any]:
    """
    å¯¼å‡ºé—¨åº—å¯¹æ¯”æ•°æ®
    
    æ”¯æŒ JSON å’Œ CSV æ ¼å¼å¯¼å‡º
    """
    from fastapi.responses import Response
    import io
    import csv
    
    # è·å–æ•°æ®
    df = get_all_stores_data(start_date, end_date, channel)
    
    if df.empty:
        return {"success": False, "error": "æ— æ•°æ®å¯å¯¼å‡º"}
    
    store_stats = calculate_store_metrics(df)
    
    if store_stats.empty:
        return {"success": False, "error": "æ— æ•°æ®å¯å¯¼å‡º"}
    
    # å‡†å¤‡å¯¼å‡ºæ•°æ®
    export_data = []
    for _, row in store_stats.iterrows():
        export_data.append({
            "é—¨åº—åç§°": row['store_name'],
            "è®¢å•é‡": int(row['order_count']),
            "é”€å”®é¢": round(float(row['total_revenue']), 2),
            "åˆ©æ¶¦": round(float(row['total_profit']), 2),
            "åˆ©æ¶¦ç‡(%)": round(float(row['profit_margin']), 2),
            "å®¢å•ä»·": round(float(row['aov']), 2),
            "å•å‡é…é€è´¹": round(float(row['avg_delivery_fee']), 2),
            "å•å‡è¥é”€è´¹": round(float(row['avg_marketing_cost']), 2),
            "é…é€æˆæœ¬ç‡(%)": round(float(row['delivery_cost_rate']), 2),
            "è¥é”€æˆæœ¬ç‡(%)": round(float(row['marketing_cost_rate']), 2),
            "é”€å”®é¢æ’å": int(row['revenue_rank']),
            "åˆ©æ¶¦æ’å": int(row['profit_rank']),
            "åˆ©æ¶¦ç‡æ’å": int(row['profit_margin_rank'])
        })
    
    if format == "csv":
        # ç”ŸæˆCSV
        output = io.StringIO()
        if export_data:
            writer = csv.DictWriter(output, fieldnames=export_data[0].keys())
            writer.writeheader()
            writer.writerows(export_data)
        
        return {
            "success": True,
            "data": {
                "format": "csv",
                "content": output.getvalue(),
                "filename": f"é—¨åº—å¯¹æ¯”æ•°æ®_{start_date or 'all'}_{end_date or 'all'}.csv"
            }
        }
    else:
        # JSONæ ¼å¼
        return {
            "success": True,
            "data": {
                "format": "json",
                "content": export_data,
                "filename": f"é—¨åº—å¯¹æ¯”æ•°æ®_{start_date or 'all'}_{end_date or 'all'}.json",
                "summary": {
                    "total_stores": len(export_data),
                    "date_range": f"{start_date or 'å…¨éƒ¨'} ~ {end_date or 'å…¨éƒ¨'}",
                    "channel": channel or "å…¨éƒ¨æ¸ é“"
                }
            }
        }


@router.get("/comparison/stores-by-channel")
async def get_stores_by_channel(
    start_date: Optional[date] = Query(None, description="å¼€å§‹æ—¥æœŸ"),
    end_date: Optional[date] = Query(None, description="ç»“æŸæ—¥æœŸ"),
    channel: Optional[str] = Query(None, description="æ¸ é“ç­›é€‰")
) -> Dict[str, Any]:
    """
    è·å–æŒ‡å®šæ¸ é“ä¸‹çš„é—¨åº—åˆ—è¡¨
    
    ç”¨äºæ¸ é“ç­›é€‰åæ›´æ–°é—¨åº—ç­›é€‰å™¨
    """
    df = get_all_stores_data(start_date, end_date, channel)
    
    if df.empty or 'é—¨åº—åç§°' not in df.columns:
        return {"success": True, "data": []}
    
    store_names = sorted(df['é—¨åº—åç§°'].dropna().unique().tolist())
    
    return {
        "success": True,
        "data": store_names,
        "count": len(store_names)
    }


# ==================== å…¨å±€é—¨åº—æ´å¯Ÿåˆ†æå¼•æ“ ====================

class InsightsEngine:
    """
    å…¨å±€é—¨åº—æ´å¯Ÿåˆ†æå¼•æ“
    
    æä¾›åŸºäºè§„åˆ™çš„ç»Ÿè®¡åˆ†æï¼Œç”Ÿæˆç»“æ„åŒ–çš„æ´å¯ŸæŠ¥å‘Š
    """
    
    def __init__(self, stores_data: pd.DataFrame, week_over_week_data: List[Dict] = None):
        """
        åˆå§‹åŒ–æ´å¯Ÿå¼•æ“
        
        Args:
            stores_data: é—¨åº—æŒ‡æ ‡DataFrame
            week_over_week_data: ç¯æ¯”æ•°æ®åˆ—è¡¨
        """
        self.stores = stores_data
        self.wow_data = week_over_week_data or []
        
    def calculate_statistics(self) -> Dict:
        """è®¡ç®—æè¿°æ€§ç»Ÿè®¡"""
        if self.stores.empty:
            return self._empty_statistics()
        
        def calc_stats(series):
            return {
                'mean': round(float(series.mean()), 2),
                'median': round(float(series.median()), 2),
                'std': round(float(series.std()), 2),
                'p25': round(float(np.percentile(series, 25)), 2),
                'p50': round(float(np.percentile(series, 50)), 2),
                'p75': round(float(np.percentile(series, 75)), 2),
                'p90': round(float(np.percentile(series, 90)), 2)
            }
        
        return {
            'profit_margin': calc_stats(self.stores['profit_margin']),
            'aov': calc_stats(self.stores['aov']),
            'order_count': calc_stats(self.stores['order_count'])
        }
    
    def _empty_statistics(self) -> Dict:
        empty = {'mean': 0, 'median': 0, 'std': 0, 'p25': 0, 'p50': 0, 'p75': 0, 'p90': 0}
        return {'profit_margin': empty, 'aov': empty, 'order_count': empty}

    def cluster_stores(self) -> Dict:
        """é—¨åº—åˆ†ç¾¤åˆ†æï¼ˆåŸºäºåˆ©æ¶¦ç‡åˆ†ä½æ•°ï¼‰"""
        if self.stores.empty:
            return self._empty_clustering()
        
        profit_margins = self.stores['profit_margin'].values
        p25 = np.percentile(profit_margins, 25)
        p75 = np.percentile(profit_margins, 75)
        
        high = self.stores[self.stores['profit_margin'] >= p75]
        medium = self.stores[(self.stores['profit_margin'] >= p25) & (self.stores['profit_margin'] < p75)]
        low = self.stores[self.stores['profit_margin'] < p25]
        
        def group_stats(group_df):
            if group_df.empty:
                return {
                    'count': 0, 'percentage': 0,
                    'avg_metrics': {'revenue': 0, 'profit': 0, 'profit_margin': 0, 'aov': 0},
                    'top_stores': [], 'characteristics': ''
                }
            return {
                'count': len(group_df),
                'percentage': round(len(group_df) / len(self.stores) * 100, 1),
                'avg_metrics': {
                    'revenue': round(float(group_df['total_revenue'].mean()), 2),
                    'profit': round(float(group_df['total_profit'].mean()), 2),
                    'profit_margin': round(float(group_df['profit_margin'].mean()), 2),
                    'aov': round(float(group_df['aov'].mean()), 2)
                },
                'top_stores': group_df.nlargest(3, 'total_profit')['store_name'].tolist(),
                'characteristics': ''
            }
        
        result = {
            'high_performance': group_stats(high),
            'medium_performance': group_stats(medium),
            'low_performance': group_stats(low)
        }
        
        # ç”Ÿæˆç‰¹å¾æè¿°
        result['high_performance']['characteristics'] = self._gen_cluster_char('high', result['high_performance'])
        result['medium_performance']['characteristics'] = self._gen_cluster_char('medium', result['medium_performance'])
        result['low_performance']['characteristics'] = self._gen_cluster_char('low', result['low_performance'])
        result['summary_text'] = self._gen_clustering_summary(result)
        
        return result

    def _gen_cluster_char(self, level: str, group: Dict) -> str:
        if group['count'] == 0:
            return "æ— é—¨åº—"
        metrics = group['avg_metrics']
        if level == 'high':
            return f"å¹³å‡åˆ©æ¶¦ç‡{metrics['profit_margin']:.1f}%ï¼Œå®¢å•ä»·Â¥{metrics['aov']:.1f}ï¼Œç›ˆåˆ©èƒ½åŠ›å¼º"
        elif level == 'medium':
            return f"å¹³å‡åˆ©æ¶¦ç‡{metrics['profit_margin']:.1f}%ï¼Œå®¢å•ä»·Â¥{metrics['aov']:.1f}ï¼Œæœ‰æå‡ç©ºé—´"
        else:
            return f"å¹³å‡åˆ©æ¶¦ç‡{metrics['profit_margin']:.1f}%ï¼Œå®¢å•ä»·Â¥{metrics['aov']:.1f}ï¼Œéœ€é‡ç‚¹å…³æ³¨"
    
    def _gen_clustering_summary(self, result: Dict) -> str:
        high = result['high_performance']
        low = result['low_performance']
        return f"""ğŸ¯ é—¨åº—åˆ†ç¾¤åˆ†æ

æ ¹æ®åˆ©æ¶¦ç‡å°†é—¨åº—åˆ†ä¸ºä¸‰ä¸ªå±‚çº§ï¼š

ã€é«˜ç»©æ•ˆé—¨åº—ã€‘{high['count']}å®¶ï¼ˆå æ¯”{high['percentage']:.1f}%ï¼‰
{high['characteristics']}
ä»£è¡¨é—¨åº—ï¼š{', '.join(high['top_stores'][:3]) if high['top_stores'] else 'æ— '}

ã€ä¸­ç­‰é—¨åº—ã€‘{result['medium_performance']['count']}å®¶ï¼ˆå æ¯”{result['medium_performance']['percentage']:.1f}%ï¼‰
{result['medium_performance']['characteristics']}

ã€ä½ç»©æ•ˆé—¨åº—ã€‘{low['count']}å®¶ï¼ˆå æ¯”{low['percentage']:.1f}%ï¼‰
{low['characteristics']}
ä»£è¡¨é—¨åº—ï¼š{', '.join(low['top_stores'][:3]) if low['top_stores'] else 'æ— '}

ğŸ’¡ å»ºè®®ï¼šé‡ç‚¹å…³æ³¨ä½ç»©æ•ˆé—¨åº—ï¼Œåˆ†æå…¶æˆæœ¬ç»“æ„å’Œè¿è¥é—®é¢˜ã€‚"""
    
    def _empty_clustering(self) -> Dict:
        empty_group = {'count': 0, 'percentage': 0, 'avg_metrics': {'revenue': 0, 'profit': 0, 'profit_margin': 0, 'aov': 0}, 'top_stores': [], 'characteristics': ''}
        return {'high_performance': empty_group, 'medium_performance': empty_group, 'low_performance': empty_group, 'summary_text': 'æš‚æ— æ•°æ®'}

    def detect_anomalies(self) -> Dict:
        """å¼‚å¸¸é—¨åº—æ£€æµ‹"""
        if self.stores.empty:
            return self._empty_anomalies()
        
        anomalies = {'low_profit_margin': [], 'low_order_count': [], 'high_marketing_cost': [], 'high_delivery_cost': []}
        
        # Z-scoreæ£€æµ‹åˆ©æ¶¦ç‡å¼‚å¸¸
        pm_mean = self.stores['profit_margin'].mean()
        pm_std = self.stores['profit_margin'].std()
        if pm_std > 0:
            for _, row in self.stores.iterrows():
                z = (row['profit_margin'] - pm_mean) / pm_std
                if z < -2:
                    anomalies['low_profit_margin'].append({
                        'store_name': row['store_name'],
                        'value': round(row['profit_margin'], 2),
                        'threshold': round(pm_mean - 2 * pm_std, 2),
                        'severity': 'high' if z < -3 else 'medium',
                        'message': f"åˆ©æ¶¦ç‡{row['profit_margin']:.1f}%æ˜¾è‘—ä½äºå¹³å‡å€¼{pm_mean:.1f}%"
                    })
        
        # IQRæ£€æµ‹è®¢å•é‡å¼‚å¸¸
        oc_q1 = np.percentile(self.stores['order_count'], 25)
        oc_q3 = np.percentile(self.stores['order_count'], 75)
        oc_iqr = oc_q3 - oc_q1
        oc_lower = oc_q1 - 1.5 * oc_iqr
        for _, row in self.stores.iterrows():
            if row['order_count'] < oc_lower:
                anomalies['low_order_count'].append({
                    'store_name': row['store_name'],
                    'value': int(row['order_count']),
                    'threshold': int(oc_lower),
                    'severity': 'medium',
                    'message': f"è®¢å•é‡{int(row['order_count'])}æ˜¾è‘—ä½äºæ­£å¸¸èŒƒå›´"
                })
        
        # é˜ˆå€¼æ£€æµ‹è¥é”€æˆæœ¬ç‡ï¼ˆ>15%ï¼‰
        for _, row in self.stores.iterrows():
            if row['marketing_cost_rate'] > 15:
                anomalies['high_marketing_cost'].append({
                    'store_name': row['store_name'],
                    'value': round(row['marketing_cost_rate'], 2),
                    'threshold': 15,
                    'severity': 'high' if row['marketing_cost_rate'] > 20 else 'medium',
                    'message': f"è¥é”€æˆæœ¬ç‡{row['marketing_cost_rate']:.1f}%è¿‡é«˜"
                })
        
        # é˜ˆå€¼æ£€æµ‹é…é€æˆæœ¬ç‡ï¼ˆ>20%ï¼‰
        for _, row in self.stores.iterrows():
            if row['delivery_cost_rate'] > 20:
                anomalies['high_delivery_cost'].append({
                    'store_name': row['store_name'],
                    'value': round(row['delivery_cost_rate'], 2),
                    'threshold': 20,
                    'severity': 'high' if row['delivery_cost_rate'] > 25 else 'medium',
                    'message': f"é…é€æˆæœ¬ç‡{row['delivery_cost_rate']:.1f}%è¿‡é«˜"
                })
        
        total = len(set(a['store_name'] for t in anomalies.values() for a in t))
        return {
            'total_anomaly_stores': total,
            'by_type': anomalies,
            'summary_text': self._gen_anomaly_summary(anomalies, total)
        }

    def _gen_anomaly_summary(self, anomalies: Dict, total: int) -> str:
        if total == 0:
            return "âœ… å¼‚å¸¸æ£€æµ‹\n\næ‰€æœ‰é—¨åº—è¿è¥æŒ‡æ ‡æ­£å¸¸ï¼Œæœªå‘ç°æ˜¾è‘—å¼‚å¸¸ã€‚"
        
        lines = [f"âš ï¸ å¼‚å¸¸æ£€æµ‹\n\nå…±å‘ç° {total} å®¶é—¨åº—å­˜åœ¨å¼‚å¸¸æƒ…å†µï¼š\n"]
        
        if anomalies['low_profit_margin']:
            lines.append(f"ğŸ”´ åˆ©æ¶¦ç‡å¼‚å¸¸ï¼š{len(anomalies['low_profit_margin'])}å®¶")
            for a in anomalies['low_profit_margin'][:3]:
                lines.append(f"   - {a['store_name']}: {a['message']}")
        
        if anomalies['low_order_count']:
            lines.append(f"ğŸŸ  è®¢å•é‡å¼‚å¸¸ï¼š{len(anomalies['low_order_count'])}å®¶")
            for a in anomalies['low_order_count'][:3]:
                lines.append(f"   - {a['store_name']}: {a['message']}")
        
        if anomalies['high_marketing_cost']:
            lines.append(f"ğŸŸ¡ è¥é”€æˆæœ¬è¿‡é«˜ï¼š{len(anomalies['high_marketing_cost'])}å®¶")
            for a in anomalies['high_marketing_cost'][:3]:
                lines.append(f"   - {a['store_name']}: {a['message']}")
        
        if anomalies['high_delivery_cost']:
            lines.append(f"ğŸŸ¡ é…é€æˆæœ¬è¿‡é«˜ï¼š{len(anomalies['high_delivery_cost'])}å®¶")
            for a in anomalies['high_delivery_cost'][:3]:
                lines.append(f"   - {a['store_name']}: {a['message']}")
        
        lines.append("\nğŸ’¡ å»ºè®®ï¼šä¼˜å…ˆå¤„ç†é«˜ä¸¥é‡åº¦å¼‚å¸¸ï¼Œé€ä¸€æ’æŸ¥é—®é¢˜æ ¹å› ã€‚")
        return '\n'.join(lines)
    
    def _empty_anomalies(self) -> Dict:
        return {'total_anomaly_stores': 0, 'by_type': {'low_profit_margin': [], 'low_order_count': [], 'high_marketing_cost': [], 'high_delivery_cost': []}, 'summary_text': 'æš‚æ— æ•°æ®'}

    def compare_head_tail(self, n: int = 3) -> Dict:
        """å¤´å°¾é—¨åº—å¯¹æ¯”åˆ†æ"""
        if self.stores.empty or len(self.stores) < 2:
            return self._empty_head_tail()
        
        sorted_stores = self.stores.sort_values('profit_margin', ascending=False)
        top = sorted_stores.head(n)
        bottom = sorted_stores.tail(n)
        
        def store_metrics(row):
            return {
                'store_name': row['store_name'],
                'order_count': int(row['order_count']),
                'total_revenue': round(float(row['total_revenue']), 2),
                'total_profit': round(float(row['total_profit']), 2),
                'profit_margin': round(float(row['profit_margin']), 2),
                'aov': round(float(row['aov']), 2),
                'marketing_cost_rate': round(float(row['marketing_cost_rate']), 2),
                'delivery_cost_rate': round(float(row['delivery_cost_rate']), 2)
            }
        
        top_list = [store_metrics(row) for _, row in top.iterrows()]
        bottom_list = [store_metrics(row) for _, row in bottom.iterrows()]
        
        # è®¡ç®—å·®å¼‚
        top_avg = lambda f: top[f].mean()
        bottom_avg = lambda f: bottom[f].mean()
        
        differences = {
            'profit_margin_gap': round(top_avg('profit_margin') - bottom_avg('profit_margin'), 2),
            'aov_gap': round(top_avg('aov') - bottom_avg('aov'), 2),
            'marketing_cost_rate_gap': round(top_avg('marketing_cost_rate') - bottom_avg('marketing_cost_rate'), 2),
            'delivery_cost_rate_gap': round(top_avg('delivery_cost_rate') - bottom_avg('delivery_cost_rate'), 2)
        }
        
        # åˆ†æç‰¹å¾
        top_char = self._analyze_top_characteristics(top)
        bottom_issues = self._analyze_bottom_issues(bottom)
        
        return {
            'top_stores': top_list,
            'bottom_stores': bottom_list,
            'differences': differences,
            'top_characteristics': top_char,
            'bottom_issues': bottom_issues,
            'summary_text': self._gen_head_tail_summary(top_list, bottom_list, differences, top_char, bottom_issues)
        }

    def _analyze_top_characteristics(self, top_df: pd.DataFrame) -> str:
        if top_df.empty:
            return "æ— æ•°æ®"
        avg_pm = top_df['profit_margin'].mean()
        avg_aov = top_df['aov'].mean()
        avg_mc = top_df['marketing_cost_rate'].mean()
        avg_dc = top_df['delivery_cost_rate'].mean()
        chars = []
        if avg_pm > 25:
            chars.append("åˆ©æ¶¦ç‡ä¼˜ç§€")
        if avg_aov > self.stores['aov'].median():
            chars.append("å®¢å•ä»·è¾ƒé«˜")
        if avg_mc < 10:
            chars.append("è¥é”€æˆæœ¬æ§åˆ¶è‰¯å¥½")
        if avg_dc < 15:
            chars.append("é…é€æˆæœ¬æ§åˆ¶è‰¯å¥½")
        return 'ã€'.join(chars) if chars else "ç»¼åˆè¡¨ç°å‡è¡¡"
    
    def _analyze_bottom_issues(self, bottom_df: pd.DataFrame) -> str:
        if bottom_df.empty:
            return "æ— æ•°æ®"
        avg_pm = bottom_df['profit_margin'].mean()
        avg_mc = bottom_df['marketing_cost_rate'].mean()
        avg_dc = bottom_df['delivery_cost_rate'].mean()
        issues = []
        if avg_pm < 15:
            issues.append("åˆ©æ¶¦ç‡åä½")
        if avg_mc > 15:
            issues.append("è¥é”€æˆæœ¬è¿‡é«˜")
        if avg_dc > 20:
            issues.append("é…é€æˆæœ¬è¿‡é«˜")
        return 'ã€'.join(issues) if issues else "éœ€è¿›ä¸€æ­¥åˆ†æ"
    
    def _gen_head_tail_summary(self, top, bottom, diff, top_char, bottom_issues) -> str:
        return f"""ğŸ”„ å¤´å°¾é—¨åº—å¯¹æ¯”

ã€å¤´éƒ¨é—¨åº— Top3ã€‘
{chr(10).join([f"  {i+1}. {s['store_name']}: åˆ©æ¶¦ç‡{s['profit_margin']:.1f}%, å®¢å•ä»·Â¥{s['aov']:.1f}" for i, s in enumerate(top)])}
å…±åŒç‰¹å¾ï¼š{top_char}

ã€å°¾éƒ¨é—¨åº— Bottom3ã€‘
{chr(10).join([f"  {i+1}. {s['store_name']}: åˆ©æ¶¦ç‡{s['profit_margin']:.1f}%, å®¢å•ä»·Â¥{s['aov']:.1f}" for i, s in enumerate(bottom)])}
ä¸»è¦é—®é¢˜ï¼š{bottom_issues}

ã€å·®è·åˆ†æã€‘
- åˆ©æ¶¦ç‡å·®è·ï¼š{diff['profit_margin_gap']:.1f}ä¸ªç™¾åˆ†ç‚¹
- å®¢å•ä»·å·®è·ï¼šÂ¥{diff['aov_gap']:.1f}
- è¥é”€æˆæœ¬ç‡å·®è·ï¼š{diff['marketing_cost_rate_gap']:.1f}ä¸ªç™¾åˆ†ç‚¹
- é…é€æˆæœ¬ç‡å·®è·ï¼š{diff['delivery_cost_rate_gap']:.1f}ä¸ªç™¾åˆ†ç‚¹

ğŸ’¡ å»ºè®®ï¼šå­¦ä¹ å¤´éƒ¨é—¨åº—çš„æˆåŠŸç»éªŒï¼Œé’ˆå¯¹å°¾éƒ¨é—¨åº—çš„é—®é¢˜åˆ¶å®šæ”¹è¿›æ–¹æ¡ˆã€‚"""
    
    def _empty_head_tail(self) -> Dict:
        return {'top_stores': [], 'bottom_stores': [], 'differences': {'profit_margin_gap': 0, 'aov_gap': 0, 'marketing_cost_rate_gap': 0, 'delivery_cost_rate_gap': 0}, 'top_characteristics': '', 'bottom_issues': '', 'summary_text': 'æš‚æ— æ•°æ®'}

    def analyze_attribution(self) -> Dict:
        """åˆ©æ¶¦ç‡å½’å› åˆ†æï¼ˆç›¸å…³æ€§åˆ†æï¼‰"""
        if self.stores.empty or len(self.stores) < 3:
            return self._empty_attribution()
        
        pm = self.stores['profit_margin'].values
        aov = self.stores['aov'].values
        mc = self.stores['marketing_cost_rate'].values
        dc = self.stores['delivery_cost_rate'].values
        
        # è®¡ç®—ç›¸å…³ç³»æ•°
        def safe_corr(a, b):
            if len(a) < 2 or np.std(a) == 0 or np.std(b) == 0:
                return 0
            return round(float(np.corrcoef(a, b)[0, 1]), 3)
        
        correlations = {
            'aov_correlation': safe_corr(pm, aov),
            'marketing_cost_correlation': safe_corr(pm, mc),
            'delivery_cost_correlation': safe_corr(pm, dc)
        }
        
        # è¯†åˆ«ä¸»è¦å½±å“å› ç´ 
        factors = [
            ('å®¢å•ä»·', correlations['aov_correlation'], 'æ­£ç›¸å…³' if correlations['aov_correlation'] > 0 else 'è´Ÿç›¸å…³'),
            ('è¥é”€æˆæœ¬ç‡', correlations['marketing_cost_correlation'], 'æ­£ç›¸å…³' if correlations['marketing_cost_correlation'] > 0 else 'è´Ÿç›¸å…³'),
            ('é…é€æˆæœ¬ç‡', correlations['delivery_cost_correlation'], 'æ­£ç›¸å…³' if correlations['delivery_cost_correlation'] > 0 else 'è´Ÿç›¸å…³')
        ]
        factors.sort(key=lambda x: abs(x[1]), reverse=True)
        primary = factors[0]
        
        return {
            'correlations': correlations,
            'primary_factor': primary[0],
            'summary_text': self._gen_attribution_summary(correlations, primary)
        }
    
    def _gen_attribution_summary(self, corr, primary) -> str:
        return f"""ğŸ“ˆ åˆ©æ¶¦ç‡å½’å› åˆ†æ

é€šè¿‡ç›¸å…³æ€§åˆ†æï¼Œè¯†åˆ«å½±å“é—¨åº—åˆ©æ¶¦ç‡çš„å…³é”®å› ç´ ï¼š

ã€ç›¸å…³ç³»æ•°ã€‘
- å®¢å•ä»· vs åˆ©æ¶¦ç‡ï¼š{corr['aov_correlation']:.3f} {'ï¼ˆæ­£ç›¸å…³ï¼‰' if corr['aov_correlation'] > 0 else 'ï¼ˆè´Ÿç›¸å…³ï¼‰'}
- è¥é”€æˆæœ¬ç‡ vs åˆ©æ¶¦ç‡ï¼š{corr['marketing_cost_correlation']:.3f} {'ï¼ˆæ­£ç›¸å…³ï¼‰' if corr['marketing_cost_correlation'] > 0 else 'ï¼ˆè´Ÿç›¸å…³ï¼‰'}
- é…é€æˆæœ¬ç‡ vs åˆ©æ¶¦ç‡ï¼š{corr['delivery_cost_correlation']:.3f} {'ï¼ˆæ­£ç›¸å…³ï¼‰' if corr['delivery_cost_correlation'] > 0 else 'ï¼ˆè´Ÿç›¸å…³ï¼‰'}

ã€ä¸»è¦å½±å“å› ç´ ã€‘
{primary[0]}æ˜¯å½±å“åˆ©æ¶¦ç‡çš„æœ€ä¸»è¦å› ç´ ï¼ˆç›¸å…³ç³»æ•°{primary[1]:.3f}ï¼‰

ğŸ’¡ å»ºè®®ï¼š
- è‹¥å®¢å•ä»·æ­£ç›¸å…³å¼ºï¼Œå¯é€šè¿‡æå‡å®¢å•ä»·æ¥æ”¹å–„åˆ©æ¶¦
- è‹¥æˆæœ¬ç‡è´Ÿç›¸å…³å¼ºï¼Œåº”é‡ç‚¹æ§åˆ¶ç›¸åº”æˆæœ¬"""
    
    def _empty_attribution(self) -> Dict:
        return {'correlations': {'aov_correlation': 0, 'marketing_cost_correlation': 0, 'delivery_cost_correlation': 0}, 'primary_factor': '', 'summary_text': 'æ•°æ®ä¸è¶³ï¼Œæ— æ³•è¿›è¡Œå½’å› åˆ†æ'}

    def analyze_trends(self) -> Dict:
        """è¶‹åŠ¿å˜åŒ–åˆ†æï¼ˆåŸºäºç¯æ¯”æ•°æ®ï¼‰"""
        if not self.wow_data:
            return self._empty_trends()
        
        growing = []
        declining = []
        
        for store in self.wow_data:
            change = store.get('changes', {}).get('profit', 0)
            if change > 0:
                growing.append({
                    'store_name': store['store_name'],
                    'change_rate': round(change, 2),
                    'current_value': store.get('current', {}).get('total_profit', 0),
                    'previous_value': store.get('current', {}).get('total_profit', 0) / (1 + change/100) if change != -100 else 0
                })
            elif change < 0:
                declining.append({
                    'store_name': store['store_name'],
                    'change_rate': round(change, 2),
                    'current_value': store.get('current', {}).get('total_profit', 0),
                    'previous_value': store.get('current', {}).get('total_profit', 0) / (1 + change/100) if change != -100 else 0
                })
        
        growing.sort(key=lambda x: x['change_rate'], reverse=True)
        declining.sort(key=lambda x: x['change_rate'])
        
        total = len(self.wow_data)
        return {
            'growing_stores': {
                'count': len(growing),
                'percentage': round(len(growing) / total * 100, 1) if total > 0 else 0,
                'top3': growing[:3]
            },
            'declining_stores': {
                'count': len(declining),
                'percentage': round(len(declining) / total * 100, 1) if total > 0 else 0,
                'top3': declining[:3]
            },
            'summary_text': self._gen_trends_summary(growing, declining, total)
        }
    
    def _gen_trends_summary(self, growing, declining, total) -> str:
        if total == 0:
            return "ğŸ“‰ è¶‹åŠ¿åˆ†æ\n\næš‚æ— ç¯æ¯”æ•°æ®"
        
        lines = [f"ğŸ“‰ è¶‹åŠ¿å˜åŒ–åˆ†æ\n\nå…±{total}å®¶é—¨åº—å‚ä¸ç¯æ¯”åˆ†æï¼š\n"]
        
        lines.append(f"ã€å¢é•¿é—¨åº—ã€‘{len(growing)}å®¶ï¼ˆå æ¯”{len(growing)/total*100:.1f}%ï¼‰")
        if growing:
            for s in growing[:3]:
                lines.append(f"  â†‘ {s['store_name']}: +{s['change_rate']:.1f}%")
        
        lines.append(f"\nã€ä¸‹æ»‘é—¨åº—ã€‘{len(declining)}å®¶ï¼ˆå æ¯”{len(declining)/total*100:.1f}%ï¼‰")
        if declining:
            for s in declining[:3]:
                lines.append(f"  â†“ {s['store_name']}: {s['change_rate']:.1f}%")
        
        lines.append("\nğŸ’¡ å»ºè®®ï¼šå…³æ³¨ä¸‹æ»‘é—¨åº—ï¼Œåˆ†æä¸‹æ»‘åŸå› å¹¶åŠæ—¶å¹²é¢„ã€‚")
        return '\n'.join(lines)
    
    def _empty_trends(self) -> Dict:
        return {'growing_stores': {'count': 0, 'percentage': 0, 'top3': []}, 'declining_stores': {'count': 0, 'percentage': 0, 'top3': []}, 'summary_text': 'æš‚æ— ç¯æ¯”æ•°æ®'}

    def generate_recommendations(self, anomalies: Dict, clustering: Dict, attribution: Dict, trends: Dict) -> Dict:
        """ç”Ÿæˆç­–ç•¥å»ºè®®"""
        urgent = []
        important = []
        general = []
        
        # åŸºäºå¼‚å¸¸æ£€æµ‹ç”Ÿæˆç´§æ€¥å»ºè®®
        if anomalies['by_type']['low_profit_margin']:
            stores = [a['store_name'] for a in anomalies['by_type']['low_profit_margin']]
            urgent.append({
                'priority': 'urgent',
                'category': 'åˆ©æ¶¦å¼‚å¸¸',
                'title': 'åˆ©æ¶¦ç‡å¼‚å¸¸é—¨åº—éœ€ç´§æ€¥å…³æ³¨',
                'description': f"å‘ç°{len(stores)}å®¶é—¨åº—åˆ©æ¶¦ç‡æ˜¾è‘—ä½äºå¹³å‡æ°´å¹³ï¼Œéœ€ç«‹å³æ’æŸ¥åŸå› ",
                'action_items': ['æ£€æŸ¥å•†å“å®šä»·æ˜¯å¦åˆç†', 'åˆ†ææˆæœ¬ç»“æ„', 'æ ¸å®æ˜¯å¦å­˜åœ¨å¼‚å¸¸è®¢å•'],
                'affected_stores': stores[:5]
            })
        
        if anomalies['by_type']['high_marketing_cost']:
            stores = [a['store_name'] for a in anomalies['by_type']['high_marketing_cost']]
            important.append({
                'priority': 'important',
                'category': 'æˆæœ¬æ§åˆ¶',
                'title': 'è¥é”€æˆæœ¬è¿‡é«˜éœ€ä¼˜åŒ–',
                'description': f"{len(stores)}å®¶é—¨åº—è¥é”€æˆæœ¬ç‡è¶…è¿‡15%ï¼Œå»ºè®®ä¼˜åŒ–æ´»åŠ¨ç­–ç•¥",
                'action_items': ['è¯„ä¼°æ´»åŠ¨ROI', 'å‡å°‘ä½æ•ˆä¿ƒé”€', 'ä¼˜åŒ–ä¼˜æƒ åˆ¸å‘æ”¾ç­–ç•¥'],
                'affected_stores': stores[:5]
            })
        
        if anomalies['by_type']['high_delivery_cost']:
            stores = [a['store_name'] for a in anomalies['by_type']['high_delivery_cost']]
            important.append({
                'priority': 'important',
                'category': 'æˆæœ¬æ§åˆ¶',
                'title': 'é…é€æˆæœ¬è¿‡é«˜éœ€ä¼˜åŒ–',
                'description': f"{len(stores)}å®¶é—¨åº—é…é€æˆæœ¬ç‡è¶…è¿‡20%ï¼Œå»ºè®®ä¼˜åŒ–é…é€èŒƒå›´",
                'action_items': ['è°ƒæ•´é…é€èŒƒå›´', 'ä¼˜åŒ–èµ·é€é‡‘é¢', 'è€ƒè™‘è‡ªé…é€æ–¹æ¡ˆ'],
                'affected_stores': stores[:5]
            })
        
        # åŸºäºåˆ†ç¾¤ç”Ÿæˆå»ºè®®
        if clustering['low_performance']['count'] > 0:
            stores = clustering['low_performance']['top_stores']
            general.append({
                'priority': 'general',
                'category': 'é—¨åº—æå‡',
                'title': 'ä½ç»©æ•ˆé—¨åº—æå‡è®¡åˆ’',
                'description': f"{clustering['low_performance']['count']}å®¶é—¨åº—å¤„äºä½ç»©æ•ˆåŒºé—´ï¼Œå»ºè®®åˆ¶å®šæå‡è®¡åˆ’",
                'action_items': ['å¯¹æ ‡é«˜ç»©æ•ˆé—¨åº—', 'åˆ†æå·®è·åŸå› ', 'åˆ¶å®šæ”¹è¿›æªæ–½'],
                'affected_stores': stores[:5]
            })
        
        # åŸºäºå½’å› åˆ†æç”Ÿæˆå»ºè®®
        if attribution['primary_factor'] == 'å®¢å•ä»·' and attribution['correlations']['aov_correlation'] > 0.3:
            general.append({
                'priority': 'general',
                'category': 'æ”¶å…¥æå‡',
                'title': 'æå‡å®¢å•ä»·ç­–ç•¥',
                'description': 'å®¢å•ä»·ä¸åˆ©æ¶¦ç‡å¼ºæ­£ç›¸å…³ï¼Œå»ºè®®é€šè¿‡æå‡å®¢å•ä»·æ¥æ”¹å–„åˆ©æ¶¦',
                'action_items': ['ä¼˜åŒ–å•†å“ç»„åˆ', 'è®¾ç½®æ»¡å‡é—¨æ§›', 'æ¨å¹¿é«˜æ¯›åˆ©å•†å“'],
                'affected_stores': []
            })
        
        return {
            'urgent': urgent,
            'important': important,
            'general': general,
            'summary_text': self._gen_recommendations_summary(urgent, important, general)
        }

    def _gen_recommendations_summary(self, urgent, important, general) -> str:
        total = len(urgent) + len(important) + len(general)
        if total == 0:
            return "ğŸ’¡ ç­–ç•¥å»ºè®®\n\nå½“å‰è¿è¥çŠ¶å†µè‰¯å¥½ï¼Œæš‚æ— ç‰¹åˆ«å»ºè®®ã€‚"
        
        lines = [f"ğŸ’¡ ç­–ç•¥å»ºè®®\n\nå…±ç”Ÿæˆ{total}æ¡å»ºè®®ï¼š\n"]
        
        if urgent:
            lines.append(f"ğŸ”´ ç´§æ€¥ï¼ˆ{len(urgent)}æ¡ï¼‰")
            for r in urgent:
                lines.append(f"  â€¢ {r['title']}")
        
        if important:
            lines.append(f"\nğŸŸ  é‡è¦ï¼ˆ{len(important)}æ¡ï¼‰")
            for r in important:
                lines.append(f"  â€¢ {r['title']}")
        
        if general:
            lines.append(f"\nğŸŸ¢ ä¸€èˆ¬ï¼ˆ{len(general)}æ¡ï¼‰")
            for r in general:
                lines.append(f"  â€¢ {r['title']}")
        
        return '\n'.join(lines)
    
    def generate_overview(self) -> Dict:
        """ç”Ÿæˆæ•´ä½“æ¦‚å†µ"""
        if self.stores.empty:
            return self._empty_overview()
        
        total_revenue = float(self.stores['total_revenue'].sum())
        total_profit = float(self.stores['total_profit'].sum())
        weighted_pm = (total_profit / total_revenue * 100) if total_revenue > 0 else 0
        
        stats = self.calculate_statistics()
        
        overview = {
            'total_stores': len(self.stores),
            'total_orders': int(self.stores['order_count'].sum()),
            'total_revenue': round(total_revenue, 2),
            'total_profit': round(total_profit, 2),
            'weighted_profit_margin': round(weighted_pm, 2),
            'statistics': stats,
            'summary_text': self._gen_overview_summary(len(self.stores), int(self.stores['order_count'].sum()), total_revenue, total_profit, weighted_pm, stats)
        }
        return overview
    
    def _gen_overview_summary(self, stores, orders, revenue, profit, pm, stats) -> str:
        health = "âœ… æ•´ä½“ç»è¥çŠ¶å†µè‰¯å¥½" if pm >= 25 else ("âš ï¸ æ•´ä½“ç»è¥çŠ¶å†µä¸€èˆ¬" if pm >= 15 else "ğŸ”´ æ•´ä½“åˆ©æ¶¦ç‡åä½")
        return f"""ğŸ“Š æ•´ä½“ç»è¥æ¦‚å†µ

å½“å‰å…±æœ‰ {stores} å®¶é—¨åº—å‚ä¸åˆ†æï¼Œç´¯è®¡å®Œæˆ {orders:,} ç¬”è®¢å•ï¼Œ
å®ç°é”€å”®é¢ Â¥{revenue:,.0f}ï¼Œæ€»åˆ©æ¶¦ Â¥{profit:,.0f}ã€‚

åŠ æƒå¹³å‡åˆ©æ¶¦ç‡ä¸º {pm:.1f}%ï¼Œåˆ©æ¶¦ç‡ä¸­ä½æ•°ä¸º {stats['profit_margin']['median']:.1f}%ã€‚

ã€åˆ©æ¶¦ç‡åˆ†å¸ƒã€‘
- P25ï¼ˆä½äº75%é—¨åº—ï¼‰: {stats['profit_margin']['p25']:.1f}%
- P50ï¼ˆä¸­ä½æ•°ï¼‰: {stats['profit_margin']['p50']:.1f}%
- P75ï¼ˆé«˜äº75%é—¨åº—ï¼‰: {stats['profit_margin']['p75']:.1f}%
- P90ï¼ˆå¤´éƒ¨10%é—¨åº—ï¼‰: {stats['profit_margin']['p90']:.1f}%

{health}"""
    
    def _empty_overview(self) -> Dict:
        return {'total_stores': 0, 'total_orders': 0, 'total_revenue': 0, 'total_profit': 0, 'weighted_profit_margin': 0, 'statistics': self._empty_statistics(), 'summary_text': 'æš‚æ— æ•°æ®'}

    def calculate_health_scores(self) -> Dict:
        """
        é—¨åº—å¥åº·åº¦è¯„åˆ†ï¼ˆ0-100åˆ†ï¼‰
        
        è¯„åˆ†ç»´åº¦åŠæƒé‡ï¼š
        - åˆ©æ¶¦ç‡å¾—åˆ†ï¼ˆ40%ï¼‰ï¼šåŸºäºåˆ©æ¶¦ç‡åˆ†ä½æ•°
        - è®¢å•é‡å¾—åˆ†ï¼ˆ20%ï¼‰ï¼šåŸºäºè®¢å•é‡åˆ†ä½æ•°
        - è¥é”€æˆæœ¬ç‡å¾—åˆ†ï¼ˆ20%ï¼‰ï¼šæˆæœ¬ç‡è¶Šä½å¾—åˆ†è¶Šé«˜
        - é…é€æˆæœ¬ç‡å¾—åˆ†ï¼ˆ20%ï¼‰ï¼šæˆæœ¬ç‡è¶Šä½å¾—åˆ†è¶Šé«˜
        """
        if self.stores.empty:
            return self._empty_health_scores()
        
        scores = []
        for _, row in self.stores.iterrows():
            # åˆ©æ¶¦ç‡å¾—åˆ†ï¼ˆ0-100ï¼ŒåŸºäºåˆ†ä½æ•°ï¼‰
            pm_percentile = (self.stores['profit_margin'] <= row['profit_margin']).mean() * 100
            pm_score = pm_percentile * 0.4
            
            # è®¢å•é‡å¾—åˆ†ï¼ˆ0-100ï¼ŒåŸºäºåˆ†ä½æ•°ï¼‰
            oc_percentile = (self.stores['order_count'] <= row['order_count']).mean() * 100
            oc_score = oc_percentile * 0.2
            
            # è¥é”€æˆæœ¬ç‡å¾—åˆ†ï¼ˆè¶Šä½è¶Šå¥½ï¼Œ15%ä»¥ä¸‹æ»¡åˆ†ï¼Œ30%ä»¥ä¸Š0åˆ†ï¼‰
            mc_rate = row['marketing_cost_rate']
            mc_score = max(0, min(100, (30 - mc_rate) / 15 * 100)) * 0.2
            
            # é…é€æˆæœ¬ç‡å¾—åˆ†ï¼ˆè¶Šä½è¶Šå¥½ï¼Œ10%ä»¥ä¸‹æ»¡åˆ†ï¼Œ30%ä»¥ä¸Š0åˆ†ï¼‰
            dc_rate = row['delivery_cost_rate']
            dc_score = max(0, min(100, (30 - dc_rate) / 20 * 100)) * 0.2
            
            total_score = pm_score + oc_score + mc_score + dc_score
            scores.append({
                'store_name': row['store_name'],
                'health_score': round(total_score, 1),
                'pm_score': round(pm_score / 0.4, 1),
                'oc_score': round(oc_score / 0.2, 1),
                'mc_score': round(mc_score / 0.2, 1),
                'dc_score': round(dc_score / 0.2, 1)
            })
        
        scores.sort(key=lambda x: x['health_score'], reverse=True)
        
        # åˆ†å¸ƒç»Ÿè®¡
        excellent = len([s for s in scores if s['health_score'] >= 80])
        good = len([s for s in scores if 60 <= s['health_score'] < 80])
        average = len([s for s in scores if 40 <= s['health_score'] < 60])
        poor = len([s for s in scores if s['health_score'] < 40])
        
        return {
            'scores': scores,
            'distribution': {
                'excellent': {'count': excellent, 'percentage': round(excellent / len(scores) * 100, 1)},
                'good': {'count': good, 'percentage': round(good / len(scores) * 100, 1)},
                'average': {'count': average, 'percentage': round(average / len(scores) * 100, 1)},
                'poor': {'count': poor, 'percentage': round(poor / len(scores) * 100, 1)}
            },
            'top_stores': scores[:3],
            'bottom_stores': scores[-3:] if len(scores) >= 3 else scores,
            'avg_score': round(sum(s['health_score'] for s in scores) / len(scores), 1),
            'summary_text': self._gen_health_summary(scores, excellent, good, average, poor)
        }
    
    def _gen_health_summary(self, scores, excellent, good, average, poor) -> str:
        total = len(scores)
        avg = sum(s['health_score'] for s in scores) / total
        return f"""ğŸ¥ é—¨åº—å¥åº·åº¦è¯„åˆ†

åŸºäºåˆ©æ¶¦ç‡(40%)ã€è®¢å•é‡(20%)ã€è¥é”€æˆæœ¬ç‡(20%)ã€é…é€æˆæœ¬ç‡(20%)ç»¼åˆè¯„åˆ†ï¼š

ã€å¥åº·åº¦åˆ†å¸ƒã€‘
- ğŸŸ¢ ä¼˜ç§€ï¼ˆâ‰¥80åˆ†ï¼‰ï¼š{excellent}å®¶ï¼ˆ{excellent/total*100:.1f}%ï¼‰
- ğŸ”µ è‰¯å¥½ï¼ˆ60-80åˆ†ï¼‰ï¼š{good}å®¶ï¼ˆ{good/total*100:.1f}%ï¼‰
- ğŸŸ¡ ä¸€èˆ¬ï¼ˆ40-60åˆ†ï¼‰ï¼š{average}å®¶ï¼ˆ{average/total*100:.1f}%ï¼‰
- ğŸ”´ è¾ƒå·®ï¼ˆ<40åˆ†ï¼‰ï¼š{poor}å®¶ï¼ˆ{poor/total*100:.1f}%ï¼‰

å¹³å‡å¥åº·åº¦ï¼š{avg:.1f}åˆ†

ã€æœ€å¥åº·é—¨åº—ã€‘
{chr(10).join([f"  {i+1}. {s['store_name']}: {s['health_score']:.1f}åˆ†" for i, s in enumerate(scores[:3])])}

ã€éœ€å…³æ³¨é—¨åº—ã€‘
{chr(10).join([f"  {i+1}. {s['store_name']}: {s['health_score']:.1f}åˆ†" for i, s in enumerate(scores[-3:])])}

ğŸ’¡ å»ºè®®ï¼šé‡ç‚¹å…³æ³¨å¥åº·åº¦ä½äº40åˆ†çš„é—¨åº—ï¼Œåˆ†æå…¶è–„å¼±ç¯èŠ‚ã€‚"""
    
    def _empty_health_scores(self) -> Dict:
        return {'scores': [], 'distribution': {'excellent': {'count': 0, 'percentage': 0}, 'good': {'count': 0, 'percentage': 0}, 'average': {'count': 0, 'percentage': 0}, 'poor': {'count': 0, 'percentage': 0}}, 'top_stores': [], 'bottom_stores': [], 'avg_score': 0, 'summary_text': 'æš‚æ— æ•°æ®'}

    def analyze_cost_structure(self) -> Dict:
        """æˆæœ¬ç»“æ„åˆ†æ"""
        if self.stores.empty:
            return self._empty_cost_structure()
        
        # è®¡ç®—æ€»æˆæœ¬
        total_marketing = float(self.stores['total_marketing_cost'].sum()) if 'total_marketing_cost' in self.stores.columns else 0
        total_delivery = float(self.stores['total_delivery_cost'].sum()) if 'total_delivery_cost' in self.stores.columns else 0
        total_revenue = float(self.stores['total_revenue'].sum())
        
        # è®¡ç®—æˆæœ¬ç‡ç»Ÿè®¡
        mc_rates = self.stores['marketing_cost_rate'].values
        dc_rates = self.stores['delivery_cost_rate'].values
        
        def rate_stats(rates):
            return {
                'mean': round(float(np.mean(rates)), 2),
                'median': round(float(np.median(rates)), 2),
                'std': round(float(np.std(rates)), 2),
                'min': round(float(np.min(rates)), 2),
                'max': round(float(np.max(rates)), 2)
            }
        
        # è¯†åˆ«æˆæœ¬å¼‚å¸¸é—¨åº—
        mc_high = self.stores[self.stores['marketing_cost_rate'] > 15]['store_name'].tolist()
        dc_high = self.stores[self.stores['delivery_cost_rate'] > 20]['store_name'].tolist()
        
        # é«˜ç»©æ•ˆ vs ä½ç»©æ•ˆé—¨åº—æˆæœ¬å¯¹æ¯”
        pm_median = self.stores['profit_margin'].median()
        high_perf = self.stores[self.stores['profit_margin'] >= pm_median]
        low_perf = self.stores[self.stores['profit_margin'] < pm_median]
        
        comparison = {
            'high_performance': {
                'avg_marketing_rate': round(float(high_perf['marketing_cost_rate'].mean()), 2) if not high_perf.empty else 0,
                'avg_delivery_rate': round(float(high_perf['delivery_cost_rate'].mean()), 2) if not high_perf.empty else 0
            },
            'low_performance': {
                'avg_marketing_rate': round(float(low_perf['marketing_cost_rate'].mean()), 2) if not low_perf.empty else 0,
                'avg_delivery_rate': round(float(low_perf['delivery_cost_rate'].mean()), 2) if not low_perf.empty else 0
            }
        }
        
        return {
            'totals': {
                'marketing_cost': round(total_marketing, 2),
                'delivery_cost': round(total_delivery, 2),
                'marketing_ratio': round(total_marketing / total_revenue * 100, 2) if total_revenue > 0 else 0,
                'delivery_ratio': round(total_delivery / total_revenue * 100, 2) if total_revenue > 0 else 0
            },
            'marketing_rate_stats': rate_stats(mc_rates),
            'delivery_rate_stats': rate_stats(dc_rates),
            'anomaly_stores': {
                'high_marketing': mc_high[:5],
                'high_delivery': dc_high[:5]
            },
            'performance_comparison': comparison,
            'summary_text': self._gen_cost_structure_summary(total_marketing, total_delivery, total_revenue, mc_high, dc_high, comparison)
        }
    
    def _gen_cost_structure_summary(self, mc, dc, revenue, mc_high, dc_high, comparison) -> str:
        mc_ratio = mc / revenue * 100 if revenue > 0 else 0
        dc_ratio = dc / revenue * 100 if revenue > 0 else 0
        
        return f"""ğŸ’° æˆæœ¬ç»“æ„åˆ†æ

ã€æˆæœ¬æ€»è§ˆã€‘
- è¥é”€æˆæœ¬ï¼šÂ¥{mc:,.0f}ï¼ˆå é”€å”®é¢{mc_ratio:.1f}%ï¼‰
- é…é€æˆæœ¬ï¼šÂ¥{dc:,.0f}ï¼ˆå é”€å”®é¢{dc_ratio:.1f}%ï¼‰

ã€æˆæœ¬å¼‚å¸¸é—¨åº—ã€‘
- è¥é”€æˆæœ¬ç‡>15%ï¼š{len(mc_high)}å®¶ {('(' + ', '.join(mc_high[:3]) + '...)') if mc_high else ''}
- é…é€æˆæœ¬ç‡>20%ï¼š{len(dc_high)}å®¶ {('(' + ', '.join(dc_high[:3]) + '...)') if dc_high else ''}

ã€é«˜ç»©æ•ˆ vs ä½ç»©æ•ˆé—¨åº—å¯¹æ¯”ã€‘
- é«˜ç»©æ•ˆé—¨åº—ï¼šè¥é”€æˆæœ¬ç‡{comparison['high_performance']['avg_marketing_rate']:.1f}%ï¼Œé…é€æˆæœ¬ç‡{comparison['high_performance']['avg_delivery_rate']:.1f}%
- ä½ç»©æ•ˆé—¨åº—ï¼šè¥é”€æˆæœ¬ç‡{comparison['low_performance']['avg_marketing_rate']:.1f}%ï¼Œé…é€æˆæœ¬ç‡{comparison['low_performance']['avg_delivery_rate']:.1f}%

ğŸ’¡ ä¼˜åŒ–å»ºè®®ï¼š
- {'è¥é”€æˆæœ¬åé«˜ï¼Œå»ºè®®ä¼˜åŒ–æ´»åŠ¨ç­–ç•¥' if mc_ratio > 12 else 'è¥é”€æˆæœ¬æ§åˆ¶è‰¯å¥½'}
- {'é…é€æˆæœ¬åé«˜ï¼Œå»ºè®®ä¼˜åŒ–é…é€èŒƒå›´' if dc_ratio > 15 else 'é…é€æˆæœ¬æ§åˆ¶è‰¯å¥½'}"""
    
    def _empty_cost_structure(self) -> Dict:
        return {'totals': {'marketing_cost': 0, 'delivery_cost': 0, 'marketing_ratio': 0, 'delivery_ratio': 0}, 'marketing_rate_stats': {'mean': 0, 'median': 0, 'std': 0, 'min': 0, 'max': 0}, 'delivery_rate_stats': {'mean': 0, 'median': 0, 'std': 0, 'min': 0, 'max': 0}, 'anomaly_stores': {'high_marketing': [], 'high_delivery': []}, 'performance_comparison': {'high_performance': {'avg_marketing_rate': 0, 'avg_delivery_rate': 0}, 'low_performance': {'avg_marketing_rate': 0, 'avg_delivery_rate': 0}}, 'summary_text': 'æš‚æ— æ•°æ®'}


@router.get("/comparison/global-insights")
async def get_global_insights(
    start_date: Optional[date] = Query(None, description="å¼€å§‹æ—¥æœŸ"),
    end_date: Optional[date] = Query(None, description="ç»“æŸæ—¥æœŸ"),
    channel: Optional[str] = Query(None, description="æ¸ é“ç­›é€‰"),
    include_trends: bool = Query(True, description="æ˜¯å¦åŒ…å«è¶‹åŠ¿åˆ†æ")
) -> Dict[str, Any]:
    """
    å…¨å±€é—¨åº—æ´å¯Ÿåˆ†æ
    
    è¿”å›å®Œæ•´çš„æ´å¯ŸæŠ¥å‘Šï¼ŒåŒ…å«ï¼š
    - æ•´ä½“æ¦‚å†µåˆ†æ
    - é—¨åº—åˆ†ç¾¤åˆ†æ
    - å¼‚å¸¸é—¨åº—æ£€æµ‹
    - å¤´å°¾å¯¹æ¯”åˆ†æ
    - åˆ©æ¶¦ç‡å½’å› åˆ†æ
    - è¶‹åŠ¿å˜åŒ–åˆ†æ
    - ç­–ç•¥å»ºè®®
    """
    import time
    from datetime import datetime as dt
    
    query_start = time.time()
    
    # è·å–é—¨åº—æ•°æ®
    store_stats = None
    if AGGREGATION_TABLE_AVAILABLE:
        store_stats = get_store_metrics_from_aggregation(start_date, end_date, channel)
    
    if store_stats is None or store_stats.empty:
        df = get_all_stores_data(start_date, end_date, channel)
        if not df.empty:
            store_stats = calculate_store_metrics(df)
    
    if store_stats is None or store_stats.empty:
        return {"success": True, "data": None, "message": "æš‚æ— é—¨åº—æ•°æ®"}
    
    # è·å–ç¯æ¯”æ•°æ®ï¼ˆå¦‚æœéœ€è¦ï¼‰
    wow_data = []
    if include_trends and end_date:
        try:
            wow_response = await get_stores_week_over_week(end_date, None, None, channel)
            if wow_response.get('success') and wow_response.get('data'):
                wow_data = wow_response['data'].get('stores', [])
        except Exception as e:
            print(f"âš ï¸ è·å–ç¯æ¯”æ•°æ®å¤±è´¥: {e}")
    
    # åˆå§‹åŒ–æ´å¯Ÿå¼•æ“
    engine = InsightsEngine(store_stats, wow_data)
    
    # ç”Ÿæˆå„æ¨¡å—åˆ†æ
    overview = engine.generate_overview()
    clustering = engine.cluster_stores()
    anomalies = engine.detect_anomalies()
    head_tail = engine.compare_head_tail()
    attribution = engine.analyze_attribution()
    trends = engine.analyze_trends()
    health_scores = engine.calculate_health_scores()
    cost_structure = engine.analyze_cost_structure()
    recommendations = engine.generate_recommendations(anomalies, clustering, attribution, trends)
    
    query_time = (time.time() - query_start) * 1000
    print(f"âœ… [å…¨å±€æ´å¯Ÿ] åˆ†æå®Œæˆï¼Œè€—æ—¶: {query_time:.1f}ms")
    
    return {
        "success": True,
        "data": {
            "overview": overview,
            "clustering": clustering,
            "anomalies": anomalies,
            "head_tail_comparison": head_tail,
            "attribution": attribution,
            "trends": trends,
            "health_scores": health_scores,
            "cost_structure": cost_structure,
            "recommendations": recommendations,
            "generated_at": dt.now().strftime("%Y-%m-%d %H:%M:%S")
        }
    }
