# -*- coding: utf-8 -*-
"""
åº“å­˜é£é™©åˆ†æ API

ä¸ Dash ç‰ˆæœ¬å®Œå…¨ä¸€è‡´çš„è®¡ç®—é€»è¾‘ï¼š
- å”®ç½„å“: åº“å­˜=0 ä¸” è¿‘7å¤©æœ‰é”€é‡
- æ»é”€å“åˆ†çº§ï¼ˆğŸ†• ä¼˜åŒ–ç‰ˆï¼šä»¥å•†å“é¦–æ¬¡å‡ºç°æ—¥æœŸä¸ºåŸºå‡†ï¼‰:
  - å…³æ³¨: 3å¤©æ— é”€é‡ ä¸” åº“å­˜ > 0
  - è½»åº¦æ»é”€: 7å¤©æ— é”€é‡ ä¸” åº“å­˜ > 0
  - ä¸­åº¦æ»é”€: 15å¤©æ— é”€é‡ ä¸” åº“å­˜ > 0
  - é‡åº¦æ»é”€: 30å¤©æ— é”€é‡ ä¸” åº“å­˜ > 0
- åº“å­˜å‘¨è½¬å¤©æ•°: å½“å‰åº“å­˜ / æ—¥å‡é”€é‡

ğŸ†• 2025-01-16 ä¼˜åŒ–ï¼š
æ»é”€å¤©æ•°è®¡ç®—é€»è¾‘æ”¹ä¸º"ä»¥å•†å“é¦–æ¬¡å‡ºç°æ—¥æœŸä¸ºè§‚å¯Ÿèµ·ç‚¹"
- å•†å“Aåœ¨1æ—¥æœ‰é”€å”® â†’ ä»1æ—¥å¼€å§‹è®¡ç®—æ— é”€å”®å¤©æ•°
- å•†å“Båœ¨5æ—¥é¦–æ¬¡å‡ºç° â†’ ä»5æ—¥å¼€å§‹è®¡ç®—æ— é”€å”®å¤©æ•°
- è§£å†³äº†æ•°æ®çª—å£è¾¹ç•Œå¯¼è‡´çš„æ»é”€åˆ¤æ–­å¤±çœŸé—®é¢˜

ä¸šåŠ¡é€»è¾‘æ¥æº: æ™ºèƒ½é—¨åº—çœ‹æ¿_Dashç‰ˆ.py ç¬¬11333-11430è¡Œ
"""

from fastapi import APIRouter, Query, HTTPException
from typing import Optional, Dict, Any, List
from datetime import timedelta
import pandas as pd
import numpy as np

import sys
from pathlib import Path
APP_DIR = Path(__file__).resolve().parent.parent.parent
if str(APP_DIR) not in sys.path:
    sys.path.insert(0, str(APP_DIR))

from .orders import get_order_data

router = APIRouter()


def get_product_latest_stock(df: pd.DataFrame, stock_col: str, date_col: str) -> Dict[str, float]:
    """
    è·å–æ¯ä¸ªå•†å“çš„æœ€æ–°åº“å­˜ï¼ˆä¸Dashç‰ˆæœ¬ä¸€è‡´ï¼‰
    
    é€»è¾‘ï¼šæŒ‰æ—¥æœŸæ’åºï¼Œå–æ¯ä¸ªå•†å“æœ€åä¸€æ¡è®°å½•çš„åº“å­˜å€¼
    """
    if stock_col not in df.columns or date_col not in df.columns:
        return {}
    
    df_sorted = df.sort_values(date_col)
    latest = df_sorted.groupby('å•†å“åç§°')[stock_col].last()
    return latest.to_dict()


def calculate_inventory_risk_dash_style(df: pd.DataFrame, store_name: str = None) -> Dict[str, Any]:
    """
    è®¡ç®—åº“å­˜é£é™©ç»Ÿè®¡ï¼ˆä¸Dashç‰ˆæœ¬å®Œå…¨ä¸€è‡´ï¼‰
    
    æ¥æº: æ™ºèƒ½é—¨åº—çœ‹æ¿_Dashç‰ˆ.py ç¬¬11333-11430è¡Œ
    """
    result = {
        "sold_out": {"total": 0, "products": [], "by_category": {}},
        "slow_moving": {
            "total": 0, 
            "by_severity": {"light": 0, "medium": 0, "heavy": 0, "critical": 0},
            "products": [],
            "by_category": {}
        },
        "by_category": [],
        "turnover": {}
    }
    
    if df.empty:
        return result
    
    # ==================== 1. æ£€æŸ¥å¿…éœ€å­—æ®µ ====================
    date_col = None
    for col in ['æ—¥æœŸ', 'ä¸‹å•æ—¶é—´']:
        if col in df.columns:
            date_col = col
            break
    
    stock_col = None
    for col in ['åº“å­˜', 'å‰©ä½™åº“å­˜', 'stock', 'remaining_stock']:
        if col in df.columns:
            stock_col = col
            break
    
    sales_col = 'æœˆå”®' if 'æœˆå”®' in df.columns else 'é”€é‡' if 'é”€é‡' in df.columns else None
    category_col = 'ä¸€çº§åˆ†ç±»å' if 'ä¸€çº§åˆ†ç±»å' in df.columns else 'ä¸€çº§åˆ†ç±»'
    
    if not date_col:
        print("âš ï¸ ç¼ºå°‘æ—¥æœŸå­—æ®µï¼Œæ— æ³•è®¡ç®—åº“å­˜é£é™©")
        return result
    
    # ==================== 2. å‡†å¤‡æ•°æ® ====================
    df = df.copy()
    df[date_col] = pd.to_datetime(df[date_col], errors='coerce')
    df = df.dropna(subset=[date_col])
    
    if df.empty:
        return result
    
    last_date = df[date_col].max()
    seven_days_ago = last_date - timedelta(days=7)
    
    # ==================== 3. è·å–å•†å“æœ€æ–°åº“å­˜çŠ¶æ€ ====================
    if stock_col:
        stock_map = get_product_latest_stock(df, stock_col=stock_col, date_col=date_col)
        
        all_products = df['å•†å“åç§°'].unique()
        last_stock = pd.DataFrame({
            'å•†å“åç§°': all_products,
            'åº“å­˜': [stock_map.get(p, 0) for p in all_products]
        })
        
        # æ·»åŠ åˆ†ç±»ä¿¡æ¯
        product_category_map = df.groupby('å•†å“åç§°')[category_col].first().to_dict()
        last_stock['åˆ†ç±»'] = last_stock['å•†å“åç§°'].map(product_category_map)
    else:
        print("âš ï¸ ç¼ºå°‘åº“å­˜å­—æ®µï¼Œæ— æ³•è®¡ç®—åº“å­˜é£é™©")
        return result
    
    # ==================== 4. å”®ç½„å“ç»Ÿè®¡ (åº“å­˜=0ä¸”è¿‘7å¤©æœ‰é”€é‡) ====================
    # ç­›é€‰è¿‘7å¤©æœ‰é”€é‡çš„æ•°æ®
    recent_sales = df[df[date_col] >= seven_days_ago]
    recent_products = set(recent_sales['å•†å“åç§°'].unique())
    
    # è·å–å½“å‰åº“å­˜=0çš„å•†å“
    zero_stock_products = set(last_stock[last_stock['åº“å­˜'] == 0]['å•†å“åç§°'].unique())
    
    # å”®ç½„å“ = åº“å­˜0 ä¸” è¿‘7å¤©æœ‰é”€é‡
    sellout_products = zero_stock_products & recent_products
    
    result["sold_out"]["total"] = len(sellout_products)
    
    # æŒ‰åˆ†ç±»ç»Ÿè®¡å”®ç½„å“
    if len(sellout_products) > 0:
        sellout_df = df[df['å•†å“åç§°'].isin(sellout_products)][[category_col, 'å•†å“åç§°']].drop_duplicates()
        sellout_by_cat = sellout_df.groupby(category_col).size().to_dict()
        result["sold_out"]["by_category"] = sellout_by_cat
        
        # ç”Ÿæˆå”®ç½„å“è¯¦æƒ…åˆ—è¡¨
        for product in sellout_products:
            product_data = recent_sales[recent_sales['å•†å“åç§°'] == product]
            category = product_category_map.get(product, 'æœªçŸ¥')
            
            # è®¡ç®—å½±å“é‡‘é¢ï¼ˆè¿‘7å¤©é”€å”®é¢ï¼‰
            impact = product_data['å®æ”¶ä»·æ ¼'].sum() if 'å®æ”¶ä»·æ ¼' in product_data.columns else 0
            
            result["sold_out"]["products"].append({
                "id": f"oos-{hash(product) % 10000}",
                "skuName": product,
                "spec": "",
                "issueType": "OUT_OF_STOCK",
                "reason": "åº“å­˜ä¸º0ä½†è¿‘7å¤©æœ‰é”€é‡",
                "impactValue": round(float(impact), 2),
                "duration": "7å¤©å†…",
                "action": "ç«‹å³è¡¥è´§",
                "category": category
            })
    
    # ==================== 5. æ»é”€å“å››çº§åˆ†çº§ç»Ÿè®¡ï¼ˆğŸ†• ä¼˜åŒ–ç‰ˆï¼šä»¥é¦–æ¬¡å‡ºç°æ—¥æœŸä¸ºåŸºå‡†ï¼‰ ====================
    # ğŸ†• è®¡ç®—æ¯ä¸ªå•†å“çš„é¦–æ¬¡å‡ºç°æ—¥æœŸå’Œæœ€åé”€å”®æ—¥æœŸ
    product_first_sale = df.groupby('å•†å“åç§°')[date_col].min().reset_index()
    product_first_sale.columns = ['å•†å“åç§°', 'é¦–æ¬¡å‡ºç°æ—¥æœŸ']
    
    product_last_sale = df.groupby('å•†å“åç§°')[date_col].max().reset_index()
    product_last_sale.columns = ['å•†å“åç§°', 'æœ€åé”€å”®æ—¥æœŸ']
    
    # åˆå¹¶é¦–æ¬¡å’Œæœ€åé”€å”®æ—¥æœŸ
    product_sales_info = product_first_sale.merge(product_last_sale, on='å•†å“åç§°')
    
    # ğŸ†• è®¡ç®—æ»é”€å¤©æ•°ï¼ˆæ–°é€»è¾‘ï¼‰
    # å¦‚æœæœ€åé”€å”®æ—¥æœŸ == é¦–æ¬¡å‡ºç°æ—¥æœŸï¼Œè¯´æ˜åªå–è¿‡ä¸€æ¬¡ï¼Œä»é¦–æ¬¡å‡ºç°æ—¥æœŸå¼€å§‹è®¡ç®—
    # å¦åˆ™ä»æœ€åé”€å”®æ—¥æœŸå¼€å§‹è®¡ç®—
    def calc_days_no_sale(row):
        if row['æœ€åé”€å”®æ—¥æœŸ'] == row['é¦–æ¬¡å‡ºç°æ—¥æœŸ']:
            # åªåœ¨é¦–æ¬¡å‡ºç°æ—¶å–è¿‡ä¸€æ¬¡ï¼Œä»é¦–æ¬¡å‡ºç°æ—¥æœŸå¼€å§‹è®¡ç®—
            return (last_date - row['é¦–æ¬¡å‡ºç°æ—¥æœŸ']).days
        else:
            # æœ‰å¤šæ¬¡é”€å”®ï¼Œä»æœ€åé”€å”®æ—¥æœŸå¼€å§‹è®¡ç®—
            return (last_date - row['æœ€åé”€å”®æ—¥æœŸ']).days
    
    product_sales_info['æ»é”€å¤©æ•°'] = product_sales_info.apply(calc_days_no_sale, axis=1)
    
    # åˆå¹¶åº“å­˜ä¿¡æ¯
    product_stagnant = product_sales_info.merge(
        last_stock[['å•†å“åç§°', 'åº“å­˜', 'åˆ†ç±»']], 
        on='å•†å“åç§°', 
        how='left'
    )
    product_stagnant['åº“å­˜'] = product_stagnant['åº“å­˜'].fillna(0)
    
    # ğŸ†• æ»é”€å“åˆ†çº§ï¼ˆ4çº§ï¼šå…³æ³¨/è½»åº¦/ä¸­åº¦/é‡åº¦ï¼Œäº’æ–¥åˆ†çº§ï¼‰
    product_stagnant['å…³æ³¨'] = ((product_stagnant['æ»é”€å¤©æ•°'] >= 3) & (product_stagnant['æ»é”€å¤©æ•°'] < 7) & (product_stagnant['åº“å­˜'] > 0)).astype(int)
    product_stagnant['è½»åº¦æ»é”€'] = ((product_stagnant['æ»é”€å¤©æ•°'] >= 7) & (product_stagnant['æ»é”€å¤©æ•°'] < 15) & (product_stagnant['åº“å­˜'] > 0)).astype(int)
    product_stagnant['ä¸­åº¦æ»é”€'] = ((product_stagnant['æ»é”€å¤©æ•°'] >= 15) & (product_stagnant['æ»é”€å¤©æ•°'] < 30) & (product_stagnant['åº“å­˜'] > 0)).astype(int)
    product_stagnant['é‡åº¦æ»é”€'] = ((product_stagnant['æ»é”€å¤©æ•°'] >= 30) & (product_stagnant['åº“å­˜'] > 0)).astype(int)
    
    # æ±‡æ€»æ»é”€å“æ•°é‡
    result["slow_moving"]["by_severity"] = {
        "watch": int(product_stagnant['å…³æ³¨'].sum()),
        "light": int(product_stagnant['è½»åº¦æ»é”€'].sum()),
        "medium": int(product_stagnant['ä¸­åº¦æ»é”€'].sum()),
        "heavy": int(product_stagnant['é‡åº¦æ»é”€'].sum()),
        "critical": 0  # ä¸å†ä½¿ç”¨è¶…é‡åº¦ï¼Œç»Ÿä¸€å½’å…¥é‡åº¦
    }
    result["slow_moving"]["total"] = sum(result["slow_moving"]["by_severity"].values())
    
    # æŒ‰åˆ†ç±»æ±‡æ€»æ»é”€å“
    stagnant_by_cat = product_stagnant.groupby('åˆ†ç±»').agg({
        'å…³æ³¨': 'sum',
        'è½»åº¦æ»é”€': 'sum',
        'ä¸­åº¦æ»é”€': 'sum',
        'é‡åº¦æ»é”€': 'sum'
    }).to_dict('index')
    
    for cat, counts in stagnant_by_cat.items():
        total = sum(counts.values())
        if total > 0:
            result["slow_moving"]["by_category"][cat] = {
                "watch": int(counts['å…³æ³¨']),
                "light": int(counts['è½»åº¦æ»é”€']),
                "medium": int(counts['ä¸­åº¦æ»é”€']),
                "heavy": int(counts['é‡åº¦æ»é”€']),
                "critical": 0,
                "total": int(total)
            }
    
    # ç”Ÿæˆæ»é”€å“è¯¦æƒ…åˆ—è¡¨
    slow_products = product_stagnant[
        (product_stagnant['å…³æ³¨'] == 1) |
        (product_stagnant['è½»åº¦æ»é”€'] == 1) | 
        (product_stagnant['ä¸­åº¦æ»é”€'] == 1) | 
        (product_stagnant['é‡åº¦æ»é”€'] == 1)
    ]
    
    # ğŸ”§ æ€§èƒ½ä¼˜åŒ–ï¼šé¢„è®¡ç®—æ¯ä¸ªå•†å“çš„å¹³å‡å•ä»·ï¼Œé¿å…å¾ªç¯å†…è¿‡æ»¤
    avg_price_map = {}
    if 'å®æ”¶ä»·æ ¼' in df.columns:
        avg_price_map = df.groupby('å•†å“åç§°')['å®æ”¶ä»·æ ¼'].mean().to_dict()
    
    for _, row in slow_products.iterrows():
        # ğŸ†• ç¡®å®šæ»é”€ç­‰çº§ï¼ˆ4çº§ï¼šå…³æ³¨/è½»åº¦/ä¸­åº¦/é‡åº¦ï¼‰
        if row['é‡åº¦æ»é”€'] == 1:
            severity = 'heavy'
            action = 'é™ä»·æ¸…ä»“'
        elif row['ä¸­åº¦æ»é”€'] == 1:
            severity = 'medium'
            action = 'ä¿ƒé”€æ¨è'
        elif row['è½»åº¦æ»é”€'] == 1:
            severity = 'light'
            action = 'å…³æ³¨è§‚å¯Ÿ'
        else:  # å…³æ³¨
            severity = 'watch'
            action = 'æŒç»­å…³æ³¨'
        
        # ğŸ”§ ä¼˜åŒ–ï¼šä½¿ç”¨é¢„è®¡ç®—çš„å¹³å‡å•ä»·
        avg_price = avg_price_map.get(row['å•†å“åç§°'], 0)
        impact = row['åº“å­˜'] * avg_price
        
        result["slow_moving"]["products"].append({
            "id": f"slow-{hash(row['å•†å“åç§°']) % 10000}",
            "skuName": row['å•†å“åç§°'],
            "spec": "",
            "issueType": "SLOW_MOVING",
            "reason": f"{int(row['æ»é”€å¤©æ•°'])}å¤©æ— é”€é‡",
            "impactValue": round(float(impact), 2),
            "duration": f"{int(row['æ»é”€å¤©æ•°'])}å¤©",
            "action": action,
            "severity": severity,
            "category": row['åˆ†ç±»'] if pd.notna(row['åˆ†ç±»']) else 'æœªçŸ¥'
        })
    
    # ==================== 6. åº“å­˜å‘¨è½¬å¤©æ•°è®¡ç®— ====================
    if sales_col:
        date_range_days = (df[date_col].max() - df[date_col].min()).days + 1
        if date_range_days <= 0:
            date_range_days = 1
        
        # æŒ‰åˆ†ç±»ç»Ÿè®¡
        category_stats = df.groupby(category_col).agg({
            sales_col: 'sum'
        }).reset_index()
        category_stats.columns = ['åˆ†ç±»', 'æ€»é”€é‡']
        
        # æŒ‰åˆ†ç±»ç»Ÿè®¡å½“å‰åº“å­˜
        category_stock = last_stock.groupby('åˆ†ç±»')['åº“å­˜'].sum().reset_index()
        category_stock.columns = ['åˆ†ç±»', 'å½“å‰åº“å­˜']
        
        category_stats = category_stats.merge(category_stock, on='åˆ†ç±»', how='left')
        category_stats['å½“å‰åº“å­˜'] = category_stats['å½“å‰åº“å­˜'].fillna(0)
        
        # è®¡ç®—æ—¥å‡é”€é‡å’Œåº“å­˜å‘¨è½¬å¤©æ•°
        category_stats['æ—¥å‡é”€é‡'] = (category_stats['æ€»é”€é‡'] / date_range_days).round(2)
        category_stats['åº“å­˜å‘¨è½¬å¤©æ•°'] = category_stats.apply(
            lambda r: round(r['å½“å‰åº“å­˜'] / r['æ—¥å‡é”€é‡'], 1) if r['æ—¥å‡é”€é‡'] > 0 else 0,
            axis=1
        )
        
        result["turnover"] = category_stats.set_index('åˆ†ç±»')['åº“å­˜å‘¨è½¬å¤©æ•°'].to_dict()
    
    # ==================== 7. æŒ‰åˆ†ç±»æ±‡æ€» ====================
    categories = df[category_col].unique()
    for cat in categories:
        sold_out_count = result["sold_out"]["by_category"].get(cat, 0)
        slow_moving_data = result["slow_moving"]["by_category"].get(cat, {})
        slow_moving_count = slow_moving_data.get("total", 0) if isinstance(slow_moving_data, dict) else 0
        turnover = result["turnover"].get(cat, 0)
        
        result["by_category"].append({
            "category": cat,
            "soldOutCount": int(sold_out_count),
            "slowMovingCount": int(slow_moving_count),
            "inventoryTurnover": float(turnover),
            "slowMovingDetail": slow_moving_data if isinstance(slow_moving_data, dict) else {}
        })
    
    # æŒ‰å”®ç½„+æ»é”€æ€»æ•°æ’åº
    result["by_category"].sort(key=lambda x: x["soldOutCount"] + x["slowMovingCount"], reverse=True)
    
    return result


@router.get("/summary")
async def get_inventory_risk_summary(
    store_name: Optional[str] = Query(None, description="é—¨åº—åç§°ç­›é€‰"),
    category: Optional[str] = Query(None, description="åˆ†ç±»ç­›é€‰")
) -> Dict[str, Any]:
    """
    è·å–åº“å­˜é£é™©æ±‡æ€»ï¼ˆä¸Dashç‰ˆæœ¬ä¸€è‡´ï¼‰
    """
    df = get_order_data(store_name)
    if df.empty:
        return {
            "success": True,
            "data": {
                "sold_out": {"total": 0, "products": [], "by_category": {}},
                "slow_moving": {"total": 0, "by_severity": {}, "products": [], "by_category": {}},
                "by_category": [],
                "turnover": {}
            }
        }
    
    # åˆ†ç±»ç­›é€‰
    if category:
        category_col = 'ä¸€çº§åˆ†ç±»å' if 'ä¸€çº§åˆ†ç±»å' in df.columns else 'ä¸€çº§åˆ†ç±»'
        if category_col in df.columns:
            df = df[df[category_col] == category]
    
    result = calculate_inventory_risk_dash_style(df, store_name)
    
    return {"success": True, "data": result}


@router.get("/sold-out")
async def get_sold_out_products(
    store_name: Optional[str] = Query(None, description="é—¨åº—åç§°ç­›é€‰"),
    category: Optional[str] = Query(None, description="åˆ†ç±»ç­›é€‰"),
    page: int = Query(1, ge=1),
    page_size: int = Query(20, ge=1, le=100)
) -> Dict[str, Any]:
    """
    è·å–å”®ç½„å“åˆ—è¡¨ï¼ˆä¸Dashç‰ˆæœ¬ä¸€è‡´ï¼‰
    
    å”®ç½„å“å®šä¹‰: åº“å­˜=0 ä¸” è¿‘7å¤©æœ‰é”€é‡
    """
    df = get_order_data(store_name)
    if df.empty:
        return {"success": True, "data": [], "total": 0}
    
    result = calculate_inventory_risk_dash_style(df, store_name)
    products = result["sold_out"]["products"]
    
    # åˆ†ç±»ç­›é€‰
    if category:
        products = [p for p in products if p.get("category") == category]
    
    # åˆ†é¡µ
    total = len(products)
    start = (page - 1) * page_size
    end = start + page_size
    
    return {
        "success": True,
        "data": products[start:end],
        "total": total,
        "page": page,
        "page_size": page_size
    }


@router.get("/slow-moving")
async def get_slow_moving_products(
    store_name: Optional[str] = Query(None, description="é—¨åº—åç§°ç­›é€‰"),
    category: Optional[str] = Query(None, description="åˆ†ç±»ç­›é€‰"),
    severity: Optional[str] = Query(None, description="æ»é”€ç­‰çº§: light/medium/heavy/critical"),
    page: int = Query(1, ge=1),
    page_size: int = Query(20, ge=1, le=100)
) -> Dict[str, Any]:
    """
    è·å–æ»é”€å“åˆ—è¡¨ï¼ˆä¸Dashç‰ˆæœ¬ä¸€è‡´ï¼‰
    
    æ»é”€å“åˆ†çº§:
    - light: æ»é”€å¤©æ•° == 7
    - medium: æ»é”€å¤©æ•° 8-15
    - heavy: æ»é”€å¤©æ•° 16-30
    - critical: æ»é”€å¤©æ•° > 30
    """
    df = get_order_data(store_name)
    if df.empty:
        return {"success": True, "data": [], "total": 0, "by_severity": {}}
    
    result = calculate_inventory_risk_dash_style(df, store_name)
    products = result["slow_moving"]["products"]
    
    # åˆ†ç±»ç­›é€‰
    if category:
        products = [p for p in products if p.get("category") == category]
    
    # ç­‰çº§ç­›é€‰
    if severity:
        products = [p for p in products if p.get("severity") == severity]
    
    # åˆ†é¡µ
    total = len(products)
    start = (page - 1) * page_size
    end = start + page_size
    
    return {
        "success": True,
        "data": products[start:end],
        "total": total,
        "page": page,
        "page_size": page_size,
        "by_severity": result["slow_moving"]["by_severity"]
    }


@router.get("/category-risk")
async def get_category_risk_stats(
    store_name: Optional[str] = Query(None, description="é—¨åº—åç§°ç­›é€‰")
) -> Dict[str, Any]:
    """
    è·å–æŒ‰åˆ†ç±»çš„åº“å­˜é£é™©ç»Ÿè®¡ï¼ˆä¸Dashç‰ˆæœ¬ä¸€è‡´ï¼‰
    
    ç”¨äºå“ç±»æ•ˆç›ŠçŸ©é˜µä¸­æ˜¾ç¤ºæ¯ä¸ªåˆ†ç±»çš„å”®ç½„å“å’Œæ»é”€å“æ•°é‡
    """
    df = get_order_data(store_name)
    if df.empty:
        return {"success": True, "data": []}
    
    result = calculate_inventory_risk_dash_style(df, store_name)
    
    return {"success": True, "data": result["by_category"]}


@router.get("/trend")
async def get_inventory_risk_trend(
    store_name: Optional[str] = Query(None, description="é—¨åº—åç§°ç­›é€‰"),
    category: Optional[str] = Query(None, description="åˆ†ç±»ç­›é€‰"),
    days: int = Query(30, ge=7, le=90, description="è¶‹åŠ¿å¤©æ•°")
) -> Dict[str, Any]:
    """
    è·å–åº“å­˜é£é™©è¶‹åŠ¿æ•°æ®ï¼ˆå”®ç½„ç‡è¶‹åŠ¿ + æ»é”€ç‡è¶‹åŠ¿ï¼‰
    
    ğŸ†• é‡æ„ç‰ˆæœ¬ - è§£å†³æ•°æ®çª—å£é—®é¢˜ï¼š
    
    æ»é”€åˆ†çº§å®šä¹‰ï¼ˆç®€åŒ–ä¸º3çº§ï¼‰ï¼š
    - è½»åº¦(light): 7å¤©æ— é”€é‡ï¼Œéœ€è¦ >= 8å¤©æ•°æ®
    - ä¸­åº¦(medium): 15å¤©æ— é”€é‡ï¼Œéœ€è¦ >= 16å¤©æ•°æ®
    - é‡åº¦(heavy): 30å¤©æ— é”€é‡ï¼Œéœ€è¦ >= 31å¤©æ•°æ®
    
    è‡ªé€‚åº”é€»è¾‘ï¼š
    - æ ¹æ®æ•°æ®é‡è‡ªåŠ¨å†³å®šå¯å±•ç¤ºçš„ç­‰çº§
    - è¶‹åŠ¿èµ·å§‹æ—¥ = æ•°æ®èµ·å§‹æ—¥ + æœ€é«˜å¯ç”¨ç­‰çº§çš„å›æº¯å¤©æ•°
    - é¿å…æ•°æ®ä¸è¶³å¯¼è‡´çš„è™šå‡é€’å¢è¶‹åŠ¿
    
    è¿”å›ï¼š
    - æ¯æ—¥å”®ç½„ç‡ã€æ»é”€ç‡ï¼ˆç™¾åˆ†æ¯”ï¼‰
    - å¯ç”¨çš„æ»é”€ç­‰çº§åˆ—è¡¨
    - è¶‹åŠ¿æœ‰æ•ˆèµ·å§‹æ—¥æœŸ
    """
    df = get_order_data(store_name)
    if df.empty:
        return {"success": True, "data": [], "message": "æ— æ•°æ®", "availableLevels": []}
    
    # æ£€æŸ¥å¿…éœ€å­—æ®µ
    date_col = None
    for col in ['æ—¥æœŸ', 'ä¸‹å•æ—¶é—´']:
        if col in df.columns:
            date_col = col
            break
    
    stock_col = None
    for col in ['åº“å­˜', 'å‰©ä½™åº“å­˜', 'stock', 'remaining_stock']:
        if col in df.columns:
            stock_col = col
            break
    
    if not date_col or not stock_col:
        return {"success": True, "data": [], "message": f"ç¼ºå°‘å¿…éœ€å­—æ®µ: date={date_col}, stock={stock_col}", "availableLevels": []}
    
    # å‡†å¤‡æ•°æ®
    df = df.copy()
    df[date_col] = pd.to_datetime(df[date_col], errors='coerce')
    df = df.dropna(subset=[date_col])
    
    if df.empty:
        return {"success": True, "data": [], "message": "æ—¥æœŸè§£æåæ— æœ‰æ•ˆæ•°æ®", "availableLevels": []}
    
    # ğŸ†• åˆ†ç±»ç­›é€‰ï¼ˆæ”¯æŒä¸€çº§åˆ†ç±»å’Œä¸‰çº§åˆ†ç±»ï¼‰
    category_col = 'ä¸€çº§åˆ†ç±»å' if 'ä¸€çº§åˆ†ç±»å' in df.columns else 'ä¸€çº§åˆ†ç±»'
    l3_col = 'ä¸‰çº§åˆ†ç±»å' if 'ä¸‰çº§åˆ†ç±»å' in df.columns else 'ä¸‰çº§åˆ†ç±»'
    
    if category and category_col in df.columns:
        if '|' in category:
            # ä¸‰çº§åˆ†ç±»æ ¼å¼ï¼šä¸€çº§åˆ†ç±»|ä¸‰çº§åˆ†ç±»
            parts = category.split('|')
            l1_cat = parts[0]
            l3_cat = parts[1] if len(parts) > 1 else None
            
            df = df[df[category_col] == l1_cat]
            if l3_cat and l3_col in df.columns:
                df = df[df[l3_col] == l3_cat]
        else:
            # ä¸€çº§åˆ†ç±»
            df = df[df[category_col] == category]
        
        if df.empty:
            return {"success": True, "data": [], "message": f"åˆ†ç±» {category} æ— æ•°æ®", "availableLevels": []}
    
    # ç¡®å®šæ—¥æœŸèŒƒå›´
    max_date = df[date_col].max()
    min_date = df[date_col].min()
    total_data_days = (max_date - min_date).days + 1
    
    # ==================== ğŸ†• æ»é”€åˆ†çº§å®šä¹‰ï¼ˆ4çº§ï¼šå…³æ³¨/è½»åº¦/ä¸­åº¦/é‡åº¦ï¼‰ ====================
    SLOW_MOVING_LEVELS = [
        {"key": "watch", "label": "å…³æ³¨", "days": 3, "min_data_days": 4},
        {"key": "light", "label": "è½»åº¦", "days": 7, "min_data_days": 8},
        {"key": "medium", "label": "ä¸­åº¦", "days": 15, "min_data_days": 16},
        {"key": "heavy", "label": "é‡åº¦", "days": 30, "min_data_days": 31},
    ]
    
    # æ ¹æ®æ•°æ®é‡ç¡®å®šå¯ç”¨ç­‰çº§
    available_levels = []
    max_lookback_days = 0
    for level in SLOW_MOVING_LEVELS:
        if total_data_days >= level["min_data_days"]:
            available_levels.append(level["key"])
            max_lookback_days = level["days"]
    
    if not available_levels:
        return {
            "success": True, 
            "data": [], 
            "message": f"æ•°æ®é‡ä¸è¶³ï¼ˆ{total_data_days}å¤©ï¼‰ï¼Œè‡³å°‘éœ€è¦8å¤©æ•°æ®æ‰èƒ½è®¡ç®—æ»é”€è¶‹åŠ¿",
            "availableLevels": [],
            "totalDataDays": total_data_days
        }
    
    # ==================== ğŸ†• è®¡ç®—è¶‹åŠ¿æœ‰æ•ˆèµ·å§‹æ—¥ ====================
    # è¶‹åŠ¿èµ·å§‹æ—¥ = æ•°æ®èµ·å§‹æ—¥ + æœ€é«˜å¯ç”¨ç­‰çº§çš„å›æº¯å¤©æ•°
    trend_start_date = min_date + timedelta(days=max_lookback_days)
    
    # ç¡®ä¿è¶‹åŠ¿èµ·å§‹æ—¥ä¸è¶…è¿‡æœ€å¤§æ—¥æœŸ
    if trend_start_date > max_date:
        trend_start_date = max_date
    
    # ç”Ÿæˆè¶‹åŠ¿æ—¥æœŸåºåˆ—
    date_range = pd.date_range(start=trend_start_date, end=max_date, freq='D')
    
    if len(date_range) == 0:
        return {
            "success": True,
            "data": [],
            "message": "è¶‹åŠ¿æ—¥æœŸèŒƒå›´ä¸ºç©º",
            "availableLevels": available_levels,
            "totalDataDays": total_data_days
        }
    
    trend_data = []
    
    # ==================== ğŸš€ æ€§èƒ½ä¼˜åŒ–ï¼šé¢„è®¡ç®—æ‰€æœ‰æ•°æ® ====================
    df_sorted = df.sort_values(date_col)
    
    # 1. é¢„è®¡ç®—æ¯ä¸ªå•†å“æ¯å¤©çš„æœ€æ–°åº“å­˜ï¼ˆç´¯ç§¯åˆ°å½“å¤©ï¼‰
    # ä½¿ç”¨ pivot åˆ›å»º å•†å“Ã—æ—¥æœŸ çš„åº“å­˜çŸ©é˜µ
    all_products = df['å•†å“åç§°'].unique()
    all_dates = pd.date_range(start=min_date, end=max_date, freq='D')
    
    # æŒ‰æ—¥æœŸå’Œå•†å“åˆ†ç»„ï¼Œå–æ¯å¤©æ¯ä¸ªå•†å“çš„æœ€ååº“å­˜
    daily_stock_df = df_sorted.groupby([df_sorted[date_col].dt.date, 'å•†å“åç§°'])[stock_col].last().unstack(fill_value=np.nan)
    
    # å‰å‘å¡«å……ï¼šå¦‚æœæŸå¤©æ²¡æœ‰æ•°æ®ï¼Œä½¿ç”¨å‰ä¸€å¤©çš„åº“å­˜
    daily_stock_df = daily_stock_df.ffill()
    
    # 2. ğŸ†• é¢„è®¡ç®—æ¯ä¸ªå•†å“çš„é¦–æ¬¡å‡ºç°æ—¥æœŸï¼ˆä½œä¸ºæ»é”€è®¡ç®—çš„åŸºå‡†ç‚¹ï¼‰
    # å•†å“é¦–æ¬¡å‡ºç°æ—¥æœŸ = è¯¥å•†å“åœ¨æ•°æ®ä¸­ç¬¬ä¸€æ¬¡æœ‰é”€å”®è®°å½•çš„æ—¥æœŸ
    product_first_appearance = df_sorted.groupby('å•†å“åç§°')[date_col].min()
    print(f"[inventory_risk] å•†å“é¦–æ¬¡å‡ºç°æ—¥æœŸç¤ºä¾‹: {dict(list(product_first_appearance.items())[:3])}")
    
    # 3. é¢„è®¡ç®—æ¯ä¸ªå•†å“æ¯å¤©çš„æœ€åé”€å”®æ—¥æœŸï¼ˆç”¨äºåˆ¤æ–­æ˜¯å¦æœ‰æ–°é”€å”®ï¼‰
    daily_last_sale = df_sorted.groupby([df_sorted[date_col].dt.date, 'å•†å“åç§°'])[date_col].max().unstack()
    daily_last_sale = daily_last_sale.ffill()  # å‰å‘å¡«å……
    
    # 4. é¢„è®¡ç®—æ¯ä¸ªå•†å“åœ¨æ¯ä¸ª7å¤©çª—å£å†…æ˜¯å¦æœ‰é”€é‡
    # åˆ›å»ºä¸€ä¸ªæ ‡è®°ï¼šæ¯å¤©æ¯ä¸ªå•†å“æ˜¯å¦æœ‰é”€å”®è®°å½•
    daily_has_sale = df_sorted.groupby([df_sorted[date_col].dt.date, 'å•†å“åç§°']).size().unstack(fill_value=0)
    daily_has_sale = (daily_has_sale > 0).astype(int)
    
    # è®¡ç®—7å¤©æ»šåŠ¨çª—å£å†…æ˜¯å¦æœ‰é”€é‡
    rolling_7d_sales = daily_has_sale.rolling(window=7, min_periods=1).sum()
    
    # ==================== éå†æ—¥æœŸè®¡ç®—è¶‹åŠ¿ ====================
    for current_date in date_range:
        current_date_key = current_date.date()
        current_date_ts = pd.Timestamp(current_date)
        
        # è·å–å½“å¤©çš„åº“å­˜çŠ¶æ€
        if current_date_key not in daily_stock_df.index:
            # æ‰¾æœ€è¿‘çš„å‰ä¸€å¤©
            valid_dates = [d for d in daily_stock_df.index if d <= current_date_key]
            if not valid_dates:
                continue
            current_date_key = max(valid_dates)
        
        stock_series = daily_stock_df.loc[current_date_key].dropna()
        if stock_series.empty:
            continue
        
        total_sku = len(stock_series)
        total_sku_with_stock = int((stock_series > 0).sum())
        
        # ==================== å”®ç½„è®¡ç®— ====================
        # åº“å­˜=0 çš„å•†å“
        zero_stock_products = set(stock_series[stock_series == 0].index)
        
        # è¿‘7å¤©æœ‰é”€é‡çš„å•†å“
        if current_date_key in rolling_7d_sales.index:
            recent_sales_mask = rolling_7d_sales.loc[current_date_key] > 0
            recent_products = set(recent_sales_mask[recent_sales_mask].index)
        else:
            recent_products = set()
        
        sold_out_count = len(zero_stock_products & recent_products)
        sold_out_rate = round(sold_out_count / total_sku * 100, 2) if total_sku > 0 else 0
        
        # ==================== æ»é”€è®¡ç®—ï¼ˆğŸ†• ä¼˜åŒ–ç‰ˆï¼šä»¥é¦–æ¬¡å‡ºç°æ—¥æœŸä¸ºåŸºå‡†ï¼‰ ====================
        slow_moving_counts = {"watch": 0, "light": 0, "medium": 0, "heavy": 0}
        
        # ğŸ†• æ–°é€»è¾‘ï¼šæ»é”€å¤©æ•° = å½“å‰æ—¥æœŸ - å•†å“é¦–æ¬¡å‡ºç°æ—¥æœŸï¼ˆå¦‚æœé¦–æ¬¡å‡ºç°åä¸€ç›´æ²¡æœ‰å†é”€å”®ï¼‰
        # æˆ–è€… = å½“å‰æ—¥æœŸ - æœ€åé”€å”®æ—¥æœŸï¼ˆå¦‚æœé¦–æ¬¡å‡ºç°åæœ‰è¿‡é”€å”®ï¼‰
        
        # åªç»Ÿè®¡æœ‰åº“å­˜çš„å•†å“
        products_with_stock = stock_series[stock_series > 0].index.tolist()
        
        if products_with_stock:
            days_no_sale_list = []
            
            for product in products_with_stock:
                # è·å–å•†å“é¦–æ¬¡å‡ºç°æ—¥æœŸ
                first_date = product_first_appearance.get(product)
                if first_date is None:
                    continue
                
                # è·å–å•†å“æœ€åé”€å”®æ—¥æœŸï¼ˆæˆªè‡³å½“å‰æ—¥æœŸï¼‰
                last_sale_date = None
                if current_date_key in daily_last_sale.index and product in daily_last_sale.columns:
                    last_sale_val = daily_last_sale.loc[current_date_key, product]
                    if pd.notna(last_sale_val):
                        last_sale_date = pd.Timestamp(last_sale_val)
                
                # ğŸ†• è®¡ç®—æ— é”€å”®å¤©æ•°
                # å¦‚æœæœ€åé”€å”®æ—¥æœŸ == é¦–æ¬¡å‡ºç°æ—¥æœŸï¼Œè¯´æ˜åªåœ¨é¦–æ¬¡å‡ºç°æ—¶å–è¿‡ä¸€æ¬¡
                # æ»é”€å¤©æ•° = å½“å‰æ—¥æœŸ - é¦–æ¬¡å‡ºç°æ—¥æœŸ
                if last_sale_date is None or last_sale_date == first_date:
                    # ä»é¦–æ¬¡å‡ºç°æ—¥æœŸå¼€å§‹è®¡ç®—
                    days_no_sale = (current_date_ts - pd.Timestamp(first_date)).days
                else:
                    # ä»æœ€åé”€å”®æ—¥æœŸå¼€å§‹è®¡ç®—
                    days_no_sale = (current_date_ts - last_sale_date).days
                
                days_no_sale_list.append((product, days_no_sale))
            
            # è½¬æ¢ä¸º Series ä¾¿äºç»Ÿè®¡
            if days_no_sale_list:
                days_no_sale_series = pd.Series(
                    {p: d for p, d in days_no_sale_list}
                )
                
                # ç»Ÿè®¡å„ç­‰çº§ï¼ˆäº’æ–¥åˆ†çº§ï¼‰
                if "heavy" in available_levels:
                    slow_moving_counts["heavy"] = int((days_no_sale_series >= 30).sum())
                if "medium" in available_levels:
                    slow_moving_counts["medium"] = int(((days_no_sale_series >= 15) & (days_no_sale_series < 30)).sum())
                if "light" in available_levels:
                    slow_moving_counts["light"] = int(((days_no_sale_series >= 7) & (days_no_sale_series < 15)).sum())
                if "watch" in available_levels:
                    slow_moving_counts["watch"] = int(((days_no_sale_series >= 3) & (days_no_sale_series < 7)).sum())
        
        # è®¡ç®—å„ç­‰çº§æ»é”€ç‡
        slow_moving_rates = {}
        for level_key in available_levels:
            slow_moving_rates[level_key] = round(
                slow_moving_counts[level_key] / total_sku_with_stock * 100, 2
            ) if total_sku_with_stock > 0 else 0
        
        total_slow_moving = sum(slow_moving_counts[k] for k in available_levels)
        total_slow_moving_rate = round(
            total_slow_moving / total_sku_with_stock * 100, 2
        ) if total_sku_with_stock > 0 else 0
        
        trend_data.append({
            "date": current_date.strftime('%Y-%m-%d'),
            # å”®ç½„
            "soldOutCount": sold_out_count,
            "soldOutRate": sold_out_rate,
            # æ»é”€ï¼ˆæ€»è®¡ï¼‰
            "slowMovingCount": total_slow_moving,
            "slowMovingRate": total_slow_moving_rate,
            # æ»é”€ï¼ˆåˆ†çº§ï¼‰
            "slowMovingByLevel": {k: slow_moving_counts[k] for k in available_levels},
            "slowMovingRateByLevel": {k: slow_moving_rates[k] for k in available_levels},
            # åŸºæ•°
            "totalSku": total_sku,
            "totalSkuWithStock": total_sku_with_stock
        })
    
    # è®¡ç®—è¶‹åŠ¿å˜åŒ–ï¼ˆé¦–æ—¥ vs æœ«æ—¥ï¼‰
    first_day = trend_data[0] if trend_data else None
    last_day = trend_data[-1] if trend_data else None
    
    change_summary = None
    if first_day and last_day and len(trend_data) > 1:
        change_summary = {
            "soldOutRateChange": round(last_day["soldOutRate"] - first_day["soldOutRate"], 2),
            "slowMovingRateChange": round(last_day["slowMovingRate"] - first_day["slowMovingRate"], 2),
            "periodDays": len(trend_data)
        }
    
    return {
        "success": True,
        "data": trend_data,
        "availableLevels": available_levels,
        "trendStartDate": trend_start_date.strftime('%Y-%m-%d'),
        "dateRange": {
            "start": min_date.strftime('%Y-%m-%d'),
            "end": max_date.strftime('%Y-%m-%d')
        },
        "totalDataDays": total_data_days,
        "changeSummary": change_summary,
        # ğŸ†• å”®ç½„å®šä¹‰è¯´æ˜
        "soldOutDefinition": "åº“å­˜=0 ä¸” è¿‘7å¤©æœ‰é”€é‡",
        "levelDefinitions": {
            "watch": "3å¤©æ— é”€é‡",
            "light": "7å¤©æ— é”€é‡",
            "medium": "15å¤©æ— é”€é‡", 
            "heavy": "30å¤©æ— é”€é‡"
        }
    }

@router.get("/sold-out-analysis")
async def get_sold_out_analysis(
    store_name: Optional[str] = Query(None, description="é—¨åº—åç§°ç­›é€‰"),
    category: Optional[str] = Query(None, description="åˆ†ç±»ç­›é€‰"),
    days: int = Query(30, ge=7, le=90, description="åˆ†æå¤©æ•°")
) -> Dict[str, Any]:
    """
    è·å–å”®ç½„æ·±åº¦åˆ†ææ•°æ®
    
    åŒ…å«ï¼š
    - å½“å‰å”®ç½„å“æ•°é‡
    - å”®ç½„æŸå¤±é‡‘é¢ï¼ˆåŸºäºæ—¥å‡é”€å”®é¢ä¼°ç®—ï¼‰
    - å”®ç½„å“ç±»åˆ†å¸ƒ
    - é«˜é¢‘å”®ç½„å“ï¼ˆè¿‘Nå¤©å”®ç½„>=2æ¬¡ï¼‰
    - å¹³å‡æ¢å¤æ—¶é—´
    """
    df = get_order_data(store_name)
    if df.empty:
        return {
            "success": True,
            "data": {
                "soldOutCount": 0,
                "estimatedLoss": 0,
                "byCategory": [],
                "frequentSoldOut": [],
                "avgRecoveryDays": 0
            }
        }
    
    # æ£€æŸ¥å¿…éœ€å­—æ®µ
    date_col = None
    for col in ['æ—¥æœŸ', 'ä¸‹å•æ—¶é—´']:
        if col in df.columns:
            date_col = col
            break
    
    stock_col = None
    for col in ['åº“å­˜', 'å‰©ä½™åº“å­˜', 'stock', 'remaining_stock']:
        if col in df.columns:
            stock_col = col
            break
    
    category_col = 'ä¸€çº§åˆ†ç±»å' if 'ä¸€çº§åˆ†ç±»å' in df.columns else 'ä¸€çº§åˆ†ç±»'
    price_col = 'å®æ”¶ä»·æ ¼' if 'å®æ”¶ä»·æ ¼' in df.columns else None
    
    if not date_col or not stock_col:
        return {
            "success": True,
            "data": {
                "soldOutCount": 0,
                "estimatedLoss": 0,
                "byCategory": [],
                "frequentSoldOut": [],
                "avgRecoveryDays": 0
            },
            "message": f"ç¼ºå°‘å¿…éœ€å­—æ®µ: date={date_col}, stock={stock_col}"
        }
    
    # å‡†å¤‡æ•°æ®
    df = df.copy()
    df[date_col] = pd.to_datetime(df[date_col], errors='coerce')
    df = df.dropna(subset=[date_col])
    
    if df.empty:
        return {
            "success": True,
            "data": {
                "soldOutCount": 0,
                "estimatedLoss": 0,
                "byCategory": [],
                "frequentSoldOut": [],
                "avgRecoveryDays": 0
            }
        }
    
    # ğŸ†• åˆ†ç±»ç­›é€‰ï¼ˆæ”¯æŒä¸€çº§åˆ†ç±»å’Œä¸‰çº§åˆ†ç±»ï¼‰
    l3_col = 'ä¸‰çº§åˆ†ç±»å' if 'ä¸‰çº§åˆ†ç±»å' in df.columns else 'ä¸‰çº§åˆ†ç±»'
    
    if category and category_col in df.columns:
        if '|' in category:
            # ä¸‰çº§åˆ†ç±»æ ¼å¼ï¼šä¸€çº§åˆ†ç±»|ä¸‰çº§åˆ†ç±»
            parts = category.split('|')
            l1_cat = parts[0]
            l3_cat = parts[1] if len(parts) > 1 else None
            
            df = df[df[category_col] == l1_cat]
            if l3_cat and l3_col in df.columns:
                df = df[df[l3_col] == l3_cat]
        else:
            # ä¸€çº§åˆ†ç±»
            df = df[df[category_col] == category]
        
        if df.empty:
            return {
                "success": True,
                "data": {
                    "soldOutCount": 0,
                    "estimatedLoss": 0,
                    "byCategory": [],
                    "frequentSoldOut": [],
                    "avgRecoveryDays": 0
                },
                "message": f"åˆ†ç±» {category} æ— æ•°æ®"
            }
    
    max_date = df[date_col].max()
    min_date = max_date - timedelta(days=days)
    seven_days_ago = max_date - timedelta(days=7)
    
    # ç­›é€‰åˆ†æå‘¨æœŸå†…çš„æ•°æ®
    df_period = df[df[date_col] >= min_date].copy()
    
    # ==================== 1. å½“å‰å”®ç½„å“ ====================
    # è·å–æ¯ä¸ªå•†å“çš„æœ€æ–°åº“å­˜
    df_sorted = df.sort_values(date_col)
    latest_stock = df_sorted.groupby('å•†å“åç§°')[stock_col].last()
    
    # è¿‘7å¤©æœ‰é”€é‡çš„å•†å“
    recent_sales = df[df[date_col] >= seven_days_ago]
    recent_products = set(recent_sales['å•†å“åç§°'].unique())
    
    # å”®ç½„å“ = åº“å­˜0 ä¸” è¿‘7å¤©æœ‰é”€é‡
    zero_stock_products = set(latest_stock[latest_stock == 0].index)
    sold_out_products = zero_stock_products & recent_products
    sold_out_count = len(sold_out_products)
    
    # ==================== 2. å”®ç½„æŸå¤±é‡‘é¢ ====================
    estimated_loss = 0
    if price_col and len(sold_out_products) > 0:
        # è®¡ç®—æ¯ä¸ªå”®ç½„å“çš„æ—¥å‡é”€å”®é¢
        sold_out_df = recent_sales[recent_sales['å•†å“åç§°'].isin(sold_out_products)]
        if not sold_out_df.empty:
            # æŒ‰å•†å“åˆ†ç»„è®¡ç®—è¿‘7å¤©æ€»é”€å”®é¢
            product_sales = sold_out_df.groupby('å•†å“åç§°')[price_col].sum()
            # æ—¥å‡é”€å”®é¢
            daily_avg_sales = product_sales / 7
            # ä¼°ç®—æŸå¤± = æ—¥å‡é”€å”®é¢ Ã— å‡è®¾å”®ç½„1å¤©
            estimated_loss = float(daily_avg_sales.sum())
    
    # ==================== 3. å”®ç½„å“ç±»åˆ†å¸ƒ ====================
    by_category = []
    if len(sold_out_products) > 0 and category_col in df.columns:
        # è·å–å”®ç½„å“çš„åˆ†ç±»
        product_category = df[df['å•†å“åç§°'].isin(sold_out_products)].groupby('å•†å“åç§°')[category_col].first()
        
        # æŒ‰åˆ†ç±»ç»Ÿè®¡
        category_counts = product_category.value_counts()
        
        # è®¡ç®—æ¯ä¸ªåˆ†ç±»çš„æŸå¤±
        for cat, count in category_counts.items():
            cat_products = product_category[product_category == cat].index
            cat_loss = 0
            if price_col:
                cat_sales = recent_sales[recent_sales['å•†å“åç§°'].isin(cat_products)]
                if not cat_sales.empty:
                    cat_loss = float(cat_sales[price_col].sum() / 7)
            
            by_category.append({
                "category": cat,
                "count": int(count),
                "loss": round(cat_loss, 2)
            })
        
        # æŒ‰æ•°é‡æ’åº
        by_category.sort(key=lambda x: x["count"], reverse=True)
    
    # ==================== 4. é«˜é¢‘å”®ç½„å“ï¼ˆä¼˜åŒ–ç‰ˆï¼‰ ====================
    frequent_sold_out = []
    product_sold_out_days = {}
    product_recovery_days = {}
    
    # ğŸš€ ä¼˜åŒ–ï¼šé¢„è®¡ç®—æ‰€æœ‰æ•°æ®ï¼Œé¿å…åŒé‡å¾ªç¯
    df_period_sorted = df_period.sort_values(date_col)
    
    # é¢„è®¡ç®—æ¯ä¸ªå•†å“æ¯å¤©çš„åº“å­˜
    daily_stock_pivot = df_period_sorted.groupby([df_period_sorted[date_col].dt.date, 'å•†å“åç§°'])[stock_col].last().unstack(fill_value=np.nan)
    daily_stock_pivot = daily_stock_pivot.ffill()
    
    # é¢„è®¡ç®—æ¯ä¸ªå•†å“æ¯å¤©æ˜¯å¦æœ‰é”€å”®
    daily_has_sale = df_period_sorted.groupby([df_period_sorted[date_col].dt.date, 'å•†å“åç§°']).size().unstack(fill_value=0)
    daily_has_sale = (daily_has_sale > 0).astype(int)
    
    # è®¡ç®—7å¤©æ»šåŠ¨çª—å£å†…æ˜¯å¦æœ‰é”€é‡
    rolling_7d = daily_has_sale.rolling(window=7, min_periods=1).sum()
    
    # è®¡ç®—æ¯å¤©æ¯ä¸ªå•†å“æ˜¯å¦å”®ç½„ï¼ˆåº“å­˜=0 ä¸” è¿‘7å¤©æœ‰é”€é‡ï¼‰
    is_sold_out_matrix = (daily_stock_pivot == 0) & (rolling_7d > 0)
    
    # ç»Ÿè®¡æ¯ä¸ªå•†å“çš„å”®ç½„æ¬¡æ•°ï¼ˆè¿ç»­å”®ç½„åªç®—ä¸€æ¬¡ï¼‰
    for product in is_sold_out_matrix.columns:
        sold_out_series = is_sold_out_matrix[product].dropna()
        if sold_out_series.empty:
            continue
        
        # æ‰¾å‡ºå”®ç½„å¼€å§‹çš„æ—¥æœŸï¼ˆä»éå”®ç½„å˜ä¸ºå”®ç½„ï¼‰
        sold_out_starts = sold_out_series & (~sold_out_series.shift(1, fill_value=False))
        sold_out_dates = sold_out_starts[sold_out_starts].index.tolist()
        
        # æ‰¾å‡ºæ¢å¤çš„æ—¥æœŸï¼ˆä»å”®ç½„å˜ä¸ºéå”®ç½„ï¼‰
        recovery_starts = (~sold_out_series) & sold_out_series.shift(1, fill_value=False)
        recovery_dates = recovery_starts[recovery_starts].index.tolist()
        
        # è®¡ç®—æ¢å¤æ—¶é—´
        recovery_times = []
        for i, start_date in enumerate(sold_out_dates):
            # æ‰¾åˆ°å¯¹åº”çš„æ¢å¤æ—¥æœŸ
            recovery_after = [d for d in recovery_dates if d > start_date]
            if recovery_after:
                recovery_time = (recovery_after[0] - start_date).days
                if recovery_time > 0:
                    recovery_times.append(recovery_time)
        
        if len(sold_out_dates) >= 2:  # è‡³å°‘å”®ç½„2æ¬¡æ‰ç®—é«˜é¢‘
            product_sold_out_days[product] = sold_out_dates
            product_recovery_days[product] = recovery_times
    
    # ç”Ÿæˆé«˜é¢‘å”®ç½„å“åˆ—è¡¨
    product_category_map = df.groupby('å•†å“åç§°')[category_col].first().to_dict() if category_col in df.columns else {}
    
    for product, dates_list in product_sold_out_days.items():
        times = len(dates_list)
        recovery_list = product_recovery_days.get(product, [])
        avg_recovery = round(sum(recovery_list) / len(recovery_list), 1) if recovery_list else 0
        
        # è·å–åˆ†ç±»
        cat = product_category_map.get(product, 'æœªçŸ¥')
        
        frequent_sold_out.append({
            "name": product,
            "times": times,
            "avgRecoveryDays": avg_recovery,
            "category": cat
        })
    
    # æŒ‰å”®ç½„æ¬¡æ•°æ’åºï¼Œå–å‰10
    frequent_sold_out.sort(key=lambda x: x["times"], reverse=True)
    frequent_sold_out = frequent_sold_out[:10]
    
    # ==================== 5. å¹³å‡æ¢å¤æ—¶é—´ ====================
    all_recovery_times = []
    for times in product_recovery_days.values():
        all_recovery_times.extend(times)
    
    avg_recovery_days = round(sum(all_recovery_times) / len(all_recovery_times), 1) if all_recovery_times else 0
    
    return {
        "success": True,
        "data": {
            "soldOutCount": sold_out_count,
            "estimatedLoss": round(estimated_loss, 2),
            "byCategory": by_category,
            "frequentSoldOut": frequent_sold_out,
            "avgRecoveryDays": avg_recovery_days
        },
        "period": {
            "start": min_date.strftime('%Y-%m-%d'),
            "end": max_date.strftime('%Y-%m-%d'),
            "days": days
        }
    }
