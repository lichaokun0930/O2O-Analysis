#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
çœŸå®æ•°æ®æ¥å…¥å’Œé¢„å¤„ç†æ¨¡å—
æ ¹æ®ç”¨æˆ·æä¾›çš„å®é™…æ•°æ®ä¼˜åŒ–ç®—æ³•å‚æ•°å’Œä¸šåŠ¡é€»è¾‘
"""

import pandas as pd
import numpy as np
import os
import json
from typing import Dict, List, Any, Optional, Tuple
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

class RealDataProcessor:
    """çœŸå®æ•°æ®å¤„ç†å™¨"""
    
    def __init__(self, data_dir: str = "å®é™…æ•°æ®"):
        self.data_dir = data_dir
        self.processed_data = {}
        self.data_quality_report = {}
        self.business_insights = {}
        
        # ç¡®ä¿æ•°æ®ç›®å½•å­˜åœ¨
        os.makedirs(data_dir, exist_ok=True)
        
        print(f"ğŸ“‚ æ•°æ®å¤„ç†å™¨åˆå§‹åŒ–å®Œæˆï¼Œæ•°æ®ç›®å½•: {data_dir}")
    
    def load_all_data(self) -> Dict[str, pd.DataFrame]:
        """åŠ è½½æ‰€æœ‰å¯ç”¨æ•°æ®"""
        
        print("ğŸ” æœç´¢å¯ç”¨æ•°æ®æ–‡ä»¶...")
        
        data_files = {
            'sales_data': self._find_file(['é”€å”®', 'sales', 'å•†å“', 'product']),
            'competitor_data': self._find_file(['ç«å¯¹', 'competitor', 'ç«å“']),
            'cost_data': self._find_file(['æˆæœ¬', 'cost', 'è´¹ç”¨']),
            'store_data': self._find_file(['é—¨åº—', 'store', 'åº—é“º']),
            'order_data': self._find_file(['è®¢å•', 'order', 'äº¤æ˜“']),
            'historical_data': self._find_file(['å†å²', 'history', 'è¶‹åŠ¿'])
        }
        
        loaded_data = {}
        
        for data_type, file_path in data_files.items():
            if file_path:
                try:
                    df = self._load_file(file_path)
                    loaded_data[data_type] = df
                    print(f"âœ… å·²åŠ è½½ {data_type}: {len(df)} æ¡è®°å½•")
                    
                    # ç”Ÿæˆæ•°æ®è´¨é‡æŠ¥å‘Š
                    self.data_quality_report[data_type] = self._assess_data_quality(df)
                    
                except Exception as e:
                    print(f"âŒ åŠ è½½ {data_type} å¤±è´¥: {str(e)}")
            else:
                print(f"âš ï¸  æœªæ‰¾åˆ° {data_type} æ•°æ®æ–‡ä»¶")
        
        self.processed_data = loaded_data
        return loaded_data
    
    def _find_file(self, keywords: List[str]) -> Optional[str]:
        """æ ¹æ®å…³é”®è¯æŸ¥æ‰¾æ–‡ä»¶"""
        
        for file in os.listdir(self.data_dir):
            if file.endswith(('.xlsx', '.xls', '.csv')):
                for keyword in keywords:
                    if keyword in file:
                        return os.path.join(self.data_dir, file)
        return None
    
    def _load_file(self, file_path: str) -> pd.DataFrame:
        """åŠ è½½å•ä¸ªæ•°æ®æ–‡ä»¶"""
        
        if file_path.endswith('.csv'):
            # å°è¯•ä¸åŒç¼–ç 
            for encoding in ['utf-8', 'gbk', 'gb2312']:
                try:
                    return pd.read_csv(file_path, encoding=encoding)
                except:
                    continue
            raise ValueError(f"æ— æ³•è¯»å–CSVæ–‡ä»¶: {file_path}")
        
        elif file_path.endswith(('.xlsx', '.xls')):
            return pd.read_excel(file_path)
        
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {file_path}")
    
    def _assess_data_quality(self, df: pd.DataFrame) -> Dict[str, Any]:
        """è¯„ä¼°æ•°æ®è´¨é‡"""
        
        quality_report = {
            'total_rows': len(df),
            'total_columns': len(df.columns),
            'missing_values': df.isnull().sum().sum(),
            'duplicate_rows': df.duplicated().sum(),
            'data_types': df.dtypes.to_dict(),
            'memory_usage_mb': df.memory_usage(deep=True).sum() / 1024 / 1024,
            'quality_score': 0.0
        }
        
        # è®¡ç®—è´¨é‡åˆ†æ•°
        missing_rate = quality_report['missing_values'] / (len(df) * len(df.columns))
        duplicate_rate = quality_report['duplicate_rows'] / len(df)
        
        quality_score = max(0, 1.0 - missing_rate * 2 - duplicate_rate)
        quality_report['quality_score'] = round(quality_score, 3)
        
        return quality_report
    
    def standardize_sales_data(self, sales_df: pd.DataFrame) -> pd.DataFrame:
        """æ ‡å‡†åŒ–é”€å”®æ•°æ®ï¼ˆä¿æŒä¸­æ–‡å­—æ®µåï¼ŒåŒ¹é…é—®é¢˜è¯Šæ–­å¼•æ“ï¼‰"""
        
        print("ğŸ”§ æ ‡å‡†åŒ–é”€å”®æ•°æ®...")
        
        # å­—æ®µæ˜ å°„ (æ˜ å°„ä¸ºä¸­æ–‡å­—æ®µåï¼ŒåŒ¹é…è¯Šæ–­å¼•æ“éœ€æ±‚)
        field_mapping = {
            # å•†å“ä¿¡æ¯
            'å•†å“åç§°': ['å•†å“åç§°', 'product_name', 'name', 'åç§°', 'å•†å“'],
            'æ¡ç ': ['æ¡ç ', 'barcode', 'sku', 'SKU', 'å•†å“ç¼–ç '],
            'ä¸€çº§åˆ†ç±»å': ['ç¾å›¢ä¸€çº§åˆ†ç±»', 'ä¸€çº§åˆ†ç±»å', 'category_l1', 'primary_category', 'ä¸€çº§åˆ†ç±»'],
            'ä¸‰çº§åˆ†ç±»å': ['ç¾å›¢ä¸‰çº§åˆ†ç±»', 'ä¸‰çº§åˆ†ç±»å', 'category_l3', 'tertiary_category', 'ä¸‰çº§åˆ†ç±»'],
            
            # ä»·æ ¼æˆæœ¬ä¿¡æ¯ï¼ˆåŒ¹é…è¯Šæ–­å¼•æ“å­—æ®µï¼‰
            'å•†å“å®å”®ä»·': ['å”®ä»·', 'å•†å“å®å”®ä»·', 'price', 'selling_price', 'ç°ä»·', 'å®å”®ä»·'],
            'å•†å“é‡‡è´­æˆæœ¬': ['å•†å“é‡‡è´­æˆæœ¬', 'æˆæœ¬', 'åŸä»·', 'original_price', 'cost', 'list_price', 'æ ‡ä»·', 'è¿›è´§ä»·', 'å•†å“åŸä»·'],
            'å®æ”¶ä»·æ ¼': ['å®æ”¶ä»·æ ¼', 'actual_price', 'received_price', 'å®ä»˜ä»·æ ¼', 'å®¢æˆ·å®ä»˜'],  # âœ… æ–°å¢ï¼šWåˆ—å®æ”¶ä»·æ ¼
            
            # è®¢å•é…é€ä¿¡æ¯
            'è®¢å•ID': ['è®¢å•ID', 'order_id', 'orderId', 'è®¢å•å·'],
            'ç‰©æµé…é€è´¹': ['ç‰©æµé…é€è´¹', 'é…é€è´¹', 'delivery_fee', 'shipping_fee'],
            'å¹³å°ä½£é‡‘': ['å¹³å°ä½£é‡‘', 'ä½£é‡‘', 'commission', 'platform_fee'],
            
            # é”€é‡åº“å­˜
            'æœˆå”®': ['æœˆå”®', 'monthly_sales', 'sales_volume', 'æœˆé”€é‡', 'é”€é‡'],
            'åº“å­˜': ['åº“å­˜', 'stock', 'inventory', 'å­˜é‡', 'å‰©ä½™åº“å­˜'],
            
            # æ—¶æ®µåœºæ™¯ä¿¡æ¯
            'æ—¶æ®µ': ['æ—¶æ®µ', 'time_period', 'æ—¶é—´æ®µ'],
            'åœºæ™¯': ['åœºæ™¯', 'scene', 'scenario'],
            'å•†å“è§’è‰²': ['å•†å“è§’è‰²', 'product_role', 'è§’è‰²'],
            
            # æ—¶é—´ä¿¡æ¯ â­ é‡è¦: å¢åŠ "ä¸‹å•æ—¶é—´"æ˜ å°„
            'æ—¥æœŸ': ['æ—¥æœŸ', 'date', 'ä¸‹å•æ—¶é—´', 'é‡‡é›†æ—¶é—´', 'collect_time', 'timestamp', 'æ—¶é—´', 'åˆ›å»ºæ—¶é—´'],
            'å‘¨': ['å‘¨', 'week', 'æ˜ŸæœŸ'],
            'é—¨åº—åç§°': ['é—¨åº—åç§°', 'store_name', 'shop_name', 'åº—å']
        }
        
        # æ‰§è¡Œå­—æ®µæ˜ å°„
        standardized_df = sales_df.copy()
        mapped_fields = {}
        
        for standard_field, possible_names in field_mapping.items():
            for possible_name in possible_names:
                if possible_name in standardized_df.columns:
                    if standard_field != possible_name:
                        standardized_df = standardized_df.rename(columns={possible_name: standard_field})
                    mapped_fields[standard_field] = possible_name
                    break
        
        # æ•°æ®ç±»å‹è½¬æ¢å’Œæ¸…æ´—ï¼ˆä½¿ç”¨ä¸­æ–‡å­—æ®µåï¼‰
        if 'å•†å“å®å”®ä»·' in standardized_df.columns:
            standardized_df['å•†å“å®å”®ä»·'] = pd.to_numeric(standardized_df['å•†å“å®å”®ä»·'], errors='coerce')
        
        if 'å•†å“é‡‡è´­æˆæœ¬' in standardized_df.columns:
            standardized_df['å•†å“é‡‡è´­æˆæœ¬'] = pd.to_numeric(standardized_df['å•†å“é‡‡è´­æˆæœ¬'], errors='coerce')
        
        if 'æœˆå”®' in standardized_df.columns:
            standardized_df['æœˆå”®'] = pd.to_numeric(standardized_df['æœˆå”®'], errors='coerce')
        
        if 'åº“å­˜' in standardized_df.columns:
            standardized_df['åº“å­˜'] = pd.to_numeric(standardized_df['åº“å­˜'], errors='coerce')
        
        if 'ç‰©æµé…é€è´¹' in standardized_df.columns:
            standardized_df['ç‰©æµé…é€è´¹'] = pd.to_numeric(standardized_df['ç‰©æµé…é€è´¹'], errors='coerce')
        
        if 'å¹³å°ä½£é‡‘' in standardized_df.columns:
            standardized_df['å¹³å°ä½£é‡‘'] = pd.to_numeric(standardized_df['å¹³å°ä½£é‡‘'], errors='coerce')
        
        # æ—¥æœŸç±»å‹è½¬æ¢
        if 'æ—¥æœŸ' in standardized_df.columns:
            standardized_df['æ—¥æœŸ'] = pd.to_datetime(standardized_df['æ—¥æœŸ'], errors='coerce')
        
        # è®¡ç®—è¡ç”Ÿå­—æ®µï¼ˆåŒ¹é…è¯Šæ–­å¼•æ“è®¡ç®—é€»è¾‘ï¼‰
        if 'å•†å“å®å”®ä»·' in standardized_df.columns and 'å•†å“é‡‡è´­æˆæœ¬' in standardized_df.columns:
            # å•å“æ¯›åˆ©
            standardized_df['å•å“æ¯›åˆ©'] = standardized_df['å•†å“å®å”®ä»·'] - standardized_df['å•†å“é‡‡è´­æˆæœ¬']
            # å•å“æ¯›åˆ©ç‡ï¼ˆç™¾åˆ†æ¯”ï¼‰
            standardized_df['å•å“æ¯›åˆ©ç‡'] = (
                (standardized_df['å•å“æ¯›åˆ©'] / standardized_df['å•†å“å®å”®ä»·'].where(standardized_df['å•†å“å®å”®ä»·'] > 0)) * 100
            ).fillna(0)
        
        if 'æœˆå”®' in standardized_df.columns and 'åº“å­˜' in standardized_df.columns:
            standardized_df['åº“å­˜å‘¨è½¬ç‡'] = (
                standardized_df['æœˆå”®'] / 
                standardized_df['åº“å­˜'].where(standardized_df['åº“å­˜'] > 0)
            )
        
        print(f"âœ… é”€å”®æ•°æ®æ ‡å‡†åŒ–å®Œæˆ: {len(standardized_df)} æ¡è®°å½•")
        print(f"ğŸ“Š æ˜ å°„å­—æ®µ: {mapped_fields}")
        
        return standardized_df
    
    def analyze_business_patterns(self) -> Dict[str, Any]:
        """åˆ†æä¸šåŠ¡æ¨¡å¼å’Œç‰¹å¾"""
        
        if 'sales_data' not in self.processed_data:
            return {"error": "ç¼ºå°‘é”€å”®æ•°æ®"}
        
        sales_df = self.processed_data['sales_data']
        standardized_sales = self.standardize_sales_data(sales_df)
        
        analysis = {
            'data_overview': self._analyze_data_overview(standardized_sales),
            'price_analysis': self._analyze_price_patterns(standardized_sales),
            'sales_analysis': self._analyze_sales_patterns(standardized_sales),
            'category_analysis': self._analyze_category_patterns(standardized_sales),
            'optimization_suggestions': []
        }
        
        # ç”Ÿæˆä¼˜åŒ–å»ºè®®
        analysis['optimization_suggestions'] = self._generate_optimization_suggestions(analysis)
        
        self.business_insights = analysis
        return analysis
    
    def _analyze_data_overview(self, df: pd.DataFrame) -> Dict[str, Any]:
        """æ•°æ®æ€»è§ˆåˆ†æ"""
        
        return {
            'total_products': len(df),
            'unique_products': df['product_name'].nunique() if 'product_name' in df.columns else 0,
            'price_range': {
                'min': df['price'].min() if 'price' in df.columns else 0,
                'max': df['price'].max() if 'price' in df.columns else 0,
                'mean': df['price'].mean() if 'price' in df.columns else 0
            },
            'sales_range': {
                'min': df['monthly_sales'].min() if 'monthly_sales' in df.columns else 0,
                'max': df['monthly_sales'].max() if 'monthly_sales' in df.columns else 0,
                'mean': df['monthly_sales'].mean() if 'monthly_sales' in df.columns else 0
            },
            'categories': df['category_l1'].value_counts().to_dict() if 'category_l1' in df.columns else {}
        }
    
    def _analyze_price_patterns(self, df: pd.DataFrame) -> Dict[str, Any]:
        """ä»·æ ¼æ¨¡å¼åˆ†æ"""
        
        if 'price' not in df.columns:
            return {"error": "ç¼ºå°‘ä»·æ ¼å­—æ®µ"}
        
        price_analysis = {
            'price_distribution': {
                'low_price': len(df[df['price'] <= df['price'].quantile(0.25)]),
                'medium_price': len(df[(df['price'] > df['price'].quantile(0.25)) & 
                                     (df['price'] <= df['price'].quantile(0.75))]),
                'high_price': len(df[df['price'] > df['price'].quantile(0.75)])
            }
        }
        
        # ä»·æ ¼ä¸é”€é‡å…³ç³»
        if 'monthly_sales' in df.columns:
            price_sales_corr = df[['price', 'monthly_sales']].corr().iloc[0, 1]
            price_analysis['price_sales_correlation'] = price_sales_corr
        
        # æ¯›åˆ©ç‡åˆ†æ
        if 'margin_rate' in df.columns:
            price_analysis['margin_distribution'] = {
                'high_margin': len(df[df['margin_rate'] > 0.3]),
                'medium_margin': len(df[(df['margin_rate'] > 0.1) & (df['margin_rate'] <= 0.3)]),
                'low_margin': len(df[df['margin_rate'] <= 0.1])
            }
        
        return price_analysis
    
    def _analyze_sales_patterns(self, df: pd.DataFrame) -> Dict[str, Any]:
        """é”€å”®æ¨¡å¼åˆ†æ"""
        
        if 'monthly_sales' not in df.columns:
            return {"error": "ç¼ºå°‘é”€é‡å­—æ®µ"}
        
        # é”€å”®åˆ†å±‚åˆ†æ
        high_sales_threshold = df['monthly_sales'].quantile(0.8)
        medium_sales_threshold = df['monthly_sales'].quantile(0.5)
        
        sales_analysis = {
            'sales_distribution': {
                'high_volume': len(df[df['monthly_sales'] >= high_sales_threshold]),
                'medium_volume': len(df[(df['monthly_sales'] >= medium_sales_threshold) & 
                                       (df['monthly_sales'] < high_sales_threshold)]),
                'low_volume': len(df[df['monthly_sales'] < medium_sales_threshold])
            },
            'top_products': df.nlargest(10, 'monthly_sales')[['product_name', 'monthly_sales']].to_dict('records')
        }
        
        # ABCåˆ†æ (å¸•ç´¯æ‰˜åˆ†æ)
        df_sorted = df.sort_values('monthly_sales', ascending=False)
        df_sorted['sales_cumsum'] = df_sorted['monthly_sales'].cumsum()
        total_sales = df_sorted['monthly_sales'].sum()
        
        df_sorted['sales_cumsum_pct'] = df_sorted['sales_cumsum'] / total_sales
        
        a_products = len(df_sorted[df_sorted['sales_cumsum_pct'] <= 0.8])
        b_products = len(df_sorted[(df_sorted['sales_cumsum_pct'] > 0.8) & 
                                  (df_sorted['sales_cumsum_pct'] <= 0.95)])
        c_products = len(df_sorted) - a_products - b_products
        
        sales_analysis['abc_analysis'] = {
            'A_products': a_products,
            'B_products': b_products, 
            'C_products': c_products
        }
        
        return sales_analysis
    
    def _analyze_category_patterns(self, df: pd.DataFrame) -> Dict[str, Any]:
        """å“ç±»æ¨¡å¼åˆ†æ"""
        
        if 'category_l1' not in df.columns:
            return {"error": "ç¼ºå°‘åˆ†ç±»å­—æ®µ"}
        
        category_stats = df.groupby('category_l1').agg({
            'product_name': 'count',
            'price': 'mean',
            'monthly_sales': 'sum' if 'monthly_sales' in df.columns else 'count'
        }).round(2)
        
        category_analysis = {
            'category_performance': category_stats.to_dict('index'),
            'dominant_categories': category_stats.sort_values('monthly_sales', ascending=False).head(5).index.tolist()
        }
        
        return category_analysis
    
    def _generate_optimization_suggestions(self, analysis: Dict[str, Any]) -> List[str]:
        """åŸºäºåˆ†æç»“æœç”Ÿæˆä¼˜åŒ–å»ºè®®"""
        
        suggestions = []
        
        # åŸºäºä»·æ ¼åˆ†æçš„å»ºè®®
        if 'price_analysis' in analysis:
            price_data = analysis['price_analysis']
            
            if 'price_sales_correlation' in price_data:
                correlation = price_data['price_sales_correlation']
                if correlation < -0.5:
                    suggestions.append("ä»·æ ¼æ•æ„Ÿåº¦è¾ƒé«˜ï¼Œå»ºè®®å®æ–½ç«äº‰å®šä»·ç­–ç•¥")
                elif correlation > 0.2:
                    suggestions.append("ä»·æ ¼ä¸é”€é‡æ­£ç›¸å…³ï¼Œå¯èƒ½å­˜åœ¨å“ç‰Œæº¢ä»·ç©ºé—´")
        
        # åŸºäºé”€å”®åˆ†æçš„å»ºè®®
        if 'sales_analysis' in analysis:
            sales_data = analysis['sales_analysis']
            
            if 'abc_analysis' in sales_data:
                abc = sales_data['abc_analysis']
                a_ratio = abc['A_products'] / (abc['A_products'] + abc['B_products'] + abc['C_products'])
                
                if a_ratio < 0.2:
                    suggestions.append("Aç±»å•†å“å æ¯”è¾ƒä½ï¼Œå»ºè®®åŠ å¼ºæ ¸å¿ƒå•†å“æ¨å¹¿")
                
                if abc['C_products'] > abc['A_products'] * 2:
                    suggestions.append("Cç±»å•†å“è¿‡å¤šï¼Œå»ºè®®ä¼˜åŒ–å•†å“ç»“æ„")
        
        # åŸºäºå“ç±»åˆ†æçš„å»ºè®®
        if 'category_analysis' in analysis:
            category_data = analysis['category_analysis']
            
            if 'dominant_categories' in category_data:
                dominant_cats = category_data['dominant_categories']
                if len(dominant_cats) <= 2:
                    suggestions.append("å“ç±»é›†ä¸­åº¦è¾ƒé«˜ï¼Œå»ºè®®æ‰©å±•å¤šå…ƒåŒ–å•†å“")
        
        return suggestions
    
    def generate_optimized_parameters(self) -> Dict[str, Any]:
        """åŸºäºçœŸå®æ•°æ®ç”Ÿæˆä¼˜åŒ–å‚æ•°"""
        
        if not self.business_insights:
            self.analyze_business_patterns()
        
        optimized_params = {
            'traffic_product_params': self._optimize_traffic_product_params(),
            'discount_product_params': self._optimize_discount_product_params(),
            'risk_assessment_params': self._optimize_risk_params(),
            'prediction_params': self._optimize_prediction_params()
        }
        
        return optimized_params
    
    def _optimize_traffic_product_params(self) -> Dict[str, float]:
        """ä¼˜åŒ–æµé‡å“è¯†åˆ«å‚æ•°"""
        
        sales_data = self.processed_data.get('sales_data')
        if sales_data is None:
            return {"sales_weight": 0.4, "price_weight": 0.3, "brand_weight": 0.2, "correlation_weight": 0.1}
        
        standardized_sales = self.standardize_sales_data(sales_data)
        
        # åŸºäºå®é™…æ•°æ®è°ƒæ•´æƒé‡
        params = {"sales_weight": 0.4, "price_weight": 0.3, "brand_weight": 0.2, "correlation_weight": 0.1}
        
        if 'monthly_sales' in standardized_sales.columns:
            sales_std = standardized_sales['monthly_sales'].std()
            sales_mean = standardized_sales['monthly_sales'].mean()
            
            # å¦‚æœé”€é‡å·®å¼‚å¾ˆå¤§ï¼Œå¢åŠ é”€é‡æƒé‡
            if sales_std / sales_mean > 2.0:
                params["sales_weight"] = 0.5
                params["price_weight"] = 0.25
        
        return params
    
    def _optimize_discount_product_params(self) -> Dict[str, float]:
        """ä¼˜åŒ–æŠ˜æ‰£å“è¯†åˆ«å‚æ•°"""
        
        return {
            "inventory_weight": 0.4,
            "margin_weight": 0.3, 
            "seasonality_weight": 0.2,
            "category_weight": 0.1,
            "min_margin_threshold": 0.15,
            "inventory_turnover_threshold": 0.5
        }
    
    def _optimize_risk_params(self) -> Dict[str, float]:
        """ä¼˜åŒ–é£é™©è¯„ä¼°å‚æ•°"""
        
        return {
            "market_risk_weight": 0.4,
            "operational_risk_weight": 0.3,
            "financial_risk_weight": 0.3,
            "high_risk_threshold": 0.7,
            "medium_risk_threshold": 0.4
        }
    
    def _optimize_prediction_params(self) -> Dict[str, Any]:
        """ä¼˜åŒ–é¢„æµ‹æ¨¡å‹å‚æ•°"""
        
        return {
            "trend_window": 7,  # è¶‹åŠ¿è®¡ç®—çª—å£æœŸ
            "seasonal_factor": 0.1,  # å­£èŠ‚æ€§å› å­
            "noise_factor": 0.02,  # éšæœºå™ªå£°å› å­
            "confidence_interval": 0.95  # ç½®ä¿¡åŒºé—´
        }
    
    def export_optimization_config(self, output_path: str = "ä¼˜åŒ–å‚æ•°é…ç½®.json"):
        """å¯¼å‡ºä¼˜åŒ–é…ç½®"""
        
        config = {
            "generation_time": datetime.now().isoformat(),
            "data_sources": list(self.processed_data.keys()),
            "data_quality": self.data_quality_report,
            "business_insights": self.business_insights,
            "optimized_parameters": self.generate_optimized_parameters()
        }
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(config, f, ensure_ascii=False, indent=2, default=str)
        
        print(f"âœ… ä¼˜åŒ–é…ç½®å·²å¯¼å‡ºåˆ°: {output_path}")
        
        return config
    
    def generate_data_report(self) -> str:
        """ç”Ÿæˆæ•°æ®è´¨é‡å’Œåˆ†ææŠ¥å‘Š"""
        
        report = []
        report.append("# ğŸ“Š æ•°æ®è´¨é‡å’Œä¸šåŠ¡åˆ†ææŠ¥å‘Š\n")
        report.append(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        
        # æ•°æ®è´¨é‡æ¦‚è§ˆ
        report.append("## ğŸ“‹ æ•°æ®è´¨é‡æ¦‚è§ˆ\n")
        for data_type, quality in self.data_quality_report.items():
            report.append(f"### {data_type}")
            report.append(f"- æ•°æ®é‡: {quality['total_rows']} è¡Œ Ã— {quality['total_columns']} åˆ—")
            report.append(f"- ç¼ºå¤±å€¼: {quality['missing_values']} ä¸ª")
            report.append(f"- é‡å¤è¡Œ: {quality['duplicate_rows']} è¡Œ")
            report.append(f"- è´¨é‡è¯„åˆ†: {quality['quality_score']:.3f}/1.000")
            report.append(f"- å†…å­˜å ç”¨: {quality['memory_usage_mb']:.2f} MB\n")
        
        # ä¸šåŠ¡åˆ†ææ´å¯Ÿ
        if self.business_insights:
            report.append("## ğŸ¯ ä¸šåŠ¡åˆ†ææ´å¯Ÿ\n")
            
            insights = self.business_insights
            
            if 'data_overview' in insights:
                overview = insights['data_overview']
                report.append("### æ•°æ®æ¦‚è§ˆ")
                report.append(f"- å•†å“æ€»æ•°: {overview['total_products']}")
                report.append(f"- ç‹¬ç‰¹å•†å“: {overview['unique_products']}")
                report.append(f"- ä»·æ ¼åŒºé—´: Â¥{overview['price_range']['min']:.2f} - Â¥{overview['price_range']['max']:.2f}")
                report.append(f"- å¹³å‡ä»·æ ¼: Â¥{overview['price_range']['mean']:.2f}\n")
            
            if 'optimization_suggestions' in insights:
                report.append("### ğŸš€ ä¼˜åŒ–å»ºè®®")
                for i, suggestion in enumerate(insights['optimization_suggestions'], 1):
                    report.append(f"{i}. {suggestion}")
                report.append("")
        
        return "\n".join(report)


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    print("ğŸ¯ çœŸå®æ•°æ®å¤„ç†å™¨æµ‹è¯•è¿è¡Œ")
    
    processor = RealDataProcessor("å®é™…æ•°æ®")
    
    # å¦‚æœæœ‰æ•°æ®æ–‡ä»¶ï¼Œå°†è‡ªåŠ¨åŠ è½½å’Œåˆ†æ
    loaded_data = processor.load_all_data()
    
    if loaded_data:
        print("\nğŸ“Š æ‰§è¡Œä¸šåŠ¡æ¨¡å¼åˆ†æ...")
        business_analysis = processor.analyze_business_patterns()
        
        print("\nğŸ”§ ç”Ÿæˆä¼˜åŒ–å‚æ•°...")
        optimized_params = processor.generate_optimized_parameters()
        
        print("\nğŸ“ å¯¼å‡ºé…ç½®æ–‡ä»¶...")
        config = processor.export_optimization_config()
        
        print("\nğŸ“‹ ç”Ÿæˆæ•°æ®æŠ¥å‘Š...")
        report = processor.generate_data_report()
        
        with open("æ•°æ®åˆ†ææŠ¥å‘Š.md", "w", encoding="utf-8") as f:
            f.write(report)
        
        print("âœ… æ•°æ®å¤„ç†å’Œåˆ†æå®Œæˆï¼")
    else:
        print("â„¹ï¸  æœªæ‰¾åˆ°æ•°æ®æ–‡ä»¶ï¼Œè¯·å°†æ•°æ®æ–‡ä»¶æ”¾å…¥ 'å®é™…æ•°æ®' ç›®å½•")
        print("æ”¯æŒæ ¼å¼: .xlsx, .xls, .csv")
        print("å»ºè®®æ–‡ä»¶ååŒ…å«: é”€å”®ã€ç«å¯¹ã€æˆæœ¬ã€é—¨åº—ã€è®¢å•ã€å†å² ç­‰å…³é”®è¯")