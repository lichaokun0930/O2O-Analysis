#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¼˜åŒ–çš„å…«è±¡é™åˆ†æå™¨ - ç§‘å­¦ç‰ˆ
æ•´åˆå“ç±»åŠ¨æ€é˜ˆå€¼ã€è¶‹åŠ¿åˆ†æã€ç½®ä¿¡åº¦è¯„ä¼°
"""

import pandas as pd
import numpy as np
from typing import Dict, Tuple, Optional


class ScientificQuadrantAnalyzer:
    """
    ç§‘å­¦çš„å…«è±¡é™åˆ†æå™¨
    
    æ”¹è¿›ç‚¹:
    1. æ”¯æŒå“ç±»åŠ¨æ€é˜ˆå€¼(ä¸åŒå“ç±»ä¸åŒæ ‡å‡†)
    2. å¢åŠ ç½®ä¿¡åº¦è¯„ä¼°(è¾¹ç•Œå•†å“æ ‡è®°)
    3. æ”¯æŒè¶‹åŠ¿åˆ†æ(30å¤©æ•°æ®å¯åˆ†æè¶‹åŠ¿)
    4. å¢åŠ åˆ©æ¶¦è´¡çŒ®åº¦æƒé‡
    """
    
    def __init__(self, data: pd.DataFrame, use_category_threshold: bool = True):
        """
        åˆå§‹åŒ–åˆ†æå™¨
        
        Args:
            data: è®¢å•æ•°æ®DataFrame
            use_category_threshold: æ˜¯å¦ä½¿ç”¨å“ç±»åŠ¨æ€é˜ˆå€¼
        """
        self.data = data.copy()
        self.use_category_threshold = use_category_threshold
        self.category_col = self._detect_category_field()
        self._map_fields()  # å­—æ®µæ˜ å°„
    
    def _map_fields(self):
        """æ™ºèƒ½å­—æ®µæ˜ å°„"""
        # æœˆå”®å­—æ®µ
        if 'æœˆå”®' not in self.data.columns and 'é”€é‡' in self.data.columns:
            self.data['æœˆå”®'] = self.data['é”€é‡']
        
        # è¥é”€æ€»æˆæœ¬å­—æ®µ (ä¿®æ­£: ä¼˜å…ˆä½¿ç”¨è¥é”€æ´»åŠ¨è¡¥è´´ï¼Œè€Œéå¹³å°ä½£é‡‘)
        # è¥é”€æ´»åŠ¨å­—æ®µåˆ—è¡¨
        marketing_cols = ['æ»¡å‡é‡‘é¢', 'æ–°å®¢å‡å…é‡‘é¢', 'é…é€è´¹å‡å…é‡‘é¢', 'å•†å®¶ä»£é‡‘åˆ¸', 
                         'å•†å®¶æ‰¿æ‹…éƒ¨åˆ†åˆ¸', 'æ»¡èµ é‡‘é¢', 'å•†å®¶å…¶ä»–ä¼˜æƒ ', 'å•†å“å‡å…é‡‘é¢']
        
        # æ£€æŸ¥æ˜¯å¦å­˜åœ¨è¥é”€å­—æ®µ
        available_marketing_cols = [col for col in marketing_cols if col in self.data.columns]
        
        if available_marketing_cols:
            # å¦‚æœæœ‰è¥é”€å­—æ®µï¼Œè®¡ç®—æ€»è¥é”€æˆæœ¬
            # æ³¨æ„: è¿™äº›é€šå¸¸æ˜¯è®¢å•çº§å­—æ®µï¼Œå¦‚æœæ•°æ®æ˜¯å•†å“çº§æ˜ç»†ï¼Œç›´æ¥ç›¸åŠ ä¼šé‡å¤è®¡ç®—
            # è¿™é‡Œå‡è®¾è¾“å…¥æ•°æ®æ˜¯å•†å“çº§æ˜ç»†(æ¯è¡Œä¸€ä¸ªå•†å“)ï¼Œä¸”è®¢å•çº§å­—æ®µåœ¨åŒä¸€è®¢å•çš„æ‰€æœ‰è¡Œä¸­é‡å¤
            
            # ç­–ç•¥: æš‚æ—¶å…ˆä¸åœ¨æ­¤å¤„è®¡ç®—ï¼Œè€Œåœ¨ _aggregate_to_product_level ä¸­é€šè¿‡åˆ†æ‘Šé€»è¾‘è®¡ç®—
            pass
        elif 'è¥é”€æ€»æˆæœ¬' not in self.data.columns:
            # é™çº§æ–¹æ¡ˆ: å¦‚æœæ²¡æœ‰è¥é”€æ´»åŠ¨å­—æ®µï¼Œæ‰ä½¿ç”¨å¹³å°æœåŠ¡è´¹/ä½£é‡‘
            if 'å¹³å°æœåŠ¡è´¹' in self.data.columns:
                self.data['è¥é”€æ€»æˆæœ¬'] = self.data['å¹³å°æœåŠ¡è´¹'].fillna(0)
            elif 'å¹³å°ä½£é‡‘' in self.data.columns:
                self.data['è¥é”€æ€»æˆæœ¬'] = self.data['å¹³å°ä½£é‡‘'].fillna(0)
    
    def _detect_category_field(self) -> Optional[str]:
        """æ£€æµ‹å“ç±»å­—æ®µ"""
        for col in ['ä¸€çº§åˆ†ç±»å', 'ç¾å›¢ä¸€çº§åˆ†ç±»', 'ä¸€çº§åˆ†ç±»']:
            if col in self.data.columns:
                return col
        return None
    
    def calculate_category_thresholds(self) -> Dict[str, Dict[str, float]]:
        """
        è®¡ç®—å“ç±»åŠ¨æ€é˜ˆå€¼
        
        Returns:
            {
                'é¥®æ–™': {'è¥é”€å æ¯”': 0.45, 'æ¯›åˆ©ç‡': 0.25, 'å”®ç½„ç‡': 0.55},
                'ä¼‘é—²é£Ÿå“': {'è¥é”€å æ¯”': 0.52, 'æ¯›åˆ©ç‡': 0.32, 'å”®ç½„ç‡': 0.48},
                ...
            }
        """
        if not self.category_col or not self.use_category_threshold:
            return {}
        
        # èšåˆåˆ°å•†å“çº§åˆ«
        product_data = self._aggregate_to_product_level()
        
        thresholds = {}
        for category in product_data[self.category_col].unique():
            cat_data = product_data[product_data[self.category_col] == category]
            
            # å“ç±»å•†å“æ•°å¤ªå°‘,ä¸ä½¿ç”¨åŠ¨æ€é˜ˆå€¼
            if len(cat_data) < 10:
                continue
            
            thresholds[category] = {
                # è¥é”€å æ¯”: ä½¿ç”¨60åˆ†ä½æ•°(é«˜äº60%çš„å•†å“ç®—é«˜è¥é”€)
                'è¥é”€å æ¯”': cat_data['è¥é”€å æ¯”'].quantile(0.6),
                # æ¯›åˆ©ç‡: ä½¿ç”¨40åˆ†ä½æ•°(ä½äº40%çš„å•†å“ç®—ä½æ¯›åˆ©)
                'æ¯›åˆ©ç‡': cat_data['æ¯›åˆ©ç‡'].quantile(0.4),
                # å”®ç½„ç‡: ä½¿ç”¨50åˆ†ä½æ•° + 30åˆ†ä½æ•°æœˆå”®
                'å”®ç½„ç‡': cat_data['å”®ç½„ç‡'].quantile(0.5) if 'å”®ç½„ç‡' in cat_data.columns else 0,
                'æœˆå”®': cat_data['æœˆå”®'].quantile(0.3),
            }
        
        return thresholds
    
    def _aggregate_to_product_level(self) -> pd.DataFrame:
        """èšåˆåˆ°å•†å“çº§åˆ«"""
        # å…ˆè®¡ç®—æ¯æ¡è®°å½•çš„è®¢å•æ€»æ”¶å…¥ï¼ˆå®æ”¶ä»·æ ¼æ˜¯å•ä»·ï¼Œéœ€è¦ä¹˜ä»¥é”€é‡ï¼‰
        self.data['è®¢å•æ€»æ”¶å…¥'] = self.data['å®æ”¶ä»·æ ¼'] * self.data['æœˆå”®']
        
        # === æ ¸å¿ƒä¿®æ­£: è¥é”€æˆæœ¬åˆ†æ‘Šé€»è¾‘ ===
        # è¥é”€æ´»åŠ¨å­—æ®µåˆ—è¡¨
        marketing_cols = ['æ»¡å‡é‡‘é¢', 'æ–°å®¢å‡å…é‡‘é¢', 'é…é€è´¹å‡å…é‡‘é¢', 'å•†å®¶ä»£é‡‘åˆ¸', 
                         'å•†å®¶æ‰¿æ‹…éƒ¨åˆ†åˆ¸', 'æ»¡èµ é‡‘é¢', 'å•†å®¶å…¶ä»–ä¼˜æƒ ', 'å•†å“å‡å…é‡‘é¢']
        available_marketing_cols = [col for col in marketing_cols if col in self.data.columns]
        
        if available_marketing_cols and 'è®¢å•ID' in self.data.columns:
            # 1. è®¡ç®—æ¯ä¸ªè®¢å•çš„æ€»è¥é”€æˆæœ¬ (å–firsté¿å…é‡å¤)
            order_marketing = self.data.groupby('è®¢å•ID')[available_marketing_cols].first().sum(axis=1).reset_index(name='è®¢å•è¥é”€æ€»é¢')
            
            # 2. è®¡ç®—æ¯ä¸ªè®¢å•çš„æ€»GMV (ç”¨äºåˆ†æ‘Š)
            order_gmv = self.data.groupby('è®¢å•ID')['è®¢å•æ€»æ”¶å…¥'].sum().reset_index(name='è®¢å•GMV')
            
            # 3. åˆå¹¶å›åŸæ•°æ®
            temp_df = self.data.merge(order_marketing, on='è®¢å•ID', how='left').merge(order_gmv, on='è®¢å•ID', how='left')
            
            # 4. æŒ‰é‡‘é¢å æ¯”åˆ†æ‘Šè¥é”€æˆæœ¬
            # åˆ†æ‘Šå…¬å¼: å•†å“è¥é”€æˆæœ¬ = è®¢å•è¥é”€æ€»é¢ * (å•†å“æ”¶å…¥ / è®¢å•GMV)
            # å¤„ç†é™¤é›¶é”™è¯¯
            temp_df['åˆ†æ‘Šè¥é”€æˆæœ¬'] = np.where(
                temp_df['è®¢å•GMV'] > 0,
                temp_df['è®¢å•è¥é”€æ€»é¢'] * (temp_df['è®¢å•æ€»æ”¶å…¥'] / temp_df['è®¢å•GMV']),
                0
            )
            
            # æ›´æ–°åˆ°self.data (ä¸ºäº†åç»­èšåˆ)
            self.data['åˆ†æ‘Šè¥é”€æˆæœ¬'] = temp_df['åˆ†æ‘Šè¥é”€æˆæœ¬']
            marketing_agg_col = 'åˆ†æ‘Šè¥é”€æˆæœ¬'
        else:
            # é™çº§: ä½¿ç”¨é¢„å…ˆå­˜åœ¨çš„è¥é”€æ€»æˆæœ¬(å¯èƒ½æ˜¯ä½£é‡‘)
            marketing_agg_col = 'è¥é”€æ€»æˆæœ¬' if 'è¥é”€æ€»æˆæœ¬' in self.data.columns else None

        agg_dict = {
            'è®¢å•æ€»æ”¶å…¥': 'sum',      # å®æ”¶ä»·æ ¼Ã—é”€é‡çš„æ€»å’Œ
            'åˆ©æ¶¦é¢': 'sum',          # å·²æ˜¯æ€»é¢ï¼Œç›´æ¥sum
            'æœˆå”®': 'sum'
        }
        
        if marketing_agg_col:
            agg_dict[marketing_agg_col] = 'sum'
        
        # æ·»åŠ åº—å†…ç å­—æ®µï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        if 'åº—å†…ç ' in self.data.columns:
            agg_dict['åº—å†…ç '] = 'first'  # å–ç¬¬ä¸€æ¬¡å‡ºç°çš„åº—å†…ç 
        
        # åˆ†ç»„å­—æ®µ
        group_fields = ['å•†å“åç§°']
        if self.category_col:
            group_fields.append(self.category_col)
        
        product_data = self.data.groupby(group_fields).agg(agg_dict).reset_index()
        
        # é‡å‘½åå›å®æ”¶ä»·æ ¼ï¼ˆç°åœ¨æ˜¯æ€»æ”¶å…¥ï¼‰
        product_data.rename(columns={'è®¢å•æ€»æ”¶å…¥': 'å®æ”¶ä»·æ ¼'}, inplace=True)
        
        # ç»Ÿä¸€è¥é”€æˆæœ¬å­—æ®µå
        if marketing_agg_col == 'åˆ†æ‘Šè¥é”€æˆæœ¬':
            product_data.rename(columns={'åˆ†æ‘Šè¥é”€æˆæœ¬': 'è¥é”€æ€»æˆæœ¬'}, inplace=True)
        elif marketing_agg_col is None:
            product_data['è¥é”€æ€»æˆæœ¬'] = 0
            
        # è·å–æœŸæœ«åº“å­˜(æœ€åè®¢å•æ—¥çš„å‰©ä½™åº“å­˜)
        stock_col = self._detect_stock_field()
        if stock_col:
            last_stock = self._get_last_day_stock(stock_col)
            product_data = product_data.merge(
                last_stock.rename('å®é™…å‰©ä½™åº“å­˜'),
                on='å•†å“åç§°',
                how='left'
            )
            # ä¿ç•™åŸå§‹åº“å­˜å€¼,åŒæ—¶åˆ›å»ºæœŸæœ«åº“å­˜å­—æ®µ(ç”¨äºè®¡ç®—)
            product_data['æœŸæœ«åº“å­˜'] = product_data['å®é™…å‰©ä½™åº“å­˜'].fillna(0)
        
        # è®¡ç®—æŒ‡æ ‡
        product_data['è¥é”€å æ¯”'] = np.where(
            product_data['å®æ”¶ä»·æ ¼'] > 0,
            product_data['è¥é”€æ€»æˆæœ¬'] / product_data['å®æ”¶ä»·æ ¼'],
            0
        )
        product_data['æ¯›åˆ©ç‡'] = np.where(
            product_data['å®æ”¶ä»·æ ¼'] > 0,
            product_data['åˆ©æ¶¦é¢'] / product_data['å®æ”¶ä»·æ ¼'],
            0
        )
        
        if stock_col:
            # å”®ç½„ç‡ = æœˆå”® / (æœˆå”® + æœŸæœ«åº“å­˜)
            product_data['å”®ç½„ç‡'] = np.where(
                (product_data['æœˆå”®'] + product_data['æœŸæœ«åº“å­˜']) > 0,
                product_data['æœˆå”®'] / (product_data['æœˆå”®'] + product_data['æœŸæœ«åº“å­˜']),
                0
            )
        
        return product_data
    
    def _detect_stock_field(self) -> Optional[str]:
        """æ£€æµ‹åº“å­˜å­—æ®µ"""
        for col in ['å‰©ä½™åº“å­˜', 'åº“å­˜', 'æœŸæœ«åº“å­˜']:
            if col in self.data.columns:
                return col
        return None
    
    def _get_last_day_stock(self, stock_col: str) -> pd.Series:
        """è·å–æ¯ä¸ªå•†å“æœ€åä¸€æ¬¡è®¢å•çš„å‰©ä½™åº“å­˜"""
        # æ”¹ä¸ºå–æ¯ä¸ªå•†å“æœ€åä¸€æ¬¡å‡ºç°æ—¶çš„åº“å­˜,é¿å…å› max(æ—¥æœŸ)å¯¼è‡´çš„æ•°æ®ç¼ºå¤±
        return self.data.groupby('å•†å“åç§°')[stock_col].last()
    
    def analyze_with_confidence(self,
                                marketing_threshold: float = 0.15,
                                margin_threshold: float = 0.3,
                                turnover_rate_threshold: float = 0.5) -> pd.DataFrame:
        """
        å…«è±¡é™åˆ†æ + ç½®ä¿¡åº¦è¯„ä¼°
        
        Args:
            marketing_threshold: å…¨å±€è¥é”€å æ¯”é˜ˆå€¼(å“ç±»é˜ˆå€¼ä¼˜å…ˆ)
            margin_threshold: å…¨å±€æ¯›åˆ©ç‡é˜ˆå€¼(å“ç±»é˜ˆå€¼ä¼˜å…ˆ)
            turnover_rate_threshold: å”®ç½„ç‡é˜ˆå€¼
        
        Returns:
            åŒ…å«è±¡é™ã€ç½®ä¿¡åº¦ã€å»ºè®®çš„DataFrame
        """
        product_data = self._aggregate_to_product_level()
        
        # è·å–å“ç±»é˜ˆå€¼
        category_thresholds = self.calculate_category_thresholds()
        
        # ä¸ºæ¯ä¸ªå•†å“ç¡®å®šé˜ˆå€¼
        def get_threshold(row, metric):
            """è·å–å•†å“çš„é˜ˆå€¼(å“ç±»æˆ–å…¨å±€)"""
            if self.category_col and row[self.category_col] in category_thresholds:
                return category_thresholds[row[self.category_col]][metric]
            else:
                # ä½¿ç”¨å…¨å±€é˜ˆå€¼
                if metric == 'è¥é”€å æ¯”':
                    return marketing_threshold
                elif metric == 'æ¯›åˆ©ç‡':
                    return margin_threshold
                elif metric == 'å”®ç½„ç‡':
                    return turnover_rate_threshold
                elif metric == 'æœˆå”®':
                    return product_data['æœˆå”®'].quantile(0.3)
        
        # åˆ¤æ–­ç­‰çº§
        product_data['è¥é”€é˜ˆå€¼'] = product_data.apply(lambda row: get_threshold(row, 'è¥é”€å æ¯”'), axis=1)
        product_data['æ¯›åˆ©é˜ˆå€¼'] = product_data.apply(lambda row: get_threshold(row, 'æ¯›åˆ©ç‡'), axis=1)
        product_data['å”®ç½„ç‡é˜ˆå€¼'] = product_data.apply(lambda row: get_threshold(row, 'å”®ç½„ç‡'), axis=1)
        product_data['æœˆå”®é˜ˆå€¼'] = product_data.apply(lambda row: get_threshold(row, 'æœˆå”®'), axis=1)
        
        # åˆ†ç±»
        product_data['è¥é”€ç­‰çº§'] = np.where(
            product_data['è¥é”€å æ¯”'] >= product_data['è¥é”€é˜ˆå€¼'], 'é«˜è¥é”€', 'ä½è¥é”€'
        )
        product_data['æ¯›åˆ©ç­‰çº§'] = np.where(
            product_data['æ¯›åˆ©ç‡'] >= product_data['æ¯›åˆ©é˜ˆå€¼'], 'é«˜æ¯›åˆ©', 'ä½æ¯›åˆ©'
        )
        
        # åŠ¨é”€ç­‰çº§(åŒé‡åˆ¤æ–­:å”®ç½„ç‡+æœˆå”®)
        if 'å”®ç½„ç‡' in product_data.columns:
            product_data['åŠ¨é”€ç­‰çº§'] = np.where(
                (product_data['å”®ç½„ç‡'] >= product_data['å”®ç½„ç‡é˜ˆå€¼']) &
                (product_data['æœˆå”®'] >= product_data['æœˆå”®é˜ˆå€¼']),
                'é«˜åŠ¨é”€',
                'ä½åŠ¨é”€'
            )
        else:
            product_data['åŠ¨é”€ç­‰çº§'] = np.where(
                product_data['æœˆå”®'] >= product_data['æœˆå”®é˜ˆå€¼'], 'é«˜åŠ¨é”€', 'ä½åŠ¨é”€'
            )
        
        # ğŸ†• ç½®ä¿¡åº¦è¯„ä¼°(è¾¹ç•Œå•†å“æ ‡è®°)
        boundary_range = 0.1  # Â±10%ä¸ºè¾¹ç•Œ
        
        product_data['è¥é”€ç½®ä¿¡åº¦'] = product_data.apply(
            lambda row: self._calculate_confidence(
                row['è¥é”€å æ¯”'], row['è¥é”€é˜ˆå€¼'], boundary_range
            ), axis=1
        )
        product_data['æ¯›åˆ©ç½®ä¿¡åº¦'] = product_data.apply(
            lambda row: self._calculate_confidence(
                row['æ¯›åˆ©ç‡'], row['æ¯›åˆ©é˜ˆå€¼'], boundary_range
            ), axis=1
        )
        product_data['åŠ¨é”€ç½®ä¿¡åº¦'] = product_data.apply(
            lambda row: self._calculate_confidence(
                row.get('å”®ç½„ç‡', row['æœˆå”®']/row['æœˆå”®é˜ˆå€¼']), 
                row['å”®ç½„ç‡é˜ˆå€¼'], 
                boundary_range
            ), axis=1
        )
        
        # ç»¼åˆç½®ä¿¡åº¦(å–æœ€ä½)
        product_data['åˆ†ç±»ç½®ä¿¡åº¦'] = product_data[[
            'è¥é”€ç½®ä¿¡åº¦', 'æ¯›åˆ©ç½®ä¿¡åº¦', 'åŠ¨é”€ç½®ä¿¡åº¦'
        ]].min(axis=1)
        
        # è±¡é™æ˜ å°„
        quadrant_map = {
            ('é«˜è¥é”€', 'é«˜æ¯›åˆ©', 'é«˜åŠ¨é”€'): ('Q1', 'ğŸ’°é‡‘ç‰›è¿‡åº¦', 'P1', 'é™ä½è¥é”€æŠ•å…¥,æµ‹è¯•ä»·æ ¼å¼¹æ€§'),
            ('é«˜è¥é”€', 'é«˜æ¯›åˆ©', 'ä½åŠ¨é”€'): ('Q2', 'âš ï¸é«˜æˆæœ¬è“„å®¢', 'P2', 'ä¼˜åŒ–è¥é”€ç­–ç•¥æˆ–è€ƒè™‘é€€å‡º'),
            ('é«˜è¥é”€', 'ä½æ¯›åˆ©', 'é«˜åŠ¨é”€'): ('Q3', 'ğŸ”´å¼•æµäºæŸ', 'P1', 'æä»·æˆ–å‡å°‘è¥é”€,è­¦æƒ•äºæŸ'),
            ('é«˜è¥é”€', 'ä½æ¯›åˆ©', 'ä½åŠ¨é”€'): ('Q4', 'âŒåŒè¾“å•†å“', 'P0', 'ç«‹å³åœæ­¢è¥é”€æˆ–ä¸‹æ¶'),
            ('ä½è¥é”€', 'é«˜æ¯›åˆ©', 'é«˜åŠ¨é”€'): ('Q5', 'â­é»„é‡‘å•†å“', 'OK', 'ä¿æŒç­–ç•¥,å¯é€‚åº¦åŠ å¤§è¥é”€'),
            ('ä½è¥é”€', 'é«˜æ¯›åˆ©', 'ä½åŠ¨é”€'): ('Q6', 'ğŸ’æ½œåŠ›å•†å“', 'P3', 'å¢åŠ è¥é”€æŠ•å…¥,æå‡æ›å…‰'),
            ('ä½è¥é”€', 'ä½æ¯›åˆ©', 'é«˜åŠ¨é”€'): ('Q7', 'ğŸ¯å¼•æµçˆ†æ¬¾', 'OK', 'ç»´æŒç°çŠ¶,æ­é…é«˜æ¯›åˆ©å•†å“'),
            ('ä½è¥é”€', 'ä½æ¯›åˆ©', 'ä½åŠ¨é”€'): ('Q8', 'ğŸ—‘ï¸æ·˜æ±°åŒº', 'P4', 'è€ƒè™‘æ¸…ä»“æˆ–ä¸‹æ¶')
        }
        
        product_data['è±¡é™ç»„åˆ'] = list(zip(
            product_data['è¥é”€ç­‰çº§'],
            product_data['æ¯›åˆ©ç­‰çº§'],
            product_data['åŠ¨é”€ç­‰çº§']
        ))
        
        quadrant_info = product_data['è±¡é™ç»„åˆ'].map(
            lambda x: quadrant_map.get(x, ('Q0', 'æœªåˆ†ç±»', 'P5', 'éœ€äººå·¥åˆ¤æ–­'))
        )
        product_data[['è±¡é™ç¼–å·', 'è±¡é™åç§°', 'ä¼˜å…ˆçº§', 'ä¼˜åŒ–å»ºè®®']] = pd.DataFrame(
            quadrant_info.tolist(),
            index=product_data.index
        )
        
        # ğŸ†• ç½®ä¿¡åº¦æ ‡ç­¾
        product_data['ç½®ä¿¡åº¦æ ‡ç­¾'] = product_data['åˆ†ç±»ç½®ä¿¡åº¦'].apply(
            lambda x: 'é«˜ç½®ä¿¡' if x > 0.7 else ('ä¸­ç½®ä¿¡' if x > 0.4 else 'ä½ç½®ä¿¡')
        )
        
        # ğŸ†• å¢å¼ºå»ºè®®(ç»“åˆç½®ä¿¡åº¦)
        product_data['å¢å¼ºå»ºè®®'] = product_data.apply(
            lambda row: self._generate_enhanced_advice(row), axis=1
        )
        
        # æ¸…ç†ä¸´æ—¶åˆ—
        product_data = product_data.drop(columns=['è±¡é™ç»„åˆ'])
        
        # æ’åº
        priority_order = ['P0', 'P1', 'P2', 'P3', 'P4', 'OK', 'P5']
        product_data['ä¼˜å…ˆçº§æ’åº'] = product_data['ä¼˜å…ˆçº§'].map(
            {p: i for i, p in enumerate(priority_order)}
        )
        product_data = product_data.sort_values(
            ['ä¼˜å…ˆçº§æ’åº', 'åˆ©æ¶¦é¢'],
            ascending=[True, False]
        ).drop(columns=['ä¼˜å…ˆçº§æ’åº'])
        
        return product_data
    
    def _calculate_confidence(self, value: float, threshold: float, boundary_range: float) -> float:
        """
        è®¡ç®—åˆ†ç±»ç½®ä¿¡åº¦
        
        Args:
            value: å®é™…å€¼
            threshold: é˜ˆå€¼
            boundary_range: è¾¹ç•ŒèŒƒå›´
        
        Returns:
            ç½®ä¿¡åº¦ (0-1),è¶Šæ¥è¿‘é˜ˆå€¼ç½®ä¿¡åº¦è¶Šä½
        """
        distance = abs(value - threshold)
        if distance > boundary_range:
            return 1.0  # é«˜ç½®ä¿¡
        else:
            # çº¿æ€§è¡°å‡: distance=0 â†’ confidence=0, distance=boundary_range â†’ confidence=1
            return distance / boundary_range
    
    def _generate_enhanced_advice(self, row: pd.Series) -> str:
        """ç”Ÿæˆå¢å¼ºå»ºè®®"""
        base_advice = row['ä¼˜åŒ–å»ºè®®']
        confidence = row['ç½®ä¿¡åº¦æ ‡ç­¾']
        
        if confidence == 'ä½ç½®ä¿¡':
            return f"{base_advice} (âš ï¸è¾¹ç•Œå•†å“,å»ºè®®äººå·¥å¤æ ¸)"
        elif confidence == 'ä¸­ç½®ä¿¡':
            return f"{base_advice} (â„¹ï¸æ¥è¿‘é˜ˆå€¼,å¯†åˆ‡å…³æ³¨)"
        else:
            return base_advice
    
    def calculate_trend(self, days_split: int = 15) -> pd.DataFrame:
        """
        è®¡ç®—è¶‹åŠ¿(éœ€è¦æœ‰æ—¥æœŸå­—æ®µ)
        
        Args:
            days_split: æ•°æ®åˆ†å‰²ç‚¹(é»˜è®¤15å¤©,å‰åå„15å¤©)
        
        Returns:
            åŒ…å«è¶‹åŠ¿æ ‡ç­¾çš„DataFrame
        """
        if 'æ—¥æœŸ' not in self.data.columns:
            print("âš ï¸ æ•°æ®ä¸­ç¼ºå°‘æ—¥æœŸå­—æ®µ,æ— æ³•è®¡ç®—è¶‹åŠ¿")
            return self._aggregate_to_product_level()
        
        self.data['æ—¥æœŸ'] = pd.to_datetime(self.data['æ—¥æœŸ'])
        max_date = self.data['æ—¥æœŸ'].max()
        min_date = self.data['æ—¥æœŸ'].min()
        split_date = max_date - pd.Timedelta(days=days_split)
        
        if split_date <= min_date:
            print(f"âš ï¸ æ•°æ®è·¨åº¦ä¸è¶³{days_split*2}å¤©,æ— æ³•è®¡ç®—è¶‹åŠ¿")
            return self._aggregate_to_product_level()
        
        # å‰æœŸå’ŒåæœŸæ•°æ®
        early_data = self.data[self.data['æ—¥æœŸ'] < split_date]
        recent_data = self.data[self.data['æ—¥æœŸ'] >= split_date]
        
        # èšåˆ
        def aggregate_period(df):
            return df.groupby('å•†å“åç§°').agg({
                'æœˆå”®': 'sum',
                'åˆ©æ¶¦é¢': 'sum',
                'å®æ”¶ä»·æ ¼': 'sum'
            }).add_suffix('_period')
        
        early_agg = aggregate_period(early_data)
        recent_agg = aggregate_period(recent_data)
        
        # åˆå¹¶
        trend_data = early_agg.merge(recent_agg, left_index=True, right_index=True, how='outer').fillna(0)
        
        # è®¡ç®—å˜åŒ–ç‡
        trend_data['é”€é‡å˜åŒ–ç‡'] = np.where(
            trend_data['æœˆå”®_period_x'] > 0,
            (trend_data['æœˆå”®_period_y'] - trend_data['æœˆå”®_period_x']) / trend_data['æœˆå”®_period_x'],
            0
        )
        trend_data['åˆ©æ¶¦å˜åŒ–ç‡'] = np.where(
            trend_data['åˆ©æ¶¦é¢_period_x'] > 0,
            (trend_data['åˆ©æ¶¦é¢_period_y'] - trend_data['åˆ©æ¶¦é¢_period_x']) / trend_data['åˆ©æ¶¦é¢_period_x'],
            0
        )
        
        # è¶‹åŠ¿æ ‡ç­¾
        trend_data['é”€é‡è¶‹åŠ¿'] = trend_data['é”€é‡å˜åŒ–ç‡'].apply(
            lambda x: 'ä¸Šå‡â¬†ï¸' if x > 0.1 else ('ä¸‹é™â¬‡ï¸' if x < -0.1 else 'å¹³ç¨³â†’')
        )
        trend_data['åˆ©æ¶¦è¶‹åŠ¿'] = trend_data['åˆ©æ¶¦å˜åŒ–ç‡'].apply(
            lambda x: 'ä¸Šå‡â¬†ï¸' if x > 0.1 else ('ä¸‹é™â¬‡ï¸' if x < -0.1 else 'å¹³ç¨³â†’')
        )
        
        return trend_data.reset_index()
    
    def generate_diagnostic_report(self, product_name: str) -> str:
        """
        ç”Ÿæˆå•å“è¯Šæ–­æŠ¥å‘Š
        
        Args:
            product_name: å•†å“åç§°
        
        Returns:
            è¯Šæ–­æŠ¥å‘Šæ–‡æœ¬
        """
        product_data = self.analyze_with_confidence()
        
        if product_name not in product_data['å•†å“åç§°'].values:
            return f"âŒ æœªæ‰¾åˆ°å•†å“: {product_name}"
        
        product = product_data[product_data['å•†å“åç§°'] == product_name].iloc[0]
        
        report = f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  ğŸ“¦ {product_name} - æ·±åº¦è¯Šæ–­æŠ¥å‘Š
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ã€åŸºç¡€ä¿¡æ¯ã€‘
  è±¡é™: {product['è±¡é™åç§°']} ({product['è±¡é™ç¼–å·']})
  ä¼˜å…ˆçº§: {product['ä¼˜å…ˆçº§']}
  ç½®ä¿¡åº¦: {product['ç½®ä¿¡åº¦æ ‡ç­¾']} ({product['åˆ†ç±»ç½®ä¿¡åº¦']:.1%})

ã€æ ¸å¿ƒæŒ‡æ ‡ã€‘
  ğŸ’° åˆ©æ¶¦è´¡çŒ®: Â¥{product['åˆ©æ¶¦é¢']:.2f} (æ¯›åˆ©ç‡: {product['æ¯›åˆ©ç‡']:.1%})
  ğŸ“Š é”€é‡: {product['æœˆå”®']:.0f}ä»¶
  ğŸ’¸ è¥é”€å æ¯”: {product['è¥é”€å æ¯”']:.1%} (é˜ˆå€¼: {product['è¥é”€é˜ˆå€¼']:.1%})
  ğŸ”„ åŠ¨é”€ç‡: {product.get('åŠ¨é”€ç‡', 0):.1%} (é˜ˆå€¼: {product['åŠ¨é”€ç‡é˜ˆå€¼']:.1%})

ã€ç›¸å¯¹ä½ç½®ã€‘
  è¥é”€ç­‰çº§: {product['è¥é”€ç­‰çº§']} (ç½®ä¿¡åº¦: {product['è¥é”€ç½®ä¿¡åº¦']:.1%})
  æ¯›åˆ©ç­‰çº§: {product['æ¯›åˆ©ç­‰çº§']} (ç½®ä¿¡åº¦: {product['æ¯›åˆ©ç½®ä¿¡åº¦']:.1%})
  åŠ¨é”€ç­‰çº§: {product['åŠ¨é”€ç­‰çº§']} (ç½®ä¿¡åº¦: {product['åŠ¨é”€ç½®ä¿¡åº¦']:.1%})

ã€ä¼˜åŒ–å»ºè®®ã€‘
  {product['å¢å¼ºå»ºè®®']}

ã€é˜ˆå€¼è¯´æ˜ã€‘
  {'âœ… ä½¿ç”¨å“ç±»åŠ¨æ€é˜ˆå€¼' if self.use_category_threshold and self.category_col else 'âš ï¸ ä½¿ç”¨å…¨å±€å›ºå®šé˜ˆå€¼'}
  {'(å“ç±»: ' + str(product.get(self.category_col, '')) + ')' if self.category_col else ''}
"""
        return report


# ==================== ä½¿ç”¨ç¤ºä¾‹ ====================
if __name__ == '__main__':
    print("=" * 80)
    print("ğŸ”¬ ç§‘å­¦çš„å…«è±¡é™åˆ†æå™¨ - ä½¿ç”¨æŒ‡å—")
    print("=" * 80)
    print()
    print("æ ¸å¿ƒæ”¹è¿›:")
    print("  1. âœ… å“ç±»åŠ¨æ€é˜ˆå€¼ - ä¸åŒå“ç±»ä¸åŒæ ‡å‡†")
    print("  2. âœ… ç½®ä¿¡åº¦è¯„ä¼° - æ ‡è®°è¾¹ç•Œå•†å“")
    print("  3. âœ… è¶‹åŠ¿åˆ†æ - åˆ©ç”¨30å¤©æ•°æ®åˆ†æè¶‹åŠ¿")
    print("  4. âœ… å¢å¼ºå»ºè®® - ç»“åˆç½®ä¿¡åº¦ç»™å‡ºå»ºè®®")
    print()
    print("ä½¿ç”¨æ–¹æ³•:")
    print("```python")
    print("# åˆå§‹åŒ–åˆ†æå™¨")
    print("analyzer = ScientificQuadrantAnalyzer(df, use_category_threshold=True)")
    print()
    print("# è·å–å“ç±»é˜ˆå€¼")
    print("thresholds = analyzer.calculate_category_thresholds()")
    print("print(thresholds)")
    print()
    print("# æ‰§è¡Œåˆ†æ")
    print("result = analyzer.analyze_with_confidence()")
    print()
    print("# æŸ¥çœ‹ä½ç½®ä¿¡åº¦å•†å“(éœ€è¦äººå·¥å¤æ ¸)")
    print("low_confidence = result[result['ç½®ä¿¡åº¦æ ‡ç­¾'] == 'ä½ç½®ä¿¡']")
    print()
    print("# ç”Ÿæˆå•å“è¯Šæ–­")
    print("report = analyzer.generate_diagnostic_report('è´ç‰¹å¹‚å•¤é…’')")
    print("print(report)")
    print()
    print("# è®¡ç®—è¶‹åŠ¿")
    print("trend_data = analyzer.calculate_trend(days_split=15)")
    print("```")
    print()
    print("ğŸ’¡ å»ºè®®:")
    print("  - å…ˆè¿è¡Œå“ç±»é˜ˆå€¼è¯Šæ–­å·¥å…·,äº†è§£å„å“ç±»å·®å¼‚")
    print("  - å¦‚æœå“ç±»å·®å¼‚å¤§(>30%),ä½¿ç”¨å“ç±»åŠ¨æ€é˜ˆå€¼")
    print("  - ä½ç½®ä¿¡åº¦å•†å“éœ€è¦äººå·¥å¤æ ¸,ä¸è¦ç›²ç›®æ‰§è¡Œå»ºè®®")
    print("  - ç»“åˆè¶‹åŠ¿åˆ†æ,é¢„åˆ¤å•†å“æœªæ¥èµ°å‘")
