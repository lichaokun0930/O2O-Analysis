#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Redisç¼“å­˜ç®¡ç†æ¨¡å—
ç”¨äºå¤šç”¨æˆ·åœºæ™¯ä¸‹çš„æ•°æ®ç¼“å­˜å…±äº«
"""

import redis
import pickle
import hashlib
import json
from datetime import datetime, timedelta
from typing import Any, Optional, Dict, List
import pandas as pd
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class RedisCacheManager:
    """Redisç¼“å­˜ç®¡ç†å™¨ - æ”¯æŒå¤šç”¨æˆ·æ•°æ®å…±äº«"""
    
    def __init__(
        self, 
        host: str = 'localhost', 
        port: int = 6379, 
        db: int = 0,
        password: Optional[str] = None,
        default_ttl: int = 3600  # é»˜è®¤1å°æ—¶è¿‡æœŸ
    ):
        """
        åˆå§‹åŒ–Redisè¿æ¥
        
        Args:
            host: RedisæœåŠ¡å™¨åœ°å€
            port: Redisç«¯å£
            db: æ•°æ®åº“ç¼–å·
            password: å¯†ç ï¼ˆå¦‚æœ‰ï¼‰
            default_ttl: é»˜è®¤è¿‡æœŸæ—¶é—´ï¼ˆç§’ï¼‰
        """
        self.default_ttl = default_ttl
        self.enabled = False
        
        try:
            self.client = redis.Redis(
                host=host,
                port=port,
                db=db,
                password=password,
                decode_responses=False,  # ä¿æŒäºŒè¿›åˆ¶æ¨¡å¼ï¼Œç”¨äºpickle
                socket_connect_timeout=5,  # å¢åŠ è¶…æ—¶æ—¶é—´åˆ°5ç§’
                socket_timeout=5,
                retry_on_timeout=True  # è¶…æ—¶è‡ªåŠ¨é‡è¯•
            )
            
            # æµ‹è¯•è¿æ¥ï¼ˆå¢åŠ é‡è¯•é€»è¾‘ï¼‰
            max_retries = 3
            for attempt in range(max_retries):
                try:
                    self.client.ping()
                    self.enabled = True
                    logger.info(f"âœ… Redisè¿æ¥æˆåŠŸ: {host}:{port}/{db}")
                    break
                except redis.TimeoutError:
                    if attempt < max_retries - 1:
                        logger.warning(f"âš ï¸ Redisè¿æ¥è¶…æ—¶ï¼Œé‡è¯• {attempt + 1}/{max_retries}...")
                        import time
                        time.sleep(1)
                    else:
                        raise
            
        except redis.ConnectionError as e:
            logger.warning(f"âš ï¸  Redisè¿æ¥å¤±è´¥ï¼Œç¼“å­˜åŠŸèƒ½å·²ç¦ç”¨: {e}")
            self.client = None
            self.enabled = False
        except Exception as e:
            logger.error(f"âŒ Redisåˆå§‹åŒ–é”™è¯¯: {e}")
            self.client = None
            self.enabled = False
    
    def _generate_key(self, prefix: str, **kwargs) -> str:
        """
        ç”Ÿæˆç¼“å­˜é”®
        
        Args:
            prefix: é”®å‰ç¼€ï¼ˆå¦‚ 'store_data', 'analysis_result'ï¼‰
            **kwargs: ç”¨äºç”Ÿæˆé”®çš„å‚æ•°
            
        Returns:
            æ ¼å¼åŒ–çš„ç¼“å­˜é”®
        """
        # å¯¹å‚æ•°æ’åºå¹¶åºåˆ—åŒ–
        params_str = json.dumps(kwargs, sort_keys=True)
        params_hash = hashlib.md5(params_str.encode()).hexdigest()[:8]
        
        return f"o2o_dashboard:{prefix}:{params_hash}"
    
    def set(
        self, 
        key: str, 
        value: Any, 
        ttl: Optional[int] = None,
        compress: bool = True
    ) -> bool:
        """
        è®¾ç½®ç¼“å­˜
        
        Args:
            key: ç¼“å­˜é”®
            value: ç¼“å­˜å€¼ï¼ˆæ”¯æŒDataFrameã€dictç­‰ï¼‰
            ttl: è¿‡æœŸæ—¶é—´ï¼ˆç§’ï¼‰ï¼ŒNoneä½¿ç”¨é»˜è®¤å€¼
            compress: æ˜¯å¦å‹ç¼©ï¼ˆæ¨èDataFrameä½¿ç”¨ï¼‰
            
        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        if not self.enabled:
            return False
        
        try:
            # åºåˆ—åŒ–æ•°æ®
            if isinstance(value, pd.DataFrame):
                # DataFrameç‰¹æ®Šå¤„ç†
                serialized = pickle.dumps({
                    'type': 'dataframe',
                    'data': value.to_dict('records'),
                    'columns': value.columns.tolist(),
                    'index': value.index.tolist()
                })
            else:
                serialized = pickle.dumps({
                    'type': 'generic',
                    'data': value
                })
            
            # è®¾ç½®ç¼“å­˜
            ttl = ttl or self.default_ttl
            self.client.setex(
                name=key,
                time=ttl,
                value=serialized
            )
            
            logger.info(f"âœ… ç¼“å­˜å·²ä¿å­˜: {key} (TTL={ttl}ç§’, å¤§å°={len(serialized)/1024:.1f}KB)")
            return True
            
        except Exception as e:
            logger.error(f"âŒ ç¼“å­˜ä¿å­˜å¤±è´¥ {key}: {e}")
            return False
    
    def get(self, key: str) -> Optional[Any]:
        """
        è·å–ç¼“å­˜
        
        Args:
            key: ç¼“å­˜é”®
            
        Returns:
            ç¼“å­˜å€¼ï¼Œä¸å­˜åœ¨è¿”å›None
        """
        if not self.enabled:
            return None
        
        try:
            serialized = self.client.get(key)
            if serialized is None:
                logger.debug(f"â­ï¸  ç¼“å­˜æœªå‘½ä¸­: {key}")
                return None
            
            # ååºåˆ—åŒ–
            data_obj = pickle.loads(serialized)
            
            if data_obj['type'] == 'dataframe':
                # é‡å»ºDataFrame
                df = pd.DataFrame(data_obj['data'], columns=data_obj['columns'])
                df.index = data_obj['index']
                logger.info(f"âœ… ç¼“å­˜å‘½ä¸­: {key} (DataFrame {df.shape})")
                return df
            else:
                logger.info(f"âœ… ç¼“å­˜å‘½ä¸­: {key}")
                return data_obj['data']
                
        except Exception as e:
            logger.error(f"âŒ ç¼“å­˜è¯»å–å¤±è´¥ {key}: {e}")
            return None
    
    def delete(self, key: str) -> bool:
        """åˆ é™¤ç¼“å­˜"""
        if not self.enabled:
            return False
        
        try:
            result = self.client.delete(key)
            logger.info(f"ğŸ—‘ï¸  ç¼“å­˜å·²åˆ é™¤: {key}")
            return result > 0
        except Exception as e:
            logger.error(f"âŒ ç¼“å­˜åˆ é™¤å¤±è´¥ {key}: {e}")
            return False
    
    def exists(self, key: str) -> bool:
        """æ£€æŸ¥ç¼“å­˜æ˜¯å¦å­˜åœ¨"""
        if not self.enabled:
            return False
        
        try:
            return self.client.exists(key) > 0
        except Exception as e:
            logger.error(f"âŒ ç¼“å­˜æ£€æŸ¥å¤±è´¥ {key}: {e}")
            return False
    
    def get_ttl(self, key: str) -> int:
        """è·å–ç¼“å­˜å‰©ä½™æ—¶é—´ï¼ˆç§’ï¼‰"""
        if not self.enabled:
            return -1
        
        try:
            return self.client.ttl(key)
        except Exception as e:
            logger.error(f"âŒ TTLæŸ¥è¯¢å¤±è´¥ {key}: {e}")
            return -1
    
    def clear_pattern(self, pattern: str) -> int:
        """
        æ‰¹é‡åˆ é™¤åŒ¹é…çš„ç¼“å­˜
        
        Args:
            pattern: é”®æ¨¡å¼ï¼ˆæ”¯æŒé€šé…ç¬¦*ï¼‰
            
        Returns:
            åˆ é™¤çš„é”®æ•°é‡
        """
        if not self.enabled:
            return 0
        
        try:
            keys = self.client.keys(pattern)
            if keys:
                deleted = self.client.delete(*keys)
                logger.info(f"ğŸ—‘ï¸  æ‰¹é‡åˆ é™¤ç¼“å­˜: {pattern} ({deleted}ä¸ª)")
                return deleted
            return 0
        except Exception as e:
            logger.error(f"âŒ æ‰¹é‡åˆ é™¤å¤±è´¥ {pattern}: {e}")
            return 0
    
    def get_stats(self) -> Dict[str, Any]:
        """è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
        if not self.enabled:
            return {
                'enabled': False,
                'message': 'Redisæœªå¯ç”¨'
            }
        
        try:
            info = self.client.info('stats')
            memory = self.client.info('memory')
            
            return {
                'enabled': True,
                'total_keys': self.client.dbsize(),
                'used_memory_mb': round(memory.get('used_memory', 0) / 1024 / 1024, 2),
                'total_commands': info.get('total_commands_processed', 0),
                'hits': info.get('keyspace_hits', 0),
                'misses': info.get('keyspace_misses', 0),
                'hit_rate': round(
                    info.get('keyspace_hits', 0) / 
                    max(info.get('keyspace_hits', 0) + info.get('keyspace_misses', 0), 1) * 100,
                    2
                )
            }
        except Exception as e:
            logger.error(f"âŒ ç»Ÿè®¡ä¿¡æ¯è·å–å¤±è´¥: {e}")
            return {'enabled': False, 'error': str(e)}


# =============================================================================
# ç¼“å­˜è£…é¥°å™¨ - è‡ªåŠ¨ç¼“å­˜å‡½æ•°ç»“æœ
# =============================================================================

def redis_cache(
    cache_manager: RedisCacheManager,
    key_prefix: str,
    ttl: Optional[int] = None,
    key_params: Optional[List[str]] = None
):
    """
    Redisç¼“å­˜è£…é¥°å™¨
    
    Args:
        cache_manager: Redisç¼“å­˜ç®¡ç†å™¨å®ä¾‹
        key_prefix: ç¼“å­˜é”®å‰ç¼€
        ttl: è¿‡æœŸæ—¶é—´ï¼ˆç§’ï¼‰
        key_params: ç”¨äºç”Ÿæˆç¼“å­˜é”®çš„å‚æ•°ååˆ—è¡¨
        
    Example:
        @redis_cache(redis_manager, 'store_analysis', ttl=1800, key_params=['store_name', 'date'])
        def analyze_store(store_name, date):
            # è€—æ—¶è®¡ç®—...
            return result
    """
    def decorator(func):
        def wrapper(*args, **kwargs):
            # å¦‚æœRedisæœªå¯ç”¨ï¼Œç›´æ¥æ‰§è¡Œå‡½æ•°
            if not cache_manager.enabled:
                return func(*args, **kwargs)
            
            # ç”Ÿæˆç¼“å­˜é”®
            cache_params = {}
            if key_params:
                # ä½¿ç”¨æŒ‡å®šå‚æ•°
                func_args = inspect.signature(func).parameters
                arg_names = list(func_args.keys())
                
                for i, param_name in enumerate(key_params):
                    if i < len(args):
                        cache_params[param_name] = args[i]
                    elif param_name in kwargs:
                        cache_params[param_name] = kwargs[param_name]
            else:
                # ä½¿ç”¨æ‰€æœ‰å‚æ•°
                cache_params = {
                    'args': str(args),
                    'kwargs': str(kwargs)
                }
            
            cache_key = cache_manager._generate_key(key_prefix, **cache_params)
            
            # å°è¯•ä»ç¼“å­˜è¯»å–
            cached_result = cache_manager.get(cache_key)
            if cached_result is not None:
                logger.info(f"ğŸ¯ ç¼“å­˜å‘½ä¸­: {func.__name__}")
                return cached_result
            
            # æ‰§è¡Œå‡½æ•°
            logger.info(f"âš™ï¸  ç¼“å­˜æœªå‘½ä¸­ï¼Œæ‰§è¡Œè®¡ç®—: {func.__name__}")
            result = func(*args, **kwargs)
            
            # ä¿å­˜åˆ°ç¼“å­˜
            cache_manager.set(cache_key, result, ttl=ttl)
            
            return result
        
        return wrapper
    return decorator


# =============================================================================
# é¢„å®šä¹‰ç¼“å­˜ç®¡ç†å™¨å®ä¾‹ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰
# =============================================================================

# å…¨å±€ç¼“å­˜ç®¡ç†å™¨å®ä¾‹
_global_cache_manager: Optional[RedisCacheManager] = None


def get_cache_manager(
    host: str = 'localhost',
    port: int = 6379,
    **kwargs
) -> RedisCacheManager:
    """
    è·å–å…¨å±€ç¼“å­˜ç®¡ç†å™¨å®ä¾‹ï¼ˆå•ä¾‹ï¼‰
    
    Args:
        host: RedisæœåŠ¡å™¨åœ°å€
        port: Redisç«¯å£
        **kwargs: å…¶ä»–é…ç½®å‚æ•°
        
    Returns:
        RedisCacheManagerå®ä¾‹
    """
    global _global_cache_manager
    
    if _global_cache_manager is None:
        _global_cache_manager = RedisCacheManager(host=host, port=port, **kwargs)
    
    return _global_cache_manager


# =============================================================================
# å¿«æ·å‡½æ•° - ç®€åŒ–ä½¿ç”¨
# =============================================================================

def cache_dataframe(
    key: str,
    df: pd.DataFrame,
    ttl: int = 3600,
    cache_manager: Optional[RedisCacheManager] = None
) -> bool:
    """
    å¿«æ·ç¼“å­˜DataFrame
    
    Args:
        key: ç¼“å­˜é”®
        df: DataFrame
        ttl: è¿‡æœŸæ—¶é—´ï¼ˆç§’ï¼‰
        cache_manager: ç¼“å­˜ç®¡ç†å™¨ï¼ˆå¯é€‰ï¼‰
        
    Returns:
        æ˜¯å¦æˆåŠŸ
    """
    manager = cache_manager or get_cache_manager()
    return manager.set(key, df, ttl=ttl)


def get_cached_dataframe(
    key: str,
    cache_manager: Optional[RedisCacheManager] = None
) -> Optional[pd.DataFrame]:
    """
    å¿«æ·è·å–ç¼“å­˜çš„DataFrame
    
    Args:
        key: ç¼“å­˜é”®
        cache_manager: ç¼“å­˜ç®¡ç†å™¨ï¼ˆå¯é€‰ï¼‰
        
    Returns:
        DataFrameæˆ–None
    """
    manager = cache_manager or get_cache_manager()
    return manager.get(key)


def clear_store_cache(
    store_name: str,
    cache_manager: Optional[RedisCacheManager] = None
) -> int:
    """
    æ¸…é™¤æŒ‡å®šé—¨åº—çš„æ‰€æœ‰ç¼“å­˜
    
    Args:
        store_name: é—¨åº—åç§°
        cache_manager: ç¼“å­˜ç®¡ç†å™¨ï¼ˆå¯é€‰ï¼‰
        
    Returns:
        åˆ é™¤çš„ç¼“å­˜æ•°é‡
    """
    manager = cache_manager or get_cache_manager()
    pattern = f"o2o_dashboard:*:{store_name}*"
    return manager.clear_pattern(pattern)


# =============================================================================
# æµ‹è¯•å’Œè°ƒè¯•
# =============================================================================

if __name__ == "__main__":
    import inspect
    
    print("=" * 70)
    print(" Redisç¼“å­˜ç®¡ç†å™¨æµ‹è¯•")
    print("=" * 70)
    
    # åˆå§‹åŒ–
    cache = RedisCacheManager(host='localhost', port=6379)
    
    if cache.enabled:
        print("\n1ï¸âƒ£ æµ‹è¯•åŸºæœ¬æ“ä½œ")
        
        # è®¾ç½®ç¼“å­˜
        cache.set('test_key', {'data': 'test_value'}, ttl=60)
        
        # è·å–ç¼“å­˜
        value = cache.get('test_key')
        print(f"   è¯»å–ç¼“å­˜: {value}")
        
        # TTL
        ttl = cache.get_ttl('test_key')
        print(f"   å‰©ä½™æ—¶é—´: {ttl}ç§’")
        
        print("\n2ï¸âƒ£ æµ‹è¯•DataFrameç¼“å­˜")
        
        # åˆ›å»ºæµ‹è¯•DataFrame
        test_df = pd.DataFrame({
            'å•†å“': ['è‹¹æœ', 'é¦™è•‰', 'æ©™å­'],
            'é”€é‡': [100, 200, 150],
            'é‡‘é¢': [500, 600, 450]
        })
        
        # ç¼“å­˜DataFrame
        cache_dataframe('test_df', test_df, ttl=300)
        
        # è¯»å–DataFrame
        cached_df = get_cached_dataframe('test_df')
        print(f"\n   ç¼“å­˜çš„DataFrame:")
        print(cached_df)
        
        print("\n3ï¸âƒ£ ç¼“å­˜ç»Ÿè®¡")
        stats = cache.get_stats()
        print(f"   æ€»é”®æ•°: {stats['total_keys']}")
        print(f"   å†…å­˜ä½¿ç”¨: {stats['used_memory_mb']} MB")
        print(f"   å‘½ä¸­ç‡: {stats['hit_rate']}%")
        
        print("\n4ï¸âƒ£ æ¸…ç†æµ‹è¯•ç¼“å­˜")
        cache.delete('test_key')
        cache.delete('test_df')
        print("   æµ‹è¯•ç¼“å­˜å·²æ¸…ç†")
        
    else:
        print("\nâš ï¸  Redisæœªå¯ç”¨ï¼Œè·³è¿‡æµ‹è¯•")
    
    print("\n" + "=" * 70)


# =============================================================================
# ğŸ”§ å¯¼å‡ºå…¨å±€ç¼“å­˜ç®¡ç†å™¨å®ä¾‹ï¼ˆç”¨äºå…¶ä»–æ¨¡å—å¯¼å…¥ï¼‰
# =============================================================================
# æ³¨æ„ï¼šå®é™…çš„å®ä¾‹ä¼šåœ¨æ™ºèƒ½é—¨åº—çœ‹æ¿_Dashç‰ˆ.pyä¸­åˆå§‹åŒ–
# è¿™é‡Œåªæ˜¯æä¾›ä¸€ä¸ªå ä½ç¬¦ï¼Œé¿å…å¯¼å…¥é”™è¯¯
REDIS_CACHE_MANAGER = None
