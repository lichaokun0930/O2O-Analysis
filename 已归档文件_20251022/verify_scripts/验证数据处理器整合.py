#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ•°æ®å¤„ç†å™¨æ•´åˆéªŒè¯è„šæœ¬
éªŒè¯çœŸå®æ•°æ®å¤„ç†å™¨ä¸é—®é¢˜è¯Šæ–­å¼•æ“çš„å­—æ®µåŒ¹é…
"""

import pandas as pd
import sys
from pathlib import Path

# æ·»åŠ è·¯å¾„
APP_DIR = Path(__file__).resolve().parent
sys.path.insert(0, str(APP_DIR))

print("=" * 80)
print("ğŸ“‹ æ•°æ®å¤„ç†å™¨æ•´åˆéªŒè¯")
print("=" * 80)

# æ­¥éª¤1: æµ‹è¯•æ•°æ®å¤„ç†å™¨å¯¼å…¥
print("\nã€æ­¥éª¤1ã€‘æµ‹è¯•æ¨¡å—å¯¼å…¥...")
try:
    from çœŸå®æ•°æ®å¤„ç†å™¨ import RealDataProcessor
    print("âœ… çœŸå®æ•°æ®å¤„ç†å™¨å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    print(f"âŒ çœŸå®æ•°æ®å¤„ç†å™¨å¯¼å…¥å¤±è´¥: {e}")
    sys.exit(1)

try:
    from é—®é¢˜è¯Šæ–­å¼•æ“ import ProblemDiagnosticEngine
    print("âœ… é—®é¢˜è¯Šæ–­å¼•æ“å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    print(f"âŒ é—®é¢˜è¯Šæ–­å¼•æ“å¯¼å…¥å¤±è´¥: {e}")
    sys.exit(1)

# æ­¥éª¤2: æŸ¥æ‰¾æ•°æ®æ–‡ä»¶
print("\nã€æ­¥éª¤2ã€‘æŸ¥æ‰¾æ•°æ®æ–‡ä»¶...")
candidate_dirs = [
    APP_DIR / "å®é™…æ•°æ®",
    APP_DIR.parent / "å®é™…æ•°æ®",
    APP_DIR / "é—¨åº—æ•°æ®",
    APP_DIR / "é—¨åº—æ•°æ®" / "æ¯”ä»·çœ‹æ¿æ¨¡å—",
]

data_file = None
for data_dir in candidate_dirs:
    if data_dir.exists():
        excel_files = sorted([f for f in data_dir.glob("*.xlsx") if not f.name.startswith("~$")])
        if excel_files:
            data_file = excel_files[0]
            print(f"âœ… æ‰¾åˆ°æ•°æ®æ–‡ä»¶: {data_file}")
            break

if not data_file:
    print("âš ï¸ æœªæ‰¾åˆ°çœŸå®æ•°æ®æ–‡ä»¶ï¼Œä½¿ç”¨æµ‹è¯•æ•°æ®")
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    df = pd.DataFrame({
        'å•†å“åç§°': ['å¯å£å¯ä¹', 'é›ªç¢§', 'èŠ¬è¾¾'],
        'å”®ä»·': [3.5, 3.0, 3.2],
        'åŸä»·': [3.0, 2.5, 2.7],
        'æœˆå”®': [1500, 1200, 800],
        'ç¾å›¢ä¸€çº§åˆ†ç±»': ['é¥®æ–™', 'é¥®æ–™', 'é¥®æ–™'],
        'ç¾å›¢ä¸‰çº§åˆ†ç±»': ['ç¢³é…¸é¥®æ–™', 'ç¢³é…¸é¥®æ–™', 'ç¢³é…¸é¥®æ–™'],
        'è®¢å•ID': ['ORD001', 'ORD001', 'ORD002'],
        'æ—¥æœŸ': pd.date_range('2025-10-01', periods=3),
        'ç‰©æµé…é€è´¹': [5, 5, 6],
        'å¹³å°ä½£é‡‘': [0.5, 0.4, 0.4]
    })
    print(f"ğŸ“Š æµ‹è¯•æ•°æ®: {len(df)} è¡Œ")
else:
    # åŠ è½½çœŸå®æ•°æ®
    print("\nã€æ­¥éª¤3ã€‘åŠ è½½çœŸå®æ•°æ®...")
    try:
        df = pd.read_excel(data_file, sheet_name=0)
        print(f"âœ… æ•°æ®åŠ è½½æˆåŠŸ: {len(df)} è¡Œ Ã— {len(df.columns)} åˆ—")
        print(f"ğŸ“‹ åŸå§‹å­—æ®µåï¼ˆå‰15ä¸ªï¼‰:")
        for i, col in enumerate(df.columns[:15], 1):
            print(f"   {i:2d}. {col}")
        if len(df.columns) > 15:
            print(f"   ... (è¿˜æœ‰ {len(df.columns) - 15} ä¸ªå­—æ®µ)")
    except Exception as e:
        print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
        sys.exit(1)

# æ­¥éª¤4: æ•°æ®æ ‡å‡†åŒ–
print("\nã€æ­¥éª¤4ã€‘æ‰§è¡Œæ•°æ®æ ‡å‡†åŒ–...")
try:
    processor = RealDataProcessor()
    df_standardized = processor.standardize_sales_data(df)
    print(f"âœ… æ ‡å‡†åŒ–å®Œæˆ: {len(df_standardized)} è¡Œ Ã— {len(df_standardized.columns)} åˆ—")
    print(f"ğŸ“‹ æ ‡å‡†åŒ–å­—æ®µåï¼ˆå‰15ä¸ªï¼‰:")
    for i, col in enumerate(df_standardized.columns[:15], 1):
        print(f"   {i:2d}. {col}")
    if len(df_standardized.columns) > 15:
        print(f"   ... (è¿˜æœ‰ {len(df_standardized.columns) - 15} ä¸ªå­—æ®µ)")
except Exception as e:
    print(f"âŒ æ ‡å‡†åŒ–å¤±è´¥: {e}")
    import traceback
    traceback.print_exc()
    sys.exit(1)

# æ­¥éª¤5: å­—æ®µåŒ¹é…æ£€æŸ¥
print("\nã€æ­¥éª¤5ã€‘æ£€æŸ¥è¯Šæ–­å¼•æ“æ‰€éœ€å­—æ®µ...")
required_fields = {
    'å¿…éœ€å­—æ®µ': ['æ—¥æœŸ', 'è®¢å•ID', 'å•†å“å®å”®ä»·', 'å•†å“åç§°'],
    'æ¯›åˆ©è®¡ç®—': ['å•†å“é‡‡è´­æˆæœ¬'],
    'é…é€è´¹åˆ†æ': ['ç‰©æµé…é€è´¹'],
    'åˆ†ç±»åˆ†æ': ['ä¸€çº§åˆ†ç±»å', 'ä¸‰çº§åˆ†ç±»å'],
    'æ—¶æ®µåˆ†æ': ['æ—¶æ®µ', 'åœºæ™¯'],
    'è§’è‰²åˆ†æ': ['å•†å“è§’è‰²']
}

field_check_results = {}
for category, fields in required_fields.items():
    missing = [f for f in fields if f not in df_standardized.columns]
    existing = [f for f in fields if f in df_standardized.columns]
    
    field_check_results[category] = {
        'existing': existing,
        'missing': missing,
        'status': 'âœ…' if len(existing) == len(fields) else 'âš ï¸' if existing else 'âŒ'
    }
    
    print(f"\n{field_check_results[category]['status']} {category}:")
    if existing:
        print(f"   âœ… å­˜åœ¨: {', '.join(existing)}")
    if missing:
        print(f"   âŒ ç¼ºå¤±: {', '.join(missing)}")

# æ­¥éª¤6: æµ‹è¯•è¯Šæ–­å¼•æ“åˆå§‹åŒ–
print("\nã€æ­¥éª¤6ã€‘æµ‹è¯•è¯Šæ–­å¼•æ“åˆå§‹åŒ–...")
try:
    diagnostic_engine = ProblemDiagnosticEngine(df_standardized)
    print("âœ… è¯Šæ–­å¼•æ“åˆå§‹åŒ–æˆåŠŸ")
    
    # æ£€æŸ¥å¼•æ“å†…éƒ¨æ•°æ®
    print(f"ğŸ“Š å¼•æ“æ•°æ®å½¢çŠ¶: {diagnostic_engine.df.shape}")
    
    # æ£€æŸ¥è¡ç”Ÿå­—æ®µ
    derived_fields = ['å•å“æ¯›åˆ©', 'å•å“æ¯›åˆ©ç‡', 'é…é€è´¹å æ¯”']
    existing_derived = [f for f in derived_fields if f in diagnostic_engine.df.columns]
    missing_derived = [f for f in derived_fields if f not in diagnostic_engine.df.columns]
    
    if existing_derived:
        print(f"âœ… è¡ç”Ÿå­—æ®µå­˜åœ¨: {', '.join(existing_derived)}")
    if missing_derived:
        print(f"âš ï¸ è¡ç”Ÿå­—æ®µç¼ºå¤±: {', '.join(missing_derived)}")
    
except Exception as e:
    print(f"âŒ è¯Šæ–­å¼•æ“åˆå§‹åŒ–å¤±è´¥: {e}")
    import traceback
    traceback.print_exc()
    sys.exit(1)

# æ­¥éª¤7: æµ‹è¯•è¯Šæ–­åŠŸèƒ½
print("\nã€æ­¥éª¤7ã€‘æµ‹è¯•è¯Šæ–­åŠŸèƒ½...")
test_functions = [
    ('è·å–å¯ç”¨å‘¨æœŸ', lambda: diagnostic_engine.get_available_periods('week')),
    ('è´Ÿæ¯›åˆ©è¯Šæ–­', lambda: diagnostic_engine.diagnose_negative_margin_products()),
]

for func_name, func in test_functions:
    try:
        result = func()
        if isinstance(result, list):
            print(f"âœ… {func_name}: è¿”å› {len(result)} æ¡è®°å½•")
        elif isinstance(result, pd.DataFrame):
            print(f"âœ… {func_name}: è¿”å› {len(result)} è¡Œæ•°æ®")
        else:
            print(f"âœ… {func_name}: è¿”å› {type(result).__name__}")
    except Exception as e:
        print(f"âŒ {func_name} å¤±è´¥: {e}")

# æ­¥éª¤8: æ•°æ®ç±»å‹æ£€æŸ¥
print("\nã€æ­¥éª¤8ã€‘æ•°æ®ç±»å‹æ£€æŸ¥...")
type_checks = {
    'å•†å“å®å”®ä»·': 'numeric',
    'å•†å“é‡‡è´­æˆæœ¬': 'numeric',
    'æ—¥æœŸ': 'datetime',
    'æœˆå”®': 'numeric'
}

for field, expected_type in type_checks.items():
    if field in df_standardized.columns:
        actual_type = df_standardized[field].dtype
        is_numeric = pd.api.types.is_numeric_dtype(actual_type)
        is_datetime = pd.api.types.is_datetime64_any_dtype(actual_type)
        
        if expected_type == 'numeric' and is_numeric:
            print(f"âœ… {field}: {actual_type} (æ•°å€¼ç±»å‹)")
        elif expected_type == 'datetime' and is_datetime:
            print(f"âœ… {field}: {actual_type} (æ—¥æœŸç±»å‹)")
        else:
            print(f"âš ï¸ {field}: {actual_type} (æœŸæœ›: {expected_type})")
    else:
        print(f"âš ï¸ {field}: å­—æ®µä¸å­˜åœ¨")

# æ€»ç»“
print("\n" + "=" * 80)
print("ğŸ“Š éªŒè¯æ€»ç»“")
print("=" * 80)

total_categories = len(field_check_results)
passed_categories = sum(1 for r in field_check_results.values() if r['status'] == 'âœ…')
partial_categories = sum(1 for r in field_check_results.values() if r['status'] == 'âš ï¸')
failed_categories = sum(1 for r in field_check_results.values() if r['status'] == 'âŒ')

print(f"\nå­—æ®µåŒ¹é…ç»“æœ:")
print(f"  âœ… å®Œå…¨åŒ¹é…: {passed_categories}/{total_categories}")
print(f"  âš ï¸ éƒ¨åˆ†åŒ¹é…: {partial_categories}/{total_categories}")
print(f"  âŒ å®Œå…¨ç¼ºå¤±: {failed_categories}/{total_categories}")

if passed_categories == total_categories:
    print("\nğŸ‰ æ•´åˆéªŒè¯é€šè¿‡ï¼æ‰€æœ‰å­—æ®µå®Œå…¨åŒ¹é…ï¼Œå¯ä»¥æ­£å¸¸ä½¿ç”¨è¯Šæ–­å¼•æ“ã€‚")
elif passed_categories + partial_categories == total_categories:
    print("\nâš ï¸ æ•´åˆåŸºæœ¬å¯ç”¨ï¼Œä½†éƒ¨åˆ†åŠŸèƒ½å¯èƒ½å—é™ã€‚")
    print("å»ºè®®: è¡¥å……ç¼ºå¤±å­—æ®µä»¥å¯ç”¨å®Œæ•´åŠŸèƒ½ã€‚")
else:
    print("\nâŒ æ•´åˆå­˜åœ¨é—®é¢˜ï¼Œéœ€è¦è¡¥å……å¿…éœ€å­—æ®µã€‚")
    print("è¯·æ£€æŸ¥æ•°æ®æ–‡ä»¶æ˜¯å¦åŒ…å«æ‰€éœ€å­—æ®µã€‚")

print("\n" + "=" * 80)
print("éªŒè¯å®Œæˆï¼")
print("=" * 80)
