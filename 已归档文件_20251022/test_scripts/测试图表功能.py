"""
æµ‹è¯•å›¾è¡¨åŠŸèƒ½
å¿«é€ŸéªŒè¯6ä¸ªå›¾è¡¨çš„å›è°ƒå‡½æ•°æ˜¯å¦æ­£å¸¸å·¥ä½œ
"""

import sys
import os
sys.path.insert(0, os.path.dirname(__file__))

# å¯¼å…¥æ ¸å¿ƒæ¨¡å—
from é—®é¢˜è¯Šæ–­å¼•æ“ import ProblemDiagnosticEngine
import pandas as pd

# åˆå§‹åŒ–æ•°æ®
data_file = "é—¨åº—æ•°æ®/2025-09-01 00_00_00è‡³2025-09-30 12_42_28è®¢å•æ˜ç»†æ•°æ®å¯¼å‡ºæ±‡æ€» (2).xlsx"

if not os.path.exists(data_file):
    print(f"âŒ æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {data_file}")
    sys.exit(1)

print("ğŸ”„ æ­£åœ¨åŠ è½½æ•°æ®...")
df_raw = pd.read_excel(data_file)
print(f"âœ… æ•°æ®åŠ è½½æˆåŠŸ: {len(df_raw)} è¡Œ")

# åˆå§‹åŒ–è¯Šæ–­å¼•æ“
print("ğŸ”§ æ­£åœ¨åˆå§‹åŒ–è¯Šæ–­å¼•æ“...")
engine = ProblemDiagnosticEngine(df_raw)

# è¿è¡Œé”€é‡ä¸‹æ»‘è¯Šæ–­
print("ğŸ“Š æ­£åœ¨è¿è¡Œé”€é‡ä¸‹æ»‘è¯Šæ–­...")
result = engine.diagnose_sales_decline()

# æ£€æŸ¥ç»“æœ
if result is not None and not result.empty:
    df_decline = result
    print(f"\nâœ… ä¸‹æ»‘è¯Šæ–­æˆåŠŸ: å‘ç° {len(df_decline)} ä¸ªä¸‹æ»‘å•†å“")
    
    # æ£€æŸ¥æ‰€éœ€å­—æ®µ
    required_fields = [
        'å•†å“åç§°', 'åœºæ™¯', 'ä¸€çº§åˆ†ç±»å', 'é”€é‡å˜åŒ–', 'æ”¶å…¥å˜åŒ–', 'åˆ©æ¶¦å˜åŒ–',
        'å¯¹æ¯”å‘¨æœŸé”€é‡', 'å½“å‰å‘¨æœŸé”€é‡', 'å•†å“å®å”®ä»·', 'å¹³å‡æ¯›åˆ©ç‡%'
    ]
    
    print("\nğŸ“‹ å­—æ®µæ£€æŸ¥:")
    for field in required_fields:
        exists = field in df_decline.columns
        status = "âœ…" if exists else "âŒ"
        print(f"  {status} {field}")
    
    # æ¨¡æ‹Ÿå›¾è¡¨æ•°æ®è®¡ç®—
    print("\nğŸ“ˆ å›¾è¡¨æ•°æ®è®¡ç®—æµ‹è¯•:")
    
    # 1. åˆ†æ—¶æ®µåˆ†å¸ƒ
    if 'åœºæ™¯' in df_decline.columns:
        slot_stats = df_decline.groupby('åœºæ™¯').size()
        print(f"  âœ… åˆ†æ—¶æ®µåˆ†å¸ƒ: {len(slot_stats)} ä¸ªåœºæ™¯")
    
    # 2. å‘¨æœŸå¯¹æ¯”
    if 'å¯¹æ¯”å‘¨æœŸé”€é‡' in df_decline.columns and 'å½“å‰å‘¨æœŸé”€é‡' in df_decline.columns:
        top10 = df_decline.nlargest(10, 'é”€é‡å˜åŒ–')
        print(f"  âœ… å‘¨æœŸå¯¹æ¯”: TOP10å•†å“")
    
    # 3. åˆ†ç±»æŸå¤±
    if 'ä¸€çº§åˆ†ç±»å' in df_decline.columns and 'æ”¶å…¥å˜åŒ–' in df_decline.columns:
        cat_loss = df_decline.groupby('ä¸€çº§åˆ†ç±»å')['æ”¶å…¥å˜åŒ–'].sum()
        print(f"  âœ… åˆ†ç±»æŸå¤±: {len(cat_loss)} ä¸ªåˆ†ç±»")
    
    # 4. åˆ†ç±»TOPå•†å“
    if 'ä¸€çº§åˆ†ç±»å' in df_decline.columns and 'é”€é‡å˜åŒ–' in df_decline.columns:
        categories = df_decline['ä¸€çº§åˆ†ç±»å'].unique()
        print(f"  âœ… åˆ†ç±»TOPå•†å“: {len(categories)} ä¸ªåˆ†ç±»")
    
    # 5. å››ç»´æ•£ç‚¹å›¾
    scatter_fields = ['é”€é‡å˜åŒ–', 'åˆ©æ¶¦å˜åŒ–', 'å•†å“å®å”®ä»·', 'å¹³å‡æ¯›åˆ©ç‡%']
    if all(f in df_decline.columns for f in scatter_fields):
        print(f"  âœ… å››ç»´æ•£ç‚¹å›¾: æ‰€æœ‰å­—æ®µé½å…¨")
    
    # 6. ä»·æ ¼åˆ†å¸ƒ
    if 'å•†å“å®å”®ä»·' in df_decline.columns:
        price_range = (df_decline['å•†å“å®å”®ä»·'].min(), df_decline['å•†å“å®å”®ä»·'].max())
        print(f"  âœ… ä»·æ ¼åˆ†å¸ƒ: èŒƒå›´ Â¥{price_range[0]:.2f} - Â¥{price_range[1]:.2f}")
    
    print("\n" + "="*60)
    print("ğŸ‰ æ‰€æœ‰å›¾è¡¨æ•°æ®å‡†å¤‡å°±ç»ªï¼")
    print("ğŸ’¡ å¯ä»¥å¯åŠ¨Dashåº”ç”¨æŸ¥çœ‹å¯è§†åŒ–æ•ˆæœ")
    print("   è¿è¡Œå‘½ä»¤: python æ™ºèƒ½é—¨åº—çœ‹æ¿_Dashç‰ˆ.py")
    print("="*60)

else:
    print("âŒ æœªå‘ç°ä¸‹æ»‘å•†å“ï¼Œæ— æ³•æµ‹è¯•å›¾è¡¨åŠŸèƒ½")
