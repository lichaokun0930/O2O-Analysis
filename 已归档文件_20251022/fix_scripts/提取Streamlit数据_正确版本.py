#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æå–Streamlitç‰ˆæœ¬çš„æ•°æ®åŸºå‡† - æ­£ç¡®ç‰ˆæœ¬
å®Œå…¨æŒ‰ç…§Streamlitçš„è®¡ç®—é€»è¾‘ï¼ˆè®¢å•çº§åˆ«èšåˆï¼‰
"""

import pandas as pd
import sys
import json
from pathlib import Path

APP_DIR = Path(__file__).resolve().parent

# å¯¼å…¥çœŸå®æ•°æ®å¤„ç†å™¨
sys.path.insert(0, str(APP_DIR))
from çœŸå®æ•°æ®å¤„ç†å™¨ import RealDataProcessor

def load_and_standardize_data():
    """åŠ è½½æ•°æ®å¹¶åº”ç”¨Streamlitçš„ä¸šåŠ¡è§„åˆ™"""
    print("=" * 80)
    print("ğŸ“‚ åŠ è½½æ•°æ®å¹¶æ ‡å‡†åŒ–")
    print("=" * 80)
    
    # åŠ è½½Excelæ–‡ä»¶
    excel_file = APP_DIR / "é—¨åº—æ•°æ®" / "2025-09-01 00_00_00è‡³2025-09-30 12_42_28è®¢å•æ˜ç»†æ•°æ®å¯¼å‡ºæ±‡æ€» (2).xlsx"
    
    if not excel_file.exists():
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {excel_file}")
        return None
    
    print(f"ğŸ“„ è¯»å–æ–‡ä»¶: {excel_file.name}")
    df = pd.read_excel(excel_file)
    print(f"ğŸ“Š åŸå§‹æ•°æ®åŠ è½½: {len(df):,} è¡Œ Ã— {len(df.columns)} åˆ—")
    
    # ä½¿ç”¨RealDataProcessoræ ‡å‡†åŒ–
    processor = RealDataProcessor("å®é™…æ•°æ®")
    df_standardized = processor.standardize_sales_data(df)
    print(f"âœ… æ•°æ®æ ‡å‡†åŒ–å®Œæˆ: {len(df_standardized):,} è¡Œ")
    
    # å‰”é™¤è€—æ
    if 'ä¸€çº§åˆ†ç±»å' in df_standardized.columns:
        before_count = len(df_standardized)
        df_standardized = df_standardized[df_standardized['ä¸€çº§åˆ†ç±»å'] != 'è€—æ'].copy()
        removed_material = before_count - len(df_standardized)
        print(f"ğŸ”´ å·²å‰”é™¤è€—ææ•°æ®: {removed_material:,} è¡Œ")
        print(f"ğŸ“Š å‰”é™¤è€—æåæ•°æ®é‡: {len(df_standardized):,} è¡Œ")
    
    # å‰”é™¤å’–å•¡æ¸ é“
    if 'æ¸ é“' in df_standardized.columns:
        exclude_channels = ['é¥¿äº†ä¹ˆå’–å•¡', 'ç¾å›¢å’–å•¡']
        before_count = len(df_standardized)
        df_standardized = df_standardized[~df_standardized['æ¸ é“'].isin(exclude_channels)].copy()
        removed_coffee = before_count - len(df_standardized)
        print(f"â˜• å·²å‰”é™¤å’–å•¡æ¸ é“æ•°æ®: {removed_coffee:,} è¡Œ")
        print(f"ğŸ“Š æœ€ç»ˆæ•°æ®é‡: {len(df_standardized):,} è¡Œ")
    
    return df_standardized


def calculate_streamlit_metrics(df):
    """
    å®Œå…¨æŒ‰ç…§Streamlitç‰ˆæœ¬çš„è®¡ç®—é€»è¾‘ï¼ˆè®¢å•çº§åˆ«èšåˆï¼‰
    å‚è€ƒï¼šæ™ºèƒ½é—¨åº—ç»è¥çœ‹æ¿_å¯è§†åŒ–.py çš„ calculate_order_metrics å‡½æ•°
    """
    print("\n" + "=" * 80)
    print("ğŸ“ˆ Streamlitç‰ˆæœ¬ - è®¢å•çº§åˆ«æŒ‡æ ‡è®¡ç®—")
    print("=" * 80)
    
    if 'è®¢å•ID' not in df.columns:
        print("âŒ ç¼ºå°‘è®¢å•IDå­—æ®µï¼Œæ— æ³•è¿›è¡Œè®¢å•çº§åˆ«èšåˆ")
        return None
    
    # ========== ç¬¬1æ­¥ï¼šåˆ›å»ºè®¢å•çº§åˆ«èšåˆ ==========
    print("\nğŸ”§ æ­¥éª¤1ï¼šæŒ‰è®¢å•IDèšåˆæ˜ç»†æ•°æ®")
    
    order_agg = df.groupby('è®¢å•ID').agg({
        'å•†å“å®å”®ä»·': 'sum',           # å•†å“é”€å”®é¢ï¼ˆè®¢å•å†…æ‰€æœ‰å•†å“ï¼‰
        'å•†å“åŸä»·': 'sum',             # å•†å“åŸä»·æ€»é¢
        'å•†å“é‡‡è´­æˆæœ¬': 'sum',         # å•†å“æˆæœ¬
        'æœˆå”®': 'sum',                 # æ•°é‡
        'ç‰©æµé…é€è´¹': 'first',         # è®¢å•çº§å­—æ®µï¼ˆæ¯ä¸ªè®¢å•åªæœ‰ä¸€ä¸ªå€¼ï¼‰
        'å¹³å°ä½£é‡‘': 'first',
        'æ‰“åŒ…è¢‹é‡‘é¢': 'first',
        'ç”¨æˆ·æ”¯ä»˜é…é€è´¹': 'first',
        'é…é€è´¹å‡å…é‡‘é¢': 'first',
        'æ»¡å‡é‡‘é¢': 'first',
        'å•†å“å‡å…é‡‘é¢': 'first',
        'å•†å®¶ä»£é‡‘åˆ¸': 'first'
    }).reset_index()
    
    print(f"   ğŸ“¦ è®¢å•æ€»æ•°: {len(order_agg):,}")
    print(f"   ğŸ“¦ åŸå§‹æ˜ç»†è¡Œæ•°: {len(df):,}")
    print(f"   ğŸ“Š å¹³å‡æ¯å•å•†å“æ•°: {len(df) / len(order_agg):.1f}")
    
    # ========== ç¬¬2æ­¥ï¼šè®¡ç®—è®¢å•çº§åˆ«çš„æ”¶å…¥å’Œæˆæœ¬ ==========
    print("\nğŸ”§ æ­¥éª¤2ï¼šè®¡ç®—è®¢å•çº§åˆ«çš„æ”¶å…¥å’Œæˆæœ¬")
    
    # è®¢å•æ€»æ”¶å…¥ = å•†å“å®å”®ä»· + æ‰“åŒ…è´¹ + ç”¨æˆ·æ”¯ä»˜é…é€è´¹
    # è¿™æ˜¯Streamlitä¸­æ˜¾ç¤ºçš„"è®¢å•æ€»æ”¶å…¥"
    order_agg['è®¢å•æ€»æ”¶å…¥'] = (
        order_agg['å•†å“å®å”®ä»·'] + 
        order_agg['æ‰“åŒ…è¢‹é‡‘é¢'] + 
        order_agg['ç”¨æˆ·æ”¯ä»˜é…é€è´¹']
    )
    print(f"   ğŸ’° è®¢å•æ€»æ”¶å…¥å…¬å¼: å•†å“å®å”®ä»· + æ‰“åŒ…è´¹ + ç”¨æˆ·æ”¯ä»˜é…é€è´¹")
    
    # é…é€å‡€æˆæœ¬ = (é…é€è´¹å‡å… + ç‰©æµé…é€è´¹) - ç”¨æˆ·æ”¯ä»˜é…é€è´¹
    # Streamlitä¸­æ˜¾ç¤ºçš„"æ€»é…é€æˆæœ¬"
    order_agg['é…é€æˆæœ¬'] = (
        order_agg['é…é€è´¹å‡å…é‡‘é¢'] + 
        order_agg['ç‰©æµé…é€è´¹'] - 
        order_agg['ç”¨æˆ·æ”¯ä»˜é…é€è´¹']
    )
    print(f"   ğŸšš é…é€æˆæœ¬å…¬å¼: (é…é€è´¹å‡å… + ç‰©æµé…é€è´¹) - ç”¨æˆ·æ”¯ä»˜é…é€è´¹")
    
    # æ´»åŠ¨è¥é”€æˆæœ¬ = æ»¡å‡ + å•†å®¶ä»£é‡‘åˆ¸
    order_agg['æ´»åŠ¨è¥é”€æˆæœ¬'] = (
        order_agg['æ»¡å‡é‡‘é¢'] + 
        order_agg['å•†å®¶ä»£é‡‘åˆ¸']
    )
    print(f"   ğŸ¯ æ´»åŠ¨è¥é”€æˆæœ¬å…¬å¼: æ»¡å‡é‡‘é¢ + å•†å®¶ä»£é‡‘åˆ¸")
    
    # å•†å“æŠ˜æ‰£æˆæœ¬ = å•†å“åŸä»· - å•†å“å®å”®ä»·
    # Streamlitä¸­æ˜¾ç¤ºçš„"å•†å“æŠ˜æ‰£æˆæœ¬"
    order_agg['å•†å“æŠ˜æ‰£æˆæœ¬'] = (
        order_agg['å•†å“åŸä»·'] - 
        order_agg['å•†å“å®å”®ä»·']
    )
    print(f"   ğŸ’¸ å•†å“æŠ˜æ‰£æˆæœ¬å…¬å¼: å•†å“åŸä»· - å•†å“å®å”®ä»·")
    
    # è®¢å•å®é™…åˆ©æ¶¦ = è®¢å•æ€»æ”¶å…¥ - æˆæœ¬ - é…é€æˆæœ¬ - æ´»åŠ¨è¥é”€æˆæœ¬ - å•†å“æŠ˜æ‰£æˆæœ¬ - å¹³å°ä½£é‡‘
    order_agg['è®¢å•å®é™…åˆ©æ¶¦'] = (
        order_agg['è®¢å•æ€»æ”¶å…¥'] - 
        order_agg['å•†å“é‡‡è´­æˆæœ¬'] - 
        order_agg['é…é€æˆæœ¬'] - 
        order_agg['æ´»åŠ¨è¥é”€æˆæœ¬'] - 
        order_agg['å•†å“æŠ˜æ‰£æˆæœ¬'] - 
        order_agg['å¹³å°ä½£é‡‘']
    )
    print(f"   ğŸ’ æ€»åˆ©æ¶¦å…¬å¼: è®¢å•æ€»æ”¶å…¥ - å•†å“é‡‡è´­æˆæœ¬ - é…é€æˆæœ¬ - æ´»åŠ¨è¥é”€æˆæœ¬ - å•†å“æŠ˜æ‰£æˆæœ¬ - å¹³å°ä½£é‡‘")
    
    # ========== ç¬¬3æ­¥ï¼šç”Ÿæˆæ±‡æ€»æŒ‡æ ‡ ==========
    print("\nğŸ”§ æ­¥éª¤3ï¼šç”Ÿæˆæ±‡æ€»æŒ‡æ ‡")
    
    metrics = {}
    
    # ===== åŸºç¡€æŒ‡æ ‡ =====
    metrics['è®¢å•æ€»æ•°'] = len(order_agg)
    metrics['å•†å“SKUæ•°'] = df['å•†å“åç§°'].nunique()
    metrics['æ€»é”€é‡'] = order_agg['æœˆå”®'].sum()
    
    # ===== æ”¶å…¥æŒ‡æ ‡ =====
    metrics['å•†å“é”€å”®é¢'] = order_agg['å•†å“å®å”®ä»·'].sum()
    metrics['è®¢å•æ€»æ”¶å…¥'] = order_agg['è®¢å•æ€»æ”¶å…¥'].sum()
    metrics['å¹³å‡å®¢å•ä»·'] = metrics['å•†å“é”€å”®é¢'] / metrics['è®¢å•æ€»æ•°'] if metrics['è®¢å•æ€»æ•°'] > 0 else 0
    
    # ===== æˆæœ¬æŒ‡æ ‡ =====
    metrics['æ€»å•†å“æˆæœ¬'] = order_agg['å•†å“é‡‡è´­æˆæœ¬'].sum()
    metrics['æ€»é…é€æˆæœ¬'] = order_agg['é…é€æˆæœ¬'].sum()
    metrics['æ´»åŠ¨è¥é”€æˆæœ¬'] = order_agg['æ´»åŠ¨è¥é”€æˆæœ¬'].sum()
    metrics['å•†å“æŠ˜æ‰£æˆæœ¬'] = order_agg['å•†å“æŠ˜æ‰£æˆæœ¬'].sum()
    metrics['å¹³å°ä½£é‡‘'] = order_agg['å¹³å°ä½£é‡‘'].sum()
    
    # ===== åˆ©æ¶¦æŒ‡æ ‡ =====
    metrics['æ€»åˆ©æ¶¦é¢'] = order_agg['è®¢å•å®é™…åˆ©æ¶¦'].sum()
    metrics['å¹³å‡è®¢å•åˆ©æ¶¦'] = order_agg['è®¢å•å®é™…åˆ©æ¶¦'].mean()
    
    # ç›ˆåˆ©è®¢å•åˆ†æ
    metrics['ç›ˆåˆ©è®¢å•æ•°'] = (order_agg['è®¢å•å®é™…åˆ©æ¶¦'] > 0).sum()
    metrics['ç›ˆåˆ©è®¢å•å æ¯”'] = (order_agg['è®¢å•å®é™…åˆ©æ¶¦'] > 0).mean() * 100
    
    # åˆ©æ¶¦ç‡
    metrics['æ•´ä½“åˆ©æ¶¦ç‡'] = (metrics['æ€»åˆ©æ¶¦é¢'] / metrics['å•†å“é”€å”®é¢'] * 100) if metrics['å•†å“é”€å”®é¢'] > 0 else 0
    
    # æ¯›åˆ©ç‡
    å•å“æ¯›åˆ© = metrics['å•†å“é”€å”®é¢'] - metrics['æ€»å•†å“æˆæœ¬']
    metrics['æ¯›åˆ©ç‡'] = (å•å“æ¯›åˆ© / metrics['å•†å“é”€å”®é¢'] * 100) if metrics['å•†å“é”€å”®é¢'] > 0 else 0
    
    # ========== æ‰“å°è¾“å‡ºï¼ˆä¸Streamlitæˆªå›¾å¯¹åº”ï¼‰==========
    print("\n" + "=" * 80)
    print("ğŸ“Š ========== StreamlitåŸºå‡†æ•°æ®ï¼ˆä¸æˆªå›¾å¯¹åº”ï¼‰==========")
    print("=" * 80)
    
    print(f"\nğŸ“¦ åŸºç¡€æŒ‡æ ‡:")
    print(f"   - è®¢å•æ€»æ•°: {metrics['è®¢å•æ€»æ•°']:,}")
    print(f"   - å•†å“SKUæ•°: {metrics['å•†å“SKUæ•°']:,}")
    print(f"   - æ€»é”€é‡: {metrics['æ€»é”€é‡']:,}")
    
    print(f"\nğŸ’° æ”¶å…¥æŒ‡æ ‡:")
    print(f"   - å•†å“é”€å”®é¢: Â¥{metrics['å•†å“é”€å”®é¢']:,.0f}")
    print(f"   - è®¢å•æ€»æ”¶å…¥: Â¥{metrics['è®¢å•æ€»æ”¶å…¥']:,.0f}")
    print(f"   - å¹³å‡å®¢å•ä»·: Â¥{metrics['å¹³å‡å®¢å•ä»·']:.2f}")
    
    print(f"\nğŸ’¸ æˆæœ¬ç»“æ„åˆ†æ:")
    print(f"   - æ€»å•†å“æˆæœ¬: Â¥{metrics['æ€»å•†å“æˆæœ¬']:,.0f}")
    print(f"   - æ€»é…é€æˆæœ¬: Â¥{metrics['æ€»é…é€æˆæœ¬']:,.0f}")
    print(f"   - æ´»åŠ¨è¥é”€æˆæœ¬: Â¥{metrics['æ´»åŠ¨è¥é”€æˆæœ¬']:,.0f}")
    print(f"   - å•†å“æŠ˜æ‰£æˆæœ¬: Â¥{metrics['å•†å“æŠ˜æ‰£æˆæœ¬']:,.0f}")
    print(f"   - å¹³å°ä½£é‡‘: Â¥{metrics['å¹³å°ä½£é‡‘']:,.0f}")
    
    print(f"\nğŸ’ åˆ©æ¶¦æ·±åº¦åˆ†æ:")
    print(f"   - æ€»åˆ©æ¶¦é¢: Â¥{metrics['æ€»åˆ©æ¶¦é¢']:,.0f}")
    print(f"   - å¹³å‡è®¢å•åˆ©æ¶¦: Â¥{metrics['å¹³å‡è®¢å•åˆ©æ¶¦']:,.2f}")
    print(f"   - ç›ˆåˆ©è®¢å•æ•°: {metrics['ç›ˆåˆ©è®¢å•æ•°']:,}")
    print(f"   - ç›ˆåˆ©è®¢å•å æ¯”: {metrics['ç›ˆåˆ©è®¢å•å æ¯”']:.1f}%")
    
    print(f"\nğŸ“Š åˆ©æ¶¦ç‡åˆ†æ:")
    print(f"   - æ¯›åˆ©ç‡: {metrics['æ¯›åˆ©ç‡']:.1f}%")
    print(f"   - æ•´ä½“åˆ©æ¶¦ç‡: {metrics['æ•´ä½“åˆ©æ¶¦ç‡']:.1f}%")
    
    # ========== å…¬å¼éªŒè¯ ==========
    print(f"\nğŸ” å…¬å¼éªŒè¯:")
    expected_profit = (
        metrics['è®¢å•æ€»æ”¶å…¥'] - 
        metrics['æ€»å•†å“æˆæœ¬'] - 
        metrics['æ€»é…é€æˆæœ¬'] - 
        metrics['æ´»åŠ¨è¥é”€æˆæœ¬'] - 
        metrics['å•†å“æŠ˜æ‰£æˆæœ¬'] - 
        metrics['å¹³å°ä½£é‡‘']
    )
    print(f"   æ€»åˆ©æ¶¦ = è®¢å•æ€»æ”¶å…¥ - å•†å“æˆæœ¬ - é…é€æˆæœ¬ - æ´»åŠ¨è¥é”€ - å•†å“æŠ˜æ‰£ - å¹³å°ä½£é‡‘")
    print(f"   æ€»åˆ©æ¶¦ = {metrics['è®¢å•æ€»æ”¶å…¥']:,.2f} - {metrics['æ€»å•†å“æˆæœ¬']:,.2f} - {metrics['æ€»é…é€æˆæœ¬']:,.2f} - {metrics['æ´»åŠ¨è¥é”€æˆæœ¬']:,.2f} - {metrics['å•†å“æŠ˜æ‰£æˆæœ¬']:,.2f} - {metrics['å¹³å°ä½£é‡‘']:,.2f}")
    print(f"   è®¡ç®—ç»“æœ = Â¥{expected_profit:,.2f}")
    print(f"   å®é™…æ€»åˆ©æ¶¦ = Â¥{metrics['æ€»åˆ©æ¶¦é¢']:,.2f}")
    print(f"   å·®å¼‚ = Â¥{abs(expected_profit - metrics['æ€»åˆ©æ¶¦é¢']):,.2f} {'âœ… ä¸€è‡´' if abs(expected_profit - metrics['æ€»åˆ©æ¶¦é¢']) < 0.01 else 'âŒ ä¸ä¸€è‡´'}")
    
    return metrics


def save_results(metrics, filename="æ•°æ®éªŒè¯ç»“æœ_Streamlitç‰ˆ_æ­£ç¡®.json"):
    """ä¿å­˜ç»“æœåˆ°JSONæ–‡ä»¶"""
    import numpy as np
    
    # è½¬æ¢numpyç±»å‹ä¸ºPythonåŸç”Ÿç±»å‹
    metrics_serializable = {}
    for k, v in metrics.items():
        if isinstance(v, (np.integer, np.int64, np.int32)):
            metrics_serializable[k] = int(v)
        elif isinstance(v, (np.floating, np.float64, np.float32)):
            metrics_serializable[k] = float(v)
        else:
            metrics_serializable[k] = v
    
    output_file = APP_DIR / filename
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(metrics_serializable, f, ensure_ascii=False, indent=2)
    
    print(f"\nâœ… ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
    return str(output_file)


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹æå–Streamlitç‰ˆæœ¬çš„æ•°æ®åŸºå‡†ï¼ˆæ­£ç¡®ç‰ˆæœ¬ï¼‰\n")
    
    # åŠ è½½å¹¶æ ‡å‡†åŒ–æ•°æ®
    df = load_and_standardize_data()
    if df is None:
        return
    
    # è®¡ç®—æŒ‡æ ‡
    metrics = calculate_streamlit_metrics(df)
    if metrics is None:
        return
    
    # ä¿å­˜ç»“æœ
    save_results(metrics)
    
    print("\n" + "=" * 80)
    print("âœ… Streamlitç‰ˆæœ¬æ•°æ®éªŒè¯å®Œæˆï¼ˆæ­£ç¡®ç‰ˆæœ¬ï¼‰")
    print("=" * 80)
    print("\nğŸ“‹ ä¸‹ä¸€æ­¥ï¼šåœ¨Dashåº”ç”¨ä¸­ä¸Šä¼ ç›¸åŒæ•°æ®ï¼Œå¯¹æ¯”13ä¸ªå…³é”®æŒ‡æ ‡")
    print("   1. æ‰“å¼€ http://localhost:8050")
    print("   2. ä¸Šä¼ : é—¨åº—æ•°æ®/2025-09-01è‡³2025-09-30è®¢å•æ˜ç»†æ•°æ®å¯¼å‡ºæ±‡æ€» (2).xlsx")
    print("   3. æŸ¥çœ‹Tab 1çš„æŒ‡æ ‡å¡ç‰‡")
    print("   4. å¯¹æ¯”å·®å¼‚å¹¶å›æŠ¥")


if __name__ == "__main__":
    main()
