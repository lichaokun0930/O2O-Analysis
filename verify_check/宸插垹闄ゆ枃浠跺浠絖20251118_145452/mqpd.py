#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ™ºèƒ½é—¨åº—ç»è¥çœ‹æ¿ - å¯è§†åŒ–ç•Œé¢
é›†æˆStreamlitæ„å»ºäº¤äº’å¼çœ‹æ¿ï¼Œå±•ç¤ºäº”å¤§AIæ¨¡å‹çš„åˆ†æç»“æœ
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import json
import sys
import os
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple

APP_DIR = Path(__file__).resolve().parent
if str(APP_DIR) not in sys.path:
    sys.path.insert(0, str(APP_DIR))

from æ™ºèƒ½é—¨åº—ç»è¥çœ‹æ¿ç³»ç»Ÿ import SmartStoreDashboard
from çœŸå®æ•°æ®å¤„ç†å™¨ import RealDataProcessor
from æ ¸å¿ƒä¸šåŠ¡é€»è¾‘ import CoreBusinessLogic

PRICE_PANEL_INTERMEDIATE_DIR = APP_DIR.parent / "æ¯”ä»·æ•°æ®" / "intermediate"

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="æ™ºèƒ½é—¨åº—ç»è¥çœ‹æ¿",
    page_icon="ğŸª",
    layout="wide",
    initial_sidebar_state="expanded"
)

# è‡ªå®šä¹‰CSSæ ·å¼
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
        font-weight: bold;
    }
    .metric-card {
        background-color: #f8f9fa;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 4px solid #1f77b4;
        margin: 1rem 0;
    }
    .recommendation-box {
        background-color: #e8f5e8;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 4px solid #28a745;
        margin: 0.5rem 0;
    }
    .risk-warning {
        background-color: #fff3cd;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 4px solid #ffc107;
        margin: 0.5rem 0;
    }
    .high-risk {
        background-color: #f8d7da;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 4px solid #dc3545;
        margin: 0.5rem 0;
    }
</style>
""", unsafe_allow_html=True)

@st.cache_resource
def load_dashboard_system() -> SmartStoreDashboard:
    """åŠ è½½æ™ºèƒ½é—¨åº—ç»è¥çœ‹æ¿ç³»ç»Ÿå®ä¾‹"""
    return SmartStoreDashboard()

@st.cache_resource
def load_data_processor() -> RealDataProcessor:
    """åŠ è½½çœŸå®æ•°æ®å¤„ç†å™¨å®ä¾‹"""
    return RealDataProcessor("å®é™…æ•°æ®")

COLUMN_NAME_FIXES: Dict[str, str] = {
    # æ­£å¸¸åˆ—åé€ä¼ 
    "å•†å“åç§°": "å•†å“åç§°",
    "å•†å“å®å”®ä»·": "å•†å“å®å”®ä»·",
    "å•†å“åŸä»·": "å•†å“åŸä»·",
    "é—¨åº—åç§°": "é—¨åº—åç§°",
    "é—¨åº—ç¼–ç ": "é—¨åº—ç¼–ç ",
    "è®¢å•ID": "è®¢å•ID",
    "ä¸‹å•æ—¶é—´": "ä¸‹å•æ—¶é—´",
    "æ”¶è´§åœ°å€": "æ”¶è´§åœ°å€",
    "ç”¨æˆ·ID": "ç”¨æˆ·ID",
    "ç”¨æˆ·åç§°": "ç”¨æˆ·åç§°",
    "æ•°é‡": "æ•°é‡",
    "å‰©ä½™åº“å­˜": "å‰©ä½™åº“å­˜",
    "ç¾å›¢ä¸€çº§åˆ†ç±»": "ç¾å›¢ä¸€çº§åˆ†ç±»",
    "ç¾å›¢ä¸‰çº§åˆ†ç±»": "ç¾å›¢ä¸‰çº§åˆ†ç±»",
    "é…é€æ–¹å¼": "é…é€æ–¹å¼",
    "æ¸ é“": "æ¸ é“",
    "åŸå¸‚åç§°": "åŸå¸‚åç§°",
    "ç‰©æµé…é€è´¹": "ç‰©æµé…é€è´¹",
    "å¹³å°ä½£é‡‘": "å¹³å°ä½£é‡‘",
    "å®æ”¶ä»·æ ¼": "å®æ”¶ä»·æ ¼",
    "é¢„ä¼°è®¢å•æ”¶å…¥": "é¢„ä¼°è®¢å•æ”¶å…¥",
    "ç”¨æˆ·æ”¯ä»˜é…é€è´¹": "ç”¨æˆ·æ”¯ä»˜é…é€è´¹",
    "é…é€è´¹å‡å…é‡‘é¢": "é…é€è´¹å‡å…é‡‘é¢",
    "å•†å“ä¼˜æƒ é‡‘é¢": "å•†å“ä¼˜æƒ é‡‘é¢",
    "å•†å“å‡å…é‡‘é¢": "å•†å“å‡å…é‡‘é¢",
    # å¸¸è§ä¹±ç æ˜ å°„
    "Ò»ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½": "ä¸€çº§åˆ†ç±»",
    "ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½": "åŸå¸‚åç§°",
    "ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½": "ä¸‰çº§åˆ†ç±»",
    "ï¿½ï¿½Æ·ï¿½ï¿½ï¿½ï¿½": "å•†å“åç§°",
    "ï¿½ï¿½Æ·ï¿½ï¿½": "å•†å“ç¼–ç ",
    "ï¿½ï¿½Æ·Êµï¿½Û¼ï¿½": "å•†å“å®å”®ä»·",
    "ï¿½ï¿½Æ·Ô­ï¿½ï¿½": "å•†å“åŸä»·",
    "ï¿½ï¿½ï¿½ï¿½": "æ•°é‡",
    "Ê£ï¿½ï¿½ï¿½ï¿½": "å‰©ä½™åº“å­˜",
    "ï¿½ï¿½Æ·ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½": "å•†å“ä¼˜æƒ é‡‘é¢",
    "ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½": "é…é€æ–¹å¼",
    "ï¿½ï¿½ï¿½ï¿½ID": "è®¢å•ID",
    "ï¿½Ã»ï¿½ID": "ç”¨æˆ·ID",
    "ï¿½Ã»ï¿½ï¿½ï¿½": "ç”¨æˆ·åç§°",
    "ï¿½Ì»ï¿½ï¿½ï¿½": "é—¨åº—åç§°",
    "ï¿½Åµï¿½ï¿½ï¿½ï¿½ï¿½": "é—¨åº—åç§°",
    "ï¿½Âµï¿½Ê±ï¿½ï¿½": "ä¸‹å•æ—¶é—´",
    "ï¿½Õ»ï¿½ï¿½ï¿½Ö·": "æ”¶è´§åœ°å€",
    "Æ½Ì¨Ó¶ï¿½ï¿½": "å¹³å°ä½£é‡‘",
    "Êµï¿½Õ¼Û¸ï¿½": "å®æ”¶ä»·æ ¼",
    "Ô¤ï¿½Æ¶ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½": "é¢„ä¼°è®¢å•æ”¶å…¥",
    "ï¿½Ã»ï¿½Ö§ï¿½ï¿½ï¿½ï¿½ï¿½": "ç”¨æˆ·æ”¯ä»˜é…é€è´¹",
    "ï¿½Ã»ï¿½Ö§ï¿½ï¿½ï¿½ï¿½ï¿½Í·ï¿½": "é…é€è´¹å‡å…é‡‘é¢",
    "ï¿½ï¿½ï¿½Í·Ñ¼ï¿½ï¿½ï¿½ï¿½ï¿½": "ç‰©æµé…é€è´¹",
    "ï¿½ï¿½Æ·ï¿½ï¿½ï¿½ï¿½": "å•†å“åç§°",
    "ï¿½Ì¼Ò³Ğµï¿½ï¿½ï¿½ï¿½ï¿½È¯": "å•†å®¶ä¼˜æƒ åˆ¸",
    "ï¿½Ì¼Ò´ï¿½ï¿½ï¿½È¯": "å•†å®¶ä¼˜æƒ åˆ¸",
    "ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½": "å•†å“å‡å…é‡‘é¢",
    "ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½": "æ¸ é“",
}

SHEET_KEYWORDS: Dict[str, List[str]] = {
    "order": ["é—¨åº—è®¢å•", "è®¢å•", "order"],
    "competitor": ["ç«å¯¹", "ç«å“", "å¯¹æ‰‹"],
    "cost": ["æˆæœ¬", "cost"],
    "traffic": ["æµé‡", "traffic"],
}

NUMERIC_COLUMNS = [
    "å•†å“å®å”®ä»·",
    "å•†å“åŸä»·",
    "æ•°é‡",
    "å‰©ä½™åº“å­˜",
    "å¹³å°ä½£é‡‘",
    "ç‰©æµé…é€è´¹",
    "ç”¨æˆ·æ”¯ä»˜é…é€è´¹",
    "é…é€è´¹å‡å…é‡‘é¢",
    "é¢„ä¼°è®¢å•æ”¶å…¥",
    "å®æ”¶ä»·æ ¼",
    "å•†å“ä¼˜æƒ é‡‘é¢",
    "å•†å“å‡å…é‡‘é¢",
]

CHANNELS_TO_REMOVE = CoreBusinessLogic.CHANNELS_TO_REMOVE

def normalize_label(label: Any) -> Any:
    """å°è¯•è§„æ•´åˆ—å/è¡¨åï¼Œå…¼å®¹ä¹±ç """
    if not isinstance(label, str):
        return label
    trimmed = label.strip()
    if trimmed in COLUMN_NAME_FIXES:
        return COLUMN_NAME_FIXES[trimmed]
    # å¤šç§ç¼–ç å›é€€
    for source in ("latin1", "cp1252"):
        for target in ("gbk", "gb2312"):
            try:
                decoded = trimmed.encode(source, errors="ignore").decode(target, errors="ignore").strip()
                if decoded:
                    return COLUMN_NAME_FIXES.get(decoded, decoded)
            except Exception:
                continue
    return COLUMN_NAME_FIXES.get(trimmed, trimmed)

def rename_columns(df: pd.DataFrame, extra_map: Optional[Dict[str, str]] = None) -> pd.DataFrame:
    """ç»Ÿä¸€DataFrameåˆ—å"""
    extra_map = extra_map or {}
    rename_map: Dict[str, str] = {}
    for col in df.columns:
        normalized = normalize_label(col)
        normalized = extra_map.get(normalized, normalized)
        rename_map[col] = normalized
    return df.rename(columns=rename_map)

def convert_numeric(df: pd.DataFrame, columns: List[str]) -> pd.DataFrame:
    for col in columns:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors="coerce")
    return df

def aggregate_product_data(order_df: pd.DataFrame) -> pd.DataFrame:
    if "å•†å“åç§°" not in order_df.columns:
        return pd.DataFrame()
    agg_map: Dict[str, str] = {}
    if "å•†å“å®å”®ä»·" in order_df.columns:
        agg_map["å•†å“å®å”®ä»·"] = "mean"
    if "å•†å“åŸä»·" in order_df.columns:
        agg_map["å•†å“åŸä»·"] = "mean"
    if "æ•°é‡" in order_df.columns:
        agg_map["æ•°é‡"] = "sum"
    if "å‰©ä½™åº“å­˜" in order_df.columns:
        agg_map["å‰©ä½™åº“å­˜"] = "max"
    if "ä¸€çº§åˆ†ç±»" in order_df.columns:
        agg_map["ä¸€çº§åˆ†ç±»"] = "first"
    if "ä¸‰çº§åˆ†ç±»" in order_df.columns:
        agg_map["ä¸‰çº§åˆ†ç±»"] = "first"
    if not agg_map:
        return pd.DataFrame()
    product_df = order_df.groupby("å•†å“åç§°", as_index=False).agg(agg_map)
    rename_map = {
        "å•†å“å®å”®ä»·": "å”®ä»·",
        "å•†å“åŸä»·": "åŸä»·",
        "æ•°é‡": "æœˆå”®",
        "å‰©ä½™åº“å­˜": "åº“å­˜",
        "ä¸€çº§åˆ†ç±»": "ç¾å›¢ä¸€çº§åˆ†ç±»",
        "ä¸‰çº§åˆ†ç±»": "ç¾å›¢ä¸‰çº§åˆ†ç±»",
    }
    return product_df.rename(columns={k: v for k, v in rename_map.items() if k in product_df.columns})

def build_sales_summary(order_df: pd.DataFrame) -> pd.DataFrame:
    if "ä¸‹å•æ—¶é—´" in order_df.columns:
        order_df = order_df.copy()
        order_df["ä¸‹å•æ—¶é—´"] = pd.to_datetime(order_df["ä¸‹å•æ—¶é—´"], errors="coerce")
        order_df["ä¸‹å•æ—¥æœŸ"] = order_df["ä¸‹å•æ—¶é—´"].dt.date
    if "ä¸‹å•æ—¥æœŸ" not in order_df.columns:
        return pd.DataFrame()
    agg_dict: Dict[str, Any] = {"ä¸‹å•æ—¥æœŸ": "first"}
    if "é¢„ä¼°è®¢å•æ”¶å…¥" in order_df.columns:
        agg_dict["é¢„ä¼°è®¢å•æ”¶å…¥"] = "sum"
    if "å®æ”¶ä»·æ ¼" in order_df.columns:
        agg_dict["å®æ”¶ä»·æ ¼"] = "sum"
    if "æ•°é‡" in order_df.columns:
        agg_dict["æ•°é‡"] = "sum"
    if "è®¢å•ID" in order_df.columns:
        agg_dict["è®¢å•ID"] = pd.Series.nunique
    summary = order_df.groupby("ä¸‹å•æ—¥æœŸ").agg(agg_dict).reset_index(drop=True)
    rename_map = {
        "ä¸‹å•æ—¥æœŸ": "date",
        "é¢„ä¼°è®¢å•æ”¶å…¥": "estimated_revenue",
        "å®æ”¶ä»·æ ¼": "net_revenue",
        "æ•°é‡": "items_sold",
        "è®¢å•ID": "unique_orders",
    }
    return summary.rename(columns={k: v for k, v in rename_map.items() if k in summary.columns})

def build_customer_profile(order_df: pd.DataFrame) -> pd.DataFrame:
    candidate_cols = [
        "è®¢å•ID",
        "ç”¨æˆ·ID",
        "ç”¨æˆ·åç§°",
        "ä¸‹å•æ—¶é—´",
        "æ”¶è´§åœ°å€",
        "åŸå¸‚åç§°",
        "æ¸ é“",
        "é…é€æ–¹å¼",
        "é—¨åº—åç§°",
    ]
    available = [col for col in candidate_cols if col in order_df.columns]
    if not available:
        return pd.DataFrame()
    profile = order_df[available].copy()
    if "ä¸‹å•æ—¶é—´" in profile.columns:
        profile["ä¸‹å•æ—¶é—´"] = pd.to_datetime(profile["ä¸‹å•æ—¶é—´"], errors="coerce")
    if "è®¢å•ID" in profile.columns:
        profile = profile.drop_duplicates(subset=["è®¢å•ID"], keep="last")
    return profile

def filter_channels(order_df: pd.DataFrame) -> pd.DataFrame:
    if "æ¸ é“" not in order_df.columns:
        return order_df
    filtered = order_df[~order_df["æ¸ é“"].isin(CHANNELS_TO_REMOVE)].copy()
    return filtered

def detect_data_period(order_df: pd.DataFrame) -> Optional[str]:
    date_series = None
    if "ä¸‹å•æ—¶é—´" in order_df.columns:
        date_series = pd.to_datetime(order_df["ä¸‹å•æ—¶é—´"], errors="coerce")
    elif "ä¸‹å•æ—¥æœŸ" in order_df.columns:
        date_series = pd.to_datetime(order_df["ä¸‹å•æ—¥æœŸ"], errors="coerce")
    if date_series is None or date_series.dropna().empty:
        return None
    date_series = date_series.dropna()
    start, end = date_series.min(), date_series.max()
    try:
        return f"{start:%Y-%m-%d} ~ {end:%Y-%m-%d}"
    except Exception:
        return None

@st.cache_data
def load_real_business_data() -> Tuple[Optional[Dict[str, Any]], List[str]]:
    """æ‰«æå¹¶åŠ è½½çœŸå®ä¸šåŠ¡æ•°æ®ï¼Œè¿”å›(æ•°æ®, æç¤ºä¿¡æ¯)"""
    messages: List[str] = []
    candidate_dirs = [
        APP_DIR / "å®é™…æ•°æ®",
        APP_DIR.parent / "å®é™…æ•°æ®",
        APP_DIR / "é—¨åº—æ•°æ®",
        APP_DIR.parent / "æµ‹ç®—æ¨¡å‹" / "é—¨åº—æ•°æ®",
        APP_DIR.parent / "æµ‹ç®—æ¨¡å‹" / "é—¨åº—æ•°æ®" / "æ¯”ä»·çœ‹æ¿æ¨¡å—",
    ]

    data_dir: Optional[Path] = None
    candidates: List[Path] = []
    for path in candidate_dirs:
        if not path.exists():
            continue
        current_candidates = sorted(
            f for f in path.glob("*.xlsx")
            if not f.name.startswith("~$")
        )
        if current_candidates:
            data_dir = path
            candidates = current_candidates
            break
    if data_dir is None:
        tried = "ï¼›".join(str(path) for path in candidate_dirs)
        messages.append(f"æœªæ‰¾åˆ°æ•°æ®ç›®å½•ï¼Œå¯åœ¨ä»¥ä¸‹ä½ç½®ä¹‹ä¸€åˆ›å»º: {tried}")
        return None, messages
    if not candidates:
        messages.append("æ•°æ®ç›®å½•ä¸‹æœªæ‰¾åˆ°Excelæ–‡ä»¶")
        return None, messages

    target_file = next((f for f in candidates if "æµ‹è¯•æ•°æ®" in f.name), candidates[0])
    try:
        xls = pd.ExcelFile(target_file)
    except Exception as exc:
        messages.append(f"è¯»å– {target_file.name} å¤±è´¥: {exc}")
        return None, messages

    def pick_sheet(kind: str) -> Optional[str]:
        keywords = SHEET_KEYWORDS.get(kind, [])
        for sheet in xls.sheet_names:
            normalized = str(normalize_label(sheet)).replace(" ", "")
            for kw in keywords:
                if kw in normalized:
                    return sheet
        return None

    sheet_map = {
        "order": pick_sheet("order") or (xls.sheet_names[0] if xls.sheet_names else None),
        "competitor": pick_sheet("competitor"),
        "cost": pick_sheet("cost"),
        "traffic": pick_sheet("traffic"),
    }

    if sheet_map["competitor"] is None:
        for sheet in xls.sheet_names:
            normalized = str(normalize_label(sheet)).replace(" ", "")
            if "ç«å¯¹" in normalized or "ç«å“" in normalized:
                sheet_map["competitor"] = sheet
                break

    if sheet_map["cost"] is None:
        for sheet in xls.sheet_names:
            normalized = str(normalize_label(sheet)).replace(" ", "")
            if "æˆæœ¬" in normalized or "è´¹ç”¨" in normalized:
                sheet_map["cost"] = sheet
                break

    if sheet_map["traffic"] is None:
        for sheet in xls.sheet_names:
            normalized = str(normalize_label(sheet)).replace(" ", "")
            if "æµé‡" in normalized or "å®¢æµ" in normalized:
                sheet_map["traffic"] = sheet
                break

    data_frames: Dict[str, pd.DataFrame] = {}
    for key, sheet_name in sheet_map.items():
        if sheet_name is None:
            messages.append(f"æœªæ‰¾åˆ°{key}ç›¸å…³çš„å·¥ä½œè¡¨")
            continue
        try:
            df = pd.read_excel(xls, sheet_name=sheet_name)
            data_frames[key] = rename_columns(df)
        except Exception as exc:
            messages.append(f"è¯»å–å·¥ä½œè¡¨ {sheet_name} å¤±è´¥: {exc}")

    order_df = data_frames.get("order", pd.DataFrame())
    if order_df.empty:
        messages.append("æœªè·å–åˆ°é—¨åº—è®¢å•æ•°æ®")
        return None, messages

    order_df = convert_numeric(order_df, NUMERIC_COLUMNS)
    filtered_order_df = filter_channels(order_df)
    removed_rows = len(order_df) - len(filtered_order_df)
    if removed_rows > 0:
        messages.append(f"å·²å‰”é™¤æŒ‡å®šæ¸ é“è®¢å• {removed_rows:,} æ¡")
    order_df = filtered_order_df

    product_df = aggregate_product_data(order_df)
    sales_summary = build_sales_summary(order_df)
    customer_df = build_customer_profile(order_df)

    competitor_df = data_frames.get("competitor", pd.DataFrame())
    if not competitor_df.empty:
        competitor_df = convert_numeric(competitor_df, ["å”®ä»·", "åŸä»·", "æœˆå”®"])

    cost_df = data_frames.get("cost", pd.DataFrame())
    traffic_df = data_frames.get("traffic", pd.DataFrame())

    store_identifier = order_df.get("é—¨åº—åç§°")
    store_id = "REAL_STORE_DATA"
    if store_identifier is not None and not store_identifier.dropna().empty:
        store_id = str(store_identifier.mode().iat[0])

    data_period = detect_data_period(order_df) or "è¿‘30å¤©"

    result: Dict[str, Any] = {
        "store_id": store_id,
        "order_data": order_df,
        "product_data": product_df,
        "sales_data": sales_summary,
        "customer_data": customer_df,
        "competitor_data": competitor_df,
        "cost_data": cost_df,
        "traffic_data": traffic_df,
        "data_source": f"æ–‡ä»¶: {target_file.name}",
        "data_period": data_period,
    "total_orders": int(order_df["è®¢å•ID"].nunique()) if "è®¢å•ID" in order_df.columns else len(order_df),
        "total_products": int(product_df["å•†å“åç§°"].nunique()) if not product_df.empty else order_df.get("å•†å“åç§°", pd.Series(dtype=str)).nunique(),
    }

    return result, messages

@st.cache_data
def load_price_panel_metrics() -> Optional[Dict[str, Any]]:
    """è¯»å–æ¯”ä»·é¢æ¿æŒ‡æ ‡"""
    metrics_path = PRICE_PANEL_INTERMEDIATE_DIR / "price_panel_metrics.json"
    if not metrics_path.exists():
        return None
    try:
        with open(metrics_path, "r", encoding="utf-8") as fp:
            payload = json.load(fp)
        return payload
    except Exception:
        return None


def _format_metric_value(metric: Dict[str, Any]) -> str:
    value = metric.get("value")
    unit = metric.get("unit")
    if value is None:
        return "â€”"
    if unit == "%":
        return f"{float(value):.1f}%"
    if unit == "ä¸ª":
        try:
            return f"{int(value):,}"
        except Exception:
            return str(value)
    if isinstance(value, float):
        return f"{value:,.2f}"
    if isinstance(value, int):
        return f"{value:,}"
    return str(value)


def _build_metric_context_lines(metric: Dict[str, Any], payload: Dict[str, Any]) -> List[str]:
    context = metric.get("context") or {}
    metric_id = metric.get("id")
    lines: List[str] = []

    if metric_id == "matched_pairs":
        stores = context.get("stores") or [store.get("display_name", "") for store in payload.get("stores", [])[:2]]
        stores = [s for s in stores if s]
        if stores:
            lines.append(" vs ".join(stores))
    elif metric_id in {"match_rate_store_a", "match_rate_store_b"}:
        matched = context.get("matched")
        total = context.get("total")
        if matched is not None and total:
            lines.append(f"åŒ¹é… {int(matched):,} / æ€» {int(total):,}")
    elif metric_id in {"unique_store_a", "unique_store_b"}:
        total = context.get("total")
        value = metric.get("value")
        if value is not None and total:
            lines.append(f"ç‹¬æœ‰ {int(value):,} / æ€» {int(total):,}")
    elif metric_id == "stockout_alert":
        stores = payload.get("stores", [])[:2]
        for store in stores:
            name = store.get("display_name")
            details = context.get(name, {}) if name else {}
            zero = details.get("zero")
            with_sales = details.get("with_sales")
            if zero is None:
                continue
            line = f"{name}: {int(zero):,} ä¸ª"
            if with_sales:
                line += f"ï¼ˆå«é”€é‡ {int(with_sales):,}ï¼‰"
            lines.append(line)
        diff = context.get("difference")
        if isinstance(diff, (int, float)) and diff != 0:
            symbol = "+" if diff > 0 else ""
            lines.append(f"å·®å€¼ {symbol}{int(diff):,}")

    return lines


def render_price_panel_overview(payload: Dict[str, Any]) -> None:
    """æ¸²æŸ“æ¯”ä»·åŸºç¡€çœ‹æ¿æŒ‡æ ‡"""
    st.subheader("ğŸ’¹ æ¯”ä»·åŸºç¡€çœ‹æ¿")
    timestamp = payload.get("generated_at")
    if timestamp:
        st.caption(f"æ•°æ®æ›´æ–°: {timestamp.replace('T', ' ')[:19]}")

    for warn in payload.get("warnings", []) or []:
        st.warning(warn)

    metrics = payload.get("metrics") or []
    if not metrics:
        st.info("æš‚æ— æ¯”ä»·æŒ‡æ ‡ï¼Œè¯·å…ˆè¿è¡Œæ¯”ä»·ETLã€‚")
        return

    for start in range(0, len(metrics), 3):
        row_metrics = metrics[start:start + 3]
        columns = st.columns(len(row_metrics))
        for col, metric in zip(columns, row_metrics):
            with col:
                st.metric(metric.get("label", ""), _format_metric_value(metric))
                context_lines = _build_metric_context_lines(metric, payload)
                if context_lines:
                    st.caption(" | ".join(context_lines))


@st.cache_data
def load_sample_data():
    """åŠ è½½ç¤ºä¾‹æ•°æ®"""
    return {
        'store_id': 'DEMO_STORE_001',
        'product_data': pd.DataFrame({
            'å•†å“åç§°': ['å¯å£å¯ä¹330ml', 'å†œå¤«å±±æ³‰550ml', 'åº·å¸ˆå‚…çº¢çƒ§ç‰›è‚‰é¢', 'äº”ç²®æ¶²52åº¦500ml', 'é£å¤©èŒ…å°53åº¦500ml', 
                      'åŒæ±‡ç«è…¿è‚ ', 'ç»Ÿä¸€ç»¿èŒ¶', 'å¥¥åˆ©å¥¥é¥¼å¹²', 'å¾·èŠ™å·§å…‹åŠ›', 'æ—ºæ—ºä»™è´'],
            'å”®ä»·': [3.5, 2.0, 4.5, 168.0, 2680.0, 6.8, 3.2, 12.5, 28.0, 8.9],
            'åŸä»·': [4.0, 2.5, 5.0, 188.0, 2980.0, 8.0, 4.0, 15.0, 32.0, 10.0],
            'æœˆå”®': [1500, 2800, 800, 50, 5, 1200, 900, 600, 300, 450],
            'åº“å­˜': [200, 300, 150, 20, 3, 180, 120, 80, 50, 75],
            'ç¾å›¢ä¸€çº§åˆ†ç±»': ['é¥®å“', 'é¥®å“', 'é£Ÿå“', 'é…’ç±»', 'é…’ç±»', 'é£Ÿå“', 'é¥®å“', 'é£Ÿå“', 'é£Ÿå“', 'é£Ÿå“'],
            'ç¾å›¢ä¸‰çº§åˆ†ç±»': ['ç¢³é…¸é¥®æ–™', 'æ°´', 'æ–¹ä¾¿é¢', 'ç™½é…’', 'ç™½é…’', 'è‚‰åˆ¶å“', 'èŒ¶é¥®æ–™', 'é¥¼å¹²', 'å·§å…‹åŠ›', 'è†¨åŒ–é£Ÿå“']
        }),
        'competitor_data': pd.DataFrame({
            'å•†å“åç§°': ['å¯å£å¯ä¹330ml', 'å†œå¤«å±±æ³‰550ml', 'åº·å¸ˆå‚…çº¢çƒ§ç‰›è‚‰é¢', 'é›ªç¢§æŸ æª¬å‘³', 'ç™¾äº‹å¯ä¹'],
            'å”®ä»·': [3.2, 1.8, 4.2, 3.0, 3.3],
            'åŸä»·': [3.8, 2.2, 4.8, 3.5, 3.8],
            'æœˆå”®': [1800, 3200, 900, 1400, 1100],
            'é—¨åº—åç§°': ['ç«å¯¹A', 'ç«å¯¹A', 'ç«å¯¹A', 'ç«å¯¹A', 'ç«å¯¹A'],
            'ç¾å›¢ä¸€çº§åˆ†ç±»': ['é¥®å“', 'é¥®å“', 'é£Ÿå“', 'é¥®å“', 'é¥®å“']
        })
    }

def main():
    """ä¸»å‡½æ•°"""
    
    # é¡µé¢æ ‡é¢˜
    st.markdown('<h1 class="main-header">ğŸª æ™ºèƒ½é—¨åº—ç»è¥çœ‹æ¿</h1>', unsafe_allow_html=True)
    st.markdown("---")
    
    dashboard = load_dashboard_system()
    data_processor = load_data_processor()
    sample_data = load_sample_data()
    real_data, load_messages = load_real_business_data()

    st.sidebar.title("ğŸ“Š çœ‹æ¿æ§åˆ¶é¢æ¿")

    if load_messages:
        for msg in load_messages:
            st.sidebar.warning(msg)

    # AI å­¦ä¹ ç³»ç»Ÿæ¦‚è§ˆ
    st.sidebar.subheader("ğŸ§  AIå­¦ä¹ ç³»ç»Ÿ")
    learning_status = dashboard.get_learning_status()
    if learning_status.get("enabled"):
        st.sidebar.success("âœ… AIå­¦ä¹ ç³»ç»Ÿå·²å¯ç”¨")
        learning_stats = learning_status.get("learning_statistics", {})
        if learning_stats:
            st.sidebar.write("**å­¦ä¹ çŠ¶æ€**")
            st.sidebar.write(f"â€¢ æ€»å­¦ä¹ æ¬¡æ•°: {learning_stats.get('total_learning_sessions', 0)}")
            st.sidebar.write(f"â€¢ åœ¨çº¿æ›´æ–°: {learning_stats.get('online_updates', 0)}")
            st.sidebar.write(f"â€¢ æ‰¹é‡æ›´æ–°: {learning_stats.get('batch_updates', 0)}")
        if st.sidebar.button("ğŸ”„ æ‰‹åŠ¨æ¨¡å‹è®­ç»ƒ", help="ä½¿ç”¨å†å²æ•°æ®æ‰‹åŠ¨è®­ç»ƒæ¨¡å‹"):
            with st.spinner("æ­£åœ¨è®­ç»ƒæ¨¡å‹..."):
                training_result = dashboard.manual_model_training([sample_data])
                if training_result.get("success"):
                    st.sidebar.success("ğŸ‰ æ¨¡å‹è®­ç»ƒå®Œæˆ")
                else:
                    st.sidebar.error(f"âŒ è®­ç»ƒå¤±è´¥: {training_result.get('error', 'æœªçŸ¥é”™è¯¯')}")
        if st.sidebar.button("ğŸ“„ å¯¼å‡ºå­¦ä¹ æŠ¥å‘Š"):
            report_path = dashboard.export_learning_insights()
            if report_path:
                st.sidebar.success("âœ… æŠ¥å‘Šå·²å¯¼å‡º")
            else:
                st.sidebar.error("âŒ å¯¼å‡ºå¤±è´¥")
    else:
        st.sidebar.info("AIå­¦ä¹ ç³»ç»Ÿæš‚æœªå¯ç”¨")

    # æ•°æ®æºé€‰æ‹©
    st.sidebar.subheader("ğŸ“ æ•°æ®è¾“å…¥")
    use_sample_data = st.sidebar.toggle("ä½¿ç”¨ç¤ºä¾‹æ•°æ®æ¼”ç¤º", value=False)
    using_sample = False

    if real_data is not None:
        if use_sample_data:
            st.sidebar.warning("å·²åŠ è½½çœŸå®æ•°æ®ï¼Œå·²ä¸´æ—¶åˆ‡æ¢åˆ°ç¤ºä¾‹æ•°æ®æ¼”ç¤ºæ¨¡å¼")
            current_data = sample_data
            using_sample = True
        else:
            current_data = real_data
            st.sidebar.success(f"ğŸ“Š å½“å‰æ•°æ®æº: {real_data['data_source']} ({real_data['data_period']})")
            st.sidebar.metric("è®¢å•æ•°", f"{real_data['total_orders']:,}")
            st.sidebar.metric("å•†å“ç§ç±»", f"{real_data['total_products']:,}")
    else:
        if use_sample_data:
            st.sidebar.warning("æœªæ‰¾åˆ°çœŸå®æ•°æ®ï¼Œå½“å‰ä»¥ç¤ºä¾‹æ•°æ®æ¼”ç¤ºç•Œé¢")
            current_data = sample_data
            using_sample = True
        else:
            st.sidebar.warning("æœªæ‰¾åˆ°çœŸå®æ•°æ®ï¼Œè¯·å°†Excelæ”¾å…¥æç¤ºç›®å½•ï¼Œæˆ–å‹¾é€‰ã€ä½¿ç”¨ç¤ºä¾‹æ•°æ®æ¼”ç¤ºã€ä½“éªŒç•Œé¢")
            current_data = {}

    price_panel_payload = load_price_panel_metrics()
    if price_panel_payload and price_panel_payload.get("metrics"):
        render_price_panel_overview(price_panel_payload)

    # åˆ†æç»´åº¦é€‰æ‹©
    st.sidebar.subheader("åˆ†æè®¾ç½®")
    analysis_scope = st.sidebar.multiselect(
        "é€‰æ‹©åˆ†æç»´åº¦",
        ["é”€å”®åˆ†æ", "ç«å¯¹åˆ†æ", "é£é™©è¯„ä¼°", "ç­–ç•¥å»ºè®®", "é¢„æµ‹åˆ†æ"],
        default=["é”€å”®åˆ†æ", "ç­–ç•¥å»ºè®®"],
    )
    forecast_days = st.sidebar.slider("é¢„æµ‹å¤©æ•°", 7, 90, 30)

    if st.sidebar.button("ğŸš€ å¼€å§‹æ™ºèƒ½åˆ†æ", type="primary"):
        if not current_data:
            st.warning("è¯·å…ˆåŠ è½½çœŸå®æ•°æ®ï¼Œæˆ–åœ¨ä¾§è¾¹æ å¯ç”¨ç¤ºä¾‹æ•°æ®æ¼”ç¤ºåå†è¿è¡Œåˆ†æã€‚")
        else:
            with st.spinner("æ­£åœ¨è¿›è¡Œæ™ºèƒ½åˆ†æ..."):
                analysis_result = dashboard.comprehensive_analysis(
                    current_data,
                    current_data.get("competitor_data"),
                )
                st.session_state["analysis_result"] = analysis_result
                st.session_state["current_data"] = current_data
                st.session_state["forecast_days"] = forecast_days

                if real_data is not None and not using_sample:
                    data_processor.processed_data = {
                        "sales_data": current_data.get("product_data", pd.DataFrame()),
                        "order_data": current_data.get("order_data", pd.DataFrame()),
                    }

    if "analysis_result" in st.session_state:
        display_analysis_results(st.session_state["analysis_result"], analysis_scope, dashboard)
    else:
        st.info("ğŸ‘† è¯·å…ˆåœ¨å·¦ä¾§ç‚¹å‡»â€œå¼€å§‹æ™ºèƒ½åˆ†æâ€")
        st.subheader("ğŸ“‹ æ•°æ®é¢„è§ˆ")
        if not current_data:
            st.info("å°šæœªåŠ è½½çœŸå®æ•°æ®ã€‚è¯·åœ¨ä¾§è¾¹æ æ”¾ç½® Excel æ–‡ä»¶æˆ–å¼€å¯ç¤ºä¾‹æ•°æ®æ¼”ç¤ºæ¨¡å¼ã€‚")
        else:
            if using_sample:
                st.caption("ä»¥ä¸‹ä¸ºå†…ç½®ç¤ºä¾‹æ•°æ®ï¼Œä»…ä¾›ç•Œé¢æ¼”ç¤ºï¼›ä¸Šä¼ çœŸå®æ•°æ®åå°†è‡ªåŠ¨æ›¿æ¢ã€‚")

            product_preview = current_data.get("product_data", pd.DataFrame())
            competitor_preview = current_data.get("competitor_data", pd.DataFrame())

            if "order_data" in current_data and not using_sample:
                col1, col2 = st.columns(2)
                with col1:
                    st.write("**é—¨åº—è®¢å•æ•°æ®**")
                    st.dataframe(current_data.get("order_data", pd.DataFrame()).head(), height=240)
                with col2:
                    st.write("**ç«å¯¹å•†å“æ•°æ®**")
                    st.dataframe(competitor_preview.head(), height=240)
                col1, col2, col3, col4 = st.columns(4)
                col1.metric("è®¢å•æ€»æ•°", f"{current_data.get('total_orders', 0):,}")
                col2.metric("å•†å“ç§ç±»", f"{current_data.get('total_products', 0):,}")
                if not competitor_preview.empty:
                    col3.metric("ç«å¯¹å•†å“", f"{len(competitor_preview):,}")
                col4.metric("æ•°æ®æœŸé—´", current_data.get("data_period", "N/A"))
            else:
                col1, col2 = st.columns(2)
                with col1:
                    st.write("**é—¨åº—å•†å“æ•°æ®**")
                    st.dataframe(product_preview.head(), height=240)
                with col2:
                    st.write("**ç«å¯¹å•†å“æ•°æ®**")
                    st.dataframe(competitor_preview.head(), height=240)

def display_analysis_results(analysis_result, analysis_scope, dashboard_instance):
    """æ˜¾ç¤ºåˆ†æç»“æœ"""
    
    # 1. æ€»ä½“æ¦‚è§ˆ
    st.subheader("ğŸ“Š åˆ†ææ¦‚è§ˆ")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric(
            "æ•°æ®è´¨é‡è¯„åˆ†",
            f"{analysis_result['store_overview']['data_quality_score']:.2f}",
            delta="è‰¯å¥½" if analysis_result['store_overview']['data_quality_score'] > 0.7 else "éœ€æ”¹å–„"
        )
    
    with col2:
        st.metric(
            "ç”Ÿæˆå‡è®¾æ•°é‡",
            len(analysis_result['hypothesis_analysis']),
            delta="å·²éªŒè¯"
        )
    
    with col3:
        total_decisions = sum(len(options) for options in analysis_result['strategic_decisions'].values())
        st.metric(
            "ç­–ç•¥å»ºè®®æ•°",
            total_decisions,
            delta="å¯æ‰§è¡Œ"
        )
    
    with col4:
        st.metric(
            "ç»¼åˆå»ºè®®æ•°",
            len(analysis_result['comprehensive_recommendations']),
            delta="ä¼˜å…ˆçº§æ’åº"
        )
    
    # 2. æ ¸å¿ƒå»ºè®®å±•ç¤º
    st.subheader("ğŸ¯ æ ¸å¿ƒå»ºè®®")
    
    for i, recommendation in enumerate(analysis_result['comprehensive_recommendations'][:5], 1):
        st.markdown(f"""
        <div class="recommendation-box">
            <strong>å»ºè®® {i}:</strong> {recommendation}
        </div>
        """, unsafe_allow_html=True)
    
    # 3. é€‰é¡¹å¡å¼è¯¦ç»†åˆ†æ
    tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs(["ğŸ›ï¸ å•†å“ç­–ç•¥", "ğŸ“ˆ è¶‹åŠ¿é¢„æµ‹", "âš ï¸ é£é™©è¯„ä¼°", "ğŸ¢ ç«å¯¹åˆ†æ", "ğŸ”¬ å‡è®¾éªŒè¯", "ğŸ§  å­¦ä¹ æ•ˆæœ"])
    
    with tab1:
        display_product_strategy(analysis_result)
    
    with tab2:
        display_trend_analysis(analysis_result)
    
    with tab3:
        display_risk_assessment(analysis_result)
    
    with tab4:
        display_competitor_analysis(analysis_result)
    
    with tab5:
        display_hypothesis_validation(analysis_result)
    
    with tab6:
        display_learning_effects(analysis_result, dashboard_instance)

def display_product_strategy(analysis_result):
    """æ˜¾ç¤ºå•†å“ç­–ç•¥åˆ†æ"""
    st.subheader("ğŸ›ï¸ å•†å“ç­–ç•¥åˆ†æ")
    
    if 'strategic_decisions' in analysis_result:
        decisions = analysis_result['strategic_decisions']
        
        # æµé‡å“ç­–ç•¥
        if 'æµé‡å“é€‰æ‹©' in decisions:
            st.write("**ğŸ¯ æµé‡å“å»ºè®®**")
            
            traffic_options = decisions['æµé‡å“é€‰æ‹©']
            if traffic_options:
                for option in traffic_options:
                    col1, col2 = st.columns([3, 1])
                    
                    with col1:
                        st.write(f"**{option.description}**")
                        st.write(f"é¢„æœŸå®¢æµå¢é•¿: +{option.expected_outcome.get('å®¢æµé‡å¢é•¿', 0)*100:.1f}%")
                        st.write(f"å…³è”é”€å”®æå‡: +{option.expected_outcome.get('å…³è”é”€å”®æå‡', 0)*100:.1f}%")
                    
                    with col2:
                        confidence_color = "green" if option.confidence_score > 0.7 else "orange"
                        st.markdown(f"<div style='text-align: center; color: {confidence_color}; font-size: 1.2em; font-weight: bold;'>ç½®ä¿¡åº¦<br>{option.confidence_score:.1%}</div>", unsafe_allow_html=True)
        
        # æŠ˜æ‰£å“ç­–ç•¥
        if 'æŠ˜æ‰£å“ç­–ç•¥' in decisions:
            st.write("**ğŸ’° æŠ˜æ‰£å“å»ºè®®**")
            
            discount_options = decisions['æŠ˜æ‰£å“ç­–ç•¥']
            if discount_options:
                for option in discount_options:
                    with st.expander(f"æŠ˜æ‰£æ–¹æ¡ˆ: {option.description}"):
                        
                        # åˆ›å»ºæŒ‡æ ‡å±•ç¤º
                        col1, col2, col3 = st.columns(3)
                        
                        with col1:
                            st.metric(
                                "é¢„æœŸé”€é‡æå‡",
                                f"+{option.expected_outcome.get('é”€é‡æå‡', 0)*100:.0f}%"
                            )
                        
                        with col2:
                            st.metric(
                                "åº“å­˜å‘¨è½¬æ”¹å–„",
                                f"+{option.expected_outcome.get('åº“å­˜å‘¨è½¬', 0)*100:.0f}%"
                            )
                        
                        with col3:
                            impact = option.expected_outcome.get('æ¯›åˆ©ç‡å½±å“', 0)
                            st.metric(
                                "æ¯›åˆ©ç‡å½±å“",
                                f"{impact*100:+.0f}%",
                                delta="é¢„æœŸèŒƒå›´å†…" if abs(impact) < 0.3 else "éœ€è°¨æ…"
                            )
        
        # å®šä»·ç­–ç•¥
        if 'å®šä»·ç­–ç•¥' in decisions:
            st.write("**ğŸ’² å®šä»·ç­–ç•¥åˆ†æ**")
            
            pricing_options = decisions['å®šä»·ç­–ç•¥']
            
            # åˆ›å»ºå®šä»·ç­–ç•¥å¯¹æ¯”è¡¨
            if pricing_options:
                pricing_data = []
                for option in pricing_options:
                    pricing_data.append({
                        'ç­–ç•¥': option.description,
                        'é£é™©ç­‰çº§': f"{option.risk_level:.1%}",
                        'é¢„æœŸå¸‚åœºä»½é¢': f"+{option.expected_outcome.get('å¸‚åœºä»½é¢', 0)*100:.1f}%",
                        'é¢„æœŸæ¯›åˆ©å½±å“': f"{option.expected_outcome.get('æ¯›åˆ©ç‡', 0)*100:+.1f}%",
                        'æ¨èåº¦': f"{option.confidence_score:.1%}"
                    })
                
                pricing_df = pd.DataFrame(pricing_data)
                st.dataframe(pricing_df, width='stretch')

def display_trend_analysis(analysis_result):
    """æ˜¾ç¤ºè¶‹åŠ¿åˆ†æ"""
    st.subheader("ğŸ“ˆ é”€å”®è¶‹åŠ¿é¢„æµ‹")
    
    if 'trend_predictions' in analysis_result:
        predictions = analysis_result['trend_predictions']
        
        # è¶‹åŠ¿å›¾
        if 'predictions' in predictions:
            pred_df = predictions['predictions']
            
            fig = go.Figure()
            
            # ä¸»è¶‹åŠ¿çº¿
            fig.add_trace(go.Scatter(
                x=pred_df['date'],
                y=pred_df['predicted_growth_rate'],
                mode='lines+markers',
                name='é¢„æµ‹å¢é•¿ç‡',
                line=dict(color='#1f77b4', width=3)
            ))
            
            # ç½®ä¿¡åŒºé—´
            fig.add_trace(go.Scatter(
                x=pred_df['date'],
                y=pred_df['confidence_upper'],
                mode='lines',
                line=dict(width=0),
                showlegend=False
            ))
            
            fig.add_trace(go.Scatter(
                x=pred_df['date'],
                y=pred_df['confidence_lower'],
                fill='tonexty',
                mode='lines',
                line=dict(width=0),
                name='ç½®ä¿¡åŒºé—´',
                fillcolor='rgba(31, 119, 180, 0.2)'
            ))
            
            fig.update_layout(
                title="æœªæ¥30å¤©é”€å”®å¢é•¿è¶‹åŠ¿é¢„æµ‹",
                xaxis_title="æ—¥æœŸ",
                yaxis_title="å¢é•¿ç‡",
                hovermode='x unified',
                template='plotly_white'
            )
            
            st.plotly_chart(fig, width='stretch', key='chart_6')
        
        # è¶‹åŠ¿æ´å¯Ÿ
        if 'trend_summary' in predictions:
            trend_summary = predictions['trend_summary']
            
            col1, col2, col3 = st.columns(3)
            
            with col1:
                trend_color = "green" if trend_summary['overall_trend'] == "ä¸Šå‡" else "red"
                st.markdown(f"""
                <div class="metric-card">
                    <h4>æ•´ä½“è¶‹åŠ¿</h4>
                    <span style="color: {trend_color}; font-size: 1.5em; font-weight: bold;">
                        {trend_summary['overall_trend']}
                    </span>
                </div>
                """, unsafe_allow_html=True)
            
            with col2:
                volatility_color = "red" if trend_summary['volatility'] == "é«˜" else "green"
                st.markdown(f"""
                <div class="metric-card">
                    <h4>æ³¢åŠ¨æ€§</h4>
                    <span style="color: {volatility_color}; font-size: 1.5em; font-weight: bold;">
                        {trend_summary['volatility']}
                    </span>
                </div>
                """, unsafe_allow_html=True)
            
            with col3:
                peak_count = len(trend_summary['peak_periods'])
                st.markdown(f"""
                <div class="metric-card">
                    <h4>é”€å”®é«˜å³°æœŸ</h4>
                    <span style="color: #1f77b4; font-size: 1.5em; font-weight: bold;">
                        {peak_count} ä¸ª
                    </span>
                </div>
                """, unsafe_allow_html=True)
        
        # å…³é”®æ´å¯Ÿ
        if 'key_insights' in predictions:
            st.write("**ğŸ” å…³é”®æ´å¯Ÿ**")
            for insight in predictions['key_insights']:
                st.markdown(f"â€¢ {insight}")

def display_risk_assessment(analysis_result):
    """æ˜¾ç¤ºé£é™©è¯„ä¼°"""
    st.subheader("âš ï¸ é£é™©è¯„ä¼°åˆ†æ")
    
    if 'risk_assessment' in analysis_result:
        risks = analysis_result['risk_assessment']
        
        # é£é™©çŸ©é˜µå¯è§†åŒ–
        risk_data = []
        all_risks = []
        
        for category, risk_factors in risks.items():
            for factor, risk_info in risk_factors.items():
                risk_data.append({
                    'category': category,
                    'factor': factor,
                    'probability': risk_info['probability'],
                    'impact': risk_info['impact'],
                    'risk_score': risk_info['risk_score']
                })
                all_risks.append(risk_info['risk_score'])
        
        # åˆ›å»ºé£é™©çŸ©é˜µå›¾
        risk_df = pd.DataFrame(risk_data)
        
        fig = px.scatter(
            risk_df,
            x='probability',
            y='impact', 
            size='risk_score',
            color='category',
            hover_data=['factor'],
            title="é£é™©çŸ©é˜µåˆ†æ",
            labels={
                'probability': 'å‘ç”Ÿæ¦‚ç‡',
                'impact': 'å½±å“ç¨‹åº¦',
                'category': 'é£é™©ç±»åˆ«'
            }
        )
        
        fig.update_layout(
            xaxis=dict(range=[0, 1]),
            yaxis=dict(range=[0, 1]),
            template='plotly_white'
        )
        
        st.plotly_chart(fig, width='stretch', key='chart_5')
        
        # é«˜é£é™©é¡¹ç›®è­¦ç¤º
        high_risks = [item for item in risk_data if item['risk_score'] > 0.5]
        
        if high_risks:
            st.write("**ğŸš¨ é«˜é£é™©è­¦ç¤º**")
            
            for risk in high_risks:
                risk_level = "high-risk" if risk['risk_score'] > 0.7 else "risk-warning"
                
                st.markdown(f"""
                <div class="{risk_level}">
                    <strong>âš ï¸ {risk['factor']}</strong><br>
                    å‘ç”Ÿæ¦‚ç‡: {risk['probability']:.1%} | å½±å“ç¨‹åº¦: {risk['impact']:.1%} | é£é™©è¯„åˆ†: {risk['risk_score']:.2f}
                </div>
                """, unsafe_allow_html=True)
        
        # ç¼“è§£ç­–ç•¥
        st.write("**ğŸ›¡ï¸ é£é™©ç¼“è§£ç­–ç•¥**")
        
        for category, risk_factors in risks.items():
            with st.expander(f"{category}ç¼“è§£ç­–ç•¥"):
                for factor, risk_info in risk_factors.items():
                    if risk_info['risk_score'] > 0.3:  # æ˜¾ç¤ºä¸­é«˜é£é™©çš„ç¼“è§£ç­–ç•¥
                        st.write(f"**{factor}:**")
                        for suggestion in risk_info['mitigation_suggestions']:
                            st.write(f"â€¢ {suggestion}")

def display_competitor_analysis(analysis_result):
    """æ˜¾ç¤ºç«å¯¹åˆ†æ"""
    st.subheader("ğŸ¢ ç«å¯¹åˆ†æ")
    
    if 'competitor_analysis' in analysis_result:
        competitor_data = analysis_result['competitor_analysis']
        
        # å®šä»·å¯¹æ¯”åˆ†æ
        if 'å®šä»·å¯¹æ¯”' in competitor_data and 'comparison_details' in competitor_data['å®šä»·å¯¹æ¯”']:
            st.write("**ğŸ’° ä»·æ ¼ç«äº‰åŠ›åˆ†æ**")
            
            price_comparisons = competitor_data['å®šä»·å¯¹æ¯”']['comparison_details']
            
            if price_comparisons:
                # åˆ›å»ºä»·æ ¼å¯¹æ¯”å›¾
                comparison_df = pd.DataFrame(price_comparisons)
                
                fig = go.Figure()
                
                # ç«å“ä»·æ ¼
                fig.add_trace(go.Bar(
                    name='ç«å“ä»·æ ¼',
                    x=comparison_df['product'],
                    y=comparison_df['competitor_price'],
                    marker_color='lightcoral'
                ))
                
                # è‡ªå·±ä»·æ ¼
                fig.add_trace(go.Bar(
                    name='æˆ‘æ–¹ä»·æ ¼',
                    x=comparison_df['product'],
                    y=comparison_df['own_price'],
                    marker_color='lightblue'
                ))
                
                fig.update_layout(
                    title='ä»·æ ¼å¯¹æ¯”åˆ†æ',
                    xaxis_title='å•†å“',
                    yaxis_title='ä»·æ ¼ (å…ƒ)',
                    barmode='group',
                    template='plotly_white'
                )
                
                st.plotly_chart(fig, width='stretch', key='chart_4')
                
                # ä»·æ ¼å»ºè®®è¡¨
                st.write("**ä»·æ ¼è°ƒæ•´å»ºè®®**")
                
                recommendation_data = []
                for item in price_comparisons:
                    recommendation_data.append({
                        'å•†å“': item['product'],
                        'ç«å“ä»·æ ¼': f"Â¥{item['competitor_price']:.2f}",
                        'æˆ‘æ–¹ä»·æ ¼': f"Â¥{item['own_price']:.2f}",
                        'ä»·å·®': f"{item['price_gap_pct']:.1%}",
                        'å»ºè®®': item['recommendation']
                    })
                
                rec_df = pd.DataFrame(recommendation_data)
                st.dataframe(rec_df, width='stretch')
        
        # æˆæœ¬åˆ©æ¶¦å€’æ¨
        if 'æˆæœ¬åˆ©æ¶¦å€’æ¨' in competitor_data:
            st.write("**ğŸ“Š ç«å“ç›ˆåˆ©èƒ½åŠ›åˆ†æ**")
            
            profitability = competitor_data['æˆæœ¬åˆ©æ¶¦å€’æ¨']
            
            if 'high_margin_products' in profitability:
                high_margin = profitability['high_margin_products']
                
                if high_margin:
                    st.write("ç«å“é«˜åˆ©æ¶¦å•†å“TOP5:")
                    
                    margin_df = pd.DataFrame(high_margin[:5])
                    
                    fig = px.bar(
                        margin_df,
                        x='product',
                        y='margin',
                        title='ç«å“é«˜åˆ©æ¶¦å•†å“åˆ†æ',
                        labels={'product': 'å•†å“', 'margin': 'æ¯›åˆ©ç‡'}
                    )
                    
                    st.plotly_chart(fig, width='stretch', key='chart_3')
            
            if 'estimated_monthly_revenue' in profitability:
                estimated_revenue = profitability['estimated_monthly_revenue']
                st.metric(
                    "ç«å“é¢„ä¼°æœˆè¥æ”¶",
                    f"Â¥{estimated_revenue:,.0f}",
                    help="åŸºäºå”®ä»·å’Œæœˆé”€é‡ä¼°ç®—"
                )
        
        # é€‰å€å»ºè®®
        if 'é€‰å€å»ºè®®' in competitor_data:
            location_rec = competitor_data['é€‰å€å»ºè®®']
            
            st.write("**ğŸ¢ é€‰å€ç­–ç•¥å»ºè®®**")
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown(f"""
                <div class="recommendation-box">
                    <h4>é€‰å€ç­–ç•¥</h4>
                    {location_rec['proximity_strategy']}
                </div>
                """, unsafe_allow_html=True)
            
            with col2:
                if 'risk_assessment' in location_rec:
                    risks = location_rec['risk_assessment']
                    
                    fig = go.Figure(go.Bar(
                        x=list(risks.keys()),
                        y=list(risks.values()),
                        marker_color=['red' if v > 0.6 else 'orange' if v > 0.4 else 'green' for v in risks.values()]
                    ))
                    
                    fig.update_layout(
                        title='é€‰å€é£é™©è¯„ä¼°',
                        yaxis_title='é£é™©ç¨‹åº¦',
                        template='plotly_white'
                    )
                    
                    st.plotly_chart(fig, width='stretch', key='chart_2')

def display_hypothesis_validation(analysis_result):
    """æ˜¾ç¤ºå‡è®¾éªŒè¯"""
    st.subheader("ğŸ”¬ å•†ä¸šå‡è®¾éªŒè¯")
    
    if 'hypothesis_analysis' in analysis_result:
        hypotheses = analysis_result['hypothesis_analysis']
        
        if hypotheses:
            for hyp_id, hypothesis in hypotheses.items():
                with st.expander(f"å‡è®¾ {hyp_id}: {hypothesis['description']}"):
                    
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        st.write("**å‡è®¾è¯¦æƒ…**")
                        st.write(f"å‡è®¾ID: {hypothesis['hypothesis_id']}")
                        st.write(f"ç½®ä¿¡åº¦: {hypothesis['confidence_level']:.1%}")
                        
                        if hypothesis['validation_result'] is not None:
                            status = "âœ… å·²éªŒè¯" if hypothesis['validation_result'] else "âŒ æœªé€šè¿‡"
                            st.write(f"éªŒè¯çŠ¶æ€: {status}")
                    
                    with col2:
                        st.write("**æµ‹è¯•æŒ‡æ ‡**")
                        for metric in hypothesis['test_metrics']:
                            st.write(f"â€¢ {metric}")
                    
                    st.write("**æ”¯æŒæ•°æ®**")
                    supporting_data = hypothesis['supporting_data']
                    
                    # åˆ›å»ºæ”¯æŒæ•°æ®çš„å¯è§†åŒ–
                    if supporting_data:
                        data_items = list(supporting_data.items())
                        if len(data_items) > 0:
                            
                            # æ•°å€¼å‹æ•°æ®ç”¨å›¾è¡¨å±•ç¤º
                            numeric_data = {k: v for k, v in data_items if isinstance(v, (int, float))}
                            
                            if numeric_data:
                                fig = go.Figure(go.Bar(
                                    x=list(numeric_data.keys()),
                                    y=list(numeric_data.values()),
                                    marker_color='lightblue'
                                ))
                                
                                fig.update_layout(
                                    title='å‡è®¾æ”¯æŒæ•°æ®',
                                    template='plotly_white'
                                )
                                
                                st.plotly_chart(fig, width='stretch', key='chart_1')
                            else:
                                # éæ•°å€¼æ•°æ®ç”¨è¡¨æ ¼å±•ç¤º
                                st.json(supporting_data)
        else:
            st.info("æš‚æ— å•†ä¸šå‡è®¾æ•°æ®ï¼Œç³»ç»Ÿå°†åŸºäºå®é™…ç»è¥æ•°æ®è‡ªåŠ¨ç”Ÿæˆå‡è®¾")

def display_learning_effects(analysis_result, dashboard_instance):
    """æ˜¾ç¤ºå­¦ä¹ æ•ˆæœåˆ†æ"""
    st.subheader("ğŸ§  AIå­¦ä¹ æ•ˆæœåˆ†æ")
    
    # æ£€æŸ¥å­¦ä¹ å…ƒæ•°æ®
    learning_metadata = analysis_result.get('learning_metadata', {})
    
    if not learning_metadata.get('learning_enabled', False):
        st.warning("âš ï¸ AIå­¦ä¹ ç³»ç»Ÿæœªå¯ç”¨æˆ–è¿è¡Œå¼‚å¸¸")
        if 'error' in learning_metadata:
            st.error(f"é”™è¯¯ä¿¡æ¯: {learning_metadata['error']}")
        return
    
    # 1. å­¦ä¹ çŠ¶æ€æ¦‚è§ˆ
    st.write("**ğŸ“Š å­¦ä¹ çŠ¶æ€æ¦‚è§ˆ**")
    
    learning_stats = learning_metadata.get('learning_statistics', {})
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        total_sessions = learning_stats.get('total_learning_sessions', 0)
        st.metric("æ€»å­¦ä¹ æ¬¡æ•°", total_sessions, 
                 delta="ç´¯ç§¯ç»éªŒ" if total_sessions > 0 else "å¾…å¼€å§‹")
    
    with col2:
        online_updates = learning_stats.get('online_updates', 0)
        st.metric("åœ¨çº¿å­¦ä¹ ", online_updates,
                 delta="å®æ—¶ä¼˜åŒ–" if online_updates > 0 else "æš‚æ— ")
    
    with col3:
        batch_updates = learning_stats.get('batch_updates', 0)
        st.metric("æ‰¹é‡è®­ç»ƒ", batch_updates,
                 delta="æ·±åº¦å­¦ä¹ " if batch_updates > 0 else "æš‚æ— ")
    
    with col4:
        recent_activity = learning_stats.get('recent_activity', {})
        recent_sessions = recent_activity.get('total_sessions', 0)
        st.metric("è¿‘7å¤©æ´»åŠ¨", recent_sessions,
                 delta="æ´»è·ƒ" if recent_sessions > 5 else "ç¨³å®š" if recent_sessions > 0 else "å¾…æ¿€æ´»")
    
    # 2. æ¨¡å‹æ€§èƒ½è¶‹åŠ¿
    if 'performance_trends' in learning_stats:
        st.write("**ğŸ“ˆ æ¨¡å‹æ€§èƒ½è¶‹åŠ¿**")
        
        performance_trends = learning_stats['performance_trends']
        
        if performance_trends:
            # åˆ›å»ºæ€§èƒ½è¶‹åŠ¿å›¾è¡¨
            trend_data = []
            for model_name, trend_info in performance_trends.items():
                trend_data.append({
                    'Model': model_name,
                    'Direction': trend_info['direction'],
                    'Rate': trend_info['rate'],
                    'Current_MAE': trend_info['current_mae'],
                    'Sample_Count': trend_info['sample_count']
                })
            
            trend_df = pd.DataFrame(trend_data)
            
            # æ€§èƒ½æ–¹å‘é¥¼å›¾
            direction_counts = trend_df['Direction'].value_counts()
            
            fig_pie = px.pie(
                values=direction_counts.values,
                names=direction_counts.index,
                title="æ¨¡å‹æ€§èƒ½è¶‹åŠ¿åˆ†å¸ƒ",
                color_discrete_map={
                    'improving': '#2E8B57',
                    'declining': '#DC143C',
                    'stable': '#4682B4'
                }
            )
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.plotly_chart(fig_pie, key="performance_pie")
            
            with col2:
                # æ€§èƒ½è¯¦ç»†è¡¨æ ¼
                st.write("**æ¨¡å‹æ€§èƒ½è¯¦æƒ…**")
                
                display_df = trend_df.copy()
                display_df['Direction'] = display_df['Direction'].map({
                    'improving': 'ğŸ“ˆ æ”¹å–„ä¸­',
                    'declining': 'ğŸ“‰ ä¸‹é™ä¸­',
                    'stable': 'â¡ï¸ ç¨³å®š'
                })
                display_df['Rate'] = display_df['Rate'].apply(lambda x: f"{x:.1%}")
                display_df['Current_MAE'] = display_df['Current_MAE'].apply(lambda x: f"{x:.4f}")
                
                st.dataframe(display_df, key="performance_table")
        else:
            st.info("æš‚æ— æ¨¡å‹æ€§èƒ½è¶‹åŠ¿æ•°æ®")
    
    # 3. å¢å¼ºé¢„æµ‹ç»“æœ
    if 'enhanced_predictions' in analysis_result:
        st.write("**ğŸ”® AIå¢å¼ºé¢„æµ‹ç»“æœ**")
        
        enhanced_predictions = analysis_result['enhanced_predictions']
        prediction_meta = enhanced_predictions.get('meta', {})
        
        # æ˜¾ç¤ºé¢„æµ‹å…ƒä¿¡æ¯
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric(
                "é¢„æµ‹æ—¶é—´",
                prediction_meta.get('prediction_time', 'N/A')[:19] if prediction_meta.get('prediction_time') else 'N/A',
                delta="æœ€æ–°"
            )
        
        with col2:
            st.metric(
                "ç‰¹å¾ç»´åº¦", 
                prediction_meta.get('feature_count', 0),
                delta="å¤šç»´åˆ†æ"
            )
        
        with col3:
            models_used = prediction_meta.get('models_used', [])
            st.metric(
                "ä½¿ç”¨æ¨¡å‹", 
                len(models_used),
                delta="é›†æˆé¢„æµ‹"
            )
        
        # æ˜¾ç¤ºå„æ¨¡å‹é¢„æµ‹ç»“æœ
        for model_name, prediction_stats in enhanced_predictions.items():
            if model_name == 'meta':
                continue
            
            with st.expander(f"æ¨¡å‹ {model_name} é¢„æµ‹è¯¦æƒ…"):
                col1, col2, col3, col4 = st.columns(4)
                
                with col1:
                    st.metric("é¢„æµ‹å‡å€¼", f"{prediction_stats.get('mean', 0):.2f}")
                
                with col2:
                    st.metric("æ ‡å‡†å·®", f"{prediction_stats.get('std', 0):.2f}")
                
                with col3:
                    st.metric("æœ€å°å€¼", f"{prediction_stats.get('min', 0):.2f}")
                
                with col4:
                    st.metric("æœ€å¤§å€¼", f"{prediction_stats.get('max', 0):.2f}")
                
                # é¢„æµ‹å€¼åˆ†å¸ƒå›¾
                predictions_list = prediction_stats.get('predictions', [])
                if predictions_list:
                    fig_hist = px.histogram(
                        x=predictions_list,
                        title=f"{model_name} é¢„æµ‹å€¼åˆ†å¸ƒ",
                        labels={'x': 'é¢„æµ‹å€¼', 'y': 'é¢‘æ¬¡'}
                    )
                    
                    st.plotly_chart(fig_hist, key=f"pred_hist_{model_name}")
    
    # 4. è‡ªé€‚åº”å»ºè®®
    adaptive_recs = learning_metadata.get('adaptive_recommendations', [])
    
    if adaptive_recs:
        st.write("**ğŸ’¡ AIè‡ªé€‚åº”å»ºè®®**")
        
        for i, recommendation in enumerate(adaptive_recs, 1):
            st.markdown(f"""
            <div class="recommendation-box">
                <strong>AIå»ºè®® {i}:</strong> {recommendation}
            </div>
            """, unsafe_allow_html=True)
    else:
        st.info("æš‚æ— AIè‡ªé€‚åº”å»ºè®®ï¼Œç³»ç»Ÿæ­£åœ¨å­¦ä¹ ä¸­...")
    
    # 5. æ•°æ®è´¨é‡è¯„ä¼°
    try:
        learning_status = dashboard_instance.get_learning_status()
        data_stats = learning_status.get('data_statistics', {})
        
        if data_stats:
            st.write("**ğŸ“Š å­¦ä¹ æ•°æ®è´¨é‡æ¦‚è§ˆ**")
            
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.metric(
                    "æ•°æ®é›†æ€»æ•°", 
                    data_stats.get('total_datasets', 0),
                    delta="å†å²ç§¯ç´¯"
                )
            
            with col2:
                avg_quality = data_stats.get('average_quality_score', 0)
                quality_label = "ä¼˜ç§€" if avg_quality > 0.8 else "è‰¯å¥½" if avg_quality > 0.6 else "å¾…æ”¹å–„"
                st.metric(
                    "å¹³å‡è´¨é‡è¯„åˆ†", 
                    f"{avg_quality:.3f}",
                    delta=quality_label
                )
            
            with col3:
                recent_datasets = data_stats.get('recent_datasets_7days', 0)
                st.metric(
                    "è¿‘æœŸæ–°å¢", 
                    recent_datasets,
                    delta="æŒç»­æ›´æ–°" if recent_datasets > 0 else "ç¨³å®šæœŸ"
                )
            
            # æ•°æ®è´¨é‡åˆ†å¸ƒ
            quality_dist = data_stats.get('quality_distribution', {})
            if quality_dist:
                fig_quality = px.bar(
                    x=list(quality_dist.keys()),
                    y=list(quality_dist.values()),
                    title="æ•°æ®è´¨é‡åˆ†å¸ƒ",
                    labels={'x': 'è´¨é‡ç­‰çº§', 'y': 'æ•°æ®é›†æ•°é‡'},
                    color=list(quality_dist.values()),
                    color_continuous_scale=['red', 'orange', 'yellow', 'green']
                )
                
                st.plotly_chart(fig_quality, key="quality_distribution")
    
    except Exception as e:
        st.error(f"è·å–å­¦ä¹ çŠ¶æ€å¤±è´¥: {e}")

if __name__ == "__main__":
    main()