"""
æ•°æ®è¿ç§»è„šæœ¬
å°†Excelæ•°æ®å¯¼å…¥PostgreSQLæ•°æ®åº“
"""
import pandas as pd
import hashlib
import sys
from pathlib import Path
from datetime import datetime
from tqdm import tqdm

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

from database.connection import get_db_context, init_database, check_connection
from database.models import Order, Product, SceneTag, DataUploadHistory
from çœŸå®æ•°æ®å¤„ç†å™¨ import RealDataProcessor
from å•†å“åœºæ™¯æ™ºèƒ½æ‰“æ ‡å¼•æ“ import ProductSceneTagger


def calculate_file_hash(file_path: str) -> str:
    """è®¡ç®—æ–‡ä»¶MD5å“ˆå¸Œ"""
    md5 = hashlib.md5()
    with open(file_path, 'rb') as f:
        for chunk in iter(lambda: f.read(4096), b""):
            md5.update(chunk)
    return md5.hexdigest()


def migrate_excel_to_database(excel_path: str, force_reimport: bool = False):
    """
    å°†Excelæ•°æ®å¯¼å…¥æ•°æ®åº“
    
    Args:
        excel_path: Excelæ–‡ä»¶è·¯å¾„
        force_reimport: æ˜¯å¦å¼ºåˆ¶é‡æ–°å¯¼å…¥ï¼ˆå³ä½¿å·²å¯¼å…¥è¿‡ï¼‰
    """
    print("\n" + "="*80)
    print("[Data Migration] Excel -> PostgreSQL")
    print("="*80 + "\n")
    
    # 1. æ£€æŸ¥æ•°æ®åº“è¿æ¥
    if not check_connection():
        print("âŒ æ•°æ®åº“è¿æ¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®ï¼")
        return False
    
    # 2. åˆå§‹åŒ–æ•°æ®åº“è¡¨
    init_database()
    
    # 3. æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å¯¼å…¥
    file_hash = calculate_file_hash(excel_path)
    file_size = Path(excel_path).stat().st_size
    file_name = Path(excel_path).name
    
    with get_db_context() as db:
        existing = db.query(DataUploadHistory).filter(
            DataUploadHistory.file_hash == file_hash
        ).first()
        
        if existing and not force_reimport:
            print(f"[INFO] File already imported on {existing.uploaded_at}")
            print(f"       Use --force to reimport")
            return True
    
    # 4. åŠ è½½Excelæ•°æ®
    print(f"[Loading data] {file_name}")
    processor = RealDataProcessor(data_dir=str(PROJECT_ROOT / "å®é™…æ•°æ®"))
    
    try:
        # RealDataProcessorè¿”å›å­—å…¸ï¼Œå–ç¬¬ä¸€ä¸ªDataFrame
        data_dict = processor.load_all_data()
        df = list(data_dict.values())[0] if data_dict else pd.DataFrame()
        print(f"[OK] Data loaded: {len(df)} rows")
    except Exception as e:
        print(f"[ERROR] Data load failed: {e}")
        return False
    
    # 5. æ™ºèƒ½åœºæ™¯æ‰“æ ‡
    print("\n[Tagging scenes...]")
    tagger = ProductSceneTagger()
    try:
        df = tagger.tag_product_scenes(df)
        print("[OK] Scene tagging completed")
    except Exception as e:
        print(f"[WARNING] Scene tagging failed: {e}, continuing...")
    
    # 6. å¼€å§‹å¯¼å…¥æ•°æ®
    print("\n[Importing data to database...]")
    
    rows_imported = 0
    rows_failed = 0
    error_messages = []
    
    with get_db_context() as db:
        try:
            # 6.1 å¯¼å…¥å•†å“ä¸»æ•°æ®
            print("\n  [1/3] å¯¼å…¥å•†å“è¡¨...")
            products_dict = {}
            
            for _, row in tqdm(df.groupby('å•†å“åç§°').first().iterrows(), desc="  å•†å“"):
                try:
                    barcode = str(row.get('æ¡ç ', ''))
                    
                    # æ£€æŸ¥å•†å“æ˜¯å¦å­˜åœ¨
                    product = db.query(Product).filter(
                        Product.barcode == barcode
                    ).first()
                    
                    if not product:
                        product = Product(
                            product_name=row['å•†å“åç§°'],
                            barcode=barcode,
                            store_code=str(row.get('åº—å†…ç ', '')),
                            category_level1=row.get('ä¸€çº§åˆ†ç±»å', ''),
                            category_level3=row.get('ä¸‰çº§åˆ†ç±»å', ''),
                            current_price=float(row.get('å•†å“å®å”®ä»·', 0)),
                            current_cost=float(row.get('å•†å“é‡‡è´­æˆæœ¬', 0)),
                            stock=int(row.get('å‰©ä½™åº“å­˜', 0)),
                        )
                        db.add(product)
                        db.flush()  # è·å–ID
                    
                    products_dict[row['å•†å“åç§°']] = product.id
                    
                except Exception as e:
                    error_messages.append(f"å•†å“å¯¼å…¥é”™è¯¯: {row.get('å•†å“åç§°', 'Unknown')} - {e}")
                    rows_failed += 1
            
            db.commit()
            print(f"  âœ… å•†å“è¡¨å¯¼å…¥å®Œæˆ: {len(products_dict)} ä¸ªå•†å“")
            
            # 6.2 å¯¼å…¥è®¢å•æ•°æ®
            print("\n  [2/3] å¯¼å…¥è®¢å•è¡¨...")
            
            for idx, row in tqdm(df.iterrows(), total=len(df), desc="  è®¢å•"):
                try:
                    order = Order(
                        order_id=str(row['è®¢å•ID']),
                        date=pd.to_datetime(row['æ—¥æœŸ']) if pd.notna(row.get('æ—¥æœŸ')) else datetime.now(),
                        store_name=row.get('é—¨åº—åç§°', ''),
                        
                        # å…³è”å•†å“
                        product_id=products_dict.get(row['å•†å“åç§°']),
                        product_name=row['å•†å“åç§°'],
                        barcode=str(row.get('æ¡ç ', '')),
                        
                        # åˆ†ç±»
                        category_level1=row.get('ä¸€çº§åˆ†ç±»å', ''),
                        category_level3=row.get('ä¸‰çº§åˆ†ç±»å', ''),
                        
                        # ä»·æ ¼
                        price=float(row.get('å•†å“å®å”®ä»·', 0)),
                        original_price=float(row.get('å•†å“åŸä»·', 0)),
                        cost=float(row.get('å•†å“é‡‡è´­æˆæœ¬', 0)),
                        actual_price=float(row.get('å®æ”¶ä»·æ ¼', 0)),
                        
                        # é”€é‡
                        quantity=int(row.get('æœˆå”®', 1)),
                        amount=float(row.get('é¢„è®¡è®¢å•æ”¶å…¥', row.get('è®¢å•é›¶å”®é¢', 0))),  # âœ… ä¿®å¤:å­˜å‚¨"é¢„è®¡è®¢å•æ”¶å…¥"è€Œä¸æ˜¯"é”€å”®é¢"
                        profit=float(row.get('åˆ©æ¶¦é¢', row.get('å®é™…åˆ©æ¶¦', 0))),  # âœ… ä¿®å¤:ä¼˜å…ˆä½¿ç”¨"åˆ©æ¶¦é¢"å­—æ®µ
                        profit_margin=float(row.get('åˆ©æ¶¦ç‡', 0)),
                        
                        # è´¹ç”¨
                        delivery_fee=float(row.get('ç‰©æµé…é€è´¹', 0)),
                        commission=float(row.get('å¹³å°ä½£é‡‘', 0)),
                        platform_service_fee=float(row.get('å¹³å°æœåŠ¡è´¹', 0)),  # ä¿®å¤:æ­£ç¡®æ˜ å°„å¹³å°æœåŠ¡è´¹å­—æ®µ
                        
                        # åœºæ™¯
                        scene=row.get('åœºæ™¯', ''),
                        time_period=row.get('æ—¶æ®µ', ''),
                        
                        # å…¶ä»–
                        address=row.get('æ”¶è´§åœ°å€', ''),
                        channel=row.get('æ¸ é“', ''),
                    )
                    
                    db.add(order)
                    rows_imported += 1
                    
                    # æ¯1000æ¡æäº¤ä¸€æ¬¡
                    if rows_imported % 1000 == 0:
                        db.commit()
                        
                except Exception as e:
                    error_messages.append(f"è®¢å•å¯¼å…¥é”™è¯¯ (è¡Œ{idx}): {e}")
                    rows_failed += 1
            
            db.commit()
            print(f"  âœ… è®¢å•è¡¨å¯¼å…¥å®Œæˆ: {rows_imported} æ¡è®¢å•")
            
            # 6.3 å¯¼å…¥åœºæ™¯æ‰“æ ‡ç»“æœ
            print("\n  [3/3] å¯¼å…¥åœºæ™¯æ‰“æ ‡ç»“æœ...")
            
            scene_count = 0
            for product_name, product_id in tqdm(products_dict.items(), desc="  åœºæ™¯"):
                try:
                    product_rows = df[df['å•†å“åç§°'] == product_name].iloc[0]
                    
                    scene_tag = SceneTag(
                        product_id=product_id,
                        base_scene=product_rows.get('åœºæ™¯', ''),
                        seasonal_scene=product_rows.get('å­£èŠ‚åœºæ™¯', ''),
                        holiday_scene=product_rows.get('èŠ‚å‡æ—¥åœºæ™¯', ''),
                        purchase_driver=product_rows.get('è´­ä¹°é©±åŠ¨', ''),
                        confidence=0.85,  # é»˜è®¤ç½®ä¿¡åº¦
                        algorithm_version='v1.0',
                    )
                    
                    db.add(scene_tag)
                    scene_count += 1
                    
                except Exception as e:
                    error_messages.append(f"åœºæ™¯æ‰“æ ‡å¯¼å…¥é”™è¯¯: {product_name} - {e}")
            
            db.commit()
            print(f"  âœ… åœºæ™¯æ‰“æ ‡ç»“æœå¯¼å…¥å®Œæˆ: {scene_count} ä¸ªå•†å“")
            
            # 7. è®°å½•ä¸Šä¼ å†å²
            upload_history = DataUploadHistory(
                file_name=file_name,
                file_size=file_size,
                file_hash=file_hash,
                rows_imported=rows_imported,
                rows_failed=rows_failed,
                success=rows_failed == 0,
                error_log="\n".join(error_messages[:100]) if error_messages else None,
            )
            db.add(upload_history)
            db.commit()
            
            # 8. æ˜¾ç¤ºç»“æœ
            print("\n" + "="*80)
            print("âœ… æ•°æ®è¿ç§»å®Œæˆï¼")
            print("="*80)
            print(f"\nğŸ“Š å¯¼å…¥ç»Ÿè®¡:")
            print(f"  - å•†å“æ•°é‡: {len(products_dict)} ä¸ª")
            print(f"  - è®¢å•æ•°é‡: {rows_imported} æ¡")
            print(f"  - åœºæ™¯æ ‡ç­¾: {scene_count} ä¸ª")
            print(f"  - å¤±è´¥è®°å½•: {rows_failed} æ¡")
            
            if error_messages:
                print(f"\nâš ï¸ éƒ¨åˆ†è®°å½•å¯¼å…¥å¤±è´¥ï¼ˆæ˜¾ç¤ºå‰5æ¡ï¼‰:")
                for msg in error_messages[:5]:
                    print(f"  - {msg}")
            
            print("\nğŸ‰ æ•°æ®åº“å‡†å¤‡å°±ç»ªï¼Œå¯ä»¥å¯åŠ¨åº”ç”¨äº†ï¼\n")
            return True
            
        except Exception as e:
            db.rollback()
            print(f"\nâŒ æ•°æ®å¯¼å…¥å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description='æ•°æ®è¿ç§»å·¥å…·')
    parser.add_argument(
        '--file',
        default='å®é™…æ•°æ®/2025-09-01 00_00_00è‡³2025-09-30 12_42_28è®¢å•æ˜ç»†æ•°æ®å¯¼å‡ºæ±‡æ€» (2).xlsx',
        help='Excelæ–‡ä»¶è·¯å¾„'
    )
    parser.add_argument(
        '--force',
        action='store_true',
        help='å¼ºåˆ¶é‡æ–°å¯¼å…¥'
    )
    
    args = parser.parse_args()
    
    # æ„å»ºå®Œæ•´è·¯å¾„
    excel_path = PROJECT_ROOT / args.file
    
    if not excel_path.exists():
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {excel_path}")
        sys.exit(1)
    
    # æ‰§è¡Œè¿ç§»
    success = migrate_excel_to_database(str(excel_path), args.force)
    sys.exit(0 if success else 1)
