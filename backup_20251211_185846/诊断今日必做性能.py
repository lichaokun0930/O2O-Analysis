#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä»Šæ—¥å¿…åšTabæ€§èƒ½è¯Šæ–­è„šæœ¬

æ£€æŸ¥æ‰€æœ‰å¯èƒ½å½±å“æ€§èƒ½çš„å› ç´ 
"""

import sys
import time
from pathlib import Path

APP_DIR = Path(__file__).resolve().parent
sys.path.insert(0, str(APP_DIR))

print("="*80)
print("ä»Šæ—¥å¿…åšTabæ€§èƒ½è¯Šæ–­")
print("="*80)
print()

# 1. æ£€æŸ¥Redisè¿æ¥
print("[1/6] æ£€æŸ¥Redisç¼“å­˜...")
try:
    import redis
    client = redis.Redis(host='localhost', port=6379, db=0, socket_timeout=5)
    result = client.ping()
    print(f"   âœ… Redisè¿æ¥: {'æ­£å¸¸' if result else 'å¤±è´¥'}")
    
    # æ£€æŸ¥ç¼“å­˜ç®¡ç†å™¨
    try:
        from redis_cache_manager import REDIS_CACHE_MANAGER
        if REDIS_CACHE_MANAGER and REDIS_CACHE_MANAGER.enabled:
            print(f"   âœ… Redisç¼“å­˜ç®¡ç†å™¨: å·²å¯ç”¨")
        else:
            print(f"   âŒ Redisç¼“å­˜ç®¡ç†å™¨: æœªå¯ç”¨")
    except Exception as e:
        print(f"   âŒ Redisç¼“å­˜ç®¡ç†å™¨å¯¼å…¥å¤±è´¥: {e}")
        
except Exception as e:
    print(f"   âŒ Redisè¿æ¥å¤±è´¥: {e}")

print()

# 2. æ£€æŸ¥æ•°æ®åº“è¿æ¥
print("[2/6] æ£€æŸ¥PostgreSQLæ•°æ®åº“...")
try:
    from database.connection import engine
    from sqlalchemy import text
    with engine.connect() as conn:
        result = conn.execute(text('SELECT 1')).fetchone()
        print(f"   âœ… æ•°æ®åº“è¿æ¥: æ­£å¸¸")
        
        # æ£€æŸ¥ç´¢å¼•
        index_query = text("""
            SELECT indexname 
            FROM pg_indexes 
            WHERE tablename = 'orders' 
            AND schemaname = 'public'
        """)
        indexes = conn.execute(index_query).fetchall()
        print(f"   âœ… ordersè¡¨ç´¢å¼•æ•°é‡: {len(indexes)}ä¸ª")
        if len(indexes) < 10:
            print(f"   âš ï¸  ç´¢å¼•æ•°é‡åå°‘ï¼Œå»ºè®®è¿è¡Œ: python database/create_indexes.py")
            
except Exception as e:
    print(f"   âŒ æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")

print()

# 3. æ£€æŸ¥æ•°æ®é‡
print("[3/6] æ£€æŸ¥æ•°æ®é‡...")
try:
    data_dir = APP_DIR / "å®é™…æ•°æ®"
    excel_files = list(data_dir.glob("*.xlsx"))
    if excel_files:
        latest_file = max(excel_files, key=lambda x: x.stat().st_mtime)
        print(f"   æ–‡ä»¶: {latest_file.name}")
        
        import pandas as pd
        df = pd.read_excel(latest_file)
        print(f"   âœ… æ•°æ®è¡Œæ•°: {len(df):,}è¡Œ")
        print(f"   âœ… è®¢å•æ•°: {df['è®¢å•ID'].nunique():,}å•")
        print(f"   âœ… å•†å“æ•°: {df['å•†å“åç§°'].nunique():,}ä¸ª")
        
        if len(df) > 50000:
            print(f"   âš ï¸  æ•°æ®é‡è¾ƒå¤§ï¼Œå»ºè®®å¯ç”¨V8.7æ•°æ®é‡‡æ ·ä¼˜åŒ–")
    else:
        print(f"   âŒ æœªæ‰¾åˆ°æ•°æ®æ–‡ä»¶")
except Exception as e:
    print(f"   âŒ æ•°æ®æ£€æŸ¥å¤±è´¥: {e}")

print()

# 4. æ£€æŸ¥V8.6ä¼˜åŒ–
print("[4/6] æ£€æŸ¥V8.6è®¢å•èšåˆä¼˜åŒ–...")
try:
    from components.today_must_do.diagnosis_analysis import calculate_order_aggregation
    print(f"   âœ… calculate_order_aggregationå‡½æ•°: å·²å¯¼å…¥")
    
    # æµ‹è¯•æ€§èƒ½
    if 'df' in locals():
        start = time.time()
        order_agg = calculate_order_aggregation(df)
        elapsed = time.time() - start
        print(f"   âœ… è®¢å•èšåˆè€—æ—¶: {elapsed:.2f}ç§’")
        if elapsed > 1:
            print(f"   âš ï¸  èšåˆè¾ƒæ…¢ï¼Œå¯èƒ½éœ€è¦ä¼˜åŒ–")
except Exception as e:
    print(f"   âŒ V8.6ä¼˜åŒ–æ£€æŸ¥å¤±è´¥: {e}")

print()

# 5. æ£€æŸ¥V8.8-V8.9ä¼˜åŒ–
print("[5/6] æ£€æŸ¥V8.8-V8.9ä¼˜åŒ–...")
try:
    from components.today_must_do.debounce_utils import debounce
    print(f"   âœ… é˜²æŠ–å·¥å…·: å·²å¯¼å…¥")
except Exception as e:
    print(f"   âŒ é˜²æŠ–å·¥å…·å¯¼å…¥å¤±è´¥: {e}")

try:
    from components.today_must_do.pagination_utils import get_pagination_config
    print(f"   âœ… åˆ†é¡µå·¥å…·: å·²å¯¼å…¥")
    
    if 'df' in locals():
        config = get_pagination_config(len(df))
        print(f"   âœ… åˆ†é¡µç­–ç•¥: {config['mode']} (æ¯é¡µ{config['page_size']}è¡Œ)")
except Exception as e:
    print(f"   âŒ åˆ†é¡µå·¥å…·å¯¼å…¥å¤±è´¥: {e}")

print()

# 6. æ€§èƒ½å»ºè®®
print("[6/6] æ€§èƒ½å»ºè®®...")
print()

issues = []
recommendations = []

# Redisæ£€æŸ¥
try:
    from redis_cache_manager import REDIS_CACHE_MANAGER
    if not (REDIS_CACHE_MANAGER and REDIS_CACHE_MANAGER.enabled):
        issues.append("Redisç¼“å­˜æœªå¯ç”¨")
        recommendations.append("1. ç¡®ä¿MemuraiæœåŠ¡æ­£åœ¨è¿è¡Œ")
        recommendations.append("2. æ£€æŸ¥çœ‹æ¿å¯åŠ¨æ—¥å¿—ä¸­çš„Redisåˆå§‹åŒ–ä¿¡æ¯")
        recommendations.append("3. è¿è¡Œ: Get-Service Memurai | Start-Service")
except:
    pass

# æ•°æ®åº“ç´¢å¼•æ£€æŸ¥
try:
    if 'indexes' in locals() and len(indexes) < 10:
        issues.append("æ•°æ®åº“ç´¢å¼•ä¸è¶³")
        recommendations.append("4. è¿è¡Œ: python database/create_indexes.py")
except:
    pass

# æ•°æ®é‡æ£€æŸ¥
try:
    if 'df' in locals() and len(df) > 50000:
        issues.append("æ•°æ®é‡è¾ƒå¤§")
        recommendations.append("5. V8.7æ•°æ®é‡‡æ ·ä¼˜åŒ–åº”è¯¥ä¼šè‡ªåŠ¨ç”Ÿæ•ˆ")
except:
    pass

if issues:
    print("âš ï¸  å‘ç°ä»¥ä¸‹é—®é¢˜:")
    for issue in issues:
        print(f"   - {issue}")
    print()
    print("ğŸ’¡ å»ºè®®:")
    for rec in recommendations:
        print(f"   {rec}")
else:
    print("âœ… æ‰€æœ‰æ£€æŸ¥é€šè¿‡ï¼Œç³»ç»Ÿé…ç½®æ­£å¸¸")
    print()
    print("å¦‚æœä»Šæ—¥å¿…åšTabä»ç„¶å¾ˆæ…¢ï¼Œå¯èƒ½çš„åŸå› :")
    print("   1. é¦–æ¬¡åŠ è½½éœ€è¦è®¡ç®—ç¼“å­˜ï¼ˆ40ç§’å·¦å³ï¼‰")
    print("   2. äºŒæ¬¡åŠ è½½åº”è¯¥<1ç§’ï¼ˆå¦‚æœRedisæ­£å¸¸ï¼‰")
    print("   3. æ£€æŸ¥æµè§ˆå™¨æ§åˆ¶å°æ˜¯å¦æœ‰é”™è¯¯")

print()
print("="*80)
print("è¯Šæ–­å®Œæˆ")
print("="*80)
