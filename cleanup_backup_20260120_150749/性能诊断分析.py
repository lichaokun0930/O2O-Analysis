# -*- coding: utf-8 -*-
"""
æ€§èƒ½è¯Šæ–­åˆ†æ - æ‰¾å‡ºç³»ç»Ÿç“¶é¢ˆ

ä½œä¸ºä¼ä¸šçº§å·¥ç¨‹å¸ˆï¼Œæˆ‘ä»¬éœ€è¦å…ˆé‡åŒ–é—®é¢˜ï¼š
1. æ•°æ®é‡æœ‰å¤šå¤§ï¼Ÿ
2. æ¯ä¸ª API çš„è€—æ—¶åˆ†å¸ƒåœ¨å“ªé‡Œï¼Ÿ
3. ç“¶é¢ˆæ˜¯ I/Oã€è®¡ç®—è¿˜æ˜¯ç½‘ç»œï¼Ÿ
"""

import time
import sys
from pathlib import Path

PROJECT_ROOT = Path(__file__).resolve().parent
sys.path.insert(0, str(PROJECT_ROOT))
sys.path.insert(0, str(PROJECT_ROOT / "backend" / "app"))

from database.connection import SessionLocal
from database.models import Order
from sqlalchemy import func, text
import pandas as pd

def diagnose_data_volume():
    """è¯Šæ–­æ•°æ®é‡"""
    print("="*80)
    print("ğŸ“Š æ•°æ®é‡è¯Šæ–­")
    print("="*80)
    
    session = SessionLocal()
    try:
        # æ€»è®°å½•æ•°
        total_records = session.query(func.count(Order.id)).scalar()
        print(f"\næ€»è®°å½•æ•°: {total_records:,} æ¡")
        
        # å”¯ä¸€è®¢å•æ•°
        unique_orders = session.query(func.count(func.distinct(Order.order_id))).scalar()
        print(f"å”¯ä¸€è®¢å•æ•°: {unique_orders:,} å•")
        
        # é—¨åº—æ•°
        store_count = session.query(func.count(func.distinct(Order.store_name))).scalar()
        print(f"é—¨åº—æ•°: {store_count} ä¸ª")
        
        # æ—¥æœŸèŒƒå›´
        min_date = session.query(func.min(Order.date)).scalar()
        max_date = session.query(func.max(Order.date)).scalar()
        print(f"æ—¥æœŸèŒƒå›´: {min_date} ~ {max_date}")
        
        # æ¯ä¸ªé—¨åº—çš„å¹³å‡è®°å½•æ•°
        avg_per_store = total_records / store_count if store_count > 0 else 0
        print(f"æ¯é—¨åº—å¹³å‡è®°å½•: {avg_per_store:,.0f} æ¡")
        
        # æ•°æ®é‡è¯„ä¼°
        print("\nğŸ“‹ æ•°æ®é‡è¯„ä¼°:")
        if total_records < 100000:
            print(f"   âœ… æ•°æ®é‡è¾ƒå° ({total_records:,} æ¡)ï¼Œä¸åº”è¯¥æœ‰æ€§èƒ½é—®é¢˜")
            print(f"   âš ï¸ å¦‚æœæœ‰æ€§èƒ½é—®é¢˜ï¼Œè¯´æ˜ä»£ç å®ç°æœ‰é—®é¢˜")
        elif total_records < 1000000:
            print(f"   âš ï¸ ä¸­ç­‰æ•°æ®é‡ ({total_records:,} æ¡)ï¼Œéœ€è¦é€‚å½“ä¼˜åŒ–")
        else:
            print(f"   ğŸ”´ å¤§æ•°æ®é‡ ({total_records:,} æ¡)ï¼Œéœ€è¦ä¼ä¸šçº§ä¼˜åŒ–")
        
        return total_records, unique_orders, store_count
    finally:
        session.close()


def diagnose_query_performance():
    """è¯Šæ–­æŸ¥è¯¢æ€§èƒ½"""
    print("\n" + "="*80)
    print("â±ï¸ æŸ¥è¯¢æ€§èƒ½è¯Šæ–­")
    print("="*80)
    
    session = SessionLocal()
    try:
        # æµ‹è¯•1: ç®€å•è®¡æ•°æŸ¥è¯¢
        start = time.time()
        session.query(func.count(Order.id)).scalar()
        count_time = time.time() - start
        print(f"\n1. ç®€å•è®¡æ•°æŸ¥è¯¢: {count_time*1000:.1f}ms")
        
        # æµ‹è¯•2: å…¨è¡¨æ‰«æ
        start = time.time()
        orders = session.query(Order).limit(10000).all()
        scan_time = time.time() - start
        print(f"2. è¯»å–10000æ¡è®°å½•: {scan_time*1000:.1f}ms")
        
        # æµ‹è¯•3: æŒ‰é—¨åº—ç­›é€‰
        start = time.time()
        orders = session.query(Order).filter(
            Order.store_name == "æƒ å®œé€‰-æ³°å·æ³°å…´åº—"
        ).all()
        filter_time = time.time() - start
        print(f"3. æŒ‰é—¨åº—ç­›é€‰: {filter_time*1000:.1f}ms ({len(orders)} æ¡)")
        
        # æµ‹è¯•4: æŒ‰æ—¥æœŸèŒƒå›´ç­›é€‰
        start = time.time()
        from datetime import datetime
        orders = session.query(Order).filter(
            Order.date >= datetime(2026, 1, 12),
            Order.date <= datetime(2026, 1, 18)
        ).all()
        date_filter_time = time.time() - start
        print(f"4. æŒ‰æ—¥æœŸèŒƒå›´ç­›é€‰: {date_filter_time*1000:.1f}ms ({len(orders)} æ¡)")
        
        # æµ‹è¯•5: å¤åˆç­›é€‰
        start = time.time()
        orders = session.query(Order).filter(
            Order.store_name == "æƒ å®œé€‰-æ³°å·æ³°å…´åº—",
            Order.date >= datetime(2026, 1, 12),
            Order.date <= datetime(2026, 1, 18)
        ).all()
        compound_time = time.time() - start
        print(f"5. å¤åˆç­›é€‰(é—¨åº—+æ—¥æœŸ): {compound_time*1000:.1f}ms ({len(orders)} æ¡)")
        
        # æ€§èƒ½è¯„ä¼°
        print("\nğŸ“‹ æŸ¥è¯¢æ€§èƒ½è¯„ä¼°:")
        if compound_time < 0.5:
            print(f"   âœ… æ•°æ®åº“æŸ¥è¯¢æ€§èƒ½è‰¯å¥½ (<500ms)")
        elif compound_time < 2:
            print(f"   âš ï¸ æ•°æ®åº“æŸ¥è¯¢è¾ƒæ…¢ ({compound_time*1000:.0f}ms)ï¼Œå»ºè®®æ·»åŠ ç´¢å¼•")
        else:
            print(f"   ğŸ”´ æ•°æ®åº“æŸ¥è¯¢å¾ˆæ…¢ ({compound_time*1000:.0f}ms)ï¼Œéœ€è¦ä¼˜åŒ–")
        
        return count_time, scan_time, filter_time
    finally:
        session.close()


def diagnose_pandas_performance():
    """è¯Šæ–­ Pandas è®¡ç®—æ€§èƒ½"""
    print("\n" + "="*80)
    print("ğŸ¼ Pandas è®¡ç®—æ€§èƒ½è¯Šæ–­")
    print("="*80)
    
    session = SessionLocal()
    try:
        # åŠ è½½æ•°æ®
        start = time.time()
        orders = session.query(Order).all()
        load_time = time.time() - start
        print(f"\n1. ä»æ•°æ®åº“åŠ è½½å…¨éƒ¨æ•°æ®: {load_time*1000:.1f}ms ({len(orders)} æ¡)")
        
        # è½¬æ¢ä¸º DataFrame
        start = time.time()
        data = []
        for order in orders:
            data.append({
                'è®¢å•ID': order.order_id,
                'é—¨åº—åç§°': order.store_name,
                'æ¸ é“': order.channel,
                'å®æ”¶ä»·æ ¼': float(order.actual_price or 0),
                'ç‰©æµé…é€è´¹': float(order.delivery_fee or 0),
                'å¹³å°æœåŠ¡è´¹': float(order.platform_service_fee or 0),
            })
        df = pd.DataFrame(data)
        convert_time = time.time() - start
        print(f"2. è½¬æ¢ä¸º DataFrame: {convert_time*1000:.1f}ms")
        
        # GroupBy èšåˆ
        start = time.time()
        order_agg = df.groupby('è®¢å•ID').agg({
            'å®æ”¶ä»·æ ¼': 'sum',
            'ç‰©æµé…é€è´¹': 'first',
            'å¹³å°æœåŠ¡è´¹': 'sum',
        }).reset_index()
        groupby_time = time.time() - start
        print(f"3. GroupBy è®¢å•èšåˆ: {groupby_time*1000:.1f}ms ({len(order_agg)} è®¢å•)")
        
        # æŒ‰é—¨åº—èšåˆ
        start = time.time()
        # å…ˆåˆå¹¶é—¨åº—ä¿¡æ¯
        order_store = df.groupby('è®¢å•ID')['é—¨åº—åç§°'].first().reset_index()
        order_agg = order_agg.merge(order_store, on='è®¢å•ID')
        store_agg = order_agg.groupby('é—¨åº—åç§°').agg({
            'è®¢å•ID': 'count',
            'å®æ”¶ä»·æ ¼': 'sum',
        }).reset_index()
        store_agg_time = time.time() - start
        print(f"4. æŒ‰é—¨åº—èšåˆ: {store_agg_time*1000:.1f}ms ({len(store_agg)} é—¨åº—)")
        
        # æ€§èƒ½è¯„ä¼°
        total_time = load_time + convert_time + groupby_time + store_agg_time
        print(f"\nğŸ“‹ Pandas è®¡ç®—æ€§èƒ½è¯„ä¼°:")
        print(f"   æ€»è€—æ—¶: {total_time*1000:.1f}ms")
        
        if total_time < 2:
            print(f"   âœ… è®¡ç®—æ€§èƒ½è‰¯å¥½ (<2ç§’)")
        elif total_time < 5:
            print(f"   âš ï¸ è®¡ç®—è¾ƒæ…¢ï¼Œå»ºè®®ä¼˜åŒ–æ•°æ®ç»“æ„")
        else:
            print(f"   ğŸ”´ è®¡ç®—å¾ˆæ…¢ï¼Œéœ€è¦é‡æ„")
        
        # ç“¶é¢ˆåˆ†æ
        print(f"\nğŸ“Š è€—æ—¶åˆ†å¸ƒ:")
        print(f"   æ•°æ®åº“åŠ è½½: {load_time/total_time*100:.1f}%")
        print(f"   DataFrameè½¬æ¢: {convert_time/total_time*100:.1f}%")
        print(f"   è®¢å•èšåˆ: {groupby_time/total_time*100:.1f}%")
        print(f"   é—¨åº—èšåˆ: {store_agg_time/total_time*100:.1f}%")
        
        return load_time, convert_time, groupby_time
    finally:
        session.close()


def diagnose_api_bottleneck():
    """è¯Šæ–­ API ç“¶é¢ˆ"""
    print("\n" + "="*80)
    print("ğŸ” API ç“¶é¢ˆè¯Šæ–­")
    print("="*80)
    
    import requests
    
    apis = [
        ("/stores/comparison", {"start_date": "2026-01-12", "end_date": "2026-01-18"}),
        ("/stores/comparison/week-over-week", {"end_date": "2026-01-18"}),
        ("/orders/overview", {"store_name": "æƒ å®œé€‰-æ³°å·æ³°å…´åº—"}),
        ("/orders/channels", {"store_name": "æƒ å®œé€‰-æ³°å·æ³°å…´åº—"}),
    ]
    
    print("\nå•ç‹¬è¯·æ±‚å„ API:")
    for api, params in apis:
        try:
            start = time.time()
            resp = requests.get(f"http://localhost:8080/api/v1{api}", params=params, timeout=60)
            elapsed = time.time() - start
            status = "âœ…" if resp.status_code == 200 else "âŒ"
            print(f"   {status} {api}: {elapsed*1000:.0f}ms")
        except Exception as e:
            print(f"   âŒ {api}: {e}")
    
    # å¹¶å‘è¯·æ±‚æµ‹è¯•
    print("\nå¹¶å‘è¯·æ±‚æµ‹è¯• (æ¨¡æ‹Ÿå‰ç«¯åŒæ—¶è¯·æ±‚):")
    import concurrent.futures
    
    def make_request(api_info):
        api, params = api_info
        start = time.time()
        try:
            resp = requests.get(f"http://localhost:8080/api/v1{api}", params=params, timeout=60)
            return api, time.time() - start, resp.status_code
        except Exception as e:
            return api, time.time() - start, str(e)
    
    start = time.time()
    with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:
        results = list(executor.map(make_request, apis))
    total_time = time.time() - start
    
    for api, elapsed, status in results:
        status_str = "âœ…" if status == 200 else f"âŒ {status}"
        print(f"   {status_str} {api}: {elapsed*1000:.0f}ms")
    
    print(f"\n   å¹¶å‘æ€»è€—æ—¶: {total_time*1000:.0f}ms")
    
    if total_time < 10:
        print(f"   âœ… å¹¶å‘æ€§èƒ½è‰¯å¥½")
    else:
        print(f"   âš ï¸ å¹¶å‘æ€§èƒ½éœ€è¦ä¼˜åŒ–")


def main():
    print("\n" + "ğŸ”¬"*40)
    print("         ä¼ä¸šçº§æ€§èƒ½è¯Šæ–­åˆ†æ")
    print("ğŸ”¬"*40)
    
    # 1. æ•°æ®é‡è¯Šæ–­
    total_records, unique_orders, store_count = diagnose_data_volume()
    
    # 2. æŸ¥è¯¢æ€§èƒ½è¯Šæ–­
    diagnose_query_performance()
    
    # 3. Pandas è®¡ç®—æ€§èƒ½è¯Šæ–­
    diagnose_pandas_performance()
    
    # 4. API ç“¶é¢ˆè¯Šæ–­
    diagnose_api_bottleneck()
    
    # æ€»ç»“
    print("\n" + "="*80)
    print("ğŸ“‹ è¯Šæ–­æ€»ç»“ä¸ä¼˜åŒ–å»ºè®®")
    print("="*80)
    
    print(f"""
æ•°æ®è§„æ¨¡: {total_records:,} æ¡è®°å½•, {unique_orders:,} è®¢å•, {store_count} é—¨åº—

è¿™ä¸ªæ•°æ®é‡çº§ï¼ˆçº¦ {total_records//1000}K æ¡ï¼‰å¯¹äºç°ä»£ç³»ç»Ÿæ¥è¯´æ˜¯å¾ˆå°çš„ï¼Œ
ä¸åº”è¯¥æœ‰ä»»ä½•æ€§èƒ½é—®é¢˜ã€‚å¦‚æœå‡ºç°è¶…æ—¶ï¼Œé—®é¢˜ä¸€å®šåœ¨ä»£ç å®ç°ä¸Šã€‚

ğŸ¯ å¯èƒ½çš„ç“¶é¢ˆç‚¹:
1. ã€æ•°æ®åº“ã€‘æ²¡æœ‰åˆé€‚çš„ç´¢å¼•
2. ã€åç«¯ã€‘æ¯æ¬¡è¯·æ±‚éƒ½é‡æ–°åŠ è½½å…¨éƒ¨æ•°æ®ï¼ˆæ²¡æœ‰ç¼“å­˜ï¼‰
3. ã€åç«¯ã€‘Pandas è®¡ç®—é€»è¾‘å†—ä½™ï¼ˆé‡å¤è®¡ç®—ï¼‰
4. ã€åç«¯ã€‘ORM å¯¹è±¡è½¬æ¢å¼€é”€å¤§
5. ã€å‰ç«¯ã€‘åŒæ—¶å‘èµ·å¤ªå¤šè¯·æ±‚ï¼Œåç«¯ä¸²è¡Œå¤„ç†
6. ã€å‰ç«¯ã€‘æ²¡æœ‰è¯·æ±‚å»é‡/é˜²æŠ–

ğŸš€ ä¼ä¸šçº§ä¼˜åŒ–æ–¹æ¡ˆ:
1. æ•°æ®åº“å±‚: æ·»åŠ å¤åˆç´¢å¼• (store_name, date)
2. ç¼“å­˜å±‚: Redis ç¼“å­˜èšåˆç»“æœï¼ˆ5åˆ†é’Ÿè¿‡æœŸï¼‰
3. è®¡ç®—å±‚: é¢„è®¡ç®—é—¨åº—æ—¥æ±‡æ€»è¡¨
4. APIå±‚: å¼‚æ­¥å¤„ç† + è¿æ¥æ± 
5. å‰ç«¯å±‚: è¯·æ±‚åˆå¹¶ + éª¨æ¶å± + æ¸è¿›åŠ è½½
""")


if __name__ == "__main__":
    main()
