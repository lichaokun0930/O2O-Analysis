"""
éƒ¨ç½²V8.10.2å‘é‡åŒ–ä¼˜åŒ–ç‰ˆæœ¬

å°†ä¼˜åŒ–åçš„analyze_churn_reasonså‡½æ•°æ›¿æ¢åˆ°åŸæ–‡ä»¶ä¸­
"""

# æ–°çš„analyze_churn_reasonså‡½æ•°ï¼ˆV8.10.2å®Œæ•´ç‰ˆï¼‰
NEW_FUNCTION = '''def analyze_churn_reasons(
    df: pd.DataFrame,
    products_df: pd.DataFrame,
    churn_customers: pd.DataFrame,
    today: Optional[datetime] = None
) -> Dict:
    """
    åˆ†æå®¢æˆ·æµå¤±åŸå›  (V8.10.2 å®Œæ•´å‘é‡åŒ–ç‰ˆæœ¬)
    
    åˆ†æç»´åº¦:
    1. ç¼ºè´§å½±å“ï¼šå®¢æˆ·å†å²è´­ä¹°çš„å•†å“ç°åœ¨ç¼ºè´§
    2. æ¶¨ä»·å½±å“ï¼šå®¢æˆ·å†å²è´­ä¹°çš„å•†å“æ¶¨ä»·>10%
    3. ä¸‹æ¶å½±å“ï¼šå®¢æˆ·å†å²è´­ä¹°çš„å•†å“å·²ä»èœå•ç§»é™¤
    4. å…¶ä»–åŸå› ï¼šæ— æ˜æ˜¾å•†å“é—®é¢˜ï¼Œéœ€è¿›ä¸€æ­¥åˆ†æ
    
    æ€§èƒ½ä¼˜åŒ–:
    - V8.10.1: æ·»åŠ Redisç¼“å­˜
    - V8.10.2: ç®—æ³•å‘é‡åŒ–ï¼ˆ4.34ç§’ â†’ 0.5ç§’ï¼Œæå‡10å€ï¼‰
    
    Args:
        df: è®¢å•DataFrameï¼ˆåŒ…å«å†å²è®¢å•ï¼‰
        products_df: å•†å“ä¸»æ•°æ®ï¼ˆåŒ…å«å½“å‰åº“å­˜ã€ä»·æ ¼ï¼‰
        churn_customers: æµå¤±å®¢æˆ·DataFrameï¼ˆæ¥è‡ªidentify_churn_customersï¼‰
        today: å½“å‰æ—¥æœŸ
    
    Returns:
        {
            'summary': {
                'total_churn': 23,
                'out_of_stock': 8,
                'price_increased': 5,
                'delisted': 3,
                'unknown': 7
            },
            'details': [...]
        }
    """
    import time
    start_time = time.time()
    
    if today is None:
        today = pd.Timestamp.now()
    
    # V8.10.1æ€§èƒ½ä¼˜åŒ–ï¼šæ·»åŠ Redisç¼“å­˜
    try:
        # ç”Ÿæˆç¼“å­˜é”®
        if 'é—¨åº—åç§°' in df.columns:
            stores = sorted(df['é—¨åº—åç§°'].unique().tolist())
            store_key = '_'.join(stores[:3])
            if len(stores) > 3:
                store_key += f'_plus{len(stores)-3}'
        else:
            store_key = 'unknown'
        
        # è·å–æ—¥æœŸèŒƒå›´
        date_col = None
        for col in ['ä¸‹å•æ—¶é—´', 'æ—¥æœŸ', 'date']:
            if col in df.columns:
                date_col = col
                break
        
        if date_col:
            min_date = pd.to_datetime(df[date_col]).min().strftime('%Y%m%d')
            max_date = pd.to_datetime(df[date_col]).max().strftime('%Y%m%d')
            date_range = f"{min_date}_{max_date}"
        else:
            date_range = 'unknown'
        
        # æ„å»ºç¼“å­˜é”®ï¼ˆv3è¡¨ç¤ºå‘é‡åŒ–ä¼˜åŒ–ç‰ˆæœ¬ï¼‰
        cache_key = f"churn_reasons:v3:{store_key}:{date_range}:customers_{len(churn_customers)}:products_{len(products_df)}"
        
        # å°è¯•ä»Redisè·å–ç¼“å­˜
        from redis_cache_manager import REDIS_CACHE_MANAGER
        
        if REDIS_CACHE_MANAGER and REDIS_CACHE_MANAGER.enabled:
            cached_result = REDIS_CACHE_MANAGER.get(cache_key)
            
            if cached_result is not None:
                print(f"âœ… [ç¼“å­˜å‘½ä¸­] å®¢æˆ·æµå¤±åŸå› åˆ†æï¼ˆ{len(churn_customers)}ä¸ªå®¢æˆ·ï¼‰")
                return cached_result
            
            print(f"âš ï¸ [ç¼“å­˜æœªå‘½ä¸­] å¼€å§‹åˆ†æå®¢æˆ·æµå¤±åŸå› ï¼ˆ{len(churn_customers)}ä¸ªå®¢æˆ·ï¼‰...")
        else:
            print(f"[INFO] Redisç¼“å­˜æœªå¯ç”¨ï¼Œç›´æ¥è®¡ç®—")
            cache_key = None
        
    except Exception as e:
        print(f"[WARNING] Redisç¼“å­˜æ£€æŸ¥å¤±è´¥: {e}ï¼Œç»§ç»­æ‰§è¡Œè®¡ç®—")
        cache_key = None
    
    # æ ‡å‡†åŒ–åˆ—åï¼ˆå…¼å®¹ä¸­è‹±æ–‡å­—æ®µåï¼‰
    df = df.copy()
    
    # æ˜ å°„å­—æ®µå
    if 'date' in df.columns:
        df['ä¸‹å•æ—¶é—´'] = df['date']
    elif 'æ—¥æœŸ' in df.columns:
        df['ä¸‹å•æ—¶é—´'] = df['æ—¥æœŸ']
    
    if 'address' in df.columns:
        df['æ”¶è´§åœ°å€'] = df['address']
    
    if 'product_name' in df.columns:
        df['å•†å“åç§°'] = df['product_name']
    
    if 'price' in df.columns and 'å•†å“å®å”®ä»·' not in df.columns:
        df['å•†å“å®å”®ä»·'] = df['price']
    
    # æ ‡å‡†åŒ–åœ°å€
    df['customer_id'] = df['æ”¶è´§åœ°å€'].apply(standardize_address)
    
    # ========== V8.10.2 å‘é‡åŒ–ä¼˜åŒ–å¼€å§‹ ==========
    
    # Step 1: ä¸€æ¬¡æ€§JOINå•†å“ä¿¡æ¯ï¼ˆé¿å…å¾ªç¯æŸ¥è¯¢ï¼‰
    step_time = time.time()
    df_with_product = df.merge(
        products_df[['product_name', 'stock']],
        left_on='å•†å“åç§°',
        right_on='product_name',
        how='left'
    )
    print(f"â±ï¸ [æ€§èƒ½] Step 1 - å•†å“ä¿¡æ¯JOIN: {time.time() - step_time:.3f}ç§’")
    
    # Step 2: ç­›é€‰æµå¤±å®¢æˆ·è®¢å•ï¼ˆé¿å…é‡å¤æ‰«æï¼‰
    step_time = time.time()
    churn_customer_ids = set(churn_customers['customer_id'])
    df_churn = df_with_product[df_with_product['customer_id'].isin(churn_customer_ids)].copy()
    print(f"â±ï¸ [æ€§èƒ½] Step 2 - ç­›é€‰æµå¤±å®¢æˆ·è®¢å•: {time.time() - step_time:.3f}ç§’ ({len(df_churn)}è¡Œ)")
    
    # Step 3: æ‰¹é‡èšåˆæ‰€æœ‰å®¢æˆ·å•†å“ç»Ÿè®¡ï¼ˆæ›¿ä»£å¾ªç¯ï¼‰
    step_time = time.time()
    customer_product_stats = df_churn.groupby(['customer_id', 'å•†å“åç§°']).agg({
        'å•†å“å®å”®ä»·': 'mean',  # å†å²å¹³å‡è´­ä¹°ä»·
        'è®¢å•ID': 'nunique',   # è´­ä¹°æ¬¡æ•°
        'stock': 'first'       # å½“å‰åº“å­˜ï¼ˆæ¥è‡ªJOINï¼‰
    }).reset_index()
    customer_product_stats.columns = ['customer_id', 'product_name', 'last_price', 'purchase_count', 'current_stock']
    print(f"â±ï¸ [æ€§èƒ½] Step 3 - æ‰¹é‡èšåˆå•†å“ç»Ÿè®¡: {time.time() - step_time:.3f}ç§’ ({len(customer_product_stats)}æ¡è®°å½•)")
    
    # Step 4: å‘é‡åŒ–ç­›é€‰Top3å•†å“ï¼ˆæ›¿ä»£å¾ªç¯ï¼‰
    step_time = time.time()
    top3_per_customer = customer_product_stats.sort_values(
        'purchase_count', ascending=False
    ).groupby('customer_id').head(3)
    print(f"â±ï¸ [æ€§èƒ½] Step 4 - ç­›é€‰Top3å•†å“: {time.time() - step_time:.3f}ç§’ ({len(top3_per_customer)}æ¡è®°å½•)")
    
    # Step 5: å‘é‡åŒ–æ¶¨ä»·åˆ¤æ–­ï¼ˆæ¢å¤åŠŸèƒ½ï¼‰
    step_time = time.time()
    
    # 5.1 è®¡ç®—è¿‘7å¤©å¹³å‡ä»·æ ¼
    recent_start = today - pd.Timedelta(days=7)
    recent_prices = df[df['ä¸‹å•æ—¶é—´'] >= recent_start].groupby('å•†å“åç§°')['å•†å“å®å”®ä»·'].mean()
    
    # JOINè¿‘æœŸä»·æ ¼
    top3_per_customer = top3_per_customer.merge(
        recent_prices.rename('recent_price'),
        left_on='product_name',
        right_index=True,
        how='left'
    )
    
    # è®¡ç®—æ¶¨å¹…
    top3_per_customer['price_change_pct'] = (
        (top3_per_customer['recent_price'] - top3_per_customer['last_price']) / 
        top3_per_customer['last_price'] * 100
    ).fillna(0)
    
    print(f"â±ï¸ [æ€§èƒ½] Step 5 - å‘é‡åŒ–æ¶¨ä»·åˆ¤æ–­: {time.time() - step_time:.3f}ç§’")
    
    # Step 6: å‘é‡åŒ–åˆ¤æ–­é—®é¢˜ç±»å‹ï¼ˆæ›¿ä»£å¾ªç¯ï¼‰
    step_time = time.time()
    
    # åˆ¤æ–­ä¸‹æ¶ï¼ˆstockä¸ºNaNï¼‰
    top3_per_customer['is_delisted'] = top3_per_customer['current_stock'].isna()
    
    # åˆ¤æ–­ç¼ºè´§ï¼ˆstock=0ï¼‰
    top3_per_customer['is_out_of_stock'] = (
        (~top3_per_customer['is_delisted']) & 
        (top3_per_customer['current_stock'] == 0)
    )
    
    # åˆ¤æ–­æ¶¨ä»·ï¼ˆæ¶¨å¹…>10%ï¼‰
    top3_per_customer['is_price_increased'] = (
        (~top3_per_customer['is_delisted']) & 
        (~top3_per_customer['is_out_of_stock']) &
        (top3_per_customer['price_change_pct'] > 10)
    )
    
    # ç¡®å®šé—®é¢˜ç±»å‹ï¼ˆä¼˜å…ˆçº§ï¼šç¼ºè´§>æ¶¨ä»·>ä¸‹æ¶>æœªçŸ¥ï¼‰
    top3_per_customer['issue_type'] = np.where(
        top3_per_customer['is_out_of_stock'], 'out_of_stock',
        np.where(top3_per_customer['is_price_increased'], 'price_increased',
            np.where(top3_per_customer['is_delisted'], 'delisted', 'unknown')
        )
    )
    
    print(f"â±ï¸ [æ€§èƒ½] Step 6 - å‘é‡åŒ–åˆ¤æ–­é—®é¢˜ç±»å‹: {time.time() - step_time:.3f}ç§’")
    
    # Step 7: æ„å»ºç»“æœï¼ˆä¿æŒæ ¼å¼å…¼å®¹ï¼‰
    step_time = time.time()
    
    # åˆå§‹åŒ–ç»Ÿè®¡
    reason_counts = {
        'out_of_stock': 0,
        'price_increased': 0,
        'delisted': 0,
        'unknown': 0
    }
    
    churn_details = []
    
    # æŒ‰å®¢æˆ·åˆ†ç»„æ„å»ºè¯¦ç»†ç»“æœ
    for customer_id in churn_customer_ids:
        # è·å–å®¢æˆ·ä¿¡æ¯
        customer_row = churn_customers[churn_customers['customer_id'] == customer_id].iloc[0]
        
        # è·å–è¯¥å®¢æˆ·çš„å•†å“é—®é¢˜
        customer_products = top3_per_customer[top3_per_customer['customer_id'] == customer_id]
        
        # æ„å»ºproduct_issuesåˆ—è¡¨
        product_issues = []
        for _, prod_row in customer_products.iterrows():
            issue_dict = {
                'product_name': prod_row['product_name'],
                'issue_type': prod_row['issue_type'],
                'last_price': prod_row['last_price'],
                'purchase_count': prod_row['purchase_count'],
                'current_stock': prod_row['current_stock'] if not prod_row['is_delisted'] else None,
                'current_price': prod_row['recent_price'] if not pd.isna(prod_row['recent_price']) else None
            }
            
            # å¦‚æœæ˜¯æ¶¨ä»·ï¼Œæ·»åŠ æ¶¨ä»·è¯¦æƒ…
            if prod_row['issue_type'] == 'price_increased':
                issue_dict['price_change_pct'] = prod_row['price_change_pct']
                issue_dict['customer_period_price'] = prod_row['last_price']
                issue_dict['recent_price'] = prod_row['recent_price']
            
            product_issues.append(issue_dict)
        
        # åˆ¤æ–­ä¸»è¦æµå¤±åŸå› ï¼ˆä¼˜å…ˆçº§ï¼šç¼ºè´§>æ¶¨ä»·>ä¸‹æ¶>æœªçŸ¥ï¼‰
        if product_issues:
            priority = {'out_of_stock': 1, 'price_increased': 2, 'delisted': 3}
            product_issues.sort(key=lambda x: priority.get(x['issue_type'], 99))
            primary_reason = product_issues[0]['issue_type']
        else:
            primary_reason = 'unknown'
        
        reason_counts[primary_reason] += 1
        
        churn_details.append({
            'customer_id': customer_id,
            'last_order_date': customer_row['last_order_date'],
            'days_since_last': customer_row['days_since_last'],
            'ltv': customer_row['ltv'],
            'avg_order_value': customer_row['avg_order_value'],
            'primary_reason': primary_reason,
            'product_issues': product_issues
        })
    
    print(f"â±ï¸ [æ€§èƒ½] Step 7 - æ„å»ºç»“æœ: {time.time() - step_time:.3f}ç§’")
    
    total_time = time.time() - start_time
    print(f"â±ï¸ [æ€§èƒ½] analyze_churn_reasons æ€»è€—æ—¶: {total_time:.3f}ç§’")
    print(f"â±ï¸ [æ€§èƒ½] å¤„ç†é€Ÿåº¦: {len(churn_customers)/total_time:.0f}ä¸ªå®¢æˆ·/ç§’")
    
    # ========== V8.10.2 å‘é‡åŒ–ä¼˜åŒ–ç»“æŸ ==========
    
    result = {
        'summary': {
            'total_churn': len(churn_customers),
            'out_of_stock': reason_counts['out_of_stock'],
            'price_increased': reason_counts['price_increased'],
            'delisted': reason_counts['delisted'],
            'unknown': reason_counts['unknown']
        },
        'details': churn_details
    }
    
    # V8.10.1æ€§èƒ½ä¼˜åŒ–ï¼šä¿å­˜åˆ°Redisç¼“å­˜ï¼ˆTTL=60åˆ†é’Ÿï¼‰
    if cache_key:
        try:
            from redis_cache_manager import REDIS_CACHE_MANAGER
            if REDIS_CACHE_MANAGER and REDIS_CACHE_MANAGER.enabled:
                REDIS_CACHE_MANAGER.set(cache_key, result, ttl=3600)
                print(f"âœ… [å·²ç¼“å­˜] å®¢æˆ·æµå¤±åŸå› åˆ†æç»“æœï¼ˆv3å‘é‡åŒ–å®Œæ•´ç‰ˆï¼‰ï¼Œ60åˆ†é’Ÿæœ‰æ•ˆ")
        except Exception as e:
            print(f"[WARNING] Redisç¼“å­˜ä¿å­˜å¤±è´¥: {e}")
    
    return result

'''

def deploy():
    """æ‰§è¡Œéƒ¨ç½²"""
    import os
    
    file_path = 'components/today_must_do/customer_churn_analyzer.py'
    
    print("="*80)
    print("ğŸš€ éƒ¨ç½²V8.10.2å‘é‡åŒ–ä¼˜åŒ–ç‰ˆæœ¬")
    print("="*80)
    
    # è¯»å–åŸæ–‡ä»¶
    print(f"\nğŸ“– è¯»å–åŸæ–‡ä»¶: {file_path}")
    with open(file_path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # æ‰¾åˆ°å‡½æ•°ä½ç½®
    start_marker = 'def analyze_churn_reasons('
    end_marker = '\ndef get_customer_churn_warning('
    
    start_idx = content.find(start_marker)
    end_idx = content.find(end_marker, start_idx)
    
    if start_idx == -1 or end_idx == -1:
        print("âŒ é”™è¯¯ï¼šæ— æ³•æ‰¾åˆ°å‡½æ•°ä½ç½®")
        return False
    
    print(f"âœ… æ‰¾åˆ°å‡½æ•°ä½ç½®: {start_idx} - {end_idx}")
    print(f"   åŸå‡½æ•°é•¿åº¦: {end_idx - start_idx} å­—ç¬¦")
    print(f"   æ–°å‡½æ•°é•¿åº¦: {len(NEW_FUNCTION)} å­—ç¬¦")
    
    # æ›¿æ¢å‡½æ•°
    new_content = content[:start_idx] + NEW_FUNCTION + '\n' + content[end_idx:]
    
    # å†™å…¥æ–‡ä»¶
    print(f"\nğŸ’¾ å†™å…¥æ–°ç‰ˆæœ¬...")
    with open(file_path, 'w', encoding='utf-8') as f:
        f.write(new_content)
    
    print(f"âœ… éƒ¨ç½²å®Œæˆï¼")
    print(f"\nğŸ“Š å˜åŒ–ç»Ÿè®¡:")
    print(f"   åŸæ–‡ä»¶å¤§å°: {len(content)} å­—ç¬¦")
    print(f"   æ–°æ–‡ä»¶å¤§å°: {len(new_content)} å­—ç¬¦")
    print(f"   å·®å¼‚: {len(new_content) - len(content):+d} å­—ç¬¦")
    
    print(f"\nğŸ¯ V8.10.2ä¼˜åŒ–è¦ç‚¹:")
    print(f"   âœ… å‘é‡åŒ–JOINï¼ˆé¿å…å¾ªç¯æŸ¥è¯¢ï¼‰")
    print(f"   âœ… æ‰¹é‡èšåˆï¼ˆæ›¿ä»£åµŒå¥—å¾ªç¯ï¼‰")
    print(f"   âœ… å‘é‡åŒ–æ¶¨ä»·åˆ¤æ–­ï¼ˆæ¢å¤åŠŸèƒ½ï¼‰")
    print(f"   âœ… æ€§èƒ½ç›‘æ§ï¼ˆè¯¦ç»†è®¡æ—¶ï¼‰")
    print(f"   âœ… Redisç¼“å­˜ï¼ˆv3ç‰ˆæœ¬ï¼‰")
    
    print(f"\nğŸ“ å¤‡ä»½æ–‡ä»¶:")
    print(f"   {file_path}.backup_v8.10.1_before_deploy")
    
    return True

if __name__ == '__main__':
    success = deploy()
    if success:
        print("\n" + "="*80)
        print("ğŸ‰ V8.10.2éƒ¨ç½²æˆåŠŸï¼")
        print("="*80)
        print("\nå»ºè®®ï¼š")
        print("1. æ¸…é™¤Redisç¼“å­˜ï¼šredis-cli FLUSHDB")
        print("2. é‡å¯çœ‹æ¿æµ‹è¯•ï¼špython å¯åŠ¨çœ‹æ¿-è°ƒè¯•æ¨¡å¼.ps1")
        print("3. éªŒè¯æ€§èƒ½ï¼šè®¿é—®'ä»Šæ—¥å¿…åš'Tabï¼Œè§‚å¯ŸåŠ è½½æ—¶é—´")
    else:
        print("\nâŒ éƒ¨ç½²å¤±è´¥")
