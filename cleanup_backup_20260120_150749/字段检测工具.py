"""
ğŸ“¦ å­—æ®µæ£€æµ‹å·¥å…· - å‚»ç“œå¼æ“ä½œ

åŠŸèƒ½ï¼š
1. æ‰«æ Excel æ–‡ä»¶ï¼Œæ£€æµ‹æ–°å­—æ®µ
2. è‡ªåŠ¨ç”Ÿæˆ models.py ä»£ç ç‰‡æ®µ
3. è‡ªåŠ¨ç”Ÿæˆ data_source_manager.py æ˜ å°„ä»£ç 
4. ä¸€é”®å¤åˆ¶åˆ°å‰ªè´´æ¿

ä½¿ç”¨æ–¹æ³•ï¼š
    ç›´æ¥è¿è¡Œæ­¤è„šæœ¬ï¼ŒæŒ‰æç¤ºæ“ä½œå³å¯

ä½œè€…: GitHub Copilot
æ—¥æœŸ: 2025-12-04
"""

import sys
import os
import re
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•
PROJECT_ROOT = Path(__file__).parent
sys.path.insert(0, str(PROJECT_ROOT))

import pandas as pd
from typing import Dict, List, Tuple


# ========================================
# é…ç½®
# ========================================
DEFAULT_EXCEL_PATH = r"é—¨åº—æ•°æ®\æ¯”ä»·çœ‹æ¿æ¨¡å—\è®¢å•æ•°æ®-æœ¬åº—.xlsx"


def get_existing_fields() -> set:
    """è·å– models.py ä¸­å·²å®šä¹‰çš„å­—æ®µï¼ˆé€šè¿‡è§£æä»£ç ï¼‰"""
    models_file = PROJECT_ROOT / "database" / "models.py"
    
    if not models_file.exists():
        print("âŒ æ‰¾ä¸åˆ° database/models.py")
        return set()
    
    with open(models_file, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # æå– Order ç±»ä¸­çš„å­—æ®µå®šä¹‰
    # åŒ¹é…æ¨¡å¼: field_name = Column(...)
    pattern = r"^\s+(\w+)\s*=\s*Column\("
    fields = set(re.findall(pattern, content, re.MULTILINE))
    
    return fields


def get_existing_chinese_mappings() -> Dict[str, str]:
    """è·å–å·²æœ‰çš„ä¸­æ–‡å­—æ®µæ˜ å°„"""
    manager_file = PROJECT_ROOT / "database" / "data_source_manager.py"
    
    if not manager_file.exists():
        return {}
    
    with open(manager_file, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # æå– DB_FIELD_MAPPING ä¸­çš„æ˜ å°„
    # åŒ¹é…æ¨¡å¼: 'ä¸­æ–‡å': ('english_name', ...)
    pattern = r"'([^']+)':\s*\('(\w+)',"
    matches = re.findall(pattern, content)
    
    return {chinese: english for chinese, english in matches}


def get_import_mappings() -> Dict[str, str]:
    """è·å–æ™ºèƒ½å¯¼å…¥ä¸­çš„å­—æ®µæ˜ å°„"""
    import_file = PROJECT_ROOT / "æ™ºèƒ½å¯¼å…¥é—¨åº—æ•°æ®.py"
    
    if not import_file.exists():
        return {}
    
    with open(import_file, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # æå–æ˜ å°„: 'db_field': row.get('ä¸­æ–‡å', ...)
    pattern = r"'(\w+)':\s*(?:str|float|int)?\(?row\.get\('([^']+)'"
    matches = re.findall(pattern, content)
    
    return {chinese: english for english, chinese in matches}


def infer_field_type(series: pd.Series, field_name: str) -> Tuple[str, str]:
    """
    æ¨æ–­å­—æ®µç±»å‹
    
    è¿”å›: (SQLAlchemyç±»å‹, é»˜è®¤å€¼)
    """
    # å…ˆæ ¹æ®å­—æ®µåæ¨æ–­
    name_lower = field_name.lower()
    
    # æ—¥æœŸæ—¶é—´ç±»å­—æ®µ
    if any(kw in name_lower for kw in ['æ—¥æœŸ', 'æ—¶é—´', 'date', 'time']):
        return "DateTime", "None"
    
    # IDç±»å­—æ®µ
    if any(kw in name_lower for kw in ['id', 'ç¼–å·', 'ç¼–ç ', 'æ¡ç ']):
        return "String(100)", "''"
    
    # åç§°ç±»å­—æ®µ
    if any(kw in name_lower for kw in ['åç§°', 'å', 'åœ°å€', 'name', 'address']):
        return "String(500)", "''"
    
    # åˆ†ç±»å­—æ®µ
    if any(kw in name_lower for kw in ['åˆ†ç±»', 'ç±»å‹', 'å¹³å°', 'æ¸ é“', 'category', 'type', 'channel']):
        return "String(100)", "''"
    
    # æ ¹æ®æ•°æ®ç±»å‹æ¨æ–­
    if series.dtype == 'object':
        # æ£€æŸ¥æ˜¯å¦å¯èƒ½æ˜¯æ—¥æœŸ
        try:
            pd.to_datetime(series.dropna().head(10))
            return "DateTime", "None"
        except:
            pass
        
        # å­—ç¬¦ä¸²ç±»å‹
        max_len = series.astype(str).str.len().max()
        if pd.isna(max_len):
            max_len = 100
        if max_len > 500:
            return "Text", "''"
        elif max_len > 200:
            return "String(500)", "''"
        else:
            return "String(100)", "''"
    
    elif series.dtype in ['int64', 'int32']:
        return "Integer", "0"
    
    elif series.dtype in ['float64', 'float32']:
        return "Float", "0.0"
    
    elif series.dtype == 'bool':
        return "Boolean", "False"
    
    else:
        return "String(100)", "''"


def chinese_to_english(chinese_name: str) -> str:
    """å°†ä¸­æ–‡å­—æ®µåè½¬æ¢ä¸ºè‹±æ–‡å˜é‡å"""
    # å¸¸è§æ˜ å°„
    mappings = {
        'è®¢å•': 'order',
        'ç¼–å·': 'number',
        'å•†å“': 'product',
        'åç§°': 'name',
        'ä»·æ ¼': 'price',
        'æˆæœ¬': 'cost',
        'é”€é‡': 'quantity',
        'é‡‘é¢': 'amount',
        'åˆ©æ¶¦': 'profit',
        'é—¨åº—': 'store',
        'æ¸ é“': 'channel',
        'å¹³å°': 'platform',
        'é…é€': 'delivery',
        'ç‰©æµ': 'logistics',
        'è´¹ç”¨': 'fee',
        'è´¹': 'fee',
        'æ—¥æœŸ': 'date',
        'æ—¶é—´': 'time',
        'åˆ†ç±»': 'category',
        'ä¸€çº§': 'level1',
        'äºŒçº§': 'level2',
        'ä¸‰çº§': 'level3',
        'åº“å­˜': 'stock',
        'ç”¨æˆ·': 'user',
        'æ”¯ä»˜': 'payment',
        'æ»¡å‡': 'full_reduction',
        'ä¼˜æƒ ': 'discount',
        'åˆ¸': 'voucher',
        'æ´»åŠ¨': 'activity',
        'å•†å®¶': 'merchant',
        'è·ç¦»': 'distance',
        'åœ°å€': 'address',
        'åŸå¸‚': 'city',
        'å‡å…': 'discount',
        'æ‰¿æ‹…': 'share',
        'éƒ¨åˆ†': 'part',
        'å®æ”¶': 'actual',
        'åŸä»·': 'original',
        'å®å”®': 'selling',
        'é‡‡è´­': 'purchase',
        'ä½£é‡‘': 'commission',
        'æœåŠ¡': 'service',
        'æ‰“åŒ…': 'packaging',
        'è¢‹': 'bag',
        'æ–°å®¢': 'new_customer',
        'åè¿”': 'rebate',
        'ä¼å®¢': 'corporate',
    }
    
    result = chinese_name
    for cn, en in mappings.items():
        result = result.replace(cn, f'_{en}_')
    
    # æ¸…ç†
    result = re.sub(r'[^\w]', '_', result)
    result = re.sub(r'_+', '_', result)
    result = result.strip('_').lower()
    
    # å¦‚æœå…¨æ˜¯ä¸­æ–‡æ²¡æœ‰è½¬æ¢æˆåŠŸï¼Œä½¿ç”¨æ‹¼éŸ³é¦–å­—æ¯
    if not result or result == chinese_name:
        result = f"field_{abs(hash(chinese_name)) % 10000}"
    
    return result


def scan_excel(excel_path: str = None) -> Dict[str, pd.Series]:
    """æ‰«æExcelæ–‡ä»¶ï¼Œè¿”å›æ‰€æœ‰å­—æ®µ"""
    if excel_path is None:
        excel_path = DEFAULT_EXCEL_PATH
    
    full_path = PROJECT_ROOT / excel_path
    
    if not full_path.exists():
        print(f"âŒ æ‰¾ä¸åˆ°æ–‡ä»¶: {full_path}")
        return {}
    
    print(f"ğŸ“‚ è¯»å–æ–‡ä»¶: {full_path}")
    
    try:
        df = pd.read_excel(full_path)
        print(f"âœ… è¯»å–æˆåŠŸï¼Œå…± {len(df)} è¡Œ, {len(df.columns)} åˆ—")
        return {col: df[col] for col in df.columns}
    except Exception as e:
        print(f"âŒ è¯»å–å¤±è´¥: {e}")
        return {}


def detect_new_fields(excel_fields: Dict[str, pd.Series]) -> List[dict]:
    """æ£€æµ‹æ–°å­—æ®µ"""
    existing_db_fields = get_existing_fields()
    existing_mappings = get_existing_chinese_mappings()
    import_mappings = get_import_mappings()
    
    # åˆå¹¶æ‰€æœ‰å·²çŸ¥çš„ä¸­æ–‡å­—æ®µå
    known_chinese = set(existing_mappings.keys()) | set(import_mappings.keys())
    
    new_fields = []
    
    for chinese_name, series in excel_fields.items():
        # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
        if chinese_name in known_chinese:
            continue
        
        # æ¨æ–­è‹±æ–‡åå’Œç±»å‹
        english_name = chinese_to_english(chinese_name)
        field_type, default_value = infer_field_type(series, chinese_name)
        
        # æ£€æŸ¥è‹±æ–‡åæ˜¯å¦å·²å­˜åœ¨
        if english_name in existing_db_fields:
            english_name = f"{english_name}_new"
        
        new_fields.append({
            'chinese': chinese_name,
            'english': english_name,
            'type': field_type,
            'default': default_value,
            'sample': str(series.dropna().head(3).tolist())[:50]
        })
    
    return new_fields


def generate_models_code(new_fields: List[dict]) -> str:
    """ç”Ÿæˆ models.py ä»£ç ç‰‡æ®µ"""
    lines = []
    lines.append("    # ========== æ–°å¢å­—æ®µï¼ˆå¤åˆ¶åˆ° Order ç±»ä¸­ï¼‰ ==========")
    
    for field in new_fields:
        comment = field['chinese']
        if 'DateTime' in field['type']:
            line = f"    {field['english']} = Column({field['type']}, comment='{comment}')"
        elif 'String' in field['type'] or 'Text' in field['type']:
            line = f"    {field['english']} = Column({field['type']}, comment='{comment}')"
        else:
            default = f", default={field['default']}" if field['default'] != 'None' else ""
            line = f"    {field['english']} = Column({field['type']}{default}, comment='{comment}')"
        
        lines.append(line)
    
    return '\n'.join(lines)


def generate_mapping_code(new_fields: List[dict]) -> str:
    """ç”Ÿæˆ data_source_manager.py æ˜ å°„ä»£ç ç‰‡æ®µ"""
    lines = []
    lines.append("    # ========== æ–°å¢å­—æ®µæ˜ å°„ï¼ˆå¤åˆ¶åˆ° DB_FIELD_MAPPING ä¸­ï¼‰ ==========")
    
    for field in new_fields:
        need_hasattr = "True"  # æ–°å­—æ®µéƒ½éœ€è¦ hasattr æ£€æŸ¥
        line = f"    '{field['chinese']}': ('{field['english']}', {field['default']}, {need_hasattr}),"
        lines.append(line)
    
    return '\n'.join(lines)


def generate_import_code(new_fields: List[dict]) -> str:
    """ç”Ÿæˆ æ™ºèƒ½å¯¼å…¥é—¨åº—æ•°æ®.py æ˜ å°„ä»£ç ç‰‡æ®µ"""
    lines = []
    lines.append("            # ========== æ–°å¢å­—æ®µæ˜ å°„ï¼ˆå¤åˆ¶åˆ°å¯¼å…¥æ˜ å°„ä¸­ï¼‰ ==========")
    
    for field in new_fields:
        if 'String' in field['type'] or 'Text' in field['type']:
            line = f"            '{field['english']}': str(row.get('{field['chinese']}', '')),"
        elif 'Float' in field['type']:
            line = f"            '{field['english']}': float(row.get('{field['chinese']}', 0) or 0),"
        elif 'Integer' in field['type']:
            line = f"            '{field['english']}': int(row.get('{field['chinese']}', 0) or 0),"
        else:
            line = f"            '{field['english']}': row.get('{field['chinese']}', None),"
        
        lines.append(line)
    
    return '\n'.join(lines)


def copy_to_clipboard(text: str):
    """å¤åˆ¶åˆ°å‰ªè´´æ¿"""
    try:
        import subprocess
        process = subprocess.Popen(['clip'], stdin=subprocess.PIPE)
        process.communicate(text.encode('utf-8'))
        return True
    except:
        return False


def main():
    """ä¸»å‡½æ•° - å‚»ç“œå¼æ“ä½œæµç¨‹"""
    print("\n" + "="*70)
    print("ğŸ“¦ å­—æ®µæ£€æµ‹å·¥å…· - å‚»ç“œå¼æ“ä½œ")
    print("="*70)
    
    # æ­¥éª¤1: é€‰æ‹©Excelæ–‡ä»¶
    print("\nğŸ“Œ æ­¥éª¤1: é€‰æ‹©Excelæ–‡ä»¶")
    print("-"*50)
    print(f"é»˜è®¤æ–‡ä»¶: {DEFAULT_EXCEL_PATH}")
    
    user_input = input("\næŒ‰å›è½¦ä½¿ç”¨é»˜è®¤æ–‡ä»¶ï¼Œæˆ–è¾“å…¥å…¶ä»–è·¯å¾„: ").strip()
    excel_path = user_input if user_input else DEFAULT_EXCEL_PATH
    
    # æ­¥éª¤2: æ‰«æExcel
    print("\nğŸ“Œ æ­¥éª¤2: æ‰«æExcelæ–‡ä»¶")
    print("-"*50)
    
    excel_fields = scan_excel(excel_path)
    if not excel_fields:
        print("âŒ æ— æ³•è¯»å–Excelæ–‡ä»¶ï¼Œè¯·æ£€æŸ¥è·¯å¾„")
        return
    
    # æ­¥éª¤3: æ£€æµ‹æ–°å­—æ®µ
    print("\nğŸ“Œ æ­¥éª¤3: æ£€æµ‹æ–°å­—æ®µ")
    print("-"*50)
    
    new_fields = detect_new_fields(excel_fields)
    
    if not new_fields:
        print("âœ… æ²¡æœ‰æ£€æµ‹åˆ°æ–°å­—æ®µï¼Œæ‰€æœ‰å­—æ®µéƒ½å·²å­˜åœ¨ï¼")
        return
    
    print(f"ğŸ” æ£€æµ‹åˆ° {len(new_fields)} ä¸ªæ–°å­—æ®µ:\n")
    
    for i, field in enumerate(new_fields, 1):
        print(f"  {i}. {field['chinese']}")
        print(f"     â†’ è‹±æ–‡å: {field['english']}")
        print(f"     â†’ ç±»å‹: {field['type']}")
        print(f"     â†’ ç¤ºä¾‹: {field['sample']}")
        print()
    
    # æ­¥éª¤4: ç¡®è®¤å­—æ®µ
    print("\nğŸ“Œ æ­¥éª¤4: ç¡®è®¤è¦æ·»åŠ çš„å­—æ®µ")
    print("-"*50)
    
    print("è¯·è¾“å…¥è¦æ·»åŠ çš„å­—æ®µåºå·ï¼ˆå¤šä¸ªç”¨é€—å·åˆ†éš”ï¼Œè¾“å…¥ all æ·»åŠ å…¨éƒ¨ï¼Œè¾“å…¥ q é€€å‡ºï¼‰")
    user_input = input(">>> ").strip().lower()
    
    if user_input == 'q':
        print("ğŸ‘‹ å·²å–æ¶ˆ")
        return
    
    if user_input == 'all':
        selected_fields = new_fields
    else:
        try:
            indices = [int(x.strip()) - 1 for x in user_input.split(',')]
            selected_fields = [new_fields[i] for i in indices if 0 <= i < len(new_fields)]
        except:
            print("âŒ è¾“å…¥æ ¼å¼é”™è¯¯")
            return
    
    if not selected_fields:
        print("âŒ æ²¡æœ‰é€‰æ‹©ä»»ä½•å­—æ®µ")
        return
    
    print(f"\nâœ… å·²é€‰æ‹© {len(selected_fields)} ä¸ªå­—æ®µ")
    
    # æ­¥éª¤5: ç”Ÿæˆä»£ç 
    print("\nğŸ“Œ æ­¥éª¤5: ç”Ÿæˆä»£ç ")
    print("-"*50)
    
    models_code = generate_models_code(selected_fields)
    mapping_code = generate_mapping_code(selected_fields)
    import_code = generate_import_code(selected_fields)
    
    # æ˜¾ç¤ºä»£ç 
    print("\n" + "="*70)
    print("ğŸ“„ 1. models.py ä»£ç ï¼ˆå¤åˆ¶åˆ° Order ç±»ä¸­ï¼‰:")
    print("="*70)
    print(models_code)
    
    print("\n" + "="*70)
    print("ğŸ“„ 2. data_source_manager.py ä»£ç ï¼ˆå¤åˆ¶åˆ° DB_FIELD_MAPPING ä¸­ï¼‰:")
    print("="*70)
    print(mapping_code)
    
    print("\n" + "="*70)
    print("ğŸ“„ 3. æ™ºèƒ½å¯¼å…¥é—¨åº—æ•°æ®.py ä»£ç ï¼ˆå¤åˆ¶åˆ°å¯¼å…¥æ˜ å°„ä¸­ï¼‰:")
    print("="*70)
    print(import_code)
    
    # æ­¥éª¤6: å¤åˆ¶åˆ°å‰ªè´´æ¿
    print("\nğŸ“Œ æ­¥éª¤6: å¤åˆ¶ä»£ç ")
    print("-"*50)
    
    all_code = f"""
# ============ models.py ============
{models_code}

# ============ data_source_manager.py ============
{mapping_code}

# ============ æ™ºèƒ½å¯¼å…¥é—¨åº—æ•°æ®.py ============
{import_code}
"""
    
    if copy_to_clipboard(all_code):
        print("âœ… æ‰€æœ‰ä»£ç å·²å¤åˆ¶åˆ°å‰ªè´´æ¿ï¼")
    else:
        print("âš ï¸ æ— æ³•å¤åˆ¶åˆ°å‰ªè´´æ¿ï¼Œè¯·æ‰‹åŠ¨å¤åˆ¶ä¸Šé¢çš„ä»£ç ")
    
    # æ­¥éª¤7: åç»­æ“ä½œæç¤º
    print("\n" + "="*70)
    print("ğŸ“Œ åç»­æ“ä½œæ­¥éª¤:")
    print("="*70)
    print("""
1. æ‰“å¼€ database/models.py
   â†’ æ‰¾åˆ° Order ç±»
   â†’ ç²˜è´´ç¬¬1æ®µä»£ç 

2. æ‰“å¼€ database/data_source_manager.py
   â†’ æ‰¾åˆ° DB_FIELD_MAPPING å­—å…¸
   â†’ ç²˜è´´ç¬¬2æ®µä»£ç 

3. æ‰“å¼€ æ™ºèƒ½å¯¼å…¥é—¨åº—æ•°æ®.py
   â†’ æ‰¾åˆ°å­—æ®µæ˜ å°„éƒ¨åˆ†
   â†’ ç²˜è´´ç¬¬3æ®µä»£ç 

4. è¿è¡Œè¿ç§»è„šæœ¬:
   python æ•°æ®åº“è¿ç§».py

5. é‡æ–°å¯¼å…¥æ•°æ®:
   python æ™ºèƒ½å¯¼å…¥é—¨åº—æ•°æ®.py

6. é‡å¯çœ‹æ¿æœåŠ¡
""")
    
    input("\næŒ‰å›è½¦é”®é€€å‡º...")


if __name__ == '__main__':
    main()
