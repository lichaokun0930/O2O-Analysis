#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
PandasAIé›†æˆæ¨¡å— (é˜¶æ®µ2ä¼˜åŒ–)
æ”¯æŒè‡ªç„¶è¯­è¨€æŸ¥è¯¢æ•°æ®,è‡ªåŠ¨ç”Ÿæˆpandasä»£ç 

åŠŸèƒ½:
1. è‡ªç„¶è¯­è¨€è½¬pandasæŸ¥è¯¢
2. è‡ªåŠ¨æ•°æ®éªŒè¯ (éµå¾ª"åˆ»åœ¨åŸºå› ä¸­"çš„è§„åˆ™)
3. æ™ºèƒ½å›¾è¡¨æ¨è
4. æŸ¥è¯¢å†å²è®°å½•

ä¾èµ–å®‰è£…:
pip install pandasai
"""

import os
import pandas as pd
from typing import Dict, List, Any, Optional
import json
from datetime import datetime

# å°è¯•å¯¼å…¥PandasAI (æ‡’åŠ è½½æ¨¡å¼)
PANDASAI_AVAILABLE = False
SmartDataframe = None
PandasAI_OpenAI = None

def _check_pandasai():
    """å»¶è¿Ÿæ£€æŸ¥PandasAIæ˜¯å¦å¯ç”¨"""
    global PANDASAI_AVAILABLE, SmartDataframe, PandasAI_OpenAI
    if PANDASAI_AVAILABLE:
        return True
    try:
        from pandasai import SmartDataframe as _SmartDataframe
        from pandasai.llm import OpenAI as _PandasAI_OpenAI
        SmartDataframe = _SmartDataframe
        PandasAI_OpenAI = _PandasAI_OpenAI
        PANDASAI_AVAILABLE = True
        return True
    except ImportError:
        return False

# å¯¼å…¥GLMå®¢æˆ·ç«¯
try:
    from zhipuai import ZhipuAI
    GLM_AVAILABLE = True
except ImportError:
    GLM_AVAILABLE = False
    print("âš ï¸ zhipuaiæœªå®‰è£…")


# ==================== æ•°æ®éªŒè¯è§„åˆ™ ====================

VALIDATION_RULES = """
ã€è‡ªåŠ¨éªŒè¯è§„åˆ™ã€‘(åˆ»åœ¨åŸºå› ä¸­)

åœ¨ç”Ÿæˆä»»ä½•æ•°æ®æŸ¥è¯¢ä»£ç æ—¶,å¿…é¡»éµå¾ªä»¥ä¸‹è§„åˆ™:

1. é”€å”®é¢è®¡ç®—:
   âœ… æ­£ç¡®: df.groupby('è®¢å•ID')['å®æ”¶ä»·æ ¼'].sum().sum()
   âŒ é”™è¯¯: df['å®æ”¶ä»·æ ¼'].sum()
   åŸå› : å¤šå•†å“è®¢å•ä¼šè¢«é‡å¤è®¡ç®—

2. å®¢å•ä»·è®¡ç®—:
   âœ… æ­£ç¡®: é”€å”®é¢ / df['è®¢å•ID'].nunique()
   âŒ é”™è¯¯: df['å®æ”¶ä»·æ ¼'].mean()
   åŸå› : å®¢å•ä»·æ˜¯æ¯ä¸ªè®¢å•çš„å¹³å‡é‡‘é¢,ä¸æ˜¯æ¯ä¸ªå•†å“çš„å¹³å‡ä»·æ ¼

3. è®¢å•æ•°è®¡ç®—:
   âœ… æ­£ç¡®: df['è®¢å•ID'].nunique()
   âŒ é”™è¯¯: len(df)
   åŸå› : len(df)æ˜¯å•†å“è¡Œæ•°,ä¸æ˜¯è®¢å•æ•°

4. æ—¶æ®µ/åœºæ™¯èšåˆ:
   å¿…é¡»å…ˆæŒ‰è®¢å•IDåˆ†ç»„,å†èšåˆæ—¶æ®µ/åœºæ™¯
   ç¤ºä¾‹: df.groupby(['è®¢å•ID', 'æ—¶æ®µ'])['å®æ”¶ä»·æ ¼'].sum().groupby('æ—¶æ®µ').sum()

5. å•†å“æ’è¡Œ:
   æŒ‰è®¢å•é”€å”®é¢æ’å,ä¸æ˜¯å•†å“è¡Œæ•°
   ç¤ºä¾‹: df.groupby('å•†å“åç§°')['å®æ”¶ä»·æ ¼'].sum().sort_values(ascending=False)

ä»£ç ç”ŸæˆæŒ‡ä»¤:
- ä½¿ç”¨groupbyæ—¶ä¼˜å…ˆæŒ‰è®¢å•IDåˆ†ç»„
- è®¡ç®—æ€»é¢æ—¶ç”¨.sum().sum()è€Œéå•å±‚.sum()
- ç»Ÿè®¡è®¢å•æ•°ç”¨.nunique()è€Œé.count()
- é¿å…ç›´æ¥å¯¹å®æ”¶ä»·æ ¼åˆ—æ±‚å’Œ
"""


# ==================== PandasAIåŒ…è£…å™¨ ====================

class SmartDataAnalyzer:
    """æ™ºèƒ½æ•°æ®åˆ†æå™¨ - PandasAI + æ•°æ®éªŒè¯"""
    
    def __init__(self, api_key: Optional[str] = None, model_type: str = 'glm'):
        """åˆå§‹åŒ–æ™ºèƒ½åˆ†æå™¨
        
        Args:
            api_key: APIå¯†é’¥
            model_type: æ¨¡å‹ç±»å‹ ('glm'/'openai')
        """
        if not PANDASAI_AVAILABLE:
            raise ImportError("è¯·å…ˆå®‰è£…PandasAI: pip install pandasai")
        
        self.api_key = api_key or os.getenv('ZHIPU_API_KEY')
        self.model_type = model_type
        self.query_history = []
        
        # åˆå§‹åŒ–LLM
        if model_type == 'glm':
            # ä½¿ç”¨è‡ªå®šä¹‰GLMåŒ…è£…å™¨
            self.llm = GLMWrapper(api_key=self.api_key)
        else:
            # ä½¿ç”¨OpenAI
            self.llm = PandasAI_OpenAI(api_token=self.api_key)
        
        print(f"âœ… SmartDataAnalyzeråˆå§‹åŒ–å®Œæˆ (æ¨¡å‹: {model_type})")
    
    def query(self, df: pd.DataFrame, question: str, 
              validate: bool = True, save_history: bool = True) -> Any:
        """è‡ªç„¶è¯­è¨€æŸ¥è¯¢æ•°æ®
        
        Args:
            df: æ•°æ®DataFrame
            question: è‡ªç„¶è¯­è¨€é—®é¢˜
            validate: æ˜¯å¦éªŒè¯ç”Ÿæˆçš„ä»£ç  (é»˜è®¤True)
            save_history: æ˜¯å¦ä¿å­˜æŸ¥è¯¢å†å² (é»˜è®¤True)
        
        Returns:
            æŸ¥è¯¢ç»“æœ (å¯èƒ½æ˜¯æ•°å€¼ã€DataFrameã€å›¾è¡¨ç­‰)
        """
        # å¢å¼ºé—®é¢˜,æ³¨å…¥éªŒè¯è§„åˆ™
        enhanced_question = self._enhance_question(question, validate)
        
        # åˆ›å»ºSmartDataframe
        sdf = SmartDataframe(
            df,
            config={
                "llm": self.llm,
                "enable_cache": True,
                "save_charts": True,
                "save_charts_path": "./charts",
                "verbose": True,
                "custom_whitelisted_dependencies": ["numpy", "pandas"],
                # æ³¨å…¥ä»£ç ç”ŸæˆæŒ‡ä»¤
                "custom_instructions": VALIDATION_RULES
            }
        )
        
        try:
            # æ‰§è¡ŒæŸ¥è¯¢
            print(f"ğŸ” æŸ¥è¯¢: {question}")
            result = sdf.chat(enhanced_question)
            
            # ä¿å­˜å†å²
            if save_history:
                self._save_query_history(question, result, success=True)
            
            print(f"âœ… æŸ¥è¯¢æˆåŠŸ")
            return result
            
        except Exception as e:
            print(f"âŒ æŸ¥è¯¢å¤±è´¥: {e}")
            if save_history:
                self._save_query_history(question, None, success=False, error=str(e))
            raise
    
    def _enhance_question(self, question: str, validate: bool) -> str:
        """å¢å¼ºé—®é¢˜,æ³¨å…¥éªŒè¯è§„åˆ™"""
        if not validate:
            return question
        
        # æ£€æŸ¥é—®é¢˜ä¸­æ˜¯å¦æ¶‰åŠéœ€è¦éªŒè¯çš„è®¡ç®—
        needs_validation = any(keyword in question for keyword in 
                              ['é”€å”®é¢', 'å®¢å•ä»·', 'è®¢å•æ•°', 'æ€»é¢', 'é”€é‡', 'æ’è¡Œ'])
        
        if needs_validation:
            enhanced = f"""
{question}

é‡è¦æç¤º:
- è®¡ç®—é”€å”®é¢æ—¶å¿…é¡»å…ˆæŒ‰è®¢å•IDåˆ†ç»„: df.groupby('è®¢å•ID')['å®æ”¶ä»·æ ¼'].sum()
- è®¡ç®—å®¢å•ä»·ç”¨è®¢å•æ•°,ä¸æ˜¯å•†å“æ•°: é”€å”®é¢ / df['è®¢å•ID'].nunique()
- ç»Ÿè®¡è®¢å•æ•°ç”¨ .nunique() è€Œé .count()
- å¤šå•†å“è®¢å•ä¸è¦é‡å¤è®¡ç®—

è¯·ä¸¥æ ¼éµå®ˆä»¥ä¸Šè§„åˆ™ç”Ÿæˆä»£ç ã€‚
"""
            return enhanced
        
        return question
    
    def _save_query_history(self, question: str, result: Any, 
                           success: bool, error: Optional[str] = None):
        """ä¿å­˜æŸ¥è¯¢å†å²"""
        history_entry = {
            "timestamp": datetime.now().isoformat(),
            "question": question,
            "success": success,
            "error": error,
            "result_type": type(result).__name__ if result is not None else None
        }
        self.query_history.append(history_entry)
    
    def get_query_history(self, limit: int = 10) -> List[Dict]:
        """è·å–æŸ¥è¯¢å†å²
        
        Args:
            limit: è¿”å›æœ€è¿‘Næ¡è®°å½•
        
        Returns:
            å†å²è®°å½•åˆ—è¡¨
        """
        return self.query_history[-limit:]
    
    def export_query_history(self, filepath: str = "query_history.json"):
        """å¯¼å‡ºæŸ¥è¯¢å†å²åˆ°æ–‡ä»¶"""
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(self.query_history, f, ensure_ascii=False, indent=2)
        print(f"âœ… æŸ¥è¯¢å†å²å·²å¯¼å‡º: {filepath}")


# ==================== GLMåŒ…è£…å™¨ (é€‚é…PandasAI) ====================

class GLMWrapper:
    """GLM-4.6åŒ…è£…å™¨,é€‚é…PandasAIçš„LLMæ¥å£"""
    
    def __init__(self, api_key: str):
        """åˆå§‹åŒ–GLMå®¢æˆ·ç«¯"""
        if not GLM_AVAILABLE:
            raise ImportError("è¯·å…ˆå®‰è£…zhipuai: pip install zhipuai")
        
        self.client = ZhipuAI(
            api_key=api_key,
            base_url="https://open.bigmodel.cn/api/paas/v4/coding"
        )
        self.model_name = 'glm-4.6'
        print(f"   âœ… GLM-4.6å·²é…ç½® (codingç«¯ç‚¹)")
    
    def generate(self, prompt: str, **kwargs) -> str:
        """ç”Ÿæˆå†…å®¹ (PandasAIè¦æ±‚çš„æ¥å£)"""
        try:
            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=[{"role": "user", "content": prompt}],
                temperature=kwargs.get('temperature', 0.3),  # ä»£ç ç”Ÿæˆç”¨ä½temperature
                max_tokens=kwargs.get('max_tokens', 2048)
            )
            return response.choices[0].message.content
        except Exception as e:
            print(f"âŒ GLM-4.6è°ƒç”¨å¤±è´¥: {e}")
            raise
    
    def chat_completion(self, messages: List[Dict], **kwargs) -> str:
        """å¯¹è¯å®Œæˆ (å¤‡ç”¨æ¥å£)"""
        try:
            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=messages,
                temperature=kwargs.get('temperature', 0.3),
                max_tokens=kwargs.get('max_tokens', 2048)
            )
            return response.choices[0].message.content
        except Exception as e:
            print(f"âŒ GLM-4.6è°ƒç”¨å¤±è´¥: {e}")
            raise


# ==================== å¿«æ·æŸ¥è¯¢å‡½æ•° ====================

def quick_query(df: pd.DataFrame, question: str, 
                api_key: Optional[str] = None) -> Any:
    """å¿«æ·æŸ¥è¯¢ (æ— éœ€åˆ›å»ºanalyzerå®ä¾‹)
    
    Args:
        df: æ•°æ®DataFrame
        question: è‡ªç„¶è¯­è¨€é—®é¢˜
        api_key: APIå¯†é’¥ (å¯é€‰,é»˜è®¤ä»ç¯å¢ƒå˜é‡è¯»å–)
    
    Returns:
        æŸ¥è¯¢ç»“æœ
    
    Example:
        >>> result = quick_query(è®¢å•æ•°æ®, "å¸®æˆ‘æ‰¾å‡ºåˆ©æ¶¦ç‡ä½äº5%çš„å•†å“TOP10")
        >>> print(result)
    """
    analyzer = SmartDataAnalyzer(api_key=api_key)
    return analyzer.query(df, question)


# ==================== é¢„å®šä¹‰æŸ¥è¯¢æ¨¡æ¿ ====================

QUERY_TEMPLATES = {
    "é«˜åˆ©æ¶¦å•†å“": "æ‰¾å‡ºåˆ©æ¶¦ç‡å¤§äº{threshold}%çš„å•†å“,æŒ‰åˆ©æ¶¦é¢æ’åº,è¿”å›TOP{top_n}",
    "ä½å®¢å•ä»·è®¢å•": "æ‰¾å‡ºå®¢å•ä»·ä½äº{threshold}å…ƒçš„è®¢å•,ç»Ÿè®¡æ•°é‡å’Œå æ¯”",
    "æ»é”€å•†å“": "æ‰¾å‡ºæœ€è¿‘{days}å¤©æ²¡æœ‰é”€å”®çš„å•†å“,è¿”å›å•†å“åç§°å’Œæœ€åé”€å”®æ—¥æœŸ",
    "æ—¶æ®µé”€é‡åˆ†æ": "åˆ†æä¸åŒæ—¶æ®µçš„è®¢å•é‡ã€é”€å”®é¢å’Œå®¢å•ä»·,å¹¶æŒ‰é”€å”®é¢é™åºæ’åº",
    "åœºæ™¯è¥é”€æ•ˆæœ": "åˆ†æä¸åŒæ¶ˆè´¹åœºæ™¯çš„è®¢å•é‡ã€é”€å”®é¢ã€å®¢å•ä»·å’Œåˆ©æ¶¦ç‡",
    "å•†å“è§’è‰²åˆ†å¸ƒ": "ç»Ÿè®¡æµé‡å“ã€åˆ©æ¶¦å“ã€å½¢è±¡å“çš„æ•°é‡å’Œé”€å”®é¢å æ¯”",
    "æˆæœ¬ç»“æ„åˆ†æ": "è®¡ç®—å•†å“æˆæœ¬ã€å±¥çº¦æˆæœ¬ã€è¥é”€æˆæœ¬çš„å æ¯”,å¹¶ä¸å¥åº·åŸºå‡†å¯¹æ¯”",
    "è¥é”€ROIæ’å": "è®¡ç®—æ¯ä¸ªè¥é”€æ´»åŠ¨çš„ROI,æŒ‰ROIé™åºæ’åº,æ ‡æ³¨å‡ºROI<1çš„æ´»åŠ¨"
}


def get_template_query(template_name: str, **params) -> str:
    """è·å–é¢„å®šä¹‰æŸ¥è¯¢æ¨¡æ¿
    
    Args:
        template_name: æ¨¡æ¿åç§°
        **params: æ¨¡æ¿å‚æ•°
    
    Returns:
        æ ¼å¼åŒ–åçš„æŸ¥è¯¢è¯­å¥
    
    Example:
        >>> query = get_template_query("é«˜åˆ©æ¶¦å•†å“", threshold=20, top_n=10)
        >>> result = quick_query(è®¢å•æ•°æ®, query)
    """
    if template_name not in QUERY_TEMPLATES:
        raise ValueError(f"æœªçŸ¥æ¨¡æ¿: {template_name}, å¯ç”¨æ¨¡æ¿: {list(QUERY_TEMPLATES.keys())}")
    
    template = QUERY_TEMPLATES[template_name]
    return template.format(**params)


# ==================== å•å…ƒæµ‹è¯• ====================

if __name__ == "__main__":
    print("=" * 80)
    print("PandasAIé›†æˆæ¨¡å—æµ‹è¯•")
    print("=" * 80)
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    test_data = pd.DataFrame({
        'è®¢å•ID': ['A001', 'A001', 'A002', 'A003', 'A003', 'A003'],
        'å•†å“åç§°': ['ç‰›å¥¶', 'é¢åŒ…', 'æ´—å‘æ°´', 'å¯ä¹', 'è–¯ç‰‡', 'å·§å…‹åŠ›'],
        'å®æ”¶ä»·æ ¼': [15.5, 8.5, 35.0, 3.5, 6.5, 12.0],
        'æˆæœ¬': [12.0, 6.0, 20.0, 2.5, 4.0, 8.0],
        'æ—¶æ®µ': ['ä¸Šåˆ', 'ä¸Šåˆ', 'ä¸‹åˆ', 'æ™šä¸Š', 'æ™šä¸Š', 'æ™šä¸Š'],
        'åœºæ™¯': ['æ—©é¤', 'æ—©é¤', 'ä¸ªæŠ¤', 'é›¶é£Ÿ', 'é›¶é£Ÿ', 'é›¶é£Ÿ']
    })
    
    print("\nã€æµ‹è¯•æ•°æ®ã€‘")
    print(test_data)
    print(f"\næ•°æ®å½¢çŠ¶: {test_data.shape}")
    print(f"è®¢å•æ•°: {test_data['è®¢å•ID'].nunique()}")
    print(f"å•†å“æ•°: {len(test_data)}")
    
    # éªŒè¯æ•°æ®è®¡ç®—è§„åˆ™
    print("\nã€éªŒè¯æ•°æ®è®¡ç®—è§„åˆ™ã€‘")
    
    # é”™è¯¯æ–¹å¼
    wrong_sales = test_data['å®æ”¶ä»·æ ¼'].sum()
    print(f"âŒ é”™è¯¯: df['å®æ”¶ä»·æ ¼'].sum() = {wrong_sales:.2f}")
    
    # æ­£ç¡®æ–¹å¼
    correct_sales = test_data.groupby('è®¢å•ID')['å®æ”¶ä»·æ ¼'].sum().sum()
    print(f"âœ… æ­£ç¡®: df.groupby('è®¢å•ID')['å®æ”¶ä»·æ ¼'].sum().sum() = {correct_sales:.2f}")
    
    # å®¢å•ä»·
    order_count = test_data['è®¢å•ID'].nunique()
    avg_order_value = correct_sales / order_count
    print(f"âœ… å®¢å•ä»·: {correct_sales:.2f} / {order_count} = {avg_order_value:.2f}å…ƒ/å•")
    
    print("\nã€æŸ¥è¯¢æ¨¡æ¿æµ‹è¯•ã€‘")
    print(f"å¯ç”¨æ¨¡æ¿: {list(QUERY_TEMPLATES.keys())}")
    
    query1 = get_template_query("é«˜åˆ©æ¶¦å•†å“", threshold=20, top_n=5)
    print(f"\næ¨¡æ¿1: {query1}")
    
    query2 = get_template_query("æ—¶æ®µé”€é‡åˆ†æ")
    print(f"æ¨¡æ¿2: {query2}")
    
    # å¦‚æœPandasAIå¯ç”¨,å°è¯•å®é™…æŸ¥è¯¢
    if PANDASAI_AVAILABLE and GLM_AVAILABLE:
        print("\nã€å®é™…æŸ¥è¯¢æµ‹è¯•ã€‘(éœ€è¦APIå¯†é’¥)")
        api_key = os.getenv('ZHIPU_API_KEY')
        if api_key:
            try:
                analyzer = SmartDataAnalyzer(api_key=api_key)
                
                # æµ‹è¯•æŸ¥è¯¢
                question = "è®¡ç®—æ€»é”€å”®é¢å’Œå®¢å•ä»·"
                print(f"\nğŸ” æŸ¥è¯¢: {question}")
                # result = analyzer.query(test_data, question)
                # print(f"ç»“æœ: {result}")
                print("(å®é™…æŸ¥è¯¢å·²æ³¨é‡Š,é¿å…æ¶ˆè€—APIé¢åº¦)")
                
            except Exception as e:
                print(f"âš ï¸ æµ‹è¯•è·³è¿‡: {e}")
        else:
            print("âš ï¸ æœªæ‰¾åˆ°ZHIPU_API_KEYç¯å¢ƒå˜é‡")
    else:
        print("\nâš ï¸ PandasAIæˆ–GLMæœªå®‰è£…,è·³è¿‡å®é™…æŸ¥è¯¢æµ‹è¯•")
    
    print("\nâœ… æµ‹è¯•å®Œæˆ!")
