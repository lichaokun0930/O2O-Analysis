#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Gemini AI æ™ºèƒ½åˆ†æåŠ©æ‰‹
é›†æˆ Google Gemini API,ä¸ºçœ‹æ¿æä¾›å…¨æ–¹ä½æ™ºèƒ½åˆ†æèƒ½åŠ›
"""

import os
import json
from datetime import datetime
from typing import Dict, List, Optional, Any
import pandas as pd

try:
    import google.generativeai as genai
    GEMINI_AVAILABLE = True
except ImportError:
    GEMINI_AVAILABLE = False
    print("âš ï¸ google-generativeai æœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install google-generativeai")


class GeminiAIAssistant:
    """Gemini AI æ™ºèƒ½åˆ†æåŠ©æ‰‹"""
    
    def __init__(self, api_key: Optional[str] = None):
        """
        åˆå§‹åŒ–AIåŠ©æ‰‹
        
        Args:
            api_key: Gemini APIå¯†é’¥ï¼Œå¦‚æœä¸æä¾›åˆ™ä»ç¯å¢ƒå˜é‡è¯»å–
        """
        self.api_key = api_key or os.getenv('GEMINI_API_KEY', '')
        self.model = None
        self.chat_history = []
        self.context_data = {}  # å­˜å‚¨å½“å‰æ•°æ®ä¸Šä¸‹æ–‡
        
        if GEMINI_AVAILABLE and self.api_key:
            self._initialize_model()
        else:
            print("âš ï¸ AIåŠ©æ‰‹æœªåˆå§‹åŒ–: ç¼ºå°‘APIå¯†é’¥æˆ–ä¾èµ–åº“")
    
    def _initialize_model(self):
        """åˆå§‹åŒ–Geminiæ¨¡å‹"""
        try:
            genai.configure(api_key=self.api_key)
            
            # ä»ç¯å¢ƒå˜é‡è¯»å–æ¨¡å‹åç§°,é»˜è®¤ä½¿ç”¨ gemini-1.5-flash
            model_name = os.getenv('GEMINI_MODEL', 'gemini-1.5-flash')
            temperature = float(os.getenv('GEMINI_TEMPERATURE', '0.7'))
            max_tokens = int(os.getenv('GEMINI_MAX_TOKENS', '2048'))
            
            # ä½¿ç”¨ Gemini 1.5 Flash (å¿«é€Ÿå“åº”) æˆ– Pro (æ›´å‡†ç¡®)
            self.model = genai.GenerativeModel(
                model_name=model_name,
                generation_config={
                    'temperature': temperature,  # æ§åˆ¶åˆ›é€ æ€§
                    'top_p': 0.95,
                    'top_k': 40,
                    'max_output_tokens': max_tokens,
                },
                safety_settings=[
                    {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
                    {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
                    {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
                    {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"},
                ]
            )
            
            # è®¾ç½®ç³»ç»Ÿæç¤ºè¯
            self.system_prompt = """ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„O2Oé—¨åº—æ•°æ®åˆ†æä¸“å®¶ã€‚ä½ çš„èŒè´£æ˜¯:
1. åˆ†æå•†å“é”€å”®æ•°æ®,è¯†åˆ«è¶‹åŠ¿å’Œå¼‚å¸¸
2. è§£è¯»å››è±¡é™åˆ†æ(æ˜æ˜Ÿ/é‡‘ç‰›/å¼•æµ/æ·˜æ±°å•†å“)
3. æä¾›åº“å­˜ä¼˜åŒ–å»ºè®®
4. åˆ†æå®¢å•ä»·å˜åŒ–åŸå› 
5. ç»™å‡ºå•†å“å®šä»·å’Œä¿ƒé”€å»ºè®®

è¯·ç”¨ä¸“ä¸šä½†æ˜“æ‡‚çš„è¯­è¨€å›ç­”,æä¾›å…·ä½“å¯æ‰§è¡Œçš„å»ºè®®ã€‚
å½“åˆ†ææ•°æ®æ—¶,è¯·å…³æ³¨:
- æ•°æ®è¶‹åŠ¿å’Œå˜åŒ–
- å¼‚å¸¸å€¼å’Œæ½œåœ¨é—®é¢˜
- ä¸šåŠ¡å½±å“å’Œä¼˜åŒ–æœºä¼š
- å…·ä½“çš„è¡ŒåŠ¨å»ºè®®

å›ç­”æ—¶è¯·ç®€æ´æ˜äº†,çªå‡ºé‡ç‚¹,ä½¿ç”¨emojiå¢å¼ºå¯è¯»æ€§ã€‚"""
            
            print("âœ… Gemini AIåŠ©æ‰‹åˆå§‹åŒ–æˆåŠŸ")
            
        except Exception as e:
            print(f"âŒ AIåŠ©æ‰‹åˆå§‹åŒ–å¤±è´¥: {str(e)}")
            self.model = None
    
    def is_ready(self) -> bool:
        """æ£€æŸ¥AIåŠ©æ‰‹æ˜¯å¦å°±ç»ª"""
        return self.model is not None
    
    def _safe_generate(self, prompt: str) -> str:
        """
        å®‰å…¨åœ°è°ƒç”¨Gemini APIå¹¶å¤„ç†å„ç§é”™è¯¯æƒ…å†µ
        
        Args:
            prompt: æç¤ºè¯
            
        Returns:
            AIå›å¤æ–‡æœ¬æˆ–é”™è¯¯ä¿¡æ¯
        """
        try:
            response = self.model.generate_content(prompt)
            
            # æ£€æŸ¥å“åº”æ˜¯å¦æœ‰æ•ˆ
            if not response.candidates or len(response.candidates) == 0:
                return "âš ï¸ APIè¿”å›ç©ºå“åº”,å¯èƒ½è¢«å®‰å…¨è¿‡æ»¤ã€‚è¯·å°è¯•æ¢ä¸ªé—®æ³•ã€‚"
            
            candidate = response.candidates[0]
            
            # æ£€æŸ¥finish_reason
            if hasattr(candidate, 'finish_reason'):
                finish_reason = candidate.finish_reason
                # æ ¹æ®Google AIæ–‡æ¡£: STOP=1, MAX_TOKENS=2, SAFETY=3, RECITATION=4
                if finish_reason == 3:  # SAFETY
                    return "âš ï¸ å†…å®¹è¢«å®‰å…¨è¿‡æ»¤æ‹¦æˆªã€‚å»ºè®®:\n1. æ¢ä¸ªæ›´ä¸­æ€§çš„é—®æ³•\n2. é¿å…æ•æ„Ÿè¯æ±‡\n3. ä½¿ç”¨æ›´ä¸“ä¸šçš„æœ¯è¯­"
                elif finish_reason == 2:  # MAX_TOKENS
                    # å°è¯•æå–å·²ç”Ÿæˆçš„å†…å®¹
                    if candidate.content and candidate.content.parts:
                        partial = ''.join([part.text for part in candidate.content.parts if hasattr(part, 'text')])
                        return f"{partial}\n\nâš ï¸ (å›å¤è¢«æˆªæ–­,å·²è¾¾åˆ°æœ€å¤§é•¿åº¦)"
                    return "âš ï¸ å›å¤è¶…å‡ºé•¿åº¦é™åˆ¶,è¯·ç®€åŒ–é—®é¢˜æˆ–åˆ†å¤šæ¬¡æé—®"
            
            # æå–æ–‡æœ¬å†…å®¹
            if hasattr(response, 'text') and response.text:
                return response.text
            elif candidate.content and candidate.content.parts:
                return ''.join([part.text for part in candidate.content.parts if hasattr(part, 'text')])
            else:
                return f"âš ï¸ æ— æ³•è§£æAIå›å¤ (finish_reason={getattr(candidate, 'finish_reason', 'unknown')})"
                
        except AttributeError as e:
            return f"âš ï¸ APIå“åº”æ ¼å¼å¼‚å¸¸: {str(e)}\nå»ºè®®: æ¢ä¸ªé—®æ³•æˆ–æ£€æŸ¥APIé…ç½®"
        except Exception as e:
            return f"âŒ APIè°ƒç”¨å¤±è´¥: {str(e)}"
    
    def update_context(self, context_type: str, data: Any):
        """
        æ›´æ–°æ•°æ®ä¸Šä¸‹æ–‡
        
        Args:
            context_type: ä¸Šä¸‹æ–‡ç±»å‹ (quadrant_data, sales_trend, inventoryç­‰)
            data: æ•°æ®å†…å®¹
        """
        self.context_data[context_type] = data
    
    def analyze_quadrant_data(self, quadrant_summary: Dict) -> str:
        """
        åˆ†æå››è±¡é™æ•°æ®
        
        Args:
            quadrant_summary: å››è±¡é™æ±‡æ€»æ•°æ®
            
        Returns:
            åˆ†æç»“æœæ–‡æœ¬
        """
        if not self.is_ready():
            return "âš ï¸ AIåŠ©æ‰‹æœªå°±ç»ª,è¯·é…ç½®APIå¯†é’¥"
        
        prompt = f"""è¯·åˆ†æä»¥ä¸‹å•†å“å››è±¡é™æ•°æ®:

{json.dumps(quadrant_summary, ensure_ascii=False, indent=2)}

è¯·æä¾›:
1. æ•´ä½“å•†å“ç»“æ„è¯„ä¼°
2. å„è±¡é™å•†å“å æ¯”åˆ†æ
3. å­˜åœ¨çš„é—®é¢˜å’Œé£é™©
4. å…·ä½“ä¼˜åŒ–å»ºè®®

é™åˆ¶åœ¨300å­—ä»¥å†…ã€‚"""
        
        return self._safe_generate(prompt)
    
    def analyze_sales_trend(self, trend_data: pd.DataFrame, product_name: str = None) -> str:
        """
        åˆ†æé”€é‡è¶‹åŠ¿
        
        Args:
            trend_data: è¶‹åŠ¿æ•°æ®DataFrame
            product_name: å•†å“åç§°(å¯é€‰)
            
        Returns:
            åˆ†æç»“æœæ–‡æœ¬
        """
        if not self.is_ready():
            return "âš ï¸ AIåŠ©æ‰‹æœªå°±ç»ª,è¯·é…ç½®APIå¯†é’¥"
        
        # ç®€åŒ–æ•°æ®ç”¨äºåˆ†æ
        data_summary = trend_data.head(20).to_dict('records') if hasattr(trend_data, 'to_dict') else str(trend_data)[:500]
        
        product_info = f"å•†å“: {product_name}\n" if product_name else ""
        
        prompt = f"""{product_info}è¯·åˆ†æä»¥ä¸‹é”€å”®è¶‹åŠ¿æ•°æ®:

{json.dumps(data_summary, ensure_ascii=False, indent=2)}

è¯·æä¾›:
1. è¶‹åŠ¿å˜åŒ–åˆ†æ(ä¸Šå‡/ä¸‹é™/ç¨³å®š)
2. å¼‚å¸¸æ—¶é—´ç‚¹è¯†åˆ«
3. å¯èƒ½åŸå› åˆ†æ
4. åº”å¯¹å»ºè®®

é™åˆ¶åœ¨250å­—ä»¥å†…ã€‚"""
        
        return self._safe_generate(prompt)
    
    def analyze_inventory_alert(self, alert_products: List[Dict]) -> str:
        """
        åˆ†æåº“å­˜é¢„è­¦
        
        Args:
            alert_products: é¢„è­¦å•†å“åˆ—è¡¨
            
        Returns:
            åˆ†æç»“æœæ–‡æœ¬
        """
        if not self.is_ready():
            return "âš ï¸ AIåŠ©æ‰‹æœªå°±ç»ª,è¯·é…ç½®APIå¯†é’¥"
        
        prompt = f"""ä»¥ä¸‹å•†å“å‡ºç°åº“å­˜é¢„è­¦:

{json.dumps(alert_products[:10], ensure_ascii=False, indent=2)}

è¯·åˆ†æ:
1. é¢„è­¦å•†å“ç‰¹å¾
2. æ½œåœ¨å½±å“
3. ä¼˜å…ˆå¤„ç†é¡ºåº
4. è¡¥è´§å»ºè®®

é™åˆ¶åœ¨200å­—ä»¥å†…ã€‚"""
        
        return self._safe_generate(prompt)
    
    def analyze_avg_price_change(self, price_data: Dict) -> str:
        """
        åˆ†æå®¢å•ä»·å˜åŒ–
        
        Args:
            price_data: å®¢å•ä»·æ•°æ®
            
        Returns:
            åˆ†æç»“æœæ–‡æœ¬
        """
        if not self.is_ready():
            return "âš ï¸ AIåŠ©æ‰‹æœªå°±ç»ª,è¯·é…ç½®APIå¯†é’¥"
        
        prompt = f"""è¯·åˆ†æä»¥ä¸‹å®¢å•ä»·å˜åŒ–æ•°æ®:

{json.dumps(price_data, ensure_ascii=False, indent=2)}

è¯·æä¾›:
1. å®¢å•ä»·å˜åŒ–è¶‹åŠ¿
2. ä¸»è¦å½±å“å› ç´ 
3. ä¸åŒåœºæ™¯è¡¨ç°
4. æå‡å»ºè®®

é™åˆ¶åœ¨250å­—ä»¥å†…ã€‚"""
        
        return self._safe_generate(prompt)
    
    def chat(self, user_message: str, include_context: bool = True) -> str:
        """
        æ™ºèƒ½å¯¹è¯
        
        Args:
            user_message: ç”¨æˆ·æ¶ˆæ¯
            include_context: æ˜¯å¦åŒ…å«æ•°æ®ä¸Šä¸‹æ–‡
            
        Returns:
            AIå›å¤
        """
        if not self.is_ready():
            return "âš ï¸ AIåŠ©æ‰‹æœªå°±ç»ª,è¯·é…ç½®APIå¯†é’¥"
        
        # æ„å»ºå®Œæ•´æç¤ºè¯
        full_prompt = self.system_prompt + "\n\n"
        
        if include_context and self.context_data:
            full_prompt += "å½“å‰æ•°æ®ä¸Šä¸‹æ–‡:\n"
            for ctx_type, ctx_data in self.context_data.items():
                # ç®€åŒ–æ•°æ®é¿å…è¿‡é•¿
                ctx_str = str(ctx_data)[:500] if not isinstance(ctx_data, dict) else json.dumps(ctx_data, ensure_ascii=False)[:500]
                full_prompt += f"\n{ctx_type}: {ctx_str}\n"
        
        # æ·»åŠ ç®€æ´å›å¤æŒ‡ä»¤
        full_prompt += f"\n\nç”¨æˆ·é—®é¢˜: {user_message}\n\nè¯·ç®€æ´å›ç­”(200å­—ä»¥å†…),çªå‡ºé‡ç‚¹:"
        
        # ä½¿ç”¨å®‰å…¨ç”Ÿæˆ
        reply_text = self._safe_generate(full_prompt)
        
        # å¦‚æœä¸æ˜¯é”™è¯¯æ¶ˆæ¯,è®°å½•å¯¹è¯å†å²
        if not reply_text.startswith('âŒ') and not reply_text.startswith('âš ï¸'):
            self.chat_history.append({
                'timestamp': datetime.now().isoformat(),
                'user': user_message,
                'assistant': reply_text
            })
        
        return reply_text
    
    def generate_report(self, report_type: str = 'comprehensive') -> str:
        """
        ç”Ÿæˆåˆ†ææŠ¥å‘Š
        
        Args:
            report_type: æŠ¥å‘Šç±»å‹ (comprehensive/weekly/daily)
            
        Returns:
            æŠ¥å‘Šå†…å®¹
        """
        if not self.is_ready():
            return "âš ï¸ AIåŠ©æ‰‹æœªå°±ç»ª,è¯·é…ç½®APIå¯†é’¥"
        
        context_summary = "\n".join([
            f"{k}: {str(v)[:300]}..." 
            for k, v in self.context_data.items()
        ])
        
        prompt = f"""åŸºäºä»¥ä¸‹æ•°æ®,ç”Ÿæˆä¸€ä»½{report_type}åˆ†ææŠ¥å‘Š:

{context_summary}

æŠ¥å‘Šåº”åŒ…å«:
1. ğŸ“Š æ•´ä½“æ¦‚å†µ
2. â­ äº®ç‚¹å‘ç°
3. âš ï¸ é£é™©é¢„è­¦
4. ğŸ’¡ ä¼˜åŒ–å»ºè®®
5. ğŸ“ˆ è¶‹åŠ¿é¢„æµ‹

è¯·ç”¨markdownæ ¼å¼,é™åˆ¶åœ¨500å­—ä»¥å†…ã€‚"""
        
        return self._safe_generate(prompt)
    
    def get_quick_insights(self, data_type: str) -> List[str]:
        """
        è·å–å¿«é€Ÿæ´å¯Ÿ(é¢„è®¾é—®é¢˜æ¨¡æ¿)
        
        Args:
            data_type: æ•°æ®ç±»å‹
            
        Returns:
            é—®é¢˜åˆ—è¡¨
        """
        templates = {
            'quadrant': [
                "ä¸ºä»€ä¹ˆæ˜æ˜Ÿå•†å“æ•°é‡åœ¨ä¸‹é™?",
                "å“ªäº›é‡‘ç‰›å•†å“æœ‰æ½œåŠ›è½¬ä¸ºæ˜æ˜Ÿ?",
                "æ·˜æ±°å•†å“åº”è¯¥å¦‚ä½•å¤„ç†?",
                "å½“å‰å•†å“ç»“æ„å¥åº·å—?",
            ],
            'sales': [
                "é”€é‡ä¸‹é™çš„ä¸»è¦åŸå› æ˜¯ä»€ä¹ˆ?",
                "å“ªä¸ªæ—¶æ®µé”€å”®æœ€å¥½?",
                "å¦‚ä½•æå‡é”€é‡?",
                "æœ‰å“ªäº›é”€å”®å¼‚å¸¸?",
            ],
            'inventory': [
                "å“ªäº›å•†å“éœ€è¦ç´§æ€¥è¡¥è´§?",
                "åº“å­˜å‘¨è½¬ç‡å¦‚ä½•?",
                "å¦‚ä½•ä¼˜åŒ–åº“å­˜?",
                "æœ‰æ»é”€é£é™©å—?",
            ],
            'price': [
                "å®¢å•ä»·ä¸ºä»€ä¹ˆä¸‹é™?",
                "å¦‚ä½•æå‡å®¢å•ä»·?",
                "å®šä»·ç­–ç•¥åˆç†å—?",
                "ä¿ƒé”€æ•ˆæœå¦‚ä½•?",
            ]
        }
        
        return templates.get(data_type, [
            "è¯·åˆ†æå½“å‰æ•°æ®",
            "æœ‰ä»€ä¹ˆä¼˜åŒ–å»ºè®®?",
            "å‘ç°å“ªäº›é—®é¢˜?",
        ])
    
    def clear_history(self):
        """æ¸…ç©ºå¯¹è¯å†å²"""
        self.chat_history = []
    
    def export_chat_history(self) -> str:
        """å¯¼å‡ºå¯¹è¯å†å²ä¸ºJSON"""
        return json.dumps(self.chat_history, ensure_ascii=False, indent=2)


# åˆ›å»ºå…¨å±€AIåŠ©æ‰‹å®ä¾‹
_ai_assistant = None

def get_ai_assistant(api_key: Optional[str] = None) -> GeminiAIAssistant:
    """è·å–AIåŠ©æ‰‹å•ä¾‹"""
    global _ai_assistant
    if _ai_assistant is None or api_key:
        _ai_assistant = GeminiAIAssistant(api_key)
    return _ai_assistant


if __name__ == '__main__':
    # æµ‹è¯•ä»£ç 
    print("ğŸ§ª æµ‹è¯• Gemini AI åŠ©æ‰‹...")
    
    # ä»ç¯å¢ƒå˜é‡è¯»å–APIå¯†é’¥è¿›è¡Œæµ‹è¯•
    assistant = get_ai_assistant()
    
    if assistant.is_ready():
        print("âœ… AIåŠ©æ‰‹å°±ç»ª")
        
        # æµ‹è¯•å¯¹è¯
        response = assistant.chat("ä½ å¥½,è¯·ä»‹ç»ä¸€ä¸‹ä½ çš„åŠŸèƒ½")
        print(f"\nğŸ¤– AIå›å¤:\n{response}")
    else:
        print("âš ï¸ è¯·è®¾ç½®ç¯å¢ƒå˜é‡ GEMINI_API_KEY æˆ–åœ¨ä»£ç ä¸­æä¾›APIå¯†é’¥")
